arguments: BackEnd/app/align_dataset_mtcnn.py BackEnd/app/Dataset/raw BackEnd/app/Dataset/processed --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25
--------------------
tensorflow version: 2.15.0
--------------------
git hash: b'59d9ff6f635da71f4d4844124e571e4287de3491'
--------------------
b'diff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/000_front.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/000_front.png\ndeleted file mode 100644\nindex 0e96db2..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/000_front.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/001_left.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/001_left.png\ndeleted file mode 100644\nindex 9827c5f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/001_left.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/002_right.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/002_right.png\ndeleted file mode 100644\nindex 0e50e1c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/002_right.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/003_up.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/003_up.png\ndeleted file mode 100644\nindex 2d70a27..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/003_up.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/004_down.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/004_down.png\ndeleted file mode 100644\nindex dc9d2cf..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/004_down.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/005_front.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/005_front.png\ndeleted file mode 100644\nindex 954ceea..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/005_front.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/006_left.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/006_left.png\ndeleted file mode 100644\nindex fb98201..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/006_left.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/007_right.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/007_right.png\ndeleted file mode 100644\nindex 2c1907f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/007_right.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/008_up.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/008_up.png\ndeleted file mode 100644\nindex 4ceec43..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/008_up.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/009_down.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/009_down.png\ndeleted file mode 100644\nindex bd6b8ab..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/009_down.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/010_front.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/010_front.png\ndeleted file mode 100644\nindex 7e0b69d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/010_front.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/011_left.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/011_left.png\ndeleted file mode 100644\nindex 6f2cf6a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/011_left.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/012_right.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/012_right.png\ndeleted file mode 100644\nindex fad32ef..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/012_right.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/013_up.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/013_up.png\ndeleted file mode 100644\nindex 2818353..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/013_up.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/014_down.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/014_down.png\ndeleted file mode 100644\nindex 8a7035f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/014_down.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/015_front.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/015_front.png\ndeleted file mode 100644\nindex 216c1dd..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/015_front.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/016_left.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/016_left.png\ndeleted file mode 100644\nindex e95717e..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/016_left.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/017_right.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/017_right.png\ndeleted file mode 100644\nindex f709a8a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/017_right.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/018_up.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/018_up.png\ndeleted file mode 100644\nindex 749e18f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/018_up.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/019_down.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/019_down.png\ndeleted file mode 100644\nindex 90917ba..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/019_down.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/020_front.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/020_front.png\ndeleted file mode 100644\nindex ed1ad87..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/020_front.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/021_left.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/021_left.png\ndeleted file mode 100644\nindex 53a8bb3..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/021_left.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/022_right.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/022_right.png\ndeleted file mode 100644\nindex 781ec03..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/022_right.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/023_up.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/023_up.png\ndeleted file mode 100644\nindex 9cd7546..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/023_up.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/024_down.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/024_down.png\ndeleted file mode 100644\nindex 522ceb8..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/024_down.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/025_front.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/025_front.png\ndeleted file mode 100644\nindex bb2bf6d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/025_front.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/026_left.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/026_left.png\ndeleted file mode 100644\nindex aaf65e6..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/026_left.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/027_right.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/027_right.png\ndeleted file mode 100644\nindex b9478b2..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/027_right.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/028_up.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/028_up.png\ndeleted file mode 100644\nindex 0b62d33..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/028_up.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/029_down.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/029_down.png\ndeleted file mode 100644\nindex b4506be..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/029_down.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/030_front.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/030_front.png\ndeleted file mode 100644\nindex 2354dba..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/030_front.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/031_left.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/031_left.png\ndeleted file mode 100644\nindex 551f32e..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/031_left.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/032_right.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/032_right.png\ndeleted file mode 100644\nindex 164c7e3..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/032_right.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/033_up.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/033_up.png\ndeleted file mode 100644\nindex d29cab9..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/033_up.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/034_down.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/034_down.png\ndeleted file mode 100644\nindex 06e985c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/034_down.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/035_front.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/035_front.png\ndeleted file mode 100644\nindex d782ba6..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/035_front.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/036_left.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/036_left.png\ndeleted file mode 100644\nindex a3de8a1..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/036_left.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/037_right.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/037_right.png\ndeleted file mode 100644\nindex 61ee1a7..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/037_right.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/038_up.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/038_up.png\ndeleted file mode 100644\nindex ce7905b..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/038_up.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/039_down.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/039_down.png\ndeleted file mode 100644\nindex d52b17c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/039_down.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/040_front.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/040_front.png\ndeleted file mode 100644\nindex 02a5e74..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/040_front.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/041_left.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/041_left.png\ndeleted file mode 100644\nindex f6b6ccf..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/041_left.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/042_right.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/042_right.png\ndeleted file mode 100644\nindex 722d919..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/042_right.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/043_up.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/043_up.png\ndeleted file mode 100644\nindex 8f91592..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/043_up.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/044_down.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/044_down.png\ndeleted file mode 100644\nindex 5d4db8c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/044_down.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/045_front.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/045_front.png\ndeleted file mode 100644\nindex 08b51c2..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/045_front.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/046_left.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/046_left.png\ndeleted file mode 100644\nindex 9908c3a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/046_left.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/047_right.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/047_right.png\ndeleted file mode 100644\nindex fa00205..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/047_right.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/048_up.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/048_up.png\ndeleted file mode 100644\nindex 0c04f06..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/048_up.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/049_down.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/049_down.png\ndeleted file mode 100644\nindex eaa02a7..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/049_down.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/050_front.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/050_front.png\ndeleted file mode 100644\nindex 1c34e8d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/050_front.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/051_left.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/051_left.png\ndeleted file mode 100644\nindex 2e0fc4a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/051_left.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/052_right.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/052_right.png\ndeleted file mode 100644\nindex 68bb9a5..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/052_right.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/053_up.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/053_up.png\ndeleted file mode 100644\nindex f7db214..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/053_up.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/054_down.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/054_down.png\ndeleted file mode 100644\nindex 8d29bf2..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/054_down.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/055_front.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/055_front.png\ndeleted file mode 100644\nindex da73a84..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/055_front.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/056_left.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/056_left.png\ndeleted file mode 100644\nindex 9dfa206..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/056_left.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/057_right.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/057_right.png\ndeleted file mode 100644\nindex 3d712b1..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/057_right.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/058_up.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/058_up.png\ndeleted file mode 100644\nindex 83127b3..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/058_up.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/059_down.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/059_down.png\ndeleted file mode 100644\nindex f73318d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/059_down.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/060_front.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/060_front.png\ndeleted file mode 100644\nindex 2cbfa67..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/060_front.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/061_left.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/061_left.png\ndeleted file mode 100644\nindex b5689ca..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/061_left.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/062_right.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/062_right.png\ndeleted file mode 100644\nindex d7eb34c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/062_right.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/064_down.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/064_down.png\ndeleted file mode 100644\nindex 064db0b..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/064_down.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/065_front.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/065_front.png\ndeleted file mode 100644\nindex b2777bb..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/065_front.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/066_left.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/066_left.png\ndeleted file mode 100644\nindex 80110ea..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/066_left.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/067_right.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/067_right.png\ndeleted file mode 100644\nindex 8b9c0b3..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/067_right.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/068_up.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/068_up.png\ndeleted file mode 100644\nindex 48e89ee..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/068_up.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/069_down.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/069_down.png\ndeleted file mode 100644\nindex 71ff98c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/069_down.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/070_front.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/070_front.png\ndeleted file mode 100644\nindex 061f4f6..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/070_front.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/071_left.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/071_left.png\ndeleted file mode 100644\nindex 81e14ee..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/071_left.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/072_right.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/072_right.png\ndeleted file mode 100644\nindex 648ae64..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/072_right.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/073_up.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/073_up.png\ndeleted file mode 100644\nindex d7ba360..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/073_up.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/074_down.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/074_down.png\ndeleted file mode 100644\nindex 893a29c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/074_down.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/075_front.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/075_front.png\ndeleted file mode 100644\nindex 724b3a0..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/075_front.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/076_left.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/076_left.png\ndeleted file mode 100644\nindex b1a290b..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/076_left.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/077_right.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/077_right.png\ndeleted file mode 100644\nindex 885e2f8..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/077_right.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/078_up.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/078_up.png\ndeleted file mode 100644\nindex 8c68737..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/078_up.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/079_down.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/079_down.png\ndeleted file mode 100644\nindex 76f2743..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/079_down.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/080_front.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/080_front.png\ndeleted file mode 100644\nindex 603355d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/080_front.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/081_left.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/081_left.png\ndeleted file mode 100644\nindex c42e96a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/081_left.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/082_right.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/082_right.png\ndeleted file mode 100644\nindex 400861a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/082_right.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/083_up.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/083_up.png\ndeleted file mode 100644\nindex ca196ec..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/083_up.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/084_down.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/084_down.png\ndeleted file mode 100644\nindex 67509fe..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/084_down.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/085_front.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/085_front.png\ndeleted file mode 100644\nindex f62f9a3..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/085_front.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/086_left.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/086_left.png\ndeleted file mode 100644\nindex 30a1f31..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/086_left.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/087_right.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/087_right.png\ndeleted file mode 100644\nindex 68e4731..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/087_right.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/088_up.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/088_up.png\ndeleted file mode 100644\nindex b9be5e0..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/088_up.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/089_down.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/089_down.png\ndeleted file mode 100644\nindex d45cadb..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/089_down.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/090_front.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/090_front.png\ndeleted file mode 100644\nindex 740aaef..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/090_front.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/091_left.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/091_left.png\ndeleted file mode 100644\nindex d77b6eb..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/091_left.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/092_right.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/092_right.png\ndeleted file mode 100644\nindex dab237c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/092_right.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/093_up.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/093_up.png\ndeleted file mode 100644\nindex 9bf8ff6..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/093_up.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/094_down.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/094_down.png\ndeleted file mode 100644\nindex a9d5348..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/094_down.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/095_front.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/095_front.png\ndeleted file mode 100644\nindex a5bdf3b..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/095_front.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/096_left.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/096_left.png\ndeleted file mode 100644\nindex ba962eb..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/096_left.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/097_right.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/097_right.png\ndeleted file mode 100644\nindex 5e7632d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/097_right.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/098_up.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/098_up.png\ndeleted file mode 100644\nindex fd7dfe9..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/098_up.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/099_down.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/099_down.png\ndeleted file mode 100644\nindex dcd8d4d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106005/099_down.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_0.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_0.png\ndeleted file mode 100644\nindex ff5e566..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_0.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_1.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_1.png\ndeleted file mode 100644\nindex 7d9aa0c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_1.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_10.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_10.png\ndeleted file mode 100644\nindex 21cbc40..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_10.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_100.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_100.png\ndeleted file mode 100644\nindex 5569f93..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_100.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_11.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_11.png\ndeleted file mode 100644\nindex a224cc6..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_11.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_12.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_12.png\ndeleted file mode 100644\nindex 256a2d4..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_12.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_13.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_13.png\ndeleted file mode 100644\nindex c0777ba..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_13.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_14.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_14.png\ndeleted file mode 100644\nindex a938816..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_14.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_15.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_15.png\ndeleted file mode 100644\nindex d0c3f63..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_15.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_16.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_16.png\ndeleted file mode 100644\nindex c877403..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_16.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_17.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_17.png\ndeleted file mode 100644\nindex fe309c6..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_17.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_18.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_18.png\ndeleted file mode 100644\nindex e673f8f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_18.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_19.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_19.png\ndeleted file mode 100644\nindex 750af7a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_19.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_2.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_2.png\ndeleted file mode 100644\nindex be1335a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_2.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_20.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_20.png\ndeleted file mode 100644\nindex 0a5d577..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_20.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_21.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_21.png\ndeleted file mode 100644\nindex e4162a0..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_21.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_22.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_22.png\ndeleted file mode 100644\nindex 128d785..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_22.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_23.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_23.png\ndeleted file mode 100644\nindex 8994faf..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_23.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_24.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_24.png\ndeleted file mode 100644\nindex 7df0624..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_24.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_25.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_25.png\ndeleted file mode 100644\nindex 702be56..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_25.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_26.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_26.png\ndeleted file mode 100644\nindex 9c74d6e..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_26.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_27.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_27.png\ndeleted file mode 100644\nindex 8a9c97c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_27.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_28.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_28.png\ndeleted file mode 100644\nindex 89558cf..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_28.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_29.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_29.png\ndeleted file mode 100644\nindex 2d02bbe..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_29.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_3.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_3.png\ndeleted file mode 100644\nindex 89f826d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_3.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_30.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_30.png\ndeleted file mode 100644\nindex 35a4e5d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_30.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_31.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_31.png\ndeleted file mode 100644\nindex e5db252..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_31.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_32.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_32.png\ndeleted file mode 100644\nindex 5fe6bfc..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_32.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_33.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_33.png\ndeleted file mode 100644\nindex 11642b2..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_33.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_34.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_34.png\ndeleted file mode 100644\nindex 39b6b3d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_34.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_35.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_35.png\ndeleted file mode 100644\nindex e9a51ee..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_35.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_36.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_36.png\ndeleted file mode 100644\nindex 152129a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_36.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_37.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_37.png\ndeleted file mode 100644\nindex 2950d7f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_37.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_38.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_38.png\ndeleted file mode 100644\nindex b468f20..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_38.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_39.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_39.png\ndeleted file mode 100644\nindex ff0af63..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_39.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_4.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_4.png\ndeleted file mode 100644\nindex 7ce783f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_4.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_40.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_40.png\ndeleted file mode 100644\nindex bd2dddd..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_40.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_41.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_41.png\ndeleted file mode 100644\nindex 7768bf1..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_41.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_42.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_42.png\ndeleted file mode 100644\nindex 202d93b..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_42.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_43.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_43.png\ndeleted file mode 100644\nindex b585ce0..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_43.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_44.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_44.png\ndeleted file mode 100644\nindex 64a7041..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_44.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_45.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_45.png\ndeleted file mode 100644\nindex 3ec44fb..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_45.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_46.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_46.png\ndeleted file mode 100644\nindex 5f3e588..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_46.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_47.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_47.png\ndeleted file mode 100644\nindex f86e5cf..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_47.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_48.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_48.png\ndeleted file mode 100644\nindex 9b23430..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_48.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_49.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_49.png\ndeleted file mode 100644\nindex 0f9cd1a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_49.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_5.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_5.png\ndeleted file mode 100644\nindex e03ccff..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_5.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_50.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_50.png\ndeleted file mode 100644\nindex 4a683ff..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_50.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_51.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_51.png\ndeleted file mode 100644\nindex 3227c26..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_51.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_52.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_52.png\ndeleted file mode 100644\nindex eed1610..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_52.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_53.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_53.png\ndeleted file mode 100644\nindex 10bcdd0..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_53.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_54.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_54.png\ndeleted file mode 100644\nindex 6c61c91..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_54.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_55.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_55.png\ndeleted file mode 100644\nindex 0a168ff..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_55.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_56.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_56.png\ndeleted file mode 100644\nindex 16c6ebe..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_56.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_57.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_57.png\ndeleted file mode 100644\nindex 01dc594..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_57.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_58.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_58.png\ndeleted file mode 100644\nindex aa67372..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_58.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_59.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_59.png\ndeleted file mode 100644\nindex eaa4245..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_59.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_6.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_6.png\ndeleted file mode 100644\nindex 1b8ee10..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_6.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_60.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_60.png\ndeleted file mode 100644\nindex aaec32d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_60.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_61.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_61.png\ndeleted file mode 100644\nindex eb4f997..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_61.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_62.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_62.png\ndeleted file mode 100644\nindex 3d361eb..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_62.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_63.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_63.png\ndeleted file mode 100644\nindex 81d5091..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_63.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_64.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_64.png\ndeleted file mode 100644\nindex 5557814..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_64.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_65.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_65.png\ndeleted file mode 100644\nindex bf7d4fd..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_65.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_66.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_66.png\ndeleted file mode 100644\nindex 8fc2dc2..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_66.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_67.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_67.png\ndeleted file mode 100644\nindex 3804c8d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_67.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_68.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_68.png\ndeleted file mode 100644\nindex 00ad66d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_68.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_69.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_69.png\ndeleted file mode 100644\nindex 62c79d5..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_69.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_7.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_7.png\ndeleted file mode 100644\nindex 155cf23..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_7.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_70.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_70.png\ndeleted file mode 100644\nindex 2841b2c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_70.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_71.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_71.png\ndeleted file mode 100644\nindex ab5cb2b..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_71.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_72.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_72.png\ndeleted file mode 100644\nindex 135d991..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_72.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_73.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_73.png\ndeleted file mode 100644\nindex 9313e68..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_73.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_74.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_74.png\ndeleted file mode 100644\nindex 60f40e4..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_74.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_75.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_75.png\ndeleted file mode 100644\nindex 8b5725d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_75.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_76.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_76.png\ndeleted file mode 100644\nindex 9eac197..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_76.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_77.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_77.png\ndeleted file mode 100644\nindex fe43b95..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_77.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_78.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_78.png\ndeleted file mode 100644\nindex f06b224..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_78.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_79.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_79.png\ndeleted file mode 100644\nindex cf2a440..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_79.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_8.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_8.png\ndeleted file mode 100644\nindex 335a504..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_8.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_80.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_80.png\ndeleted file mode 100644\nindex 11639f9..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_80.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_81.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_81.png\ndeleted file mode 100644\nindex 35b244c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_81.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_82.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_82.png\ndeleted file mode 100644\nindex 92318d7..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_82.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_83.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_83.png\ndeleted file mode 100644\nindex 562acd3..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_83.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_84.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_84.png\ndeleted file mode 100644\nindex e7be5e8..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_84.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_85.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_85.png\ndeleted file mode 100644\nindex cfd0783..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_85.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_86.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_86.png\ndeleted file mode 100644\nindex a91b93a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_86.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_87.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_87.png\ndeleted file mode 100644\nindex a2b4400..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_87.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_88.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_88.png\ndeleted file mode 100644\nindex 7329f01..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_88.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_89.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_89.png\ndeleted file mode 100644\nindex d293576..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_89.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_9.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_9.png\ndeleted file mode 100644\nindex 6791633..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_9.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_90.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_90.png\ndeleted file mode 100644\nindex 78bd815..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_90.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_91.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_91.png\ndeleted file mode 100644\nindex 3e14b02..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_91.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_92.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_92.png\ndeleted file mode 100644\nindex eebad8b..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_92.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_93.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_93.png\ndeleted file mode 100644\nindex f7dff5e..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_93.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_94.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_94.png\ndeleted file mode 100644\nindex d30b754..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_94.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_95.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_95.png\ndeleted file mode 100644\nindex 1359fb0..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_95.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_96.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_96.png\ndeleted file mode 100644\nindex 02cb984..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_96.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_97.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_97.png\ndeleted file mode 100644\nindex c3cf3ce..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_97.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_98.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_98.png\ndeleted file mode 100644\nindex 34965b9..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_98.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_99.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_99.png\ndeleted file mode 100644\nindex 1a23973..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106034/b_duyframe_99.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_0.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_0.png\ndeleted file mode 100644\nindex 92d23df..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_0.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_1.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_1.png\ndeleted file mode 100644\nindex b1a1dd5..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_1.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_10.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_10.png\ndeleted file mode 100644\nindex 0b5084b..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_10.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_11.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_11.png\ndeleted file mode 100644\nindex 220fccd..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_11.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_12.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_12.png\ndeleted file mode 100644\nindex 1536611..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_12.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_13.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_13.png\ndeleted file mode 100644\nindex e0c00fa..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_13.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_14.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_14.png\ndeleted file mode 100644\nindex 4007435..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_14.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_15.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_15.png\ndeleted file mode 100644\nindex 7ff1b0b..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_15.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_16.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_16.png\ndeleted file mode 100644\nindex 23b0928..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_16.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_17.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_17.png\ndeleted file mode 100644\nindex 7beea57..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_17.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_18.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_18.png\ndeleted file mode 100644\nindex 9be2da4..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_18.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_19.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_19.png\ndeleted file mode 100644\nindex 3cf1305..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_19.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_2.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_2.png\ndeleted file mode 100644\nindex d5c3b18..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_2.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_20.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_20.png\ndeleted file mode 100644\nindex 3e3e2e3..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_20.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_21.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_21.png\ndeleted file mode 100644\nindex dc241a3..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_21.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_22.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_22.png\ndeleted file mode 100644\nindex 2fc0690..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_22.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_23.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_23.png\ndeleted file mode 100644\nindex 38e6536..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_23.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_24.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_24.png\ndeleted file mode 100644\nindex f33b121..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_24.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_25.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_25.png\ndeleted file mode 100644\nindex 9dc71ad..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_25.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_26.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_26.png\ndeleted file mode 100644\nindex ed2bfbc..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_26.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_27.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_27.png\ndeleted file mode 100644\nindex 8e31d8e..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_27.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_28.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_28.png\ndeleted file mode 100644\nindex 2685fc9..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_28.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_29.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_29.png\ndeleted file mode 100644\nindex 409fe6f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_29.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_3.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_3.png\ndeleted file mode 100644\nindex b01d80c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_3.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_30.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_30.png\ndeleted file mode 100644\nindex 90b9fd7..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_30.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_31.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_31.png\ndeleted file mode 100644\nindex fb89295..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_31.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_32.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_32.png\ndeleted file mode 100644\nindex 796bbdb..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_32.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_33.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_33.png\ndeleted file mode 100644\nindex efd60e5..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_33.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_34.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_34.png\ndeleted file mode 100644\nindex bb03f07..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_34.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_35.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_35.png\ndeleted file mode 100644\nindex 2d466bc..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_35.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_36.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_36.png\ndeleted file mode 100644\nindex 7e6052b..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_36.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_37.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_37.png\ndeleted file mode 100644\nindex 5da8f9c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_37.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_38.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_38.png\ndeleted file mode 100644\nindex b232a2a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_38.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_39.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_39.png\ndeleted file mode 100644\nindex 6130f8b..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_39.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_4.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_4.png\ndeleted file mode 100644\nindex 75e4d54..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_4.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_40.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_40.png\ndeleted file mode 100644\nindex e83f0b3..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_40.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_41.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_41.png\ndeleted file mode 100644\nindex 6ff55bf..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_41.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_42.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_42.png\ndeleted file mode 100644\nindex a4ff8bb..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_42.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_43.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_43.png\ndeleted file mode 100644\nindex 3a1f060..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_43.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_44.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_44.png\ndeleted file mode 100644\nindex ee601dc..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_44.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_45.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_45.png\ndeleted file mode 100644\nindex 68a20f1..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_45.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_46.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_46.png\ndeleted file mode 100644\nindex 9bdb4a4..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_46.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_47.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_47.png\ndeleted file mode 100644\nindex f19b8c6..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_47.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_48.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_48.png\ndeleted file mode 100644\nindex 1542405..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_48.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_49.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_49.png\ndeleted file mode 100644\nindex 33fb39c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_49.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_5.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_5.png\ndeleted file mode 100644\nindex c191e5c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_5.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_50.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_50.png\ndeleted file mode 100644\nindex 609d073..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_50.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_51.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_51.png\ndeleted file mode 100644\nindex 9c7c17a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_51.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_52.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_52.png\ndeleted file mode 100644\nindex 701ea3a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_52.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_53.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_53.png\ndeleted file mode 100644\nindex b0bfab6..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_53.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_54.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_54.png\ndeleted file mode 100644\nindex e609ab2..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_54.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_55.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_55.png\ndeleted file mode 100644\nindex 2b47365..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_55.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_56.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_56.png\ndeleted file mode 100644\nindex 01a8ca5..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_56.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_57.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_57.png\ndeleted file mode 100644\nindex 0187c14..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_57.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_58.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_58.png\ndeleted file mode 100644\nindex 5ff80ad..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_58.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_59.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_59.png\ndeleted file mode 100644\nindex b406db0..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_59.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_6.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_6.png\ndeleted file mode 100644\nindex 3610ae7..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_6.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_60.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_60.png\ndeleted file mode 100644\nindex 8088690..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_60.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_61.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_61.png\ndeleted file mode 100644\nindex e567c92..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_61.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_62.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_62.png\ndeleted file mode 100644\nindex fba4f51..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_62.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_63.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_63.png\ndeleted file mode 100644\nindex a2e946f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_63.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_64.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_64.png\ndeleted file mode 100644\nindex a935ed9..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_64.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_65.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_65.png\ndeleted file mode 100644\nindex bac9121..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_65.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_66.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_66.png\ndeleted file mode 100644\nindex e70ba62..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_66.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_67.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_67.png\ndeleted file mode 100644\nindex ddb3c2d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_67.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_68.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_68.png\ndeleted file mode 100644\nindex 915c5fc..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_68.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_69.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_69.png\ndeleted file mode 100644\nindex 9eeb21d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_69.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_7.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_7.png\ndeleted file mode 100644\nindex 09e2e46..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_7.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_70.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_70.png\ndeleted file mode 100644\nindex a221f45..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_70.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_71.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_71.png\ndeleted file mode 100644\nindex 3ff0b75..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_71.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_72.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_72.png\ndeleted file mode 100644\nindex 7ee26e3..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_72.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_73.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_73.png\ndeleted file mode 100644\nindex c99ad2e..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_73.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_74.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_74.png\ndeleted file mode 100644\nindex 07cb696..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_74.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_75.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_75.png\ndeleted file mode 100644\nindex fcb6153..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_75.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_76.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_76.png\ndeleted file mode 100644\nindex a6d4f40..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_76.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_77.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_77.png\ndeleted file mode 100644\nindex 0ea9d94..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_77.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_78.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_78.png\ndeleted file mode 100644\nindex b57ceeb..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_78.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_79.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_79.png\ndeleted file mode 100644\nindex 742f5ff..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_79.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_8.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_8.png\ndeleted file mode 100644\nindex b9f4e49..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_8.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_80.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_80.png\ndeleted file mode 100644\nindex 1962881..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_80.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_81.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_81.png\ndeleted file mode 100644\nindex 6baf5c6..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_81.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_82.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_82.png\ndeleted file mode 100644\nindex a165569..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_82.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_83.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_83.png\ndeleted file mode 100644\nindex b34c491..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_83.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_84.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_84.png\ndeleted file mode 100644\nindex 7047d87..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_84.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_85.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_85.png\ndeleted file mode 100644\nindex bb8b85a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_85.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_86.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_86.png\ndeleted file mode 100644\nindex df9ce1b..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_86.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_87.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_87.png\ndeleted file mode 100644\nindex 524bf21..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_87.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_88.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_88.png\ndeleted file mode 100644\nindex 08c1ab3..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_88.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_89.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_89.png\ndeleted file mode 100644\nindex 98e8916..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_89.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_9.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_9.png\ndeleted file mode 100644\nindex e7e97ad..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_9.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_90.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_90.png\ndeleted file mode 100644\nindex 4575fba..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_90.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_91.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_91.png\ndeleted file mode 100644\nindex 3c65466..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_91.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_92.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_92.png\ndeleted file mode 100644\nindex 5604d6d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_92.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_93.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_93.png\ndeleted file mode 100644\nindex e175e70..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_93.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_94.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_94.png\ndeleted file mode 100644\nindex 2525c34..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_94.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_95.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_95.png\ndeleted file mode 100644\nindex 5274233..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_95.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_96.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_96.png\ndeleted file mode 100644\nindex 1f12bd0..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_96.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_97.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_97.png\ndeleted file mode 100644\nindex 04d62ce..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_97.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_98.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_98.png\ndeleted file mode 100644\nindex 90cc9a6..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_98.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_99.png b/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_99.png\ndeleted file mode 100644\nindex 92f6087..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/processed/K205480106035/frame_99.png and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/bounding_boxes_44910.txt b/BackEnd/Face_AI/Dataset/FaceData/processed/bounding_boxes_44910.txt\ndeleted file mode 100644\nindex 14d43f5..0000000\n--- a/BackEnd/Face_AI/Dataset/FaceData/processed/bounding_boxes_44910.txt\n+++ /dev/null\n@@ -1,101 +0,0 @@\n-Dataset/FaceData/processed\\K205480106035\\frame_12.png 135 288 566 817\n-Dataset/FaceData/processed\\K205480106035\\frame_61.png 47 316 473 924\n-Dataset/FaceData/processed\\K205480106035\\frame_78.png 168 329 613 893\n-Dataset/FaceData/processed\\K205480106035\\frame_77.png 172 319 613 901\n-Dataset/FaceData/processed\\K205480106035\\frame_20.png 145 276 559 776\n-Dataset/FaceData/processed\\K205480106035\\frame_82.png 216 337 639 890\n-Dataset/FaceData/processed\\K205480106035\\frame_65.png 74 315 528 933\n-Dataset/FaceData/processed\\K205480106035\\frame_7.png 131 296 576 853\n-Dataset/FaceData/processed\\K205480106035\\frame_41.png 69 280 470 857\n-Dataset/FaceData/processed\\K205480106035\\frame_89.png 253 349 683 921\n-Dataset/FaceData/processed\\K205480106035\\frame_57.png 42 336 464 932\n-Dataset/FaceData/processed\\K205480106035\\frame_64.png 48 309 509 934\n-Dataset/FaceData/processed\\K205480106035\\frame_72.png 102 318 569 910\n-Dataset/FaceData/processed\\K205480106035\\frame_2.png 126 306 581 896\n-Dataset/FaceData/processed\\K205480106035\\frame_1.png 127 314 586 918\n-Dataset/FaceData/processed\\K205480106035\\frame_66.png 66 324 521 928\n-Dataset/FaceData/processed\\K205480106035\\frame_91.png 262 343 688 915\n-Dataset/FaceData/processed\\K205480106035\\frame_73.png 112 320 577 919\n-Dataset/FaceData/processed\\K205480106035\\frame_40.png 79 281 479 857\n-Dataset/FaceData/processed\\K205480106035\\frame_31.png 115 293 502 816\n-Dataset/FaceData/processed\\K205480106035\\frame_58.png 41 334 467 933\n-Dataset/FaceData/processed\\K205480106035\\frame_25.png 138 276 546 792\n-Dataset/FaceData/processed\\K205480106035\\frame_45.png 50 306 478 897\n-Dataset/FaceData/processed\\K205480106035\\frame_98.png 254 344 713 944\n-Dataset/FaceData/processed\\K205480106035\\frame_62.png 57 308 484 943\n-Dataset/FaceData/processed\\K205480106035\\frame_67.png 78 318 532 918\n-Dataset/FaceData/processed\\K205480106035\\frame_8.png 143 291 568 846\n-Dataset/FaceData/processed\\K205480106035\\frame_99.png 253 350 709 943\n-Dataset/FaceData/processed\\K205480106035\\frame_37.png 87 285 477 828\n-Dataset/FaceData/processed\\K205480106035\\frame_95.png 254 359 701 937\n-Dataset/FaceData/processed\\K205480106035\\frame_9.png 133 287 554 847\n-Dataset/FaceData/processed\\K205480106035\\frame_3.png 127 289 575 898\n-Dataset/FaceData/processed\\K205480106035\\frame_10.png 146 284 564 835\n-Dataset/FaceData/processed\\K205480106035\\frame_53.png 40 310 461 932\n-Dataset/FaceData/processed\\K205480106035\\frame_84.png 226 329 642 906\n-Dataset/FaceData/processed\\K205480106035\\frame_70.png 90 311 556 915\n-Dataset/FaceData/processed\\K205480106035\\frame_23.png 143 271 551 793\n-Dataset/FaceData/processed\\K205480106035\\frame_85.png 235 343 658 907\n-Dataset/FaceData/processed\\K205480106035\\frame_97.png 250 344 711 943\n-Dataset/FaceData/processed\\K205480106035\\frame_52.png 41 310 462 929\n-Dataset/FaceData/processed\\K205480106035\\frame_34.png 113 301 484 819\n-Dataset/FaceData/processed\\K205480106035\\frame_48.png 38 323 474 914\n-Dataset/FaceData/processed\\K205480106035\\frame_49.png 41 331 468 918\n-Dataset/FaceData/processed\\K205480106035\\frame_59.png 40 323 472 938\n-Dataset/FaceData/processed\\K205480106035\\frame_5.png 129 295 573 875\n-Dataset/FaceData/processed\\K205480106035\\frame_51.png 38 309 451 922\n-Dataset/FaceData/processed\\K205480106035\\frame_39.png 89 284 479 842\n-Dataset/FaceData/processed\\K205480106035\\frame_24.png 139 279 550 790\n-Dataset/FaceData/processed\\K205480106035\\frame_13.png 141 282 565 810\n-Dataset/FaceData/processed\\K205480106035\\frame_42.png 76 288 464 870\n-Dataset/FaceData/processed\\K205480106035\\frame_21.png 145 280 554 775\n-Dataset/FaceData/processed\\K205480106035\\frame_15.png 146 287 562 794\n-Dataset/FaceData/processed\\K205480106035\\frame_81.png 199 336 626 879\n-Dataset/FaceData/processed\\K205480106035\\frame_93.png 260 362 703 931\n-Dataset/FaceData/processed\\K205480106035\\frame_0.png 137 318 591 906\n-Dataset/FaceData/processed\\K205480106035\\frame_14.png 132 274 548 800\n-Dataset/FaceData/processed\\K205480106035\\frame_87.png 246 350 665 917\n-Dataset/FaceData/processed\\K205480106035\\frame_29.png 128 295 521 817\n-Dataset/FaceData/processed\\K205480106035\\frame_56.png 36 334 456 938\n-Dataset/FaceData/processed\\K205480106035\\frame_32.png 113 304 494 817\n-Dataset/FaceData/processed\\K205480106035\\frame_68.png 94 315 545 923\n-Dataset/FaceData/processed\\K205480106035\\frame_18.png 145 280 573 795\n-Dataset/FaceData/processed\\K205480106035\\frame_79.png 179 327 619 885\n-Dataset/FaceData/processed\\K205480106035\\frame_28.png 127 285 528 801\n-Dataset/FaceData/processed\\K205480106035\\frame_47.png 47 304 461 910\n-Dataset/FaceData/processed\\K205480106035\\frame_63.png 54 329 491 927\n-Dataset/FaceData/processed\\K205480106035\\frame_35.png 106 282 483 822\n-Dataset/FaceData/processed\\K205480106035\\frame_92.png 264 356 702 929\n-Dataset/FaceData/processed\\K205480106035\\frame_80.png 188 329 620 876\n-Dataset/FaceData/processed\\K205480106035\\frame_94.png 255 358 700 934\n-Dataset/FaceData/processed\\K205480106035\\frame_55.png 41 327 458 935\n-Dataset/FaceData/processed\\K205480106035\\frame_11.png 150 289 563 827\n-Dataset/FaceData/processed\\K205480106035\\frame_71.png 100 321 561 914\n-Dataset/FaceData/processed\\K205480106035\\frame_30.png 125 304 508 812\n-Dataset/FaceData/processed\\K205480106035\\frame_96.png 255 350 713 940\n-Dataset/FaceData/processed\\K205480106035\\frame_6.png 125 284 576 877\n-Dataset/FaceData/processed\\K205480106035\\frame_4.png 127 293 585 890\n-Dataset/FaceData/processed\\K205480106035\\frame_17.png 146 284 565 785\n-Dataset/FaceData/processed\\K205480106035\\frame_43.png 68 287 476 887\n-Dataset/FaceData/processed\\K205480106035\\frame_46.png 58 302 470 907\n-Dataset/FaceData/processed\\K205480106035\\frame_54.png 45 318 451 928\n-Dataset/FaceData/processed\\K205480106035\\frame_88.png 247 341 680 918\n-Dataset/FaceData/processed\\K205480106035\\frame_69.png 81 308 551 925\n-Dataset/FaceData/processed\\K205480106035\\frame_75.png 148 315 602 906\n-Dataset/FaceData/processed\\K205480106035\\frame_19.png 144 273 562 780\n-Dataset/FaceData/processed\\K205480106035\\frame_26.png 144 291 541 797\n-Dataset/FaceData/processed\\K205480106035\\frame_36.png 103 287 478 824\n-Dataset/FaceData/processed\\K205480106035\\frame_22.png 140 277 554 784\n-Dataset/FaceData/processed\\K205480106035\\frame_33.png 109 291 484 813\n-Dataset/FaceData/processed\\K205480106035\\frame_74.png 122 318 580 909\n-Dataset/FaceData/processed\\K205480106035\\frame_90.png 263 350 701 919\n-Dataset/FaceData/processed\\K205480106035\\frame_27.png 129 277 538 807\n-Dataset/FaceData/processed\\K205480106035\\frame_38.png 98 277 484 843\n-Dataset/FaceData/processed\\K205480106035\\frame_44.png 54 298 479 889\n-Dataset/FaceData/processed\\K205480106035\\frame_50.png 41 336 459 924\n-Dataset/FaceData/processed\\K205480106035\\frame_16.png 153 293 557 784\n-Dataset/FaceData/processed\\K205480106035\\frame_83.png 213 346 639 917\n-Dataset/FaceData/processed\\K205480106035\\frame_86.png 241 336 664 911\n-Dataset/FaceData/processed\\K205480106035\\frame_76.png 145 322 597 905\n-Dataset/FaceData/processed\\K205480106035\\frame_60.png 39 312 475 941\n-Dataset/FaceData/processed\\K205480106005\\063_up.png\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/bounding_boxes_49745.txt b/BackEnd/Face_AI/Dataset/FaceData/processed/bounding_boxes_49745.txt\ndeleted file mode 100644\nindex 4bd0b29..0000000\n--- a/BackEnd/Face_AI/Dataset/FaceData/processed/bounding_boxes_49745.txt\n+++ /dev/null\n@@ -1,201 +0,0 @@\n-Dataset/FaceData/processed\\K205480106005\\042_right.png 301 149 522 417\n-Dataset/FaceData/processed\\K205480106005\\029_down.png 302 134 520 390\n-Dataset/FaceData/processed\\K205480106005\\048_up.png 308 134 527 407\n-Dataset/FaceData/processed\\K205480106005\\073_up.png 275 141 504 418\n-Dataset/FaceData/processed\\K205480106005\\092_right.png 267 137 489 413\n-Dataset/FaceData/processed\\K205480106005\\034_down.png 287 138 508 397\n-Dataset/FaceData/processed\\K205480106005\\094_down.png 275 148 501 411\n-Dataset/FaceData/processed\\K205480106005\\081_left.png 288 136 510 403\n-Dataset/FaceData/processed\\K205480106005\\099_down.png 286 145 517 430\n-Dataset/FaceData/processed\\K205480106005\\080_front.png 286 135 509 409\n-Dataset/FaceData/processed\\K205480106005\\027_right.png 269 156 510 433\n-Dataset/FaceData/processed\\K205480106005\\065_front.png 282 137 498 394\n-Dataset/FaceData/processed\\K205480106005\\045_front.png 307 138 527 403\n-Dataset/FaceData/processed\\K205480106005\\071_left.png 273 137 508 421\n-Dataset/FaceData/processed\\K205480106005\\047_right.png 310 140 540 417\n-Dataset/FaceData/processed\\K205480106005\\052_right.png 305 131 530 404\n-Dataset/FaceData/processed\\K205480106005\\096_left.png 290 148 509 409\n-Dataset/FaceData/processed\\K205480106005\\041_left.png 301 134 528 410\n-Dataset/FaceData/processed\\K205480106005\\021_left.png 274 139 495 398\n-Dataset/FaceData/processed\\K205480106005\\039_down.png 296 136 523 402\n-Dataset/FaceData/processed\\K205480106005\\091_left.png 286 147 505 411\n-Dataset/FaceData/processed\\K205480106005\\093_up.png 262 143 485 412\n-Dataset/FaceData/processed\\K205480106005\\074_down.png 274 138 513 425\n-Dataset/FaceData/processed\\K205480106005\\054_down.png 313 136 526 392\n-Dataset/FaceData/processed\\K205480106005\\001_left.png 260 135 468 385\n-Dataset/FaceData/processed\\K205480106005\\014_down.png 268 133 493 406\n-Dataset/FaceData/processed\\K205480106005\\068_up.png 304 141 517 396\n-Dataset/FaceData/processed\\K205480106005\\067_right.png 271 138 499 407\n-Dataset/FaceData/processed\\K205480106005\\097_right.png 281 144 513 418\n-Dataset/FaceData/processed\\K205480106005\\020_front.png 273 128 519 414\n-Dataset/FaceData/processed\\K205480106005\\040_front.png 300 136 530 408\n-Dataset/FaceData/processed\\K205480106005\\069_down.png 317 141 527 400\n-Dataset/FaceData/processed\\K205480106005\\032_right.png 272 133 503 405\n-Dataset/FaceData/processed\\K205480106005\\007_right.png 311 126 518 377\n-Dataset/FaceData/processed\\K205480106005\\000_front.png 274 131 488 394\n-Dataset/FaceData/processed\\K205480106005\\046_left.png 311 134 535 405\n-Dataset/FaceData/processed\\K205480106005\\003_up.png 263 138 472 392\n-Dataset/FaceData/processed\\K205480106005\\028_up.png 268 152 511 432\n-Dataset/FaceData/processed\\K205480106005\\037_right.png 280 145 511 431\n-Dataset/FaceData/processed\\K205480106005\\061_left.png 278 135 494 397\n-Dataset/FaceData/processed\\K205480106005\\005_front.png 294 121 510 372\n-Dataset/FaceData/processed\\K205480106005\\075_front.png 275 136 501 407\n-Dataset/FaceData/processed\\K205480106005\\082_right.png 291 134 513 399\n-Dataset/FaceData/processed\\K205480106005\\015_front.png 269 137 478 391\n-Dataset/FaceData/processed\\K205480106005\\070_front.png 260 140 481 402\n-Dataset/FaceData/processed\\K205480106005\\033_up.png 298 136 516 394\n-Dataset/FaceData/processed\\K205480106005\\022_right.png 292 143 493 390\n-Dataset/FaceData/processed\\K205480106005\\006_left.png 316 132 518 376\n-Dataset/FaceData/processed\\K205480106005\\077_right.png 276 137 508 420\n-Dataset/FaceData/processed\\K205480106005\\030_front.png 288 134 519 416\n-Dataset/FaceData/processed\\K205480106005\\066_left.png 279 135 492 397\n-Dataset/FaceData/processed\\K205480106005\\078_up.png 276 132 509 418\n-Dataset/FaceData/processed\\K205480106005\\043_up.png 301 143 526 417\n-Dataset/FaceData/processed\\K205480106005\\012_right.png 272 132 493 408\n-Dataset/FaceData/processed\\K205480106005\\009_down.png 299 128 513 395\n-Dataset/FaceData/processed\\K205480106005\\031_left.png 294 141 514 406\n-Dataset/FaceData/processed\\K205480106005\\083_up.png 294 147 507 396\n-Dataset/FaceData/processed\\K205480106005\\024_down.png 297 145 500 386\n-Dataset/FaceData/processed\\K205480106005\\058_up.png 302 130 512 388\n-Dataset/FaceData/processed\\K205480106005\\051_left.png 264 191 472 433\n-Dataset/FaceData/processed\\K205480106005\\038_up.png 295 133 526 401\n-Dataset/FaceData/processed\\K205480106005\\084_down.png 295 143 512 399\n-Dataset/FaceData/processed\\K205480106005\\072_right.png 277 136 501 411\n-Dataset/FaceData/processed\\K205480106005\\088_up.png 265 135 484 404\n-Dataset/FaceData/processed\\K205480106005\\053_up.png 308 136 532 410\n-Dataset/FaceData/processed\\K205480106005\\010_front.png 302 131 515 392\n-Dataset/FaceData/processed\\K205480106005\\056_left.png 309 136 525 390\n-Dataset/FaceData/processed\\K205480106005\\017_right.png 297 137 516 398\n-Dataset/FaceData/processed\\K205480106005\\035_front.png 284 130 502 390\n-Dataset/FaceData/processed\\K205480106005\\023_up.png 287 131 518 400\n-Dataset/FaceData/processed\\K205480106005\\025_front.png 285 129 504 397\n-Dataset/FaceData/processed\\K205480106005\\011_left.png 278 131 482 382\n-Dataset/FaceData/processed\\K205480106005\\050_front.png 308 140 523 397\n-Dataset/FaceData/processed\\K205480106005\\076_left.png 275 139 509 419\n-Dataset/FaceData/processed\\K205480106005\\036_left.png 283 144 492 393\n-Dataset/FaceData/processed\\K205480106005\\059_down.png 235 142 475 419\n-Dataset/FaceData/processed\\K205480106005\\019_down.png 301 133 522 403\n-Dataset/FaceData/processed\\K205480106005\\060_front.png 272 136 482 392\n-Dataset/FaceData/processed\\K205480106005\\018_up.png 302 134 515 396\n-Dataset/FaceData/processed\\K205480106005\\026_left.png 264 151 497 422\n-Dataset/FaceData/processed\\K205480106005\\098_up.png 284 145 513 419\n-Dataset/FaceData/processed\\K205480106005\\049_down.png 307 138 527 402\n-Dataset/FaceData/processed\\K205480106005\\064_down.png 346 127 562 402\n-Dataset/FaceData/processed\\K205480106005\\086_left.png 220 138 464 423\n-Dataset/FaceData/processed\\K205480106005\\090_front.png 269 133 492 415\n-Dataset/FaceData/processed\\K205480106005\\002_right.png 260 130 485 393\n-Dataset/FaceData/processed\\K205480106005\\079_down.png 244 138 450 385\n-Dataset/FaceData/processed\\K205480106005\\004_down.png 261 128 476 383\n-Dataset/FaceData/processed\\K205480106005\\063_up.png\n-Dataset/FaceData/processed\\K205480106005\\062_right.png 274 135 504 397\n-Dataset/FaceData/processed\\K205480106005\\085_front.png 261 143 477 385\n-Dataset/FaceData/processed\\K205480106005\\008_up.png 312 123 520 386\n-Dataset/FaceData/processed\\K205480106005\\057_right.png 308 134 524 397\n-Dataset/FaceData/processed\\K205480106005\\089_down.png 270 137 492 411\n-Dataset/FaceData/processed\\K205480106005\\044_down.png 297 135 526 417\n-Dataset/FaceData/processed\\K205480106005\\013_up.png 272 138 487 401\n-Dataset/FaceData/processed\\K205480106005\\095_front.png 289 149 508 409\n-Dataset/FaceData/processed\\K205480106005\\016_left.png 294 144 497 394\n-Dataset/FaceData/processed\\K205480106005\\055_front.png 310 136 523 394\n-Dataset/FaceData/processed\\K205480106005\\087_right.png 218 123 449 395\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_20.png 137 587 944 1585\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_86.png 197 597 912 1624\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_54.png 36 622 840 1718\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_97.png 199 615 884 1623\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_14.png 108 548 941 1646\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_65.png 0 567 854 1675\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_25.png 145 564 984 1636\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_55.png 16 650 861 1704\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_77.png 123 572 911 1630\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_39.png 13 626 792 1659\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_69.png 0 556 829 1661\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_53.png 40 614 816 1703\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_5.png 416 562 1080 1664\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_96.png 196 614 882 1625\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_83.png 185 570 917 1616\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_74.png 78 563 891 1635\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_93.png 185 607 876 1624\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_71.png 29 546 893 1641\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_28.png 128 586 945 1625\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_94.png 189 613 875 1622\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_10.png 188 553 1034 1629\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_73.png 63 546 889 1621\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_42.png 37 609 796 1678\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_31.png 96 613 890 1675\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_58.png 0 619 858 1679\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_44.png 29 619 795 1670\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_76.png 101 574 892 1635\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_47.png 27 599 816 1714\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_32.png 120 656 856 1641\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_45.png 31 595 794 1684\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_34.png 104 655 846 1646\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_15.png 118 555 948 1605\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_90.png 198 600 903 1632\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_18.png 104 554 950 1611\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_23.png 147 575 989 1619\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_12.png 145 587 980 1657\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_50.png 27 618 787 1661\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_81.png 181 596 918 1603\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_2.png 517 539 1080 1660\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_37.png 0 586 847 1703\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_46.png 0 584 785 1676\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_11.png 181 571 1033 1655\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_40.png 15 624 785 1641\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_7.png 322 556 1080 1623\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_48.png 4 601 811 1684\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_35.png 59 627 841 1694\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_89.png 201 599 908 1633\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_9.png 209 545 1066 1635\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_72.png 46 557 887 1633\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_33.png 133 682 851 1634\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_75.png 87 571 900 1643\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_63.png 0 585 831 1646\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_17.png 119 562 950 1606\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_19.png 123 582 943 1629\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_38.png 40 619 850 1708\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_99.png 200 611 888 1624\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_52.png 45 617 830 1706\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_56.png 0 637 863 1701\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_100.png 199 607 892 1628\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_24.png 140 575 971 1613\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_87.png 199 603 908 1623\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_84.png 180 586 909 1610\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_1.png 478 546 1080 1666\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_30.png 101 602 893 1652\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_95.png 191 613 877 1624\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_57.png 0 621 852 1675\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_4.png 465 531 1080 1671\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_3.png 498 545 1080 1672\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_27.png 154 671 946 1650\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_62.png 0 565 850 1684\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_60.png 0 553 818 1667\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_43.png 35 613 806 1677\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_85.png 187 597 905 1613\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_26.png 164 642 968 1629\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_82.png 193 615 911 1594\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_59.png 0 568 875 1744\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_79.png 150 587 891 1601\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_41.png 36 594 808 1689\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_21.png 140 600 954 1613\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_67.png 18 553 842 1670\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_16.png 110 568 932 1642\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_29.png 138 627 926 1623\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_78.png 122 580 881 1616\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_49.png 27 617 811 1677\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_22.png 152 579 988 1628\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_13.png 106 577 928 1633\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_91.png 202 621 891 1629\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_36.png 72 664 800 1635\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_6.png 363 572 1080 1654\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_68.png 0 527 881 1654\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_98.png 196 613 885 1626\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_64.png 0 555 842 1666\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_70.png 36 559 844 1649\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_51.png 50 625 808 1674\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_80.png 165 594 898 1601\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_61.png 0 563 835 1754\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_88.png 201 605 903 1629\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_66.png 28 548 862 1668\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_92.png 196 619 890 1631\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_0.png 496 588 1080 1620\n-Dataset/FaceData/processed\\K205480106034\\b_duyframe_8.png 272 548 1080 1643\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/processed/revision_info.txt b/BackEnd/Face_AI/Dataset/FaceData/processed/revision_info.txt\ndeleted file mode 100644\nindex bc971ff..0000000\n--- a/BackEnd/Face_AI/Dataset/FaceData/processed/revision_info.txt\n+++ /dev/null\n@@ -1,7 +0,0 @@\n-arguments: src/align_dataset_mtcnn.py Dataset/FaceData/raw Dataset/FaceData/processed --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25\n---------------------\n-tensorflow version: 2.15.0\n---------------------\n-git hash: b\'533409690ccf7b33d810b28c14a91d1ba74a8d54\'\n---------------------\n-b\'diff --git a/BackEnd/app/app.py b/BackEnd/app/app.py\\nindex f9b6b0a..6f0b8c6 100644\\n--- a/BackEnd/app/app.py\\n+++ b/BackEnd/app/app.py\\n@@ -1,14 +1,21 @@\\n-from fastapi import FastAPI, HTTPException, Request\\n+from fastapi import FastAPI, HTTPException, Request, Form\\n from typing import Optional, List\\n+from fastapi.responses import JSONResponse\\n import pyodbc\\n import jwt\\n+import align.detect_face\\n+import numpy as np\\n from datetime import datetime, timedelta\\n from fastapi.middleware.cors import CORSMiddleware\\n+from fastapi import File, UploadFile\\n from pydantic import BaseModel\\n-\\n+import cv2\\n+from FaceRecognitionCamera import FaceRecognitionCamera\\n+import base64\\n SECRET_KEY = "duycao12"\\n TOKEN_EXPIRE_MINUTES = 30\\n \\n+\\n class User:\\n     def __init__(self, username: str, password: str,role:str):\\n         self.username = username\\n@@ -36,7 +43,6 @@ def connect_to_database():\\n                           \\\'UID=sa;\\\'\\n                           \\\'PWD=123456\\\')\\n \\n-\\n def get_user_by_username(username: str) -> Optional[User]:\\n     connection = connect_to_database()\\n     cursor = connection.cursor()\\n@@ -334,6 +340,20 @@ async def get_ListSubject(MaGV : str,HocKy: str,Nam: str,MaMon:str,MaLop:str ):\\n     except Exception as e:\\n         raise HTTPException(status_code=500, detail=str(e))\\n     \\n+face_recognition = FaceRecognitionCamera()\\n+@app.post("/face-recognition")\\n+async def upload_image(request: Request,  image_data: dict=None):\\n+    if image_data and "image_data" in image_data:\\n+        image_data = base64.b64decode(image_data["image_data"].split(",")[1])\\n+        nparr = np.frombuffer(image_data, np.uint8)\\n+        image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\\n+        faces = face_recognition.detect_faces(image)\\n+\\n+    # Tr\\xe1\\xba\\xa3 v\\xe1\\xbb\\x81 k\\xe1\\xba\\xbft qu\\xe1\\xba\\xa3\\n+        return faces\\n+    else:\\n+        return JSONResponse(content={"message": "No image data received"}, status_code=400)\\n+\\n if __name__ == "__main__":\\n     import uvicorn\\n     uvicorn.run(app, host="127.0.0.1", port=8000)\\n\\\\ No newline at end of file\\ndiff --git a/demo/package-lock.json b/demo/package-lock.json\\nindex f106d5e..d0baf70 100644\\n--- a/demo/package-lock.json\\n+++ b/demo/package-lock.json\\n@@ -17,7 +17,7 @@\\n         "@testing-library/user-event": "^13.5.0",\\n         "@toast-ui/react-calendar": "^2.1.3",\\n         "antd": "^5.18.0",\\n-        "axios": "^1.6.8",\\n+        "axios": "^1.7.2",\\n         "bootstrap": "^5.3.3",\\n         "date-fns": "^3.6.0",\\n         "file-saver": "^2.0.5",\\n@@ -34,6 +34,7 @@\\n         "react-router-dom": "^6.23.1",\\n         "react-scripts": "5.0.1",\\n         "react-tooltip": "^5.26.4",\\n+        "react-webcam": "^7.2.0",\\n         "tui-calendar": "^1.15.3",\\n         "web-vitals": "^2.1.4",\\n         "xlsx": "^0.18.5"\\n@@ -5977,9 +5978,9 @@\\n       }\\n     },\\n     "node_modules/axios": {\\n-      "version": "1.6.8",\\n-      "resolved": "https://registry.npmjs.org/axios/-/axios-1.6.8.tgz",\\n-      "integrity": "sha512-v/ZHtJDU39mDpyBoFVkETcd/uNdxrWRrg3bKpOKzXFA6Bvqopts6ALSMU3y6ijYxbw2B+wPrIv46egTzJXCLGQ==",\\n+      "version": "1.7.2",\\n+      "resolved": "https://registry.npmjs.org/axios/-/axios-1.7.2.tgz",\\n+      "integrity": "sha512-2A8QhOMrbomlDuiLeK9XibIBzuHeRcqqNOHp0Cyp5EoJ1IFDh+XZH3A6BkXtv0K4gFGCI0Y4BM7B1wOEi0Rmgw==",\\n       "dependencies": {\\n         "follow-redirects": "^1.15.6",\\n         "form-data": "^4.0.0",\\n@@ -18665,6 +18666,15 @@\\n         "react-dom": ">=16.14.0"\\n       }\\n     },\\n+    "node_modules/react-webcam": {\\n+      "version": "7.2.0",\\n+      "resolved": "https://registry.npmjs.org/react-webcam/-/react-webcam-7.2.0.tgz",\\n+      "integrity": "sha512-xkrzYPqa1ag2DP+2Q/kLKBmCIfEx49bVdgCCCcZf88oF+0NPEbkwYk3/s/C7Zy0mhM8k+hpdNkBLzxg8H0aWcg==",\\n+      "peerDependencies": {\\n+        "react": ">=16.2.0",\\n+        "react-dom": ">=16.2.0"\\n+      }\\n+    },\\n     "node_modules/read-cache": {\\n       "version": "1.0.0",\\n       "resolved": "https://registry.npmjs.org/read-cache/-/read-cache-1.0.0.tgz",\\ndiff --git a/demo/package.json b/demo/package.json\\nindex ab2b331..8defd71 100644\\n--- a/demo/package.json\\n+++ b/demo/package.json\\n@@ -12,7 +12,7 @@\\n     "@testing-library/user-event": "^13.5.0",\\n     "@toast-ui/react-calendar": "^2.1.3",\\n     "antd": "^5.18.0",\\n-    "axios": "^1.6.8",\\n+    "axios": "^1.7.2",\\n     "bootstrap": "^5.3.3",\\n     "date-fns": "^3.6.0",\\n     "file-saver": "^2.0.5",\\n@@ -29,6 +29,7 @@\\n     "react-router-dom": "^6.23.1",\\n     "react-scripts": "5.0.1",\\n     "react-tooltip": "^5.26.4",\\n+    "react-webcam": "^7.2.0",\\n     "tui-calendar": "^1.15.3",\\n     "web-vitals": "^2.1.4",\\n     "xlsx": "^0.18.5"\\ndiff --git a/demo/src/Page/Class/ListStuDIem/index.js b/demo/src/Page/Class/ListStuDIem/index.js\\nindex f4c0252..bb84de1 100644\\n--- a/demo/src/Page/Class/ListStuDIem/index.js\\n+++ b/demo/src/Page/Class/ListStuDIem/index.js\\n@@ -61,7 +61,7 @@ const ListStu = ({ MaGV, HocKy, Nam }) => {\\n             },\\n         ];\\n \\n-        const monHocFields = [\\\'TenMon\\\', \\\'MaMon\\\', \\\'BuoiHoc\\\', \\\'DiemDanh\\\'];\\n+        const monHocFields = [\\\'TenMon\\\', \\\'MaMon\\\', \\\'BuoiHoc\\\', \\\'DiemDanh\\\',];\\n \\n         monHocFields.forEach(field => {\\n             columns.push({\\n@@ -69,19 +69,50 @@ const ListStu = ({ MaGV, HocKy, Nam }) => {\\n                 dataIndex: field,\\n                 key: field,\\n                 render: (text, record) => {\\n-                    return (\\n+                         return (\\n                         <ul>\\n                             {record.MonHocDetails.map((monHoc, index) => (\\n-                                <p key={index}>{monHoc[field]}</p>\\n+                                <p key={index}>\\n+                                     {field === \\\'DiemDanh\\\' && monHoc[field] === \\\'0\\\' ? \\\'Kh\\xc3\\xb4ng h\\xe1\\xbb\\x8dc bu\\xe1\\xbb\\x95i n\\xc3\\xa0o\\\' : monHoc[field]}\\n+                                     </p>\\n                             ))}\\n                         </ul>\\n                     );\\n+                    \\n                 }\\n             });\\n         });\\n \\n         return columns;\\n     };\\n+    const processedDataWithComments = data.map(student => {\\n+        let totalAbsent = 0;\\n+        let totalAttended = 0;\\n+    \\n+        student.MonHocDetails.forEach(detail => {\\n+            if (detail.DiemDanh === \\\'0\\\') {\\n+                totalAbsent++;\\n+            } else {\\n+                totalAttended++;\\n+            }\\n+        });\\n+    \\n+        let comment = \\\'\\\';\\n+        if (totalAttended === 0 && totalAbsent === 0) {\\n+            comment = \\\'Ch\\xc6\\xb0a \\xc4\\x91i h\\xe1\\xbb\\x8dc\\\';\\n+        } else if (totalAttended === 0 && totalAbsent > 0) {\\n+            comment = \\\'Ngh\\xe1\\xbb\\x89 h\\xe1\\xbb\\x8dc\\\';\\n+        } else if (totalAbsent === 0) {\\n+            comment = \\\'\\xc4\\x90i h\\xe1\\xba\\xbft bu\\xe1\\xbb\\x95i\\\';\\n+        } else {\\n+            comment = `V\\xe1\\xba\\xafng ${totalAbsent} bu\\xe1\\xbb\\x95i`;\\n+        }\\n+    \\n+        return {\\n+            ...student,\\n+            Comment: comment\\n+        };\\n+    });\\n     const exportToExcel = () => {\\n         const headers = [\\n             "M\\xc3\\xa3 SV",\\n@@ -89,25 +120,30 @@ const ListStu = ({ MaGV, HocKy, Nam }) => {\\n             "T\\xc3\\xaan m\\xc3\\xb4n",\\n             "M\\xc3\\xa3 m\\xc3\\xb4n",\\n             "Bu\\xe1\\xbb\\x95i h\\xe1\\xbb\\x8dc",\\n-            "\\xc4\\x90i\\xe1\\xbb\\x83m danh"\\n+            "\\xc4\\x90i\\xe1\\xbb\\x83m danh",\\n+            "Nh\\xe1\\xba\\xadn x\\xc3\\xa9t"\\n         ];\\n \\n         // T\\xe1\\xba\\xa1o m\\xe1\\xbb\\x99t \\xc4\\x91\\xe1\\xbb\\x91i t\\xc6\\xb0\\xe1\\xbb\\xa3ng d\\xc3\\xb9ng \\xc4\\x91\\xe1\\xbb\\x83 l\\xc6\\xb0u tr\\xe1\\xbb\\xaf d\\xe1\\xbb\\xaf li\\xe1\\xbb\\x87u \\xc4\\x91\\xc6\\xb0\\xe1\\xbb\\xa3c g\\xe1\\xbb\\x99p\\n         const mergedData = {};\\n \\n         // Duy\\xe1\\xbb\\x87t qua d\\xe1\\xbb\\xaf li\\xe1\\xbb\\x87u v\\xc3\\xa0 g\\xe1\\xbb\\x99p c\\xc3\\xa1c m\\xc3\\xb4n h\\xe1\\xbb\\x8dc c\\xe1\\xbb\\xa7a c\\xc3\\xb9ng m\\xe1\\xbb\\x99t sinh vi\\xc3\\xaan\\n-        data.forEach(student => {\\n+        processedDataWithComments.forEach(student => {\\n             const key = `${student.MaSV}-${student.name}`;\\n             if (!mergedData[key]) {\\n                 mergedData[key] = {\\n                     MaSV: student.MaSV,\\n                     name: student.name,\\n-                    MonHoc: []\\n+                    MonHoc: [],\\n                 };\\n             }\\n             student.MonHocDetails.forEach(detail => {\\n+                if (detail.DiemDanh === \\\'0\\\') {\\n+                    detail.DiemDanh = \\\'Kh\\xc3\\xb4ng h\\xe1\\xbb\\x8dc bu\\xe1\\xbb\\x95i n\\xc3\\xa0o\\\';\\n+                }\\n                 mergedData[key].MonHoc.push(detail);\\n             });\\n+            mergedData[key].Comment = student.Comment; \\n         });\\n \\n         // Chuy\\xe1\\xbb\\x83n \\xc4\\x91\\xe1\\xbb\\x95i d\\xe1\\xbb\\xaf li\\xe1\\xbb\\x87u \\xc4\\x91\\xc3\\xa3 g\\xe1\\xbb\\x99p sang \\xc4\\x91\\xe1\\xbb\\x8bnh d\\xe1\\xba\\xa1ng cho file Excel\\n@@ -120,7 +156,8 @@ const ListStu = ({ MaGV, HocKy, Nam }) => {\\n                     detail.TenMon,\\n                     detail.MaMon,\\n                     detail.BuoiHoc,\\n-                    detail.DiemDanh\\n+                    detail.DiemDanh,\\n+                    detail.Comment\\n                 ]);\\n             }).flat()\\n         ];\\n@@ -156,7 +193,7 @@ const ListStu = ({ MaGV, HocKy, Nam }) => {\\n \\n     return (\\n         <div>\\n-            <h1>Danh s\\xc3\\xa1ch \\xc4\\x91i h\\xe1\\xbb\\x8dc t\\xe1\\xbb\\xabng m\\xc3\\xb4n {HocKy} n\\xc4\\x83m {Nam} </h1>\\n+            <h1 style={{ fontFamily: \\\'cursive\\\',margin:\\\'0 0 10px 0\\\',textAlign:\\\'center\\\' }}>Danh s\\xc3\\xa1ch sinh vi\\xc3\\xaan \\xc4\\x91i h\\xe1\\xbb\\x8dc  </h1>\\n             <ReusableTable columns={columns} data={data} loading={loading} />\\n             <Button onClick={exportToExcel} type="primary" style={{ margin: 16, backgroundColor: "green" }}>\\n                 <FaFileExport /> Xu\\xe1\\xba\\xa5t file\\ndiff --git a/demo/src/Page/Class/index.js b/demo/src/Page/Class/index.js\\nindex 5aa0ddf..08ca456 100644\\n--- a/demo/src/Page/Class/index.js\\n+++ b/demo/src/Page/Class/index.js\\n@@ -5,6 +5,7 @@ import { format } from \\\'date-fns\\\';\\n import { Select, Button } from \\\'antd\\\';\\n import getListHK from "../../common/Api/ApiHK"; \\n import ListStu from "./ListStuDIem";\\n+import \\\'./style.css\\\'\\n const { Option } = Select;\\n \\n const Class = () => {\\n@@ -107,7 +108,7 @@ const Class = () => {\\n                             <Button type="primary" onClick={handleButtonClick}>Xu\\xe1\\xba\\xa5t danh s\\xc3\\xa1ch</Button>\\n                         </div>\\n                         {showExportInfo ? (\\n-                            <div style={{ padding: \\\'16px\\\', background: \\\'#f0f0f0\\\', marginBottom: \\\'16px\\\' }}>\\n+                            <div style={{ padding: \\\'16px\\\', background: \\\'white\\\', marginBottom: \\\'16px\\\' }}>\\n                                 <ListStu MaGV={localStorage.getItem(\\\'username\\\')} HocKy = {selectedHocKy} Nam={selectedNamHoc}></ListStu>\\n                                 <Button type="primary" onClick={hideExportInfoPanel}>\\xc4\\x90\\xc3\\xb3ng</Button>\\n                             </div>\\ndiff --git a/demo/src/Page/Default-page/index.js b/demo/src/Page/Default-page/index.js\\nindex a0f01b0..6014b61 100644\\n--- a/demo/src/Page/Default-page/index.js\\n+++ b/demo/src/Page/Default-page/index.js\\n@@ -3,6 +3,7 @@ import { useEffect, useState } from "react"\\n import { Select, Button } from \\\'antd\\\';\\n import getSubject from "../../common/Api/ApiGetSubject";\\n import getListSubject from "../../common/Api/ApigetListSubject";\\n+import ReusableTable from "../../common/component/AntTable";\\n const Default_page=()=>{\\n     const { Option } = Select;\\n     const role = localStorage.getItem(\\\'chuc vu\\\')\\n@@ -44,7 +45,12 @@ const Default_page=()=>{\\n     const fetchListSubject = async()=>{\\n         try{\\n             const dataList  =await getListSubject(username,selectedHocKy,selectedNamHoc,selectedClassCode,selectedSubjectCode)\\n-            setDatalist(dataList)\\n+            const processedData = dataList.map(item => ({\\n+                ...item,\\n+                SoBuoiHoc: item.SoBuoiHoc === null ? 0 : item.SoBuoiHoc,\\n+                BuoiDiemdanh: item.BuoiDiemdanh === null ? \\\'Kh\\xc3\\xb4ng h\\xe1\\xbb\\x8dc bu\\xe1\\xbb\\x95i n\\xc3\\xa0o\\\' : item.BuoiDiemdanh\\n+            }));\\n+            setDatalist(processedData)\\n         }catch(error){\\n             console.log(error);\\n         }\\n@@ -75,11 +81,36 @@ const Default_page=()=>{\\n         setSelectedSubjectCode(selectedSubject.maMon);\\n     }\\n         };\\n-    \\n+    const columns = [\\n+        {\\n+            title: \\\'M\\xc3\\xa3 SV\\\',\\n+                dataIndex: \\\'MaSV\\\',\\n+                key: \\\'MaSV\\\',\\n+        },{\\n+                title: \\\'H\\xe1\\xbb\\x8d v\\xc3\\xa0 t\\xc3\\xaan\\\',\\n+                dataIndex: \\\'name\\\',\\n+                key: \\\'name\\\',\\n+        },\\n+        {\\n+            title: \\\'M\\xc3\\xb4n h\\xe1\\xbb\\x8dc\\\',\\n+            dataIndex: \\\'TenMon\\\',\\n+            key: \\\'TenMon\\\',\\n+        },\\n+        {\\n+            title: \\\'S\\xe1\\xbb\\x91 bu\\xe1\\xbb\\x95i h\\xe1\\xbb\\x8dc\\\',\\n+            dataIndex: \\\'SoBuoiHoc\\\',\\n+            key: \\\'SoBuoiHoc\\\',\\n+        },\\n+        {\\n+            title: \\\'S\\xe1\\xbb\\x91 bu\\xe1\\xbb\\x95i \\xc4\\x91i h\\xe1\\xbb\\x8dc\\\',\\n+            dataIndex: \\\'BuoiDiemdanh\\\',\\n+            key: \\\'BuoiDiemdanh\\\',\\n+        },\\n+    ]\\n     return(\\n         <>\\n-       <h1>Danh s\\xc3\\xa1ch m\\xc3\\xb4n h\\xe1\\xbb\\x8dc k\\xe1\\xbb\\xb3 n\\xc3\\xa0y</h1> \\n-       <div style={{ marginBottom: \\\'16px\\\' }}>\\n+       <h1 style={{ fontFamily: \\\'cursive\\\',margin:\\\'0\\\' }}>Danh s\\xc3\\xa1ch m\\xc3\\xb4n h\\xe1\\xbb\\x8dc k\\xe1\\xbb\\xb3 n\\xc3\\xa0y</h1> \\n+       <div style={{ marginBottom: \\\'16px\\\',marginTop:\\\'10px\\\' }}>\\n                             <Select style={{ width: \\\'200px\\\', marginRight: \\\'8px\\\' }} placeholder="Ch\\xe1\\xbb\\x8dn h\\xe1\\xbb\\x8dc k\\xe1\\xbb\\xb3" \\n                             onChange={value => setSelectedHocKy(value)}>\\n                                 {hockyOptions.map(option => (\\n@@ -93,8 +124,7 @@ const Default_page=()=>{\\n                                 ))}\\n                             </Select>\\n                             {subjects.length > 0 && (\\n-                <div>\\n-                    <h2>C\\xc3\\xa1c m\\xc3\\xb4n h\\xe1\\xbb\\x8dc:</h2>\\n+                <div style={{ marginTop: \\\'10px\\\' }}>\\n                     <Select\\n                         style={{ width: \\\'400px\\\', marginRight: \\\'8px\\\' }}\\n                         placeholder="Ch\\xe1\\xbb\\x8dn m\\xc3\\xb4n h\\xe1\\xbb\\x8dc"\\n@@ -107,7 +137,7 @@ const Default_page=()=>{\\n                         ))}\\n                     </Select>\\n                     <Select\\n-                        style={{ width: \\\'400px\\\', marginRight: \\\'8px\\\' }}\\n+                        style={{ width: \\\'400px\\\', marginRight: \\\'8px\\\' ,marginBottom:\\\'8px\\\' }}\\n                         placeholder="Ch\\xe1\\xbb\\x8dn m\\xc3\\xa3 l\\xe1\\xbb\\x9bp"\\n                         onChange={value => setSelectedClassCode(value)}\\n                         disabled={!selectedSubjectName}\\n@@ -119,6 +149,7 @@ const Default_page=()=>{\\n                             </Option>\\n                         ))}\\n                     </Select>\\n+                    <ReusableTable columns={columns} data={listData}></ReusableTable>\\n                 </div>\\n             )}\\n          </div>\\ndiff --git a/demo/src/Page/DiemDanh/index.js b/demo/src/Page/DiemDanh/index.js\\nindex 2f74921..0528ad9 100644\\n--- a/demo/src/Page/DiemDanh/index.js\\n+++ b/demo/src/Page/DiemDanh/index.js\\n@@ -1,35 +1,73 @@\\n-import React from \\\'react\\\';\\n-\\n-const StudentTable = () => {\\n-  return (\\n-    <table style={{ borderCollapse: \\\'collapse\\\', width: \\\'100%\\\' }}>\\n-      <thead>\\n-        <tr>\\n-          <th style={styles.tableCell}>M\\xc3\\xa3 sinh vi\\xc3\\xaan</th>\\n-          <th style={styles.tableCell}>H\\xe1\\xbb\\x8d v\\xc3\\xa0 t\\xc3\\xaan</th>\\n-          <th style={styles.tableCell}>M\\xc3\\xb4n h\\xe1\\xbb\\x8dc</th>\\n-        </tr>\\n-      </thead>\\n-      <tbody>\\n-        <tr>\\n-          <td style={styles.tableCell} rowSpan="2">K205480106005</td>\\n-          <td style={styles.tableCell} rowSpan="2">Nguy\\xe1\\xbb\\x85n Duy Cao</td>\\n-          <td style={styles.tableCell}>L\\xe1\\xba\\xadp tr\\xc3\\xacnh Python (TEE0480)</td>\\n-        </tr>\\n-        <tr>\\n-          <td style={styles.tableCell}>TEE0479</td>\\n-        </tr>\\n-      </tbody>\\n-    </table>\\n-  );\\n-};\\n+import React, { useRef, useState,useEffect } from \\\'react\\\';\\n+import axios from \\\'axios\\\';\\n+\\n+const FaceRecognition = () => {\\n+    const videoRef = useRef(null);\\n+    const canvasRef = useRef(null);\\n+    const [faces, setFaces] = useState([]);\\n+\\n+    useEffect(() => {\\n+      // G\\xe1\\xbb\\x8di detectFaces() khi component \\xc4\\x91\\xc6\\xb0\\xe1\\xbb\\xa3c render l\\xe1\\xba\\xa1i\\n+      detectFaces();\\n+  }, []);\\n+    const startVideo = () => {\\n+        navigator.mediaDevices.getUserMedia({ video: true })\\n+            .then((stream) => {\\n+                if (videoRef.current) {\\n+                    videoRef.current.srcObject = stream;\\n+                }\\n+            })\\n+            .catch((err) => console.error(\\\'Error accessing media devices:\\\', err));\\n+    };\\n+\\n+    const stopVideo = () => {\\n+        const stream = videoRef.current.srcObject;\\n+        if (stream) {\\n+            const tracks = stream.getTracks();\\n+            tracks.forEach((track) => track.stop());\\n+        }\\n+    };\\n+\\n+    const detectFaces = async () => {\\n+        const video = videoRef.current;\\n+        const canvas = canvasRef.current;\\n+        const context = canvas.getContext(\\\'2d\\\');\\n+\\n+        context.drawImage(video, 0, 0, canvas.width, canvas.height);\\n+        const imageData = canvas.toDataURL(\\\'image/jpeg\\\');\\n+\\n+       \\n+          const response = await axios.post(\\\'http://localhost:8000/face-recognition\\\', { image_data: imageData });\\n+            setFaces(response.data);\\n+            console.log(\\\'API Response:\\\', response.data);\\n+            if (response.data.detected_faces) {\\n+              response.data.detected_faces.forEach((face, index) => {\\n+                  console.log(`Face ${index + 1}: Name - ${face.name}, Detectf - ${face.detectf}`);\\n+              });\\n+          }\\n+          \\n+         \\n+    };\\n+    console.log("Face: ",faces);\\n \\n-const styles = {\\n-  tableCell: {\\n-    border: \\\'1px solid black\\\',\\n-    padding: \\\'8px\\\',\\n-    textAlign: \\\'left\\\',\\n-  }\\n+    return (\\n+        <div>\\n+            <button onClick={startVideo}>Start Video</button>\\n+            <button onClick={stopVideo}>Stop Video</button>\\n+            <button onClick={detectFaces}>Detect Faces</button>\\n+            <video ref={videoRef} autoPlay muted />\\n+            <canvas ref={canvasRef} />\\n+            {faces && faces.length > 0 && (\\n+    <div>\\n+        {faces.map((face, index) => (\\n+            <div key={index}>\\n+                <p> Name - {face}</p>\\n+            </div>\\n+        ))}\\n+    </div>\\n+)}\\n+        </div>\\n+    );\\n };\\n \\n-export default StudentTable;\\n+export default FaceRecognition;\'\n\\ No newline at end of file\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/000_front.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/000_front.jpg\ndeleted file mode 100644\nindex 955f8a3..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/000_front.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/001_left.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/001_left.jpg\ndeleted file mode 100644\nindex ca9e480..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/001_left.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/002_right.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/002_right.jpg\ndeleted file mode 100644\nindex 68829e3..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/002_right.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/003_up.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/003_up.jpg\ndeleted file mode 100644\nindex 0774af5..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/003_up.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/004_down.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/004_down.jpg\ndeleted file mode 100644\nindex 96b4c5e..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/004_down.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/005_front.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/005_front.jpg\ndeleted file mode 100644\nindex 03327a7..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/005_front.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/006_left.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/006_left.jpg\ndeleted file mode 100644\nindex 7d5c309..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/006_left.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/007_right.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/007_right.jpg\ndeleted file mode 100644\nindex 27909df..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/007_right.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/008_up.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/008_up.jpg\ndeleted file mode 100644\nindex 7a9cd3f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/008_up.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/009_down.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/009_down.jpg\ndeleted file mode 100644\nindex beacc67..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/009_down.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/010_front.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/010_front.jpg\ndeleted file mode 100644\nindex f8929c4..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/010_front.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/011_left.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/011_left.jpg\ndeleted file mode 100644\nindex 1863c04..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/011_left.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/012_right.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/012_right.jpg\ndeleted file mode 100644\nindex 1a0fa98..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/012_right.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/013_up.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/013_up.jpg\ndeleted file mode 100644\nindex bba15f1..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/013_up.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/014_down.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/014_down.jpg\ndeleted file mode 100644\nindex 0440ed3..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/014_down.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/015_front.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/015_front.jpg\ndeleted file mode 100644\nindex 27460a7..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/015_front.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/016_left.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/016_left.jpg\ndeleted file mode 100644\nindex 2202ecb..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/016_left.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/017_right.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/017_right.jpg\ndeleted file mode 100644\nindex 3c9f53e..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/017_right.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/018_up.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/018_up.jpg\ndeleted file mode 100644\nindex 312acd2..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/018_up.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/019_down.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/019_down.jpg\ndeleted file mode 100644\nindex af63b3a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/019_down.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/020_front.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/020_front.jpg\ndeleted file mode 100644\nindex e0283cb..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/020_front.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/021_left.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/021_left.jpg\ndeleted file mode 100644\nindex 9b4ff87..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/021_left.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/022_right.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/022_right.jpg\ndeleted file mode 100644\nindex 8ba5cea..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/022_right.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/023_up.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/023_up.jpg\ndeleted file mode 100644\nindex cb4288f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/023_up.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/024_down.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/024_down.jpg\ndeleted file mode 100644\nindex f18ac02..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/024_down.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/025_front.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/025_front.jpg\ndeleted file mode 100644\nindex 499dceb..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/025_front.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/026_left.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/026_left.jpg\ndeleted file mode 100644\nindex 1812012..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/026_left.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/027_right.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/027_right.jpg\ndeleted file mode 100644\nindex a2629e1..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/027_right.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/028_up.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/028_up.jpg\ndeleted file mode 100644\nindex b9f547c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/028_up.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/029_down.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/029_down.jpg\ndeleted file mode 100644\nindex 5bbc557..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/029_down.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/030_front.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/030_front.jpg\ndeleted file mode 100644\nindex 82df7dc..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/030_front.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/031_left.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/031_left.jpg\ndeleted file mode 100644\nindex 6748775..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/031_left.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/032_right.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/032_right.jpg\ndeleted file mode 100644\nindex 607ee8c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/032_right.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/033_up.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/033_up.jpg\ndeleted file mode 100644\nindex cf3f524..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/033_up.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/034_down.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/034_down.jpg\ndeleted file mode 100644\nindex 07b4dff..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/034_down.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/035_front.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/035_front.jpg\ndeleted file mode 100644\nindex be18fd9..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/035_front.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/036_left.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/036_left.jpg\ndeleted file mode 100644\nindex b6c95cd..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/036_left.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/037_right.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/037_right.jpg\ndeleted file mode 100644\nindex 17dfe71..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/037_right.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/038_up.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/038_up.jpg\ndeleted file mode 100644\nindex 807b013..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/038_up.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/039_down.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/039_down.jpg\ndeleted file mode 100644\nindex 4b5bbfd..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/039_down.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/040_front.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/040_front.jpg\ndeleted file mode 100644\nindex 34b5e7a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/040_front.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/041_left.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/041_left.jpg\ndeleted file mode 100644\nindex 57c5f58..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/041_left.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/042_right.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/042_right.jpg\ndeleted file mode 100644\nindex 1a5f01d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/042_right.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/043_up.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/043_up.jpg\ndeleted file mode 100644\nindex 6b0967f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/043_up.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/044_down.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/044_down.jpg\ndeleted file mode 100644\nindex a41482d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/044_down.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/045_front.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/045_front.jpg\ndeleted file mode 100644\nindex d6c9c4c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/045_front.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/046_left.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/046_left.jpg\ndeleted file mode 100644\nindex 45b7935..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/046_left.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/047_right.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/047_right.jpg\ndeleted file mode 100644\nindex 09d21c9..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/047_right.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/048_up.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/048_up.jpg\ndeleted file mode 100644\nindex eb0e501..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/048_up.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/049_down.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/049_down.jpg\ndeleted file mode 100644\nindex 4f037f9..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/049_down.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/050_front.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/050_front.jpg\ndeleted file mode 100644\nindex 0bb9726..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/050_front.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/051_left.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/051_left.jpg\ndeleted file mode 100644\nindex b3ef775..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/051_left.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/052_right.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/052_right.jpg\ndeleted file mode 100644\nindex 1fe0375..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/052_right.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/053_up.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/053_up.jpg\ndeleted file mode 100644\nindex abb3ed9..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/053_up.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/054_down.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/054_down.jpg\ndeleted file mode 100644\nindex 562002d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/054_down.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/055_front.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/055_front.jpg\ndeleted file mode 100644\nindex 3c7aacf..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/055_front.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/056_left.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/056_left.jpg\ndeleted file mode 100644\nindex 14d62f8..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/056_left.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/057_right.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/057_right.jpg\ndeleted file mode 100644\nindex 01be3aa..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/057_right.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/058_up.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/058_up.jpg\ndeleted file mode 100644\nindex 6e4be37..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/058_up.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/059_down.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/059_down.jpg\ndeleted file mode 100644\nindex 89cb653..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/059_down.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/060_front.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/060_front.jpg\ndeleted file mode 100644\nindex 7f1f8c0..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/060_front.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/061_left.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/061_left.jpg\ndeleted file mode 100644\nindex ff9c832..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/061_left.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/062_right.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/062_right.jpg\ndeleted file mode 100644\nindex c1042d3..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/062_right.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/063_up.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/063_up.jpg\ndeleted file mode 100644\nindex 21c758b..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/063_up.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/064_down.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/064_down.jpg\ndeleted file mode 100644\nindex be747d0..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/064_down.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/065_front.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/065_front.jpg\ndeleted file mode 100644\nindex 0313813..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/065_front.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/066_left.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/066_left.jpg\ndeleted file mode 100644\nindex 0854470..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/066_left.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/067_right.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/067_right.jpg\ndeleted file mode 100644\nindex c8b306e..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/067_right.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/068_up.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/068_up.jpg\ndeleted file mode 100644\nindex b5beb83..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/068_up.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/069_down.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/069_down.jpg\ndeleted file mode 100644\nindex 77c0025..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/069_down.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/070_front.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/070_front.jpg\ndeleted file mode 100644\nindex fa9ddf6..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/070_front.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/071_left.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/071_left.jpg\ndeleted file mode 100644\nindex 451926d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/071_left.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/072_right.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/072_right.jpg\ndeleted file mode 100644\nindex 5e97cce..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/072_right.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/073_up.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/073_up.jpg\ndeleted file mode 100644\nindex a80db13..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/073_up.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/074_down.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/074_down.jpg\ndeleted file mode 100644\nindex 0d02479..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/074_down.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/075_front.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/075_front.jpg\ndeleted file mode 100644\nindex a98817f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/075_front.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/076_left.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/076_left.jpg\ndeleted file mode 100644\nindex 8b7479f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/076_left.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/077_right.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/077_right.jpg\ndeleted file mode 100644\nindex afb1fe0..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/077_right.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/078_up.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/078_up.jpg\ndeleted file mode 100644\nindex edfc278..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/078_up.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/079_down.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/079_down.jpg\ndeleted file mode 100644\nindex 97f84d6..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/079_down.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/080_front.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/080_front.jpg\ndeleted file mode 100644\nindex 44bc19f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/080_front.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/081_left.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/081_left.jpg\ndeleted file mode 100644\nindex c68f8a7..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/081_left.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/082_right.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/082_right.jpg\ndeleted file mode 100644\nindex a380fda..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/082_right.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/083_up.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/083_up.jpg\ndeleted file mode 100644\nindex 93c3080..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/083_up.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/084_down.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/084_down.jpg\ndeleted file mode 100644\nindex 7c502e6..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/084_down.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/085_front.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/085_front.jpg\ndeleted file mode 100644\nindex 9f09e70..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/085_front.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/086_left.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/086_left.jpg\ndeleted file mode 100644\nindex cfd459f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/086_left.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/087_right.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/087_right.jpg\ndeleted file mode 100644\nindex 0744528..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/087_right.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/088_up.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/088_up.jpg\ndeleted file mode 100644\nindex f25de28..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/088_up.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/089_down.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/089_down.jpg\ndeleted file mode 100644\nindex f9efed9..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/089_down.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/090_front.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/090_front.jpg\ndeleted file mode 100644\nindex 907187d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/090_front.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/091_left.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/091_left.jpg\ndeleted file mode 100644\nindex fad2bf4..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/091_left.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/092_right.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/092_right.jpg\ndeleted file mode 100644\nindex 6466f7c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/092_right.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/093_up.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/093_up.jpg\ndeleted file mode 100644\nindex 9963f88..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/093_up.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/094_down.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/094_down.jpg\ndeleted file mode 100644\nindex 1895948..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/094_down.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/095_front.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/095_front.jpg\ndeleted file mode 100644\nindex 9c425e6..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/095_front.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/096_left.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/096_left.jpg\ndeleted file mode 100644\nindex ca9902d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/096_left.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/097_right.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/097_right.jpg\ndeleted file mode 100644\nindex ab3f87e..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/097_right.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/098_up.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/098_up.jpg\ndeleted file mode 100644\nindex a207257..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/098_up.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/099_down.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/099_down.jpg\ndeleted file mode 100644\nindex 6d5148b..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106005/099_down.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_0.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_0.jpg\ndeleted file mode 100644\nindex 648fbdc..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_0.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_1.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_1.jpg\ndeleted file mode 100644\nindex 17b54f5..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_1.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_10.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_10.jpg\ndeleted file mode 100644\nindex 77d30be..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_10.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_100.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_100.jpg\ndeleted file mode 100644\nindex 4b94b7e..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_100.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_11.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_11.jpg\ndeleted file mode 100644\nindex d609289..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_11.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_12.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_12.jpg\ndeleted file mode 100644\nindex 12982af..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_12.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_13.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_13.jpg\ndeleted file mode 100644\nindex 16f6d1d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_13.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_14.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_14.jpg\ndeleted file mode 100644\nindex 2aaeb26..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_14.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_15.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_15.jpg\ndeleted file mode 100644\nindex 5310911..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_15.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_16.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_16.jpg\ndeleted file mode 100644\nindex 00c771e..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_16.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_17.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_17.jpg\ndeleted file mode 100644\nindex 7e775d5..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_17.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_18.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_18.jpg\ndeleted file mode 100644\nindex b87b0f5..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_18.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_19.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_19.jpg\ndeleted file mode 100644\nindex 20773f3..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_19.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_2.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_2.jpg\ndeleted file mode 100644\nindex e279843..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_2.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_20.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_20.jpg\ndeleted file mode 100644\nindex 8b280d0..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_20.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_21.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_21.jpg\ndeleted file mode 100644\nindex a119bc0..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_21.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_22.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_22.jpg\ndeleted file mode 100644\nindex 7f5d423..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_22.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_23.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_23.jpg\ndeleted file mode 100644\nindex cbcf03f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_23.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_24.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_24.jpg\ndeleted file mode 100644\nindex 74dfe33..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_24.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_25.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_25.jpg\ndeleted file mode 100644\nindex 819322a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_25.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_26.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_26.jpg\ndeleted file mode 100644\nindex 9b5fb66..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_26.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_27.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_27.jpg\ndeleted file mode 100644\nindex a19ed0d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_27.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_28.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_28.jpg\ndeleted file mode 100644\nindex 6f4a3ff..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_28.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_29.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_29.jpg\ndeleted file mode 100644\nindex 833602e..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_29.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_3.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_3.jpg\ndeleted file mode 100644\nindex 1509b36..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_3.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_30.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_30.jpg\ndeleted file mode 100644\nindex b443a73..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_30.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_31.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_31.jpg\ndeleted file mode 100644\nindex 765c2dc..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_31.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_32.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_32.jpg\ndeleted file mode 100644\nindex 76ad729..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_32.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_33.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_33.jpg\ndeleted file mode 100644\nindex 3f8bbe1..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_33.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_34.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_34.jpg\ndeleted file mode 100644\nindex 932f1d3..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_34.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_35.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_35.jpg\ndeleted file mode 100644\nindex d3ae174..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_35.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_36.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_36.jpg\ndeleted file mode 100644\nindex 133e7e9..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_36.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_37.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_37.jpg\ndeleted file mode 100644\nindex 6c5ec92..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_37.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_38.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_38.jpg\ndeleted file mode 100644\nindex d128b47..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_38.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_39.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_39.jpg\ndeleted file mode 100644\nindex 4c08217..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_39.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_4.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_4.jpg\ndeleted file mode 100644\nindex eb240d7..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_4.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_40.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_40.jpg\ndeleted file mode 100644\nindex e42035a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_40.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_41.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_41.jpg\ndeleted file mode 100644\nindex 9fe65c0..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_41.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_42.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_42.jpg\ndeleted file mode 100644\nindex aa17513..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_42.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_43.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_43.jpg\ndeleted file mode 100644\nindex 595e059..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_43.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_44.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_44.jpg\ndeleted file mode 100644\nindex a7e11f8..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_44.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_45.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_45.jpg\ndeleted file mode 100644\nindex 8c41679..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_45.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_46.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_46.jpg\ndeleted file mode 100644\nindex 56f8b89..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_46.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_47.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_47.jpg\ndeleted file mode 100644\nindex 87be46c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_47.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_48.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_48.jpg\ndeleted file mode 100644\nindex 534000d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_48.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_49.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_49.jpg\ndeleted file mode 100644\nindex 9708204..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_49.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_5.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_5.jpg\ndeleted file mode 100644\nindex 0fc44bb..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_5.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_50.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_50.jpg\ndeleted file mode 100644\nindex 8f137c0..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_50.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_51.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_51.jpg\ndeleted file mode 100644\nindex c4121d4..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_51.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_52.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_52.jpg\ndeleted file mode 100644\nindex a83b9a2..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_52.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_53.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_53.jpg\ndeleted file mode 100644\nindex 43bbfc3..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_53.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_54.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_54.jpg\ndeleted file mode 100644\nindex 4546d3c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_54.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_55.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_55.jpg\ndeleted file mode 100644\nindex d5b343f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_55.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_56.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_56.jpg\ndeleted file mode 100644\nindex 98e3646..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_56.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_57.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_57.jpg\ndeleted file mode 100644\nindex 20ef0d2..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_57.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_58.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_58.jpg\ndeleted file mode 100644\nindex ff9eb3d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_58.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_59.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_59.jpg\ndeleted file mode 100644\nindex fffc69f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_59.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_6.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_6.jpg\ndeleted file mode 100644\nindex 4f22a36..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_6.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_60.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_60.jpg\ndeleted file mode 100644\nindex 31744f2..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_60.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_61.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_61.jpg\ndeleted file mode 100644\nindex 5f5434b..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_61.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_62.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_62.jpg\ndeleted file mode 100644\nindex 24f507c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_62.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_63.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_63.jpg\ndeleted file mode 100644\nindex 2b7a19f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_63.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_64.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_64.jpg\ndeleted file mode 100644\nindex 084f9dd..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_64.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_65.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_65.jpg\ndeleted file mode 100644\nindex 9404fb4..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_65.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_66.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_66.jpg\ndeleted file mode 100644\nindex 420d7cf..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_66.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_67.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_67.jpg\ndeleted file mode 100644\nindex b776afb..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_67.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_68.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_68.jpg\ndeleted file mode 100644\nindex dc32f80..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_68.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_69.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_69.jpg\ndeleted file mode 100644\nindex 6643476..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_69.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_7.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_7.jpg\ndeleted file mode 100644\nindex 4b1664f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_7.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_70.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_70.jpg\ndeleted file mode 100644\nindex 09a87b9..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_70.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_71.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_71.jpg\ndeleted file mode 100644\nindex 5263f93..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_71.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_72.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_72.jpg\ndeleted file mode 100644\nindex fd7437e..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_72.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_73.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_73.jpg\ndeleted file mode 100644\nindex 71dde65..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_73.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_74.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_74.jpg\ndeleted file mode 100644\nindex 87c3d32..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_74.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_75.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_75.jpg\ndeleted file mode 100644\nindex f2068b3..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_75.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_76.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_76.jpg\ndeleted file mode 100644\nindex bbe15d5..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_76.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_77.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_77.jpg\ndeleted file mode 100644\nindex 52f54ec..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_77.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_78.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_78.jpg\ndeleted file mode 100644\nindex b5aafd6..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_78.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_79.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_79.jpg\ndeleted file mode 100644\nindex bfa6e6f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_79.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_8.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_8.jpg\ndeleted file mode 100644\nindex f76edc7..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_8.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_80.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_80.jpg\ndeleted file mode 100644\nindex 79d4f07..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_80.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_81.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_81.jpg\ndeleted file mode 100644\nindex 0343021..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_81.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_82.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_82.jpg\ndeleted file mode 100644\nindex 901d552..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_82.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_83.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_83.jpg\ndeleted file mode 100644\nindex 9599e99..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_83.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_84.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_84.jpg\ndeleted file mode 100644\nindex a25bb4b..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_84.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_85.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_85.jpg\ndeleted file mode 100644\nindex e45be4a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_85.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_86.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_86.jpg\ndeleted file mode 100644\nindex 15a843c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_86.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_87.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_87.jpg\ndeleted file mode 100644\nindex 7655a27..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_87.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_88.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_88.jpg\ndeleted file mode 100644\nindex 132ec2c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_88.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_89.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_89.jpg\ndeleted file mode 100644\nindex 26e3329..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_89.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_9.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_9.jpg\ndeleted file mode 100644\nindex 3ab96e8..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_9.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_90.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_90.jpg\ndeleted file mode 100644\nindex b5a1045..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_90.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_91.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_91.jpg\ndeleted file mode 100644\nindex ee0ecb8..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_91.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_92.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_92.jpg\ndeleted file mode 100644\nindex 32808c7..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_92.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_93.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_93.jpg\ndeleted file mode 100644\nindex 3d1cccf..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_93.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_94.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_94.jpg\ndeleted file mode 100644\nindex c83ac45..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_94.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_95.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_95.jpg\ndeleted file mode 100644\nindex c3f8354..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_95.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_96.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_96.jpg\ndeleted file mode 100644\nindex 818f100..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_96.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_97.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_97.jpg\ndeleted file mode 100644\nindex 8a58ec6..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_97.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_98.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_98.jpg\ndeleted file mode 100644\nindex cf2186f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_98.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_99.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_99.jpg\ndeleted file mode 100644\nindex b50ad32..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106034/b_duyframe_99.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_0.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_0.jpg\ndeleted file mode 100644\nindex 0970038..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_0.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_1.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_1.jpg\ndeleted file mode 100644\nindex 96aab35..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_1.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_10.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_10.jpg\ndeleted file mode 100644\nindex 73bbd40..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_10.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_11.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_11.jpg\ndeleted file mode 100644\nindex 04fb39b..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_11.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_12.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_12.jpg\ndeleted file mode 100644\nindex 52feba4..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_12.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_13.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_13.jpg\ndeleted file mode 100644\nindex f8056ce..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_13.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_14.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_14.jpg\ndeleted file mode 100644\nindex f01e3d4..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_14.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_15.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_15.jpg\ndeleted file mode 100644\nindex 61508f0..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_15.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_16.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_16.jpg\ndeleted file mode 100644\nindex 346398e..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_16.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_17.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_17.jpg\ndeleted file mode 100644\nindex 2d9a96c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_17.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_18.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_18.jpg\ndeleted file mode 100644\nindex 087b4dc..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_18.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_19.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_19.jpg\ndeleted file mode 100644\nindex 64dc4e7..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_19.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_2.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_2.jpg\ndeleted file mode 100644\nindex 188de37..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_2.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_20.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_20.jpg\ndeleted file mode 100644\nindex 0b1df3a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_20.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_21.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_21.jpg\ndeleted file mode 100644\nindex d33ccd7..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_21.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_22.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_22.jpg\ndeleted file mode 100644\nindex 7293c81..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_22.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_23.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_23.jpg\ndeleted file mode 100644\nindex d0a0028..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_23.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_24.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_24.jpg\ndeleted file mode 100644\nindex eac017c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_24.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_25.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_25.jpg\ndeleted file mode 100644\nindex ad6cd85..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_25.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_26.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_26.jpg\ndeleted file mode 100644\nindex e98cf78..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_26.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_27.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_27.jpg\ndeleted file mode 100644\nindex be78197..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_27.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_28.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_28.jpg\ndeleted file mode 100644\nindex adab5f2..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_28.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_29.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_29.jpg\ndeleted file mode 100644\nindex 5530e66..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_29.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_3.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_3.jpg\ndeleted file mode 100644\nindex eae985b..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_3.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_30.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_30.jpg\ndeleted file mode 100644\nindex 3c1d287..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_30.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_31.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_31.jpg\ndeleted file mode 100644\nindex fb092f1..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_31.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_32.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_32.jpg\ndeleted file mode 100644\nindex d4e1238..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_32.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_33.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_33.jpg\ndeleted file mode 100644\nindex e2d0170..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_33.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_34.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_34.jpg\ndeleted file mode 100644\nindex b99a543..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_34.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_35.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_35.jpg\ndeleted file mode 100644\nindex 5961ff3..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_35.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_36.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_36.jpg\ndeleted file mode 100644\nindex 2a1919b..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_36.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_37.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_37.jpg\ndeleted file mode 100644\nindex 90154bb..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_37.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_38.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_38.jpg\ndeleted file mode 100644\nindex 1d2b312..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_38.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_39.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_39.jpg\ndeleted file mode 100644\nindex fd7050b..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_39.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_4.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_4.jpg\ndeleted file mode 100644\nindex 2ef3a13..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_4.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_40.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_40.jpg\ndeleted file mode 100644\nindex 980af40..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_40.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_41.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_41.jpg\ndeleted file mode 100644\nindex 2343197..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_41.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_42.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_42.jpg\ndeleted file mode 100644\nindex 97dfc57..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_42.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_43.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_43.jpg\ndeleted file mode 100644\nindex 9806b69..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_43.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_44.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_44.jpg\ndeleted file mode 100644\nindex f80b16b..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_44.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_45.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_45.jpg\ndeleted file mode 100644\nindex 2f84c44..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_45.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_46.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_46.jpg\ndeleted file mode 100644\nindex 1aa29d2..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_46.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_47.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_47.jpg\ndeleted file mode 100644\nindex e92546f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_47.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_48.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_48.jpg\ndeleted file mode 100644\nindex 866861f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_48.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_49.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_49.jpg\ndeleted file mode 100644\nindex 1ed539a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_49.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_5.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_5.jpg\ndeleted file mode 100644\nindex 435d509..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_5.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_50.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_50.jpg\ndeleted file mode 100644\nindex 6e9bf3a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_50.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_51.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_51.jpg\ndeleted file mode 100644\nindex 3be08d7..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_51.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_52.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_52.jpg\ndeleted file mode 100644\nindex fca566c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_52.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_53.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_53.jpg\ndeleted file mode 100644\nindex bf02fab..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_53.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_54.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_54.jpg\ndeleted file mode 100644\nindex d65ea81..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_54.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_55.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_55.jpg\ndeleted file mode 100644\nindex 06975fe..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_55.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_56.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_56.jpg\ndeleted file mode 100644\nindex f37b539..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_56.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_57.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_57.jpg\ndeleted file mode 100644\nindex f6f8e43..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_57.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_58.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_58.jpg\ndeleted file mode 100644\nindex a2e20d9..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_58.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_59.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_59.jpg\ndeleted file mode 100644\nindex 9d1aef3..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_59.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_6.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_6.jpg\ndeleted file mode 100644\nindex e1d66e0..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_6.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_60.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_60.jpg\ndeleted file mode 100644\nindex 785bf96..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_60.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_61.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_61.jpg\ndeleted file mode 100644\nindex 770ca35..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_61.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_62.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_62.jpg\ndeleted file mode 100644\nindex e8bae6b..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_62.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_63.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_63.jpg\ndeleted file mode 100644\nindex d8c6e26..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_63.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_64.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_64.jpg\ndeleted file mode 100644\nindex 7781be7..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_64.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_65.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_65.jpg\ndeleted file mode 100644\nindex 2e22f0f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_65.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_66.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_66.jpg\ndeleted file mode 100644\nindex a63234c..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_66.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_67.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_67.jpg\ndeleted file mode 100644\nindex f7fa651..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_67.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_68.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_68.jpg\ndeleted file mode 100644\nindex bcd4f6e..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_68.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_69.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_69.jpg\ndeleted file mode 100644\nindex 0a1a9e2..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_69.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_7.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_7.jpg\ndeleted file mode 100644\nindex 61c309d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_7.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_70.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_70.jpg\ndeleted file mode 100644\nindex dd47bbe..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_70.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_71.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_71.jpg\ndeleted file mode 100644\nindex 79a89dd..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_71.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_72.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_72.jpg\ndeleted file mode 100644\nindex b5a431a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_72.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_73.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_73.jpg\ndeleted file mode 100644\nindex 7d09279..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_73.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_74.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_74.jpg\ndeleted file mode 100644\nindex e1f5098..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_74.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_75.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_75.jpg\ndeleted file mode 100644\nindex d29ca56..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_75.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_76.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_76.jpg\ndeleted file mode 100644\nindex 556a1fe..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_76.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_77.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_77.jpg\ndeleted file mode 100644\nindex faa1573..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_77.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_78.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_78.jpg\ndeleted file mode 100644\nindex 583a4e0..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_78.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_79.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_79.jpg\ndeleted file mode 100644\nindex 9d29dea..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_79.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_8.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_8.jpg\ndeleted file mode 100644\nindex fa79eba..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_8.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_80.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_80.jpg\ndeleted file mode 100644\nindex 75300d5..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_80.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_81.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_81.jpg\ndeleted file mode 100644\nindex af21642..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_81.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_82.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_82.jpg\ndeleted file mode 100644\nindex f83373d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_82.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_83.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_83.jpg\ndeleted file mode 100644\nindex 547e464..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_83.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_84.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_84.jpg\ndeleted file mode 100644\nindex dd2085b..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_84.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_85.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_85.jpg\ndeleted file mode 100644\nindex 1d5935d..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_85.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_86.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_86.jpg\ndeleted file mode 100644\nindex 6419aff..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_86.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_87.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_87.jpg\ndeleted file mode 100644\nindex 5f52b7e..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_87.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_88.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_88.jpg\ndeleted file mode 100644\nindex 41d190a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_88.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_89.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_89.jpg\ndeleted file mode 100644\nindex 6dc94f3..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_89.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_9.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_9.jpg\ndeleted file mode 100644\nindex 103342a..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_9.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_90.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_90.jpg\ndeleted file mode 100644\nindex b2e2d73..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_90.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_91.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_91.jpg\ndeleted file mode 100644\nindex 73db4e8..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_91.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_92.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_92.jpg\ndeleted file mode 100644\nindex 0b7c3ee..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_92.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_93.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_93.jpg\ndeleted file mode 100644\nindex 57e1c39..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_93.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_94.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_94.jpg\ndeleted file mode 100644\nindex 9a74b27..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_94.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_95.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_95.jpg\ndeleted file mode 100644\nindex bb6cd9f..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_95.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_96.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_96.jpg\ndeleted file mode 100644\nindex f2236db..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_96.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_97.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_97.jpg\ndeleted file mode 100644\nindex da80b62..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_97.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_98.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_98.jpg\ndeleted file mode 100644\nindex 8126366..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_98.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_99.jpg b/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_99.jpg\ndeleted file mode 100644\nindex 7923cab..0000000\nBinary files a/BackEnd/Face_AI/Dataset/FaceData/raw/K205480106035/frame_99.jpg and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Models/20180402-114759.pb b/BackEnd/Face_AI/Models/20180402-114759.pb\ndeleted file mode 100644\nindex 39b4ed7..0000000\nBinary files a/BackEnd/Face_AI/Models/20180402-114759.pb and /dev/null differ\ndiff --git a/BackEnd/Face_AI/Models/facemodel.pkl b/BackEnd/Face_AI/Models/facemodel.pkl\ndeleted file mode 100644\nindex a2b93eb..0000000\nBinary files a/BackEnd/Face_AI/Models/facemodel.pkl and /dev/null differ\ndiff --git a/BackEnd/Face_AI/img.py b/BackEnd/Face_AI/img.py\ndeleted file mode 100644\nindex fa99594..0000000\n--- a/BackEnd/Face_AI/img.py\n+++ /dev/null\n@@ -1,44 +0,0 @@\n-import cv2\n-import os\n-\n-\n-def capture_frames(video_path, output_folder, num_frames=100):\n-    # T\xe1\xba\xa1o th\xc6\xb0 m\xe1\xbb\xa5c \xc4\x91\xe1\xba\xa7u ra n\xe1\xba\xbfu n\xc3\xb3 kh\xc3\xb4ng t\xe1\xbb\x93n t\xe1\xba\xa1i\n-    if not os.path.exists(output_folder):\n-        os.makedirs(output_folder)\n-\n-    # M\xe1\xbb\x9f video\n-    cap = cv2.VideoCapture(video_path)\n-    if not cap.isOpened():\n-        print("Kh\xc3\xb4ng th\xe1\xbb\x83 m\xe1\xbb\x9f video.")\n-        return\n-\n-    frame_count = 0\n-    success = True\n-\n-    while frame_count < num_frames and success:\n-        # \xc4\x90\xe1\xbb\x8dc frame t\xe1\xbb\xab video\n-        success, frame = cap.read()\n-        if not success:\n-            break\n-\n-        # L\xc6\xb0u frame v\xc3\xa0o th\xc6\xb0 m\xe1\xbb\xa5c \xc4\x91\xe1\xba\xa7u ra\n-        output_path = os.path.join(output_folder, f"frame_{frame_count}.jpg")\n-        cv2.imwrite(output_path, frame)\n-\n-        frame_count += 1\n-\n-    cap.release()\n-    cv2.destroyAllWindows()\n-\n-\n-def main():\n-    video_path = r"C:\\Users\\57\\Downloads\\5527066175944.mp4"\n-    output_folder = r"D:\\AI_PROJECT\\ProJect_DiemDanh\\BackEnd\\Face_AI\\Dataset\\FaceData\\raw\\K205480106035"\n-    num_frames = 100\n-\n-    capture_frames(video_path, output_folder, num_frames)\n-\n-\n-if __name__ == "__main__":\n-    main()\ndiff --git a/BackEnd/Face_AI/run.py b/BackEnd/Face_AI/run.py\ndeleted file mode 100644\nindex c2ee1ad..0000000\n--- a/BackEnd/Face_AI/run.py\n+++ /dev/null\n@@ -1,27 +0,0 @@\n-import subprocess\n-\n-def run_command(command):\n-    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n-    stdout, stderr = process.communicate()\n-    return stdout, stderr\n-\n-# C\xc3\xa2u l\xe1\xbb\x87nh c\xe1\xba\xaft \xe1\xba\xa3nh khu\xc3\xb4n m\xe1\xba\xb7t t\xe1\xbb\xab \xe1\xba\xa3nh g\xe1\xbb\x91c\n-align_command = "python src/align_dataset_mtcnn.py Dataset/FaceData/raw Dataset/FaceData/processed --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25"\n-\n-# C\xc3\xa2u l\xe1\xbb\x87nh t\xe1\xba\xa1o model\n-model_command = "python src/classifier.py TRAIN Dataset/FaceData/processed Models/20180402-114759.pb Models/facemodel.pkl --batch_size 1000"\n-\n-# Ch\xe1\xba\xa1y c\xe1\xba\xa3 hai c\xc3\xa2u l\xe1\xbb\x87nh\n-align_output, align_error = run_command(align_command)\n-model_output, model_error = run_command(model_command)\n-\n-# Hi\xe1\xbb\x83n th\xe1\xbb\x8b k\xe1\xba\xbft qu\xe1\xba\xa3 (t\xc3\xb9y ch\xe1\xbb\x8dn)\n-print("K\xe1\xba\xbft qu\xe1\xba\xa3 c\xe1\xbb\xa7a c\xc3\xa2u l\xe1\xbb\x87nh c\xe1\xba\xaft \xe1\xba\xa3nh khu\xc3\xb4n m\xe1\xba\xb7t t\xe1\xbb\xab \xe1\xba\xa3nh g\xe1\xbb\x91c:")\n-print(align_output.decode("utf-8"))\n-print("L\xe1\xbb\x97i (n\xe1\xba\xbfu c\xc3\xb3):")\n-print(align_error.decode("utf-8"))\n-\n-print("\\nK\xe1\xba\xbft qu\xe1\xba\xa3 c\xe1\xbb\xa7a c\xc3\xa2u l\xe1\xbb\x87nh t\xe1\xba\xa1o model:")\n-print(model_output.decode("utf-8"))\n-print("L\xe1\xbb\x97i (n\xe1\xba\xbfu c\xc3\xb3):")\n-print(model_error.decode("utf-8"))\ndiff --git a/BackEnd/Face_AI/src/Danhgia.py b/BackEnd/Face_AI/src/Danhgia.py\ndeleted file mode 100644\nindex a775d91..0000000\n--- a/BackEnd/Face_AI/src/Danhgia.py\n+++ /dev/null\n@@ -1,95 +0,0 @@\n-import cv2\n-import numpy as np\n-import os\n-import tensorflow as tf\n-import facenet\n-import align.detect_face\n-import pickle\n-from tkinter import *\n-from tkinter import filedialog\n-from PIL import Image, ImageTk\n-import tkinter as tk\n-from sklearn.svm import SVC\n-from sklearn.metrics import accuracy_score\n-import matplotlib.pyplot as plt\n-\n-class FaceRecognitionApp:\n-    def __init__(self, root):\n-        # ... (ph\xe1\xba\xa7n kh\xe1\xbb\x9fi t\xe1\xba\xa1o gi\xe1\xbb\xaf nguy\xc3\xaan)\n-\n-        # Th\xc3\xaam m\xe1\xbb\x99t n\xc3\xbat \xc4\x91\xe1\xbb\x83 b\xe1\xba\xaft \xc4\x91\xe1\xba\xa7u qu\xc3\xa1 tr\xc3\xacnh \xc4\x91\xc3\xa1nh gi\xc3\xa1 m\xc3\xb4 h\xc3\xacnh\n-        self.results_label = Text(root, width=40, height=10)\n-        self.results_label.pack(pady=5, anchor=NE)\n-\n-        self.evaluate_model_button = Button(root, text="\xc4\x90\xc3\xa1nh gi\xc3\xa1 m\xc3\xb4 h\xc3\xacnh", command=self.evaluate_model)\n-        self.evaluate_model_button.pack(pady=5, anchor=NE)\n-\n-    def evaluate_model(self):\n-        # Load paths to classifier and FaceNet model\n-        CLASSIFIER_PATH = r\'../Models/facemodel.pkl\'  # \xc4\x90\xc6\xb0\xe1\xbb\x9dng d\xe1\xba\xabn \xc4\x91\xe1\xba\xbfn file classifier\n-        FACENET_MODEL_PATH = \'../Models/20180402-114759.pb\'  # \xc4\x90\xc6\xb0\xe1\xbb\x9dng d\xe1\xba\xabn \xc4\x91\xe1\xba\xbfn file FaceNet model\n-\n-        # Load classifier model\n-        with open(CLASSIFIER_PATH, \'rb\') as file:\n-            model, class_names = pickle.load(file)\n-\n-        # Load FaceNet model\n-        with tf.Graph().as_default():\n-            sess = tf.compat.v1.Session()\n-            facenet.load_model(FACENET_MODEL_PATH)\n-            images_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("input:0")\n-            embeddings = tf.compat.v1.get_default_graph().get_tensor_by_name("embeddings:0")\n-            phase_train_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("phase_train:0")\n-            embedding_size = embeddings.get_shape()[1]\n-\n-        # Load paths and labels for the test dataset\n-        dataset = facenet.get_dataset("../Dataset/FaceData/processed")\n-        paths, labels = facenet.get_image_paths_and_labels(dataset)\n-\n-        # Calculate embeddings for the test dataset\n-        emb_array = np.zeros((len(paths), embedding_size))\n-        for i in range(len(paths)):\n-            img = cv2.imread(paths[i])\n-            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n-            scaled = cv2.resize(img, (160, 160), interpolation=cv2.INTER_CUBIC)\n-            scaled = facenet.prewhiten(scaled)\n-            scaled_reshape = scaled.reshape(-1, 160, 160, 3)\n-            feed_dict = {images_placeholder: scaled_reshape, phase_train_placeholder: False}\n-            emb_array[i, :] = sess.run(embeddings, feed_dict=feed_dict)\n-\n-        # Predict labels for the test dataset\n-        predictions = model.predict(emb_array)\n-        accuracy = accuracy_score(labels, predictions)\n-\n-        # Display accuracy in the results label\n-        if hasattr(self, \'results_label\') and isinstance(self.results_label, Text):\n-            self.results_label.delete(\'1.0\', END)\n-            self.results_label.insert(END, f"\xc4\x90\xe1\xbb\x99 ch\xc3\xadnh x\xc3\xa1c tr\xc3\xaan t\xe1\xba\xadp ki\xe1\xbb\x83m tra: {accuracy:.2%}")\n-\n-        # V\xe1\xba\xbd bi\xe1\xbb\x83u \xc4\x91\xe1\xbb\x93\n-        self.plot_accuracy_curve(model, emb_array, labels, class_names)\n-\n-    def plot_accuracy_curve(self, model, emb_array, labels, class_names):\n-        # V\xe1\xba\xbd bi\xe1\xbb\x83u \xc4\x91\xe1\xbb\x93 \xc4\x91\xe1\xbb\x99 ch\xc3\xadnh x\xc3\xa1c\n-        predictions = model.predict_proba(emb_array)\n-        best_class_indices = np.argmax(predictions, axis=1)\n-        best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\n-\n-        plt.figure(figsize=(10, 6))\n-        plt.plot(range(len(best_class_indices)), best_class_probabilities, marker=\'o\', linestyle=\'-\')\n-        plt.xticks(range(len(best_class_indices)), [class_names[i] for i in best_class_indices], rotation=\'vertical\')\n-        plt.xlabel(\'L\xe1\xbb\x9bp\')\n-        plt.ylabel(\'\xc4\x90\xe1\xbb\x99 ch\xc3\xadnh x\xc3\xa1c\')\n-        plt.title(\'\xc4\x90\xe1\xbb\x99 ch\xc3\xadnh x\xc3\xa1c c\xe1\xbb\xa7a m\xc3\xb4 h\xc3\xacnh tr\xc3\xaan t\xe1\xba\xadp ki\xe1\xbb\x83m tra\')\n-        plt.grid(True)\n-        plt.tight_layout()\n-        plt.show()\n-\n-\n-def main():\n-    root = Tk()\n-    app = FaceRecognitionApp(root)\n-    root.mainloop()\n-\n-if __name__ == "__main__":\n-    main()\ndiff --git a/BackEnd/Face_AI/src/Dataset/FaceData/processed/revision_info.txt b/BackEnd/Face_AI/src/Dataset/FaceData/processed/revision_info.txt\ndeleted file mode 100644\nindex 78c108a..0000000\n--- a/BackEnd/Face_AI/src/Dataset/FaceData/processed/revision_info.txt\n+++ /dev/null\n@@ -1,7 +0,0 @@\n-arguments: align_dataset_mtcnn.py Dataset/FaceData/raw Dataset/FaceData/processed --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25\n---------------------\n-tensorflow version: 2.15.0\n---------------------\n-git hash: b\'2fd8eaf22e1fa95c9f488c1f5760e2964436925d\'\n---------------------\n-b\'diff --git a/Dataset/FaceData/processed/Bui Anh Tuan/0.png b/Dataset/FaceData/processed/Bui Anh Tuan/0.png\\ndeleted file mode 100644\\nindex d208cad..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/0.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/1.png b/Dataset/FaceData/processed/Bui Anh Tuan/1.png\\ndeleted file mode 100644\\nindex 7d01ea8..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/10.png b/Dataset/FaceData/processed/Bui Anh Tuan/10.png\\ndeleted file mode 100644\\nindex 1d705fd..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/10.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/11.png b/Dataset/FaceData/processed/Bui Anh Tuan/11.png\\ndeleted file mode 100644\\nindex 428190b..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/11.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/12.png b/Dataset/FaceData/processed/Bui Anh Tuan/12.png\\ndeleted file mode 100644\\nindex cc803bc..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/12.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/13.png b/Dataset/FaceData/processed/Bui Anh Tuan/13.png\\ndeleted file mode 100644\\nindex 2125d8e..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/13.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/14.png b/Dataset/FaceData/processed/Bui Anh Tuan/14.png\\ndeleted file mode 100644\\nindex ee5e248..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/14.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/15.png b/Dataset/FaceData/processed/Bui Anh Tuan/15.png\\ndeleted file mode 100644\\nindex 254819b..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/15.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/16.png b/Dataset/FaceData/processed/Bui Anh Tuan/16.png\\ndeleted file mode 100644\\nindex 1fdde40..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/16.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/17.png b/Dataset/FaceData/processed/Bui Anh Tuan/17.png\\ndeleted file mode 100644\\nindex 35e2dec..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/17.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/18.png b/Dataset/FaceData/processed/Bui Anh Tuan/18.png\\ndeleted file mode 100644\\nindex 45b3e5a..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/18.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/19.png b/Dataset/FaceData/processed/Bui Anh Tuan/19.png\\ndeleted file mode 100644\\nindex 1c81d1c..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/19.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/2.png b/Dataset/FaceData/processed/Bui Anh Tuan/2.png\\ndeleted file mode 100644\\nindex bdf04d7..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/20.png b/Dataset/FaceData/processed/Bui Anh Tuan/20.png\\ndeleted file mode 100644\\nindex db2b747..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/20.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/21.png b/Dataset/FaceData/processed/Bui Anh Tuan/21.png\\ndeleted file mode 100644\\nindex c8d3ed5..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/21.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/23.png b/Dataset/FaceData/processed/Bui Anh Tuan/23.png\\ndeleted file mode 100644\\nindex 7e722bb..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/23.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/24.png b/Dataset/FaceData/processed/Bui Anh Tuan/24.png\\ndeleted file mode 100644\\nindex 403ce33..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/24.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/25.png b/Dataset/FaceData/processed/Bui Anh Tuan/25.png\\ndeleted file mode 100644\\nindex 35d9f6d..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/25.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/26.png b/Dataset/FaceData/processed/Bui Anh Tuan/26.png\\ndeleted file mode 100644\\nindex d39ca33..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/26.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/27.png b/Dataset/FaceData/processed/Bui Anh Tuan/27.png\\ndeleted file mode 100644\\nindex 772ca1f..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/27.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/28.png b/Dataset/FaceData/processed/Bui Anh Tuan/28.png\\ndeleted file mode 100644\\nindex 9539230..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/28.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/29.png b/Dataset/FaceData/processed/Bui Anh Tuan/29.png\\ndeleted file mode 100644\\nindex 0847627..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/29.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/3.png b/Dataset/FaceData/processed/Bui Anh Tuan/3.png\\ndeleted file mode 100644\\nindex a93578b..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/30.png b/Dataset/FaceData/processed/Bui Anh Tuan/30.png\\ndeleted file mode 100644\\nindex 70c6bde..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/30.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/31.png b/Dataset/FaceData/processed/Bui Anh Tuan/31.png\\ndeleted file mode 100644\\nindex 7f16363..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/31.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/33.png b/Dataset/FaceData/processed/Bui Anh Tuan/33.png\\ndeleted file mode 100644\\nindex 9bd6f51..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/33.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/34.png b/Dataset/FaceData/processed/Bui Anh Tuan/34.png\\ndeleted file mode 100644\\nindex 40cf796..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/34.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/35.png b/Dataset/FaceData/processed/Bui Anh Tuan/35.png\\ndeleted file mode 100644\\nindex 8a453db..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/35.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/36.png b/Dataset/FaceData/processed/Bui Anh Tuan/36.png\\ndeleted file mode 100644\\nindex 3bc664a..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/36.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/37.png b/Dataset/FaceData/processed/Bui Anh Tuan/37.png\\ndeleted file mode 100644\\nindex d026391..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/37.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/38.png b/Dataset/FaceData/processed/Bui Anh Tuan/38.png\\ndeleted file mode 100644\\nindex d28d75a..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/38.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/39.png b/Dataset/FaceData/processed/Bui Anh Tuan/39.png\\ndeleted file mode 100644\\nindex 9b65b4c..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/39.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/4.png b/Dataset/FaceData/processed/Bui Anh Tuan/4.png\\ndeleted file mode 100644\\nindex b0465e2..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/40.png b/Dataset/FaceData/processed/Bui Anh Tuan/40.png\\ndeleted file mode 100644\\nindex ecf7bb5..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/40.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/41.png b/Dataset/FaceData/processed/Bui Anh Tuan/41.png\\ndeleted file mode 100644\\nindex c33612b..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/41.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/42.png b/Dataset/FaceData/processed/Bui Anh Tuan/42.png\\ndeleted file mode 100644\\nindex 410c9d6..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/42.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/43.png b/Dataset/FaceData/processed/Bui Anh Tuan/43.png\\ndeleted file mode 100644\\nindex 9dbf1d0..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/43.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/44.png b/Dataset/FaceData/processed/Bui Anh Tuan/44.png\\ndeleted file mode 100644\\nindex b994783..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/44.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/45.png b/Dataset/FaceData/processed/Bui Anh Tuan/45.png\\ndeleted file mode 100644\\nindex 530c524..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/45.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/46.png b/Dataset/FaceData/processed/Bui Anh Tuan/46.png\\ndeleted file mode 100644\\nindex 94d319e..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/46.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/47.png b/Dataset/FaceData/processed/Bui Anh Tuan/47.png\\ndeleted file mode 100644\\nindex 912286e..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/47.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/5.png b/Dataset/FaceData/processed/Bui Anh Tuan/5.png\\ndeleted file mode 100644\\nindex ac78868..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/5.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/6.png b/Dataset/FaceData/processed/Bui Anh Tuan/6.png\\ndeleted file mode 100644\\nindex 3d4db70..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/6.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/7.png b/Dataset/FaceData/processed/Bui Anh Tuan/7.png\\ndeleted file mode 100644\\nindex 5d91246..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/7.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/8.png b/Dataset/FaceData/processed/Bui Anh Tuan/8.png\\ndeleted file mode 100644\\nindex d5b9f07..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/8.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Bui Anh Tuan/9.png b/Dataset/FaceData/processed/Bui Anh Tuan/9.png\\ndeleted file mode 100644\\nindex 735e0c4..0000000\\nBinary files a/Dataset/FaceData/processed/Bui Anh Tuan/9.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/0.png b/Dataset/FaceData/processed/Dam vinh hung/0.png\\ndeleted file mode 100644\\nindex a5de1f4..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/0.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/1.png b/Dataset/FaceData/processed/Dam vinh hung/1.png\\ndeleted file mode 100644\\nindex 1a784f2..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/10.png b/Dataset/FaceData/processed/Dam vinh hung/10.png\\ndeleted file mode 100644\\nindex 51b13be..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/10.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/11.png b/Dataset/FaceData/processed/Dam vinh hung/11.png\\ndeleted file mode 100644\\nindex 260b7b4..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/11.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/12.png b/Dataset/FaceData/processed/Dam vinh hung/12.png\\ndeleted file mode 100644\\nindex 228d251..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/12.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/13.png b/Dataset/FaceData/processed/Dam vinh hung/13.png\\ndeleted file mode 100644\\nindex f1da2c0..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/13.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/14.png b/Dataset/FaceData/processed/Dam vinh hung/14.png\\ndeleted file mode 100644\\nindex 0f0b260..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/14.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/15.png b/Dataset/FaceData/processed/Dam vinh hung/15.png\\ndeleted file mode 100644\\nindex 25ef426..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/15.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/16.png b/Dataset/FaceData/processed/Dam vinh hung/16.png\\ndeleted file mode 100644\\nindex 3a79252..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/16.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/17.png b/Dataset/FaceData/processed/Dam vinh hung/17.png\\ndeleted file mode 100644\\nindex a266dde..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/17.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/18.png b/Dataset/FaceData/processed/Dam vinh hung/18.png\\ndeleted file mode 100644\\nindex ab3d08a..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/18.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/19.png b/Dataset/FaceData/processed/Dam vinh hung/19.png\\ndeleted file mode 100644\\nindex 2f10557..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/19.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/2.png b/Dataset/FaceData/processed/Dam vinh hung/2.png\\ndeleted file mode 100644\\nindex afa1b9f..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/20.png b/Dataset/FaceData/processed/Dam vinh hung/20.png\\ndeleted file mode 100644\\nindex 286cf7f..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/20.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/21.png b/Dataset/FaceData/processed/Dam vinh hung/21.png\\ndeleted file mode 100644\\nindex b0fddc6..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/21.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/22.png b/Dataset/FaceData/processed/Dam vinh hung/22.png\\ndeleted file mode 100644\\nindex 72fbb32..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/22.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/23.png b/Dataset/FaceData/processed/Dam vinh hung/23.png\\ndeleted file mode 100644\\nindex e40bb0c..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/23.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/24.png b/Dataset/FaceData/processed/Dam vinh hung/24.png\\ndeleted file mode 100644\\nindex cb035d8..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/24.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/25.png b/Dataset/FaceData/processed/Dam vinh hung/25.png\\ndeleted file mode 100644\\nindex 18c6740..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/25.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/26.png b/Dataset/FaceData/processed/Dam vinh hung/26.png\\ndeleted file mode 100644\\nindex 84e8685..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/26.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/27.png b/Dataset/FaceData/processed/Dam vinh hung/27.png\\ndeleted file mode 100644\\nindex a7f7946..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/27.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/28.png b/Dataset/FaceData/processed/Dam vinh hung/28.png\\ndeleted file mode 100644\\nindex 6c3e28f..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/28.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/29.png b/Dataset/FaceData/processed/Dam vinh hung/29.png\\ndeleted file mode 100644\\nindex eab9648..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/29.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/3.png b/Dataset/FaceData/processed/Dam vinh hung/3.png\\ndeleted file mode 100644\\nindex 84e981c..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/30.png b/Dataset/FaceData/processed/Dam vinh hung/30.png\\ndeleted file mode 100644\\nindex 4a07351..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/30.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/31.png b/Dataset/FaceData/processed/Dam vinh hung/31.png\\ndeleted file mode 100644\\nindex b916827..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/31.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/32.png b/Dataset/FaceData/processed/Dam vinh hung/32.png\\ndeleted file mode 100644\\nindex c99130d..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/32.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/33.png b/Dataset/FaceData/processed/Dam vinh hung/33.png\\ndeleted file mode 100644\\nindex 3e57cf8..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/33.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/34.png b/Dataset/FaceData/processed/Dam vinh hung/34.png\\ndeleted file mode 100644\\nindex cc8d7d5..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/34.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/35.png b/Dataset/FaceData/processed/Dam vinh hung/35.png\\ndeleted file mode 100644\\nindex c079528..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/35.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/36.png b/Dataset/FaceData/processed/Dam vinh hung/36.png\\ndeleted file mode 100644\\nindex cf473fd..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/36.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/37.png b/Dataset/FaceData/processed/Dam vinh hung/37.png\\ndeleted file mode 100644\\nindex a5c07ff..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/37.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/38.png b/Dataset/FaceData/processed/Dam vinh hung/38.png\\ndeleted file mode 100644\\nindex 4fc2b5c..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/38.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/39.png b/Dataset/FaceData/processed/Dam vinh hung/39.png\\ndeleted file mode 100644\\nindex 59b335c..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/39.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/4.png b/Dataset/FaceData/processed/Dam vinh hung/4.png\\ndeleted file mode 100644\\nindex 51a26b6..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/40.png b/Dataset/FaceData/processed/Dam vinh hung/40.png\\ndeleted file mode 100644\\nindex 71fa193..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/40.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/41.png b/Dataset/FaceData/processed/Dam vinh hung/41.png\\ndeleted file mode 100644\\nindex 47d17e4..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/41.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/42.png b/Dataset/FaceData/processed/Dam vinh hung/42.png\\ndeleted file mode 100644\\nindex 90983a9..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/42.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/43.png b/Dataset/FaceData/processed/Dam vinh hung/43.png\\ndeleted file mode 100644\\nindex c20300f..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/43.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/5.png b/Dataset/FaceData/processed/Dam vinh hung/5.png\\ndeleted file mode 100644\\nindex 11223bf..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/5.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/6.png b/Dataset/FaceData/processed/Dam vinh hung/6.png\\ndeleted file mode 100644\\nindex bed9681..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/6.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/7.png b/Dataset/FaceData/processed/Dam vinh hung/7.png\\ndeleted file mode 100644\\nindex 56edb70..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/7.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/8.png b/Dataset/FaceData/processed/Dam vinh hung/8.png\\ndeleted file mode 100644\\nindex 896e50d..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/8.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Dam vinh hung/9.png b/Dataset/FaceData/processed/Dam vinh hung/9.png\\ndeleted file mode 100644\\nindex fc1ad8d..0000000\\nBinary files a/Dataset/FaceData/processed/Dam vinh hung/9.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/0.png b/Dataset/FaceData/processed/Den Vau/0.png\\ndeleted file mode 100644\\nindex 2b9eb60..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/0.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/1.png b/Dataset/FaceData/processed/Den Vau/1.png\\ndeleted file mode 100644\\nindex c636527..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/10.png b/Dataset/FaceData/processed/Den Vau/10.png\\ndeleted file mode 100644\\nindex 08beab8..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/10.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/11.png b/Dataset/FaceData/processed/Den Vau/11.png\\ndeleted file mode 100644\\nindex 872918d..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/11.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/12.png b/Dataset/FaceData/processed/Den Vau/12.png\\ndeleted file mode 100644\\nindex c439740..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/12.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/13.png b/Dataset/FaceData/processed/Den Vau/13.png\\ndeleted file mode 100644\\nindex 88b20d8..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/13.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/14.png b/Dataset/FaceData/processed/Den Vau/14.png\\ndeleted file mode 100644\\nindex 4934eee..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/14.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/15.png b/Dataset/FaceData/processed/Den Vau/15.png\\ndeleted file mode 100644\\nindex 391a973..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/15.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/16.png b/Dataset/FaceData/processed/Den Vau/16.png\\ndeleted file mode 100644\\nindex 292bdff..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/16.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/17.png b/Dataset/FaceData/processed/Den Vau/17.png\\ndeleted file mode 100644\\nindex 2d49a70..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/17.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/18.png b/Dataset/FaceData/processed/Den Vau/18.png\\ndeleted file mode 100644\\nindex 2caa36d..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/18.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/19.png b/Dataset/FaceData/processed/Den Vau/19.png\\ndeleted file mode 100644\\nindex de1e75b..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/19.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/2.png b/Dataset/FaceData/processed/Den Vau/2.png\\ndeleted file mode 100644\\nindex cc7a6f8..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/20.png b/Dataset/FaceData/processed/Den Vau/20.png\\ndeleted file mode 100644\\nindex 96daa2e..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/20.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/21.png b/Dataset/FaceData/processed/Den Vau/21.png\\ndeleted file mode 100644\\nindex a15a654..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/21.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/22.png b/Dataset/FaceData/processed/Den Vau/22.png\\ndeleted file mode 100644\\nindex b5ee1ca..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/22.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/23.png b/Dataset/FaceData/processed/Den Vau/23.png\\ndeleted file mode 100644\\nindex f5061d6..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/23.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/24.png b/Dataset/FaceData/processed/Den Vau/24.png\\ndeleted file mode 100644\\nindex 4403452..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/24.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/25.png b/Dataset/FaceData/processed/Den Vau/25.png\\ndeleted file mode 100644\\nindex f43a82f..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/25.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/26.png b/Dataset/FaceData/processed/Den Vau/26.png\\ndeleted file mode 100644\\nindex 238bb13..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/26.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/27.png b/Dataset/FaceData/processed/Den Vau/27.png\\ndeleted file mode 100644\\nindex f2d0a3e..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/27.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/28.png b/Dataset/FaceData/processed/Den Vau/28.png\\ndeleted file mode 100644\\nindex b2e0c47..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/28.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/29.png b/Dataset/FaceData/processed/Den Vau/29.png\\ndeleted file mode 100644\\nindex 68f6264..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/29.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/3.png b/Dataset/FaceData/processed/Den Vau/3.png\\ndeleted file mode 100644\\nindex 3b94ef0..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/30.png b/Dataset/FaceData/processed/Den Vau/30.png\\ndeleted file mode 100644\\nindex 125c750..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/30.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/31.png b/Dataset/FaceData/processed/Den Vau/31.png\\ndeleted file mode 100644\\nindex 8124bb4..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/31.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/32.png b/Dataset/FaceData/processed/Den Vau/32.png\\ndeleted file mode 100644\\nindex e624e82..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/32.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/34.png b/Dataset/FaceData/processed/Den Vau/34.png\\ndeleted file mode 100644\\nindex 8ff7f41..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/34.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/35.png b/Dataset/FaceData/processed/Den Vau/35.png\\ndeleted file mode 100644\\nindex 65763a4..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/35.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/36.png b/Dataset/FaceData/processed/Den Vau/36.png\\ndeleted file mode 100644\\nindex 7e24814..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/36.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/38.png b/Dataset/FaceData/processed/Den Vau/38.png\\ndeleted file mode 100644\\nindex 7ed391e..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/38.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/39.png b/Dataset/FaceData/processed/Den Vau/39.png\\ndeleted file mode 100644\\nindex b13d9a6..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/39.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/4.png b/Dataset/FaceData/processed/Den Vau/4.png\\ndeleted file mode 100644\\nindex 57ee4e3..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/40.png b/Dataset/FaceData/processed/Den Vau/40.png\\ndeleted file mode 100644\\nindex 46752d4..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/40.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/41.png b/Dataset/FaceData/processed/Den Vau/41.png\\ndeleted file mode 100644\\nindex 303f14b..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/41.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/42.png b/Dataset/FaceData/processed/Den Vau/42.png\\ndeleted file mode 100644\\nindex 12c16f7..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/42.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/43.png b/Dataset/FaceData/processed/Den Vau/43.png\\ndeleted file mode 100644\\nindex 66f8db9..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/43.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/44.png b/Dataset/FaceData/processed/Den Vau/44.png\\ndeleted file mode 100644\\nindex e8948a2..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/44.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/45.png b/Dataset/FaceData/processed/Den Vau/45.png\\ndeleted file mode 100644\\nindex 7eaf5ed..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/45.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/46.png b/Dataset/FaceData/processed/Den Vau/46.png\\ndeleted file mode 100644\\nindex 8438dd6..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/46.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/47.png b/Dataset/FaceData/processed/Den Vau/47.png\\ndeleted file mode 100644\\nindex 5e0c25c..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/47.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/48.png b/Dataset/FaceData/processed/Den Vau/48.png\\ndeleted file mode 100644\\nindex 6c47fe1..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/48.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/49.png b/Dataset/FaceData/processed/Den Vau/49.png\\ndeleted file mode 100644\\nindex b99ca9c..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/49.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/5.png b/Dataset/FaceData/processed/Den Vau/5.png\\ndeleted file mode 100644\\nindex a854c19..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/5.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/50.png b/Dataset/FaceData/processed/Den Vau/50.png\\ndeleted file mode 100644\\nindex 1da8e1e..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/50.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/51.png b/Dataset/FaceData/processed/Den Vau/51.png\\ndeleted file mode 100644\\nindex 028ad09..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/51.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/52.png b/Dataset/FaceData/processed/Den Vau/52.png\\ndeleted file mode 100644\\nindex d0c1a35..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/52.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/53.png b/Dataset/FaceData/processed/Den Vau/53.png\\ndeleted file mode 100644\\nindex 737f908..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/53.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/54.png b/Dataset/FaceData/processed/Den Vau/54.png\\ndeleted file mode 100644\\nindex 70e348e..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/54.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/55.png b/Dataset/FaceData/processed/Den Vau/55.png\\ndeleted file mode 100644\\nindex d3259e2..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/55.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/56.png b/Dataset/FaceData/processed/Den Vau/56.png\\ndeleted file mode 100644\\nindex 0d6b9ec..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/56.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/58.png b/Dataset/FaceData/processed/Den Vau/58.png\\ndeleted file mode 100644\\nindex 988bd12..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/58.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/59.png b/Dataset/FaceData/processed/Den Vau/59.png\\ndeleted file mode 100644\\nindex c3c0bf6..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/59.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/6.png b/Dataset/FaceData/processed/Den Vau/6.png\\ndeleted file mode 100644\\nindex 604bfeb..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/6.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/60.png b/Dataset/FaceData/processed/Den Vau/60.png\\ndeleted file mode 100644\\nindex eb70911..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/60.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/61.png b/Dataset/FaceData/processed/Den Vau/61.png\\ndeleted file mode 100644\\nindex 7fa06a6..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/61.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/62.png b/Dataset/FaceData/processed/Den Vau/62.png\\ndeleted file mode 100644\\nindex 5f3c07a..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/62.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/63.png b/Dataset/FaceData/processed/Den Vau/63.png\\ndeleted file mode 100644\\nindex 9c69ea7..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/63.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/64.png b/Dataset/FaceData/processed/Den Vau/64.png\\ndeleted file mode 100644\\nindex d9e5d1f..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/64.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/65.png b/Dataset/FaceData/processed/Den Vau/65.png\\ndeleted file mode 100644\\nindex 8b936de..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/65.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/66.png b/Dataset/FaceData/processed/Den Vau/66.png\\ndeleted file mode 100644\\nindex 8e8b024..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/66.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/67.png b/Dataset/FaceData/processed/Den Vau/67.png\\ndeleted file mode 100644\\nindex 350aa44..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/67.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/68.png b/Dataset/FaceData/processed/Den Vau/68.png\\ndeleted file mode 100644\\nindex 21f2959..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/68.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/69.png b/Dataset/FaceData/processed/Den Vau/69.png\\ndeleted file mode 100644\\nindex 0328a36..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/69.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/7.png b/Dataset/FaceData/processed/Den Vau/7.png\\ndeleted file mode 100644\\nindex 90adacb..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/7.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/70.png b/Dataset/FaceData/processed/Den Vau/70.png\\ndeleted file mode 100644\\nindex feb2d25..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/70.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/71.png b/Dataset/FaceData/processed/Den Vau/71.png\\ndeleted file mode 100644\\nindex 6d11a2d..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/71.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/72.png b/Dataset/FaceData/processed/Den Vau/72.png\\ndeleted file mode 100644\\nindex 702447f..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/72.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/73.png b/Dataset/FaceData/processed/Den Vau/73.png\\ndeleted file mode 100644\\nindex 6a05c21..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/73.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/8.png b/Dataset/FaceData/processed/Den Vau/8.png\\ndeleted file mode 100644\\nindex 43969e5..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/8.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Den Vau/9.png b/Dataset/FaceData/processed/Den Vau/9.png\\ndeleted file mode 100644\\nindex 4339f24..0000000\\nBinary files a/Dataset/FaceData/processed/Den Vau/9.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Do hieu/176064931_2957139457942069_3035200184642124074_n.png b/Dataset/FaceData/processed/Do hieu/176064931_2957139457942069_3035200184642124074_n.png\\ndeleted file mode 100644\\nindex d4eeb89..0000000\\nBinary files a/Dataset/FaceData/processed/Do hieu/176064931_2957139457942069_3035200184642124074_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Do hieu/177907728_2957139527942062_5622464185056568311_n.png b/Dataset/FaceData/processed/Do hieu/177907728_2957139527942062_5622464185056568311_n.png\\ndeleted file mode 100644\\nindex 10e8dad..0000000\\nBinary files a/Dataset/FaceData/processed/Do hieu/177907728_2957139527942062_5622464185056568311_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Do hieu/177993461_2957139491275399_3222091836626291316_n.png b/Dataset/FaceData/processed/Do hieu/177993461_2957139491275399_3222091836626291316_n.png\\ndeleted file mode 100644\\nindex 2f1c851..0000000\\nBinary files a/Dataset/FaceData/processed/Do hieu/177993461_2957139491275399_3222091836626291316_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Do hieu/178929889_2957139244608757_1991887332909086037_n (1).png b/Dataset/FaceData/processed/Do hieu/178929889_2957139244608757_1991887332909086037_n (1).png\\ndeleted file mode 100644\\nindex f5aec41..0000000\\nBinary files a/Dataset/FaceData/processed/Do hieu/178929889_2957139244608757_1991887332909086037_n (1).png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Do hieu/178929889_2957139244608757_1991887332909086037_n.png b/Dataset/FaceData/processed/Do hieu/178929889_2957139244608757_1991887332909086037_n.png\\ndeleted file mode 100644\\nindex f5aec41..0000000\\nBinary files a/Dataset/FaceData/processed/Do hieu/178929889_2957139244608757_1991887332909086037_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Do hieu/314736967_3413393448983332_3470974153489929662_n.png b/Dataset/FaceData/processed/Do hieu/314736967_3413393448983332_3470974153489929662_n.png\\ndeleted file mode 100644\\nindex b468390..0000000\\nBinary files a/Dataset/FaceData/processed/Do hieu/314736967_3413393448983332_3470974153489929662_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Do hieu/408729291_122109331016134044_5530016628103795106_n.png b/Dataset/FaceData/processed/Do hieu/408729291_122109331016134044_5530016628103795106_n.png\\ndeleted file mode 100644\\nindex 7a82aaf..0000000\\nBinary files a/Dataset/FaceData/processed/Do hieu/408729291_122109331016134044_5530016628103795106_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Duc viet/152373366_899599367523323_8039073461193180489_n.png b/Dataset/FaceData/processed/Duc viet/152373366_899599367523323_8039073461193180489_n.png\\ndeleted file mode 100644\\nindex cf0ba12..0000000\\nBinary files a/Dataset/FaceData/processed/Duc viet/152373366_899599367523323_8039073461193180489_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Duc viet/152709553_899599430856650_818805157951754296_n.png b/Dataset/FaceData/processed/Duc viet/152709553_899599430856650_818805157951754296_n.png\\ndeleted file mode 100644\\nindex a665d32..0000000\\nBinary files a/Dataset/FaceData/processed/Duc viet/152709553_899599430856650_818805157951754296_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Duc viet/154070237_435134567707863_6078333129900068002_n.png b/Dataset/FaceData/processed/Duc viet/154070237_435134567707863_6078333129900068002_n.png\\ndeleted file mode 100644\\nindex 9653d11..0000000\\nBinary files a/Dataset/FaceData/processed/Duc viet/154070237_435134567707863_6078333129900068002_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Duc viet/61506698_348134895895603_7272087717616287744_n.png b/Dataset/FaceData/processed/Duc viet/61506698_348134895895603_7272087717616287744_n.png\\ndeleted file mode 100644\\nindex 63d631c..0000000\\nBinary files a/Dataset/FaceData/processed/Duc viet/61506698_348134895895603_7272087717616287744_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Duc viet/61560706_348134092562350_1539501885898096640_n.png b/Dataset/FaceData/processed/Duc viet/61560706_348134092562350_1539501885898096640_n.png\\ndeleted file mode 100644\\nindex c4c7e30..0000000\\nBinary files a/Dataset/FaceData/processed/Duc viet/61560706_348134092562350_1539501885898096640_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Duc viet/61584844_348135582562201_7506169027295707136_n.png b/Dataset/FaceData/processed/Duc viet/61584844_348135582562201_7506169027295707136_n.png\\ndeleted file mode 100644\\nindex ebccdb2..0000000\\nBinary files a/Dataset/FaceData/processed/Duc viet/61584844_348135582562201_7506169027295707136_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Duc viet/61820425_348134402562319_3380097574999425024_n.png b/Dataset/FaceData/processed/Duc viet/61820425_348134402562319_3380097574999425024_n.png\\ndeleted file mode 100644\\nindex aeb594e..0000000\\nBinary files a/Dataset/FaceData/processed/Duc viet/61820425_348134402562319_3380097574999425024_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Duc viet/61848774_348135615895531_3014436068146544640_n.png b/Dataset/FaceData/processed/Duc viet/61848774_348135615895531_3014436068146544640_n.png\\ndeleted file mode 100644\\nindex ae354f6..0000000\\nBinary files a/Dataset/FaceData/processed/Duc viet/61848774_348135615895531_3014436068146544640_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Duc viet/61967926_348135315895561_496212973459603456_n.png b/Dataset/FaceData/processed/Duc viet/61967926_348135315895561_496212973459603456_n.png\\ndeleted file mode 100644\\nindex f5e1a74..0000000\\nBinary files a/Dataset/FaceData/processed/Duc viet/61967926_348135315895561_496212973459603456_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Duc viet/62021360_348135282562231_7688022791626424320_n.png b/Dataset/FaceData/processed/Duc viet/62021360_348135282562231_7688022791626424320_n.png\\ndeleted file mode 100644\\nindex af919f2..0000000\\nBinary files a/Dataset/FaceData/processed/Duc viet/62021360_348135282562231_7688022791626424320_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Duc viet/62035132_348134362562323_2007170459463843840_n.png b/Dataset/FaceData/processed/Duc viet/62035132_348134362562323_2007170459463843840_n.png\\ndeleted file mode 100644\\nindex ef9ec97..0000000\\nBinary files a/Dataset/FaceData/processed/Duc viet/62035132_348134362562323_2007170459463843840_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Duc viet/64869534_359570548085371_8201502723321888768_n.png b/Dataset/FaceData/processed/Duc viet/64869534_359570548085371_8201502723321888768_n.png\\ndeleted file mode 100644\\nindex f82f998..0000000\\nBinary files a/Dataset/FaceData/processed/Duc viet/64869534_359570548085371_8201502723321888768_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/0.png b/Dataset/FaceData/processed/Ha Anh Tuan/0.png\\ndeleted file mode 100644\\nindex 4d34efb..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/0.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/1.png b/Dataset/FaceData/processed/Ha Anh Tuan/1.png\\ndeleted file mode 100644\\nindex 4a03e8a..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/10.png b/Dataset/FaceData/processed/Ha Anh Tuan/10.png\\ndeleted file mode 100644\\nindex 18ab6ce..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/10.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/11.png b/Dataset/FaceData/processed/Ha Anh Tuan/11.png\\ndeleted file mode 100644\\nindex e31db51..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/11.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/12.png b/Dataset/FaceData/processed/Ha Anh Tuan/12.png\\ndeleted file mode 100644\\nindex 34506de..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/12.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/13.png b/Dataset/FaceData/processed/Ha Anh Tuan/13.png\\ndeleted file mode 100644\\nindex 28208f0..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/13.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/14.png b/Dataset/FaceData/processed/Ha Anh Tuan/14.png\\ndeleted file mode 100644\\nindex 5967985..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/14.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/15.png b/Dataset/FaceData/processed/Ha Anh Tuan/15.png\\ndeleted file mode 100644\\nindex 2ea37f7..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/15.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/16.png b/Dataset/FaceData/processed/Ha Anh Tuan/16.png\\ndeleted file mode 100644\\nindex ca393c7..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/16.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/17.png b/Dataset/FaceData/processed/Ha Anh Tuan/17.png\\ndeleted file mode 100644\\nindex a8bf0f9..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/17.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/18.png b/Dataset/FaceData/processed/Ha Anh Tuan/18.png\\ndeleted file mode 100644\\nindex fc2cb1f..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/18.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/19.png b/Dataset/FaceData/processed/Ha Anh Tuan/19.png\\ndeleted file mode 100644\\nindex ad2d914..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/19.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/2.png b/Dataset/FaceData/processed/Ha Anh Tuan/2.png\\ndeleted file mode 100644\\nindex beebbd6..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/20.png b/Dataset/FaceData/processed/Ha Anh Tuan/20.png\\ndeleted file mode 100644\\nindex 0df1b3d..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/20.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/21.png b/Dataset/FaceData/processed/Ha Anh Tuan/21.png\\ndeleted file mode 100644\\nindex c101a73..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/21.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/22.png b/Dataset/FaceData/processed/Ha Anh Tuan/22.png\\ndeleted file mode 100644\\nindex c7c4b1d..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/22.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/23.png b/Dataset/FaceData/processed/Ha Anh Tuan/23.png\\ndeleted file mode 100644\\nindex 44303be..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/23.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/24.png b/Dataset/FaceData/processed/Ha Anh Tuan/24.png\\ndeleted file mode 100644\\nindex 01b37b1..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/24.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/26.png b/Dataset/FaceData/processed/Ha Anh Tuan/26.png\\ndeleted file mode 100644\\nindex d68ccce..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/26.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/27.png b/Dataset/FaceData/processed/Ha Anh Tuan/27.png\\ndeleted file mode 100644\\nindex 4630322..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/27.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/28.png b/Dataset/FaceData/processed/Ha Anh Tuan/28.png\\ndeleted file mode 100644\\nindex 81265a9..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/28.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/29.png b/Dataset/FaceData/processed/Ha Anh Tuan/29.png\\ndeleted file mode 100644\\nindex d541fbb..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/29.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/3.png b/Dataset/FaceData/processed/Ha Anh Tuan/3.png\\ndeleted file mode 100644\\nindex 68a58ec..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/30.png b/Dataset/FaceData/processed/Ha Anh Tuan/30.png\\ndeleted file mode 100644\\nindex 493caea..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/30.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/31.png b/Dataset/FaceData/processed/Ha Anh Tuan/31.png\\ndeleted file mode 100644\\nindex d71148b..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/31.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/32.png b/Dataset/FaceData/processed/Ha Anh Tuan/32.png\\ndeleted file mode 100644\\nindex 50033d0..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/32.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/33.png b/Dataset/FaceData/processed/Ha Anh Tuan/33.png\\ndeleted file mode 100644\\nindex d8f2784..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/33.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/34.png b/Dataset/FaceData/processed/Ha Anh Tuan/34.png\\ndeleted file mode 100644\\nindex 4a97145..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/34.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/35.png b/Dataset/FaceData/processed/Ha Anh Tuan/35.png\\ndeleted file mode 100644\\nindex 92b0a02..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/35.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/36.png b/Dataset/FaceData/processed/Ha Anh Tuan/36.png\\ndeleted file mode 100644\\nindex c23a508..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/36.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/37.png b/Dataset/FaceData/processed/Ha Anh Tuan/37.png\\ndeleted file mode 100644\\nindex 0a5d9b2..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/37.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/38.png b/Dataset/FaceData/processed/Ha Anh Tuan/38.png\\ndeleted file mode 100644\\nindex 3af89e6..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/38.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/39.png b/Dataset/FaceData/processed/Ha Anh Tuan/39.png\\ndeleted file mode 100644\\nindex edf8240..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/39.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/4.png b/Dataset/FaceData/processed/Ha Anh Tuan/4.png\\ndeleted file mode 100644\\nindex 2e1c2e8..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/40.png b/Dataset/FaceData/processed/Ha Anh Tuan/40.png\\ndeleted file mode 100644\\nindex 7399654..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/40.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/5.png b/Dataset/FaceData/processed/Ha Anh Tuan/5.png\\ndeleted file mode 100644\\nindex ab4bef2..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/5.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/6.png b/Dataset/FaceData/processed/Ha Anh Tuan/6.png\\ndeleted file mode 100644\\nindex 60259ed..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/6.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/7.png b/Dataset/FaceData/processed/Ha Anh Tuan/7.png\\ndeleted file mode 100644\\nindex efad412..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/7.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/8.png b/Dataset/FaceData/processed/Ha Anh Tuan/8.png\\ndeleted file mode 100644\\nindex 7488fd8..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/8.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ha Anh Tuan/9.png b/Dataset/FaceData/processed/Ha Anh Tuan/9.png\\ndeleted file mode 100644\\nindex 0789dfa..0000000\\nBinary files a/Dataset/FaceData/processed/Ha Anh Tuan/9.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/0.png b/Dataset/FaceData/processed/Hoai linh/0.png\\ndeleted file mode 100644\\nindex 65becdc..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/0.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/1.png b/Dataset/FaceData/processed/Hoai linh/1.png\\ndeleted file mode 100644\\nindex a7113df..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/10.png b/Dataset/FaceData/processed/Hoai linh/10.png\\ndeleted file mode 100644\\nindex b788593..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/10.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/11.png b/Dataset/FaceData/processed/Hoai linh/11.png\\ndeleted file mode 100644\\nindex a4274e5..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/11.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/12.png b/Dataset/FaceData/processed/Hoai linh/12.png\\ndeleted file mode 100644\\nindex bcd4699..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/12.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/13.png b/Dataset/FaceData/processed/Hoai linh/13.png\\ndeleted file mode 100644\\nindex 17b9a7c..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/13.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/14.png b/Dataset/FaceData/processed/Hoai linh/14.png\\ndeleted file mode 100644\\nindex f4113a3..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/14.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/15.png b/Dataset/FaceData/processed/Hoai linh/15.png\\ndeleted file mode 100644\\nindex b3396a2..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/15.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/16.png b/Dataset/FaceData/processed/Hoai linh/16.png\\ndeleted file mode 100644\\nindex 9b69bab..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/16.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/17.png b/Dataset/FaceData/processed/Hoai linh/17.png\\ndeleted file mode 100644\\nindex cee285d..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/17.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/18.png b/Dataset/FaceData/processed/Hoai linh/18.png\\ndeleted file mode 100644\\nindex 69cb1fe..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/18.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/19.png b/Dataset/FaceData/processed/Hoai linh/19.png\\ndeleted file mode 100644\\nindex 26f7451..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/19.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/2.png b/Dataset/FaceData/processed/Hoai linh/2.png\\ndeleted file mode 100644\\nindex 19a5c01..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/20.png b/Dataset/FaceData/processed/Hoai linh/20.png\\ndeleted file mode 100644\\nindex 9a249dd..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/20.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/21.png b/Dataset/FaceData/processed/Hoai linh/21.png\\ndeleted file mode 100644\\nindex 2a91245..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/21.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/22.png b/Dataset/FaceData/processed/Hoai linh/22.png\\ndeleted file mode 100644\\nindex 3217816..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/22.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/23.png b/Dataset/FaceData/processed/Hoai linh/23.png\\ndeleted file mode 100644\\nindex 916431f..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/23.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/24.png b/Dataset/FaceData/processed/Hoai linh/24.png\\ndeleted file mode 100644\\nindex b45cec2..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/24.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/25.png b/Dataset/FaceData/processed/Hoai linh/25.png\\ndeleted file mode 100644\\nindex 10cf3f9..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/25.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/26.png b/Dataset/FaceData/processed/Hoai linh/26.png\\ndeleted file mode 100644\\nindex 6a29094..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/26.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/27.png b/Dataset/FaceData/processed/Hoai linh/27.png\\ndeleted file mode 100644\\nindex 190c9bf..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/27.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/28.png b/Dataset/FaceData/processed/Hoai linh/28.png\\ndeleted file mode 100644\\nindex b31d789..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/28.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/29.png b/Dataset/FaceData/processed/Hoai linh/29.png\\ndeleted file mode 100644\\nindex c5ba458..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/29.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/3.png b/Dataset/FaceData/processed/Hoai linh/3.png\\ndeleted file mode 100644\\nindex 7c065fe..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/30.png b/Dataset/FaceData/processed/Hoai linh/30.png\\ndeleted file mode 100644\\nindex 27dd73e..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/30.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/31.png b/Dataset/FaceData/processed/Hoai linh/31.png\\ndeleted file mode 100644\\nindex 40b23df..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/31.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/32.png b/Dataset/FaceData/processed/Hoai linh/32.png\\ndeleted file mode 100644\\nindex 0e8f119..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/32.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/33.png b/Dataset/FaceData/processed/Hoai linh/33.png\\ndeleted file mode 100644\\nindex 98c1b4a..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/33.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/34.png b/Dataset/FaceData/processed/Hoai linh/34.png\\ndeleted file mode 100644\\nindex 26d31b8..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/34.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/35.png b/Dataset/FaceData/processed/Hoai linh/35.png\\ndeleted file mode 100644\\nindex d7a1fc6..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/35.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/36.png b/Dataset/FaceData/processed/Hoai linh/36.png\\ndeleted file mode 100644\\nindex 662005f..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/36.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/37.png b/Dataset/FaceData/processed/Hoai linh/37.png\\ndeleted file mode 100644\\nindex ae727f6..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/37.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/38.png b/Dataset/FaceData/processed/Hoai linh/38.png\\ndeleted file mode 100644\\nindex f276d8e..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/38.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/39.png b/Dataset/FaceData/processed/Hoai linh/39.png\\ndeleted file mode 100644\\nindex c9e763e..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/39.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/4.png b/Dataset/FaceData/processed/Hoai linh/4.png\\ndeleted file mode 100644\\nindex 73757f4..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/40.png b/Dataset/FaceData/processed/Hoai linh/40.png\\ndeleted file mode 100644\\nindex 52a985f..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/40.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/5.png b/Dataset/FaceData/processed/Hoai linh/5.png\\ndeleted file mode 100644\\nindex faaeac5..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/5.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/6.png b/Dataset/FaceData/processed/Hoai linh/6.png\\ndeleted file mode 100644\\nindex 2196f46..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/6.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/7.png b/Dataset/FaceData/processed/Hoai linh/7.png\\ndeleted file mode 100644\\nindex 200b8d6..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/7.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/8.png b/Dataset/FaceData/processed/Hoai linh/8.png\\ndeleted file mode 100644\\nindex 289e908..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/8.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Hoai linh/9.png b/Dataset/FaceData/processed/Hoai linh/9.png\\ndeleted file mode 100644\\nindex 49ae616..0000000\\nBinary files a/Dataset/FaceData/processed/Hoai linh/9.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ma bach duy/duy1.png b/Dataset/FaceData/processed/Ma bach duy/duy1.png\\ndeleted file mode 100644\\nindex ec2e936..0000000\\nBinary files a/Dataset/FaceData/processed/Ma bach duy/duy1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ma bach duy/duy2.png b/Dataset/FaceData/processed/Ma bach duy/duy2.png\\ndeleted file mode 100644\\nindex 544ce38..0000000\\nBinary files a/Dataset/FaceData/processed/Ma bach duy/duy2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ma bach duy/duy3.png b/Dataset/FaceData/processed/Ma bach duy/duy3.png\\ndeleted file mode 100644\\nindex ccfd7e7..0000000\\nBinary files a/Dataset/FaceData/processed/Ma bach duy/duy3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Ma bach duy/duy4.png b/Dataset/FaceData/processed/Ma bach duy/duy4.png\\ndeleted file mode 100644\\nindex 0380f72..0000000\\nBinary files a/Dataset/FaceData/processed/Ma bach duy/duy4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Minh hoa/116428895_656623338282021_8457872234875945077_n.png b/Dataset/FaceData/processed/Minh hoa/116428895_656623338282021_8457872234875945077_n.png\\ndeleted file mode 100644\\nindex a3a2302..0000000\\nBinary files a/Dataset/FaceData/processed/Minh hoa/116428895_656623338282021_8457872234875945077_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Minh hoa/133049557_769265223684498_4689118252074034370_n.png b/Dataset/FaceData/processed/Minh hoa/133049557_769265223684498_4689118252074034370_n.png\\ndeleted file mode 100644\\nindex 3d212ea..0000000\\nBinary files a/Dataset/FaceData/processed/Minh hoa/133049557_769265223684498_4689118252074034370_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Minh hoa/258158616_974113876532964_9067509414358086927_n.png b/Dataset/FaceData/processed/Minh hoa/258158616_974113876532964_9067509414358086927_n.png\\ndeleted file mode 100644\\nindex f8effe2..0000000\\nBinary files a/Dataset/FaceData/processed/Minh hoa/258158616_974113876532964_9067509414358086927_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Minh hoa/277588798_1056746241603060_3376911805269669778_n.png b/Dataset/FaceData/processed/Minh hoa/277588798_1056746241603060_3376911805269669778_n.png\\ndeleted file mode 100644\\nindex 431d938..0000000\\nBinary files a/Dataset/FaceData/processed/Minh hoa/277588798_1056746241603060_3376911805269669778_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Minh hoa/45761069_299092524035106_5787233926145638400_n.png b/Dataset/FaceData/processed/Minh hoa/45761069_299092524035106_5787233926145638400_n.png\\ndeleted file mode 100644\\nindex b615a23..0000000\\nBinary files a/Dataset/FaceData/processed/Minh hoa/45761069_299092524035106_5787233926145638400_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Minh hoa/51367653_335164410427917_2686636884146257920_n.png b/Dataset/FaceData/processed/Minh hoa/51367653_335164410427917_2686636884146257920_n.png\\ndeleted file mode 100644\\nindex b572353..0000000\\nBinary files a/Dataset/FaceData/processed/Minh hoa/51367653_335164410427917_2686636884146257920_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Minh hoa/72597481_459453121332378_4444718657989246976_n.png b/Dataset/FaceData/processed/Minh hoa/72597481_459453121332378_4444718657989246976_n.png\\ndeleted file mode 100644\\nindex cbc97b8..0000000\\nBinary files a/Dataset/FaceData/processed/Minh hoa/72597481_459453121332378_4444718657989246976_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/My Duyen/240594338_608022267035848_559750156049629888_n.png b/Dataset/FaceData/processed/My Duyen/240594338_608022267035848_559750156049629888_n.png\\ndeleted file mode 100644\\nindex 99ef3a6..0000000\\nBinary files a/Dataset/FaceData/processed/My Duyen/240594338_608022267035848_559750156049629888_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/My Duyen/271565569_687653065739434_6695347522364803324_n.png b/Dataset/FaceData/processed/My Duyen/271565569_687653065739434_6695347522364803324_n.png\\ndeleted file mode 100644\\nindex c8f4d94..0000000\\nBinary files a/Dataset/FaceData/processed/My Duyen/271565569_687653065739434_6695347522364803324_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/My Duyen/276281855_728896961615044_4850973774883281965_n.png b/Dataset/FaceData/processed/My Duyen/276281855_728896961615044_4850973774883281965_n.png\\ndeleted file mode 100644\\nindex d4f25ea..0000000\\nBinary files a/Dataset/FaceData/processed/My Duyen/276281855_728896961615044_4850973774883281965_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/My Duyen/375727668_1053445732493497_6855315188334578963_n.png b/Dataset/FaceData/processed/My Duyen/375727668_1053445732493497_6855315188334578963_n.png\\ndeleted file mode 100644\\nindex 784b70f..0000000\\nBinary files a/Dataset/FaceData/processed/My Duyen/375727668_1053445732493497_6855315188334578963_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/My Duyen/377915813_1055517365619667_3022176625716036504_n.png b/Dataset/FaceData/processed/My Duyen/377915813_1055517365619667_3022176625716036504_n.png\\ndeleted file mode 100644\\nindex 26dbbe3..0000000\\nBinary files a/Dataset/FaceData/processed/My Duyen/377915813_1055517365619667_3022176625716036504_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/My Duyen/383221108_1063489451489125_7303325553687006067_n.png b/Dataset/FaceData/processed/My Duyen/383221108_1063489451489125_7303325553687006067_n.png\\ndeleted file mode 100644\\nindex 219b6de..0000000\\nBinary files a/Dataset/FaceData/processed/My Duyen/383221108_1063489451489125_7303325553687006067_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/My Duyen/425727875_1136306777540725_7475412167375191065_n.png b/Dataset/FaceData/processed/My Duyen/425727875_1136306777540725_7475412167375191065_n.png\\ndeleted file mode 100644\\nindex f5c640a..0000000\\nBinary files a/Dataset/FaceData/processed/My Duyen/425727875_1136306777540725_7475412167375191065_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/My Duyen/71477803_179402706564475_6524185163780325376_n.png b/Dataset/FaceData/processed/My Duyen/71477803_179402706564475_6524185163780325376_n.png\\ndeleted file mode 100644\\nindex 3b63bb0..0000000\\nBinary files a/Dataset/FaceData/processed/My Duyen/71477803_179402706564475_6524185163780325376_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/My Duyen/Screenshot 2024-02-08 200137.png b/Dataset/FaceData/processed/My Duyen/Screenshot 2024-02-08 200137.png\\ndeleted file mode 100644\\nindex 32c4ea0..0000000\\nBinary files a/Dataset/FaceData/processed/My Duyen/Screenshot 2024-02-08 200137.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/0.png b/Dataset/FaceData/processed/Nam Em/0.png\\ndeleted file mode 100644\\nindex a0f2c19..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/0.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/1.png b/Dataset/FaceData/processed/Nam Em/1.png\\ndeleted file mode 100644\\nindex caf5588..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/10.png b/Dataset/FaceData/processed/Nam Em/10.png\\ndeleted file mode 100644\\nindex 94a11d7..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/10.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/11.png b/Dataset/FaceData/processed/Nam Em/11.png\\ndeleted file mode 100644\\nindex 302248e..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/11.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/12.png b/Dataset/FaceData/processed/Nam Em/12.png\\ndeleted file mode 100644\\nindex 46ee042..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/12.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/13.png b/Dataset/FaceData/processed/Nam Em/13.png\\ndeleted file mode 100644\\nindex d09d275..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/13.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/14.png b/Dataset/FaceData/processed/Nam Em/14.png\\ndeleted file mode 100644\\nindex a253bfc..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/14.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/15.png b/Dataset/FaceData/processed/Nam Em/15.png\\ndeleted file mode 100644\\nindex ab98a44..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/15.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/16.png b/Dataset/FaceData/processed/Nam Em/16.png\\ndeleted file mode 100644\\nindex 0e4b3b4..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/16.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/17.png b/Dataset/FaceData/processed/Nam Em/17.png\\ndeleted file mode 100644\\nindex 06164f9..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/17.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/18.png b/Dataset/FaceData/processed/Nam Em/18.png\\ndeleted file mode 100644\\nindex b60ef26..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/18.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/19.png b/Dataset/FaceData/processed/Nam Em/19.png\\ndeleted file mode 100644\\nindex efb39a2..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/19.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/2.png b/Dataset/FaceData/processed/Nam Em/2.png\\ndeleted file mode 100644\\nindex 7ffeaff..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/20.png b/Dataset/FaceData/processed/Nam Em/20.png\\ndeleted file mode 100644\\nindex f4a31b3..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/20.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/21.png b/Dataset/FaceData/processed/Nam Em/21.png\\ndeleted file mode 100644\\nindex 5b89c52..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/21.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/22.png b/Dataset/FaceData/processed/Nam Em/22.png\\ndeleted file mode 100644\\nindex 09482e8..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/22.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/23.png b/Dataset/FaceData/processed/Nam Em/23.png\\ndeleted file mode 100644\\nindex c3a4558..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/23.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/24.png b/Dataset/FaceData/processed/Nam Em/24.png\\ndeleted file mode 100644\\nindex 0caaad8..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/24.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/25.png b/Dataset/FaceData/processed/Nam Em/25.png\\ndeleted file mode 100644\\nindex f9ad937..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/25.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/26.png b/Dataset/FaceData/processed/Nam Em/26.png\\ndeleted file mode 100644\\nindex 9f8c44d..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/26.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/27.png b/Dataset/FaceData/processed/Nam Em/27.png\\ndeleted file mode 100644\\nindex a305725..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/27.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/28.png b/Dataset/FaceData/processed/Nam Em/28.png\\ndeleted file mode 100644\\nindex 26d2b94..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/28.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/29.png b/Dataset/FaceData/processed/Nam Em/29.png\\ndeleted file mode 100644\\nindex 7f70b65..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/29.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/3.png b/Dataset/FaceData/processed/Nam Em/3.png\\ndeleted file mode 100644\\nindex 1d0cd76..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/30.png b/Dataset/FaceData/processed/Nam Em/30.png\\ndeleted file mode 100644\\nindex b8aac01..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/30.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/31.png b/Dataset/FaceData/processed/Nam Em/31.png\\ndeleted file mode 100644\\nindex 68ff61e..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/31.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/32.png b/Dataset/FaceData/processed/Nam Em/32.png\\ndeleted file mode 100644\\nindex 4bc8af4..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/32.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/33.png b/Dataset/FaceData/processed/Nam Em/33.png\\ndeleted file mode 100644\\nindex 4029631..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/33.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/34.png b/Dataset/FaceData/processed/Nam Em/34.png\\ndeleted file mode 100644\\nindex c140b39..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/34.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/35.png b/Dataset/FaceData/processed/Nam Em/35.png\\ndeleted file mode 100644\\nindex 2aaace8..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/35.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/36.png b/Dataset/FaceData/processed/Nam Em/36.png\\ndeleted file mode 100644\\nindex ada1c2f..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/36.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/37.png b/Dataset/FaceData/processed/Nam Em/37.png\\ndeleted file mode 100644\\nindex 2761625..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/37.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/38.png b/Dataset/FaceData/processed/Nam Em/38.png\\ndeleted file mode 100644\\nindex 42ee990..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/38.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/39.png b/Dataset/FaceData/processed/Nam Em/39.png\\ndeleted file mode 100644\\nindex cdb328d..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/39.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/4.png b/Dataset/FaceData/processed/Nam Em/4.png\\ndeleted file mode 100644\\nindex 5038b4a..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/40.png b/Dataset/FaceData/processed/Nam Em/40.png\\ndeleted file mode 100644\\nindex 85f06c8..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/40.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/41.png b/Dataset/FaceData/processed/Nam Em/41.png\\ndeleted file mode 100644\\nindex 9795eb4..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/41.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/5.png b/Dataset/FaceData/processed/Nam Em/5.png\\ndeleted file mode 100644\\nindex 4c0ffaa..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/5.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/6.png b/Dataset/FaceData/processed/Nam Em/6.png\\ndeleted file mode 100644\\nindex 7f5430f..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/6.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/7.png b/Dataset/FaceData/processed/Nam Em/7.png\\ndeleted file mode 100644\\nindex d6e3ed5..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/7.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/8.png b/Dataset/FaceData/processed/Nam Em/8.png\\ndeleted file mode 100644\\nindex d727bad..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/8.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nam Em/9.png b/Dataset/FaceData/processed/Nam Em/9.png\\ndeleted file mode 100644\\nindex 88172c2..0000000\\nBinary files a/Dataset/FaceData/processed/Nam Em/9.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/0.png b/Dataset/FaceData/processed/Nguyen phu trong/0.png\\ndeleted file mode 100644\\nindex 1595c0d..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/0.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/1.png b/Dataset/FaceData/processed/Nguyen phu trong/1.png\\ndeleted file mode 100644\\nindex adc00c1..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/10.png b/Dataset/FaceData/processed/Nguyen phu trong/10.png\\ndeleted file mode 100644\\nindex cf7e6b7..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/10.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/11.png b/Dataset/FaceData/processed/Nguyen phu trong/11.png\\ndeleted file mode 100644\\nindex ef7565d..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/11.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/12.png b/Dataset/FaceData/processed/Nguyen phu trong/12.png\\ndeleted file mode 100644\\nindex 6b5ec56..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/12.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/13.png b/Dataset/FaceData/processed/Nguyen phu trong/13.png\\ndeleted file mode 100644\\nindex a95c6f4..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/13.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/14.png b/Dataset/FaceData/processed/Nguyen phu trong/14.png\\ndeleted file mode 100644\\nindex 2768000..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/14.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/15.png b/Dataset/FaceData/processed/Nguyen phu trong/15.png\\ndeleted file mode 100644\\nindex 4219894..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/15.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/17.png b/Dataset/FaceData/processed/Nguyen phu trong/17.png\\ndeleted file mode 100644\\nindex ecdfdd9..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/17.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/18.png b/Dataset/FaceData/processed/Nguyen phu trong/18.png\\ndeleted file mode 100644\\nindex 812ecdc..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/18.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/19.png b/Dataset/FaceData/processed/Nguyen phu trong/19.png\\ndeleted file mode 100644\\nindex f044030..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/19.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/2.png b/Dataset/FaceData/processed/Nguyen phu trong/2.png\\ndeleted file mode 100644\\nindex a03cd80..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/20.png b/Dataset/FaceData/processed/Nguyen phu trong/20.png\\ndeleted file mode 100644\\nindex 3f50f9d..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/20.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/21.png b/Dataset/FaceData/processed/Nguyen phu trong/21.png\\ndeleted file mode 100644\\nindex 49c0c71..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/21.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/22.png b/Dataset/FaceData/processed/Nguyen phu trong/22.png\\ndeleted file mode 100644\\nindex 5c126b7..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/22.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/23.png b/Dataset/FaceData/processed/Nguyen phu trong/23.png\\ndeleted file mode 100644\\nindex b38c9ba..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/23.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/24.png b/Dataset/FaceData/processed/Nguyen phu trong/24.png\\ndeleted file mode 100644\\nindex 7177afd..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/24.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/25.png b/Dataset/FaceData/processed/Nguyen phu trong/25.png\\ndeleted file mode 100644\\nindex 6784239..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/25.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/26.png b/Dataset/FaceData/processed/Nguyen phu trong/26.png\\ndeleted file mode 100644\\nindex 47c1ac4..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/26.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/27.png b/Dataset/FaceData/processed/Nguyen phu trong/27.png\\ndeleted file mode 100644\\nindex ec30026..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/27.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/28.png b/Dataset/FaceData/processed/Nguyen phu trong/28.png\\ndeleted file mode 100644\\nindex aeac9d5..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/28.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/29.png b/Dataset/FaceData/processed/Nguyen phu trong/29.png\\ndeleted file mode 100644\\nindex b4fb331..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/29.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/3.png b/Dataset/FaceData/processed/Nguyen phu trong/3.png\\ndeleted file mode 100644\\nindex d95fb40..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/30.png b/Dataset/FaceData/processed/Nguyen phu trong/30.png\\ndeleted file mode 100644\\nindex 011192e..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/30.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/31.png b/Dataset/FaceData/processed/Nguyen phu trong/31.png\\ndeleted file mode 100644\\nindex 86d8888..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/31.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/32.png b/Dataset/FaceData/processed/Nguyen phu trong/32.png\\ndeleted file mode 100644\\nindex 08aaceb..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/32.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/33.png b/Dataset/FaceData/processed/Nguyen phu trong/33.png\\ndeleted file mode 100644\\nindex 404aa1e..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/33.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/34.png b/Dataset/FaceData/processed/Nguyen phu trong/34.png\\ndeleted file mode 100644\\nindex 98c0f1f..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/34.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/35.png b/Dataset/FaceData/processed/Nguyen phu trong/35.png\\ndeleted file mode 100644\\nindex 47eb290..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/35.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/36.png b/Dataset/FaceData/processed/Nguyen phu trong/36.png\\ndeleted file mode 100644\\nindex 9ec5f4e..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/36.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/37.png b/Dataset/FaceData/processed/Nguyen phu trong/37.png\\ndeleted file mode 100644\\nindex 897a52a..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/37.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/38.png b/Dataset/FaceData/processed/Nguyen phu trong/38.png\\ndeleted file mode 100644\\nindex 03d39c6..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/38.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/39.png b/Dataset/FaceData/processed/Nguyen phu trong/39.png\\ndeleted file mode 100644\\nindex ed2880e..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/39.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/4.png b/Dataset/FaceData/processed/Nguyen phu trong/4.png\\ndeleted file mode 100644\\nindex ef615d2..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/40.png b/Dataset/FaceData/processed/Nguyen phu trong/40.png\\ndeleted file mode 100644\\nindex 69e7dc8..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/40.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/42.png b/Dataset/FaceData/processed/Nguyen phu trong/42.png\\ndeleted file mode 100644\\nindex 06dac58..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/42.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/43.png b/Dataset/FaceData/processed/Nguyen phu trong/43.png\\ndeleted file mode 100644\\nindex f8843a1..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/43.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/44.png b/Dataset/FaceData/processed/Nguyen phu trong/44.png\\ndeleted file mode 100644\\nindex 4f66a67..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/44.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/45.png b/Dataset/FaceData/processed/Nguyen phu trong/45.png\\ndeleted file mode 100644\\nindex 30583dc..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/45.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/46.png b/Dataset/FaceData/processed/Nguyen phu trong/46.png\\ndeleted file mode 100644\\nindex d5b76ac..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/46.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/47.png b/Dataset/FaceData/processed/Nguyen phu trong/47.png\\ndeleted file mode 100644\\nindex 9bb7ce1..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/47.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/5.png b/Dataset/FaceData/processed/Nguyen phu trong/5.png\\ndeleted file mode 100644\\nindex eaca72d..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/5.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/6.png b/Dataset/FaceData/processed/Nguyen phu trong/6.png\\ndeleted file mode 100644\\nindex c85f7e9..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/6.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/7.png b/Dataset/FaceData/processed/Nguyen phu trong/7.png\\ndeleted file mode 100644\\nindex d08aba8..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/7.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/8.png b/Dataset/FaceData/processed/Nguyen phu trong/8.png\\ndeleted file mode 100644\\nindex fe1848c..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/8.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Nguyen phu trong/9.png b/Dataset/FaceData/processed/Nguyen phu trong/9.png\\ndeleted file mode 100644\\nindex 6a334c2..0000000\\nBinary files a/Dataset/FaceData/processed/Nguyen phu trong/9.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/0.png b/Dataset/FaceData/processed/Quang Hai/0.png\\ndeleted file mode 100644\\nindex b94205b..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/0.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/1.png b/Dataset/FaceData/processed/Quang Hai/1.png\\ndeleted file mode 100644\\nindex 6f609da..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/10.png b/Dataset/FaceData/processed/Quang Hai/10.png\\ndeleted file mode 100644\\nindex 7b4ac74..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/10.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/11.png b/Dataset/FaceData/processed/Quang Hai/11.png\\ndeleted file mode 100644\\nindex 455b957..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/11.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/12.png b/Dataset/FaceData/processed/Quang Hai/12.png\\ndeleted file mode 100644\\nindex bac26cf..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/12.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/13.png b/Dataset/FaceData/processed/Quang Hai/13.png\\ndeleted file mode 100644\\nindex 380f950..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/13.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/14.png b/Dataset/FaceData/processed/Quang Hai/14.png\\ndeleted file mode 100644\\nindex 9fb4229..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/14.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/15.png b/Dataset/FaceData/processed/Quang Hai/15.png\\ndeleted file mode 100644\\nindex 66a4544..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/15.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/16.png b/Dataset/FaceData/processed/Quang Hai/16.png\\ndeleted file mode 100644\\nindex 267053e..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/16.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/17.png b/Dataset/FaceData/processed/Quang Hai/17.png\\ndeleted file mode 100644\\nindex 6830699..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/17.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/18.png b/Dataset/FaceData/processed/Quang Hai/18.png\\ndeleted file mode 100644\\nindex c53354b..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/18.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/19.png b/Dataset/FaceData/processed/Quang Hai/19.png\\ndeleted file mode 100644\\nindex fb17b25..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/19.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/2.png b/Dataset/FaceData/processed/Quang Hai/2.png\\ndeleted file mode 100644\\nindex 2639463..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/20.png b/Dataset/FaceData/processed/Quang Hai/20.png\\ndeleted file mode 100644\\nindex 411f577..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/20.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/21.png b/Dataset/FaceData/processed/Quang Hai/21.png\\ndeleted file mode 100644\\nindex 3ae470f..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/21.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/22.png b/Dataset/FaceData/processed/Quang Hai/22.png\\ndeleted file mode 100644\\nindex bdb4176..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/22.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/23.png b/Dataset/FaceData/processed/Quang Hai/23.png\\ndeleted file mode 100644\\nindex e2a42e2..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/23.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/24.png b/Dataset/FaceData/processed/Quang Hai/24.png\\ndeleted file mode 100644\\nindex 1a55040..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/24.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/25.png b/Dataset/FaceData/processed/Quang Hai/25.png\\ndeleted file mode 100644\\nindex 48c2c4b..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/25.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/26.png b/Dataset/FaceData/processed/Quang Hai/26.png\\ndeleted file mode 100644\\nindex 3b52507..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/26.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/27.png b/Dataset/FaceData/processed/Quang Hai/27.png\\ndeleted file mode 100644\\nindex dca00ee..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/27.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/28.png b/Dataset/FaceData/processed/Quang Hai/28.png\\ndeleted file mode 100644\\nindex 0fa0ef5..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/28.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/29.png b/Dataset/FaceData/processed/Quang Hai/29.png\\ndeleted file mode 100644\\nindex 5a0bdeb..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/29.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/3.png b/Dataset/FaceData/processed/Quang Hai/3.png\\ndeleted file mode 100644\\nindex 0562166..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/4.png b/Dataset/FaceData/processed/Quang Hai/4.png\\ndeleted file mode 100644\\nindex ba9a8a5..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/5.png b/Dataset/FaceData/processed/Quang Hai/5.png\\ndeleted file mode 100644\\nindex 40a1c95..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/5.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/6.png b/Dataset/FaceData/processed/Quang Hai/6.png\\ndeleted file mode 100644\\nindex 076f6b0..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/6.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/7.png b/Dataset/FaceData/processed/Quang Hai/7.png\\ndeleted file mode 100644\\nindex e6813c6..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/7.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/8.png b/Dataset/FaceData/processed/Quang Hai/8.png\\ndeleted file mode 100644\\nindex 35b8de6..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/8.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Quang Hai/9.png b/Dataset/FaceData/processed/Quang Hai/9.png\\ndeleted file mode 100644\\nindex 7e52452..0000000\\nBinary files a/Dataset/FaceData/processed/Quang Hai/9.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Tran Hoc/107223180_1197468397263141_6372187421696273098_n.png b/Dataset/FaceData/processed/Tran Hoc/107223180_1197468397263141_6372187421696273098_n.png\\ndeleted file mode 100644\\nindex 4b178b0..0000000\\nBinary files a/Dataset/FaceData/processed/Tran Hoc/107223180_1197468397263141_6372187421696273098_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Tran Hoc/120220333_1261416600868320_4101096592656067221_n.png b/Dataset/FaceData/processed/Tran Hoc/120220333_1261416600868320_4101096592656067221_n.png\\ndeleted file mode 100644\\nindex f956135..0000000\\nBinary files a/Dataset/FaceData/processed/Tran Hoc/120220333_1261416600868320_4101096592656067221_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Tran Hoc/235810118_1494231920920119_422367748034160663_n.png b/Dataset/FaceData/processed/Tran Hoc/235810118_1494231920920119_422367748034160663_n.png\\ndeleted file mode 100644\\nindex 9291f9a..0000000\\nBinary files a/Dataset/FaceData/processed/Tran Hoc/235810118_1494231920920119_422367748034160663_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Tran Hoc/90066892_1096495004027148_8085701175137009664_n.png b/Dataset/FaceData/processed/Tran Hoc/90066892_1096495004027148_8085701175137009664_n.png\\ndeleted file mode 100644\\nindex 50b2617..0000000\\nBinary files a/Dataset/FaceData/processed/Tran Hoc/90066892_1096495004027148_8085701175137009664_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/0.png b/Dataset/FaceData/processed/Van Dung/0.png\\ndeleted file mode 100644\\nindex e1c0931..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/0.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/1.png b/Dataset/FaceData/processed/Van Dung/1.png\\ndeleted file mode 100644\\nindex 5096a2d..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/10.png b/Dataset/FaceData/processed/Van Dung/10.png\\ndeleted file mode 100644\\nindex e918bbe..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/10.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/11.png b/Dataset/FaceData/processed/Van Dung/11.png\\ndeleted file mode 100644\\nindex 9521c4f..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/11.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/12.png b/Dataset/FaceData/processed/Van Dung/12.png\\ndeleted file mode 100644\\nindex d798634..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/12.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/13.png b/Dataset/FaceData/processed/Van Dung/13.png\\ndeleted file mode 100644\\nindex fafa87c..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/13.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/14.png b/Dataset/FaceData/processed/Van Dung/14.png\\ndeleted file mode 100644\\nindex ae4ea28..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/14.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/15.png b/Dataset/FaceData/processed/Van Dung/15.png\\ndeleted file mode 100644\\nindex 55f9569..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/15.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/16.png b/Dataset/FaceData/processed/Van Dung/16.png\\ndeleted file mode 100644\\nindex 028b24e..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/16.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/17.png b/Dataset/FaceData/processed/Van Dung/17.png\\ndeleted file mode 100644\\nindex 1bb9f17..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/17.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/18.png b/Dataset/FaceData/processed/Van Dung/18.png\\ndeleted file mode 100644\\nindex 104f6b3..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/18.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/19.png b/Dataset/FaceData/processed/Van Dung/19.png\\ndeleted file mode 100644\\nindex a73e6cd..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/19.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/2.png b/Dataset/FaceData/processed/Van Dung/2.png\\ndeleted file mode 100644\\nindex 9f5b30f..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/20.png b/Dataset/FaceData/processed/Van Dung/20.png\\ndeleted file mode 100644\\nindex 590bf61..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/20.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/21.png b/Dataset/FaceData/processed/Van Dung/21.png\\ndeleted file mode 100644\\nindex db61cf0..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/21.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/22.png b/Dataset/FaceData/processed/Van Dung/22.png\\ndeleted file mode 100644\\nindex 080e161..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/22.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/23.png b/Dataset/FaceData/processed/Van Dung/23.png\\ndeleted file mode 100644\\nindex 16e7748..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/23.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/24.png b/Dataset/FaceData/processed/Van Dung/24.png\\ndeleted file mode 100644\\nindex 63e4188..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/24.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/25.png b/Dataset/FaceData/processed/Van Dung/25.png\\ndeleted file mode 100644\\nindex 9c0493d..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/25.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/26.png b/Dataset/FaceData/processed/Van Dung/26.png\\ndeleted file mode 100644\\nindex 34b8459..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/26.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/27.png b/Dataset/FaceData/processed/Van Dung/27.png\\ndeleted file mode 100644\\nindex e87d5a2..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/27.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/28.png b/Dataset/FaceData/processed/Van Dung/28.png\\ndeleted file mode 100644\\nindex 3c3670c..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/28.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/29.png b/Dataset/FaceData/processed/Van Dung/29.png\\ndeleted file mode 100644\\nindex 00ad4ee..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/29.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/3.png b/Dataset/FaceData/processed/Van Dung/3.png\\ndeleted file mode 100644\\nindex 9909aa8..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/30.png b/Dataset/FaceData/processed/Van Dung/30.png\\ndeleted file mode 100644\\nindex c2afde6..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/30.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/31.png b/Dataset/FaceData/processed/Van Dung/31.png\\ndeleted file mode 100644\\nindex beb5828..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/31.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/32.png b/Dataset/FaceData/processed/Van Dung/32.png\\ndeleted file mode 100644\\nindex fc13fef..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/32.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/33.png b/Dataset/FaceData/processed/Van Dung/33.png\\ndeleted file mode 100644\\nindex 6af99f1..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/33.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/34.png b/Dataset/FaceData/processed/Van Dung/34.png\\ndeleted file mode 100644\\nindex d64508c..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/34.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/35.png b/Dataset/FaceData/processed/Van Dung/35.png\\ndeleted file mode 100644\\nindex 68ef2ac..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/35.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/36.png b/Dataset/FaceData/processed/Van Dung/36.png\\ndeleted file mode 100644\\nindex 0e551aa..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/36.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/37.png b/Dataset/FaceData/processed/Van Dung/37.png\\ndeleted file mode 100644\\nindex 9221551..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/37.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/38.png b/Dataset/FaceData/processed/Van Dung/38.png\\ndeleted file mode 100644\\nindex 6dc0195..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/38.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/39.png b/Dataset/FaceData/processed/Van Dung/39.png\\ndeleted file mode 100644\\nindex c28a42c..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/39.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/4.png b/Dataset/FaceData/processed/Van Dung/4.png\\ndeleted file mode 100644\\nindex 3f17f7d..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/40.png b/Dataset/FaceData/processed/Van Dung/40.png\\ndeleted file mode 100644\\nindex 8716aee..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/40.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/42.png b/Dataset/FaceData/processed/Van Dung/42.png\\ndeleted file mode 100644\\nindex afbc046..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/42.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/43.png b/Dataset/FaceData/processed/Van Dung/43.png\\ndeleted file mode 100644\\nindex 56be0d4..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/43.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/44.png b/Dataset/FaceData/processed/Van Dung/44.png\\ndeleted file mode 100644\\nindex 8ef98e2..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/44.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/45.png b/Dataset/FaceData/processed/Van Dung/45.png\\ndeleted file mode 100644\\nindex 7d90eaf..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/45.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/46.png b/Dataset/FaceData/processed/Van Dung/46.png\\ndeleted file mode 100644\\nindex 932bad5..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/46.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/47.png b/Dataset/FaceData/processed/Van Dung/47.png\\ndeleted file mode 100644\\nindex 6eafa7f..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/47.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/48.png b/Dataset/FaceData/processed/Van Dung/48.png\\ndeleted file mode 100644\\nindex 307e844..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/48.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/49.png b/Dataset/FaceData/processed/Van Dung/49.png\\ndeleted file mode 100644\\nindex 35895ec..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/49.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/5.png b/Dataset/FaceData/processed/Van Dung/5.png\\ndeleted file mode 100644\\nindex a009326..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/5.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/50.png b/Dataset/FaceData/processed/Van Dung/50.png\\ndeleted file mode 100644\\nindex 6905cdb..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/50.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/51.png b/Dataset/FaceData/processed/Van Dung/51.png\\ndeleted file mode 100644\\nindex 936696d..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/51.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/52.png b/Dataset/FaceData/processed/Van Dung/52.png\\ndeleted file mode 100644\\nindex 23d428a..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/52.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/53.png b/Dataset/FaceData/processed/Van Dung/53.png\\ndeleted file mode 100644\\nindex e0a307c..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/53.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/54.png b/Dataset/FaceData/processed/Van Dung/54.png\\ndeleted file mode 100644\\nindex b5e047b..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/54.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/55.png b/Dataset/FaceData/processed/Van Dung/55.png\\ndeleted file mode 100644\\nindex 8bc3daa..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/55.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/56.png b/Dataset/FaceData/processed/Van Dung/56.png\\ndeleted file mode 100644\\nindex cf12597..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/56.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/57.png b/Dataset/FaceData/processed/Van Dung/57.png\\ndeleted file mode 100644\\nindex af196c5..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/57.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/58.png b/Dataset/FaceData/processed/Van Dung/58.png\\ndeleted file mode 100644\\nindex c84aefb..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/58.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/59.png b/Dataset/FaceData/processed/Van Dung/59.png\\ndeleted file mode 100644\\nindex 0e08bf0..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/59.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/6.png b/Dataset/FaceData/processed/Van Dung/6.png\\ndeleted file mode 100644\\nindex 18e462f..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/6.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/60.png b/Dataset/FaceData/processed/Van Dung/60.png\\ndeleted file mode 100644\\nindex f35e040..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/60.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/61.png b/Dataset/FaceData/processed/Van Dung/61.png\\ndeleted file mode 100644\\nindex f0350d4..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/61.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/62.png b/Dataset/FaceData/processed/Van Dung/62.png\\ndeleted file mode 100644\\nindex 449819d..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/62.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/63.png b/Dataset/FaceData/processed/Van Dung/63.png\\ndeleted file mode 100644\\nindex 4076307..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/63.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/64.png b/Dataset/FaceData/processed/Van Dung/64.png\\ndeleted file mode 100644\\nindex f52f8c4..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/64.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/65.png b/Dataset/FaceData/processed/Van Dung/65.png\\ndeleted file mode 100644\\nindex ddd0527..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/65.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/66.png b/Dataset/FaceData/processed/Van Dung/66.png\\ndeleted file mode 100644\\nindex d9bb88b..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/66.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/67.png b/Dataset/FaceData/processed/Van Dung/67.png\\ndeleted file mode 100644\\nindex ea339fa..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/67.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/68.png b/Dataset/FaceData/processed/Van Dung/68.png\\ndeleted file mode 100644\\nindex a7e9410..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/68.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/69.png b/Dataset/FaceData/processed/Van Dung/69.png\\ndeleted file mode 100644\\nindex 37f1a94..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/69.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/7.png b/Dataset/FaceData/processed/Van Dung/7.png\\ndeleted file mode 100644\\nindex 6915dfb..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/7.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/70.png b/Dataset/FaceData/processed/Van Dung/70.png\\ndeleted file mode 100644\\nindex 99ce91d..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/70.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/71.png b/Dataset/FaceData/processed/Van Dung/71.png\\ndeleted file mode 100644\\nindex 1105146..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/71.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/72.png b/Dataset/FaceData/processed/Van Dung/72.png\\ndeleted file mode 100644\\nindex 2ef52ee..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/72.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/73.png b/Dataset/FaceData/processed/Van Dung/73.png\\ndeleted file mode 100644\\nindex 960b1cb..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/73.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/74.png b/Dataset/FaceData/processed/Van Dung/74.png\\ndeleted file mode 100644\\nindex 3675c6b..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/74.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/75.png b/Dataset/FaceData/processed/Van Dung/75.png\\ndeleted file mode 100644\\nindex 3d4eb68..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/75.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/76.png b/Dataset/FaceData/processed/Van Dung/76.png\\ndeleted file mode 100644\\nindex f65bf0c..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/76.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/77.png b/Dataset/FaceData/processed/Van Dung/77.png\\ndeleted file mode 100644\\nindex 574433f..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/77.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/78.png b/Dataset/FaceData/processed/Van Dung/78.png\\ndeleted file mode 100644\\nindex 656d366..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/78.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/79.png b/Dataset/FaceData/processed/Van Dung/79.png\\ndeleted file mode 100644\\nindex 0481764..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/79.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/8.png b/Dataset/FaceData/processed/Van Dung/8.png\\ndeleted file mode 100644\\nindex 450e420..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/8.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/80.png b/Dataset/FaceData/processed/Van Dung/80.png\\ndeleted file mode 100644\\nindex 761050f..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/80.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/81.png b/Dataset/FaceData/processed/Van Dung/81.png\\ndeleted file mode 100644\\nindex d919f51..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/81.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/82.png b/Dataset/FaceData/processed/Van Dung/82.png\\ndeleted file mode 100644\\nindex e2ed017..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/82.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/83.png b/Dataset/FaceData/processed/Van Dung/83.png\\ndeleted file mode 100644\\nindex 7456ee6..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/83.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/84.png b/Dataset/FaceData/processed/Van Dung/84.png\\ndeleted file mode 100644\\nindex 7d47a3b..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/84.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/85.png b/Dataset/FaceData/processed/Van Dung/85.png\\ndeleted file mode 100644\\nindex 2264905..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/85.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/86.png b/Dataset/FaceData/processed/Van Dung/86.png\\ndeleted file mode 100644\\nindex 6e06384..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/86.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/87.png b/Dataset/FaceData/processed/Van Dung/87.png\\ndeleted file mode 100644\\nindex d77976e..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/87.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/88.png b/Dataset/FaceData/processed/Van Dung/88.png\\ndeleted file mode 100644\\nindex e12a969..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/88.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Van Dung/9.png b/Dataset/FaceData/processed/Van Dung/9.png\\ndeleted file mode 100644\\nindex ce26c80..0000000\\nBinary files a/Dataset/FaceData/processed/Van Dung/9.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/0.png b/Dataset/FaceData/processed/Xuan Hinh/0.png\\ndeleted file mode 100644\\nindex d83669a..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/0.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/1.png b/Dataset/FaceData/processed/Xuan Hinh/1.png\\ndeleted file mode 100644\\nindex 08e01f0..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/10.png b/Dataset/FaceData/processed/Xuan Hinh/10.png\\ndeleted file mode 100644\\nindex 78ef505..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/10.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/11.png b/Dataset/FaceData/processed/Xuan Hinh/11.png\\ndeleted file mode 100644\\nindex 6bfd094..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/11.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/12.png b/Dataset/FaceData/processed/Xuan Hinh/12.png\\ndeleted file mode 100644\\nindex afed2c5..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/12.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/13.png b/Dataset/FaceData/processed/Xuan Hinh/13.png\\ndeleted file mode 100644\\nindex a31111a..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/13.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/14.png b/Dataset/FaceData/processed/Xuan Hinh/14.png\\ndeleted file mode 100644\\nindex 743788c..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/14.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/15.png b/Dataset/FaceData/processed/Xuan Hinh/15.png\\ndeleted file mode 100644\\nindex d1a7b60..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/15.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/16.png b/Dataset/FaceData/processed/Xuan Hinh/16.png\\ndeleted file mode 100644\\nindex a7c1f4b..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/16.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/17.png b/Dataset/FaceData/processed/Xuan Hinh/17.png\\ndeleted file mode 100644\\nindex 8a6be23..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/17.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/18.png b/Dataset/FaceData/processed/Xuan Hinh/18.png\\ndeleted file mode 100644\\nindex b61c76a..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/18.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/19.png b/Dataset/FaceData/processed/Xuan Hinh/19.png\\ndeleted file mode 100644\\nindex b93f951..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/19.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/2.png b/Dataset/FaceData/processed/Xuan Hinh/2.png\\ndeleted file mode 100644\\nindex 4870d54..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/20.png b/Dataset/FaceData/processed/Xuan Hinh/20.png\\ndeleted file mode 100644\\nindex f518cc5..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/20.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/21.png b/Dataset/FaceData/processed/Xuan Hinh/21.png\\ndeleted file mode 100644\\nindex d9ae680..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/21.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/22.png b/Dataset/FaceData/processed/Xuan Hinh/22.png\\ndeleted file mode 100644\\nindex af8ee44..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/22.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/23.png b/Dataset/FaceData/processed/Xuan Hinh/23.png\\ndeleted file mode 100644\\nindex de91e23..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/23.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/24.png b/Dataset/FaceData/processed/Xuan Hinh/24.png\\ndeleted file mode 100644\\nindex 35ec177..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/24.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/25.png b/Dataset/FaceData/processed/Xuan Hinh/25.png\\ndeleted file mode 100644\\nindex 99e54ef..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/25.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/26.png b/Dataset/FaceData/processed/Xuan Hinh/26.png\\ndeleted file mode 100644\\nindex 4ee7d98..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/26.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/27.png b/Dataset/FaceData/processed/Xuan Hinh/27.png\\ndeleted file mode 100644\\nindex 58d1431..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/27.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/28.png b/Dataset/FaceData/processed/Xuan Hinh/28.png\\ndeleted file mode 100644\\nindex 5a8035d..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/28.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/29.png b/Dataset/FaceData/processed/Xuan Hinh/29.png\\ndeleted file mode 100644\\nindex 681830f..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/29.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/3.png b/Dataset/FaceData/processed/Xuan Hinh/3.png\\ndeleted file mode 100644\\nindex a3eca3d..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/30.png b/Dataset/FaceData/processed/Xuan Hinh/30.png\\ndeleted file mode 100644\\nindex e73ec04..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/30.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/31.png b/Dataset/FaceData/processed/Xuan Hinh/31.png\\ndeleted file mode 100644\\nindex 9a2d7a2..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/31.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/32.png b/Dataset/FaceData/processed/Xuan Hinh/32.png\\ndeleted file mode 100644\\nindex 45627f4..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/32.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/33.png b/Dataset/FaceData/processed/Xuan Hinh/33.png\\ndeleted file mode 100644\\nindex 31951b1..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/33.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/34.png b/Dataset/FaceData/processed/Xuan Hinh/34.png\\ndeleted file mode 100644\\nindex db07536..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/34.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/35.png b/Dataset/FaceData/processed/Xuan Hinh/35.png\\ndeleted file mode 100644\\nindex 7a52639..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/35.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/36.png b/Dataset/FaceData/processed/Xuan Hinh/36.png\\ndeleted file mode 100644\\nindex 09e4f7a..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/36.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/37.png b/Dataset/FaceData/processed/Xuan Hinh/37.png\\ndeleted file mode 100644\\nindex 23f3cd7..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/37.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/38.png b/Dataset/FaceData/processed/Xuan Hinh/38.png\\ndeleted file mode 100644\\nindex f973849..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/38.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/39.png b/Dataset/FaceData/processed/Xuan Hinh/39.png\\ndeleted file mode 100644\\nindex fe55a6d..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/39.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/4.png b/Dataset/FaceData/processed/Xuan Hinh/4.png\\ndeleted file mode 100644\\nindex d710b7d..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/40.png b/Dataset/FaceData/processed/Xuan Hinh/40.png\\ndeleted file mode 100644\\nindex fa07ddc..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/40.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/41.png b/Dataset/FaceData/processed/Xuan Hinh/41.png\\ndeleted file mode 100644\\nindex 56f568c..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/41.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/42.png b/Dataset/FaceData/processed/Xuan Hinh/42.png\\ndeleted file mode 100644\\nindex 297d124..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/42.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/5.png b/Dataset/FaceData/processed/Xuan Hinh/5.png\\ndeleted file mode 100644\\nindex 05c3861..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/5.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/6.png b/Dataset/FaceData/processed/Xuan Hinh/6.png\\ndeleted file mode 100644\\nindex 5348ebc..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/6.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/7.png b/Dataset/FaceData/processed/Xuan Hinh/7.png\\ndeleted file mode 100644\\nindex 309c24d..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/7.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/8.png b/Dataset/FaceData/processed/Xuan Hinh/8.png\\ndeleted file mode 100644\\nindex 6e829bb..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/8.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/Xuan Hinh/9.png b/Dataset/FaceData/processed/Xuan Hinh/9.png\\ndeleted file mode 100644\\nindex 7d3deed..0000000\\nBinary files a/Dataset/FaceData/processed/Xuan Hinh/9.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/bounding_boxes_32581.txt b/Dataset/FaceData/processed/bounding_boxes_32581.txt\\ndeleted file mode 100644\\nindex d9ee475..0000000\\n--- a/Dataset/FaceData/processed/bounding_boxes_32581.txt\\n+++ /dev/null\\n@@ -1,614 +0,0 @@\\n-Dataset/FaceData/processed\\\\chunghoang\\\\chung3.png 441 403 646 648\\n-Dataset/FaceData/processed\\\\chunghoang\\\\chung1.png 674 932 796 1076\\n-Dataset/FaceData/processed\\\\chunghoang\\\\img.png 429 771 940 1398\\n-Dataset/FaceData/processed\\\\chunghoang\\\\422737427_390399053474445_3140718471568843261_n.png 903 839 1149 1156\\n-Dataset/FaceData/processed\\\\chunghoang\\\\chung6.png 890 547 1577 1440\\n-Dataset/FaceData/processed\\\\chunghoang\\\\chung4.png 224 428 391 630\\n-Dataset/FaceData/processed\\\\chunghoang\\\\386429669_867969661603917_3228776363804735267_n.png 934 297 1014 379\\n-Dataset/FaceData/processed\\\\chunghoang\\\\chung2.png 264 621 461 871\\n-Dataset/FaceData/processed\\\\chunghoang\\\\img_1.png 260 509 527 835\\n-Dataset/FaceData/processed\\\\tran nhat truong\\\\truong1.png 240 498 328 601\\n-Dataset/FaceData/processed\\\\Duc viet\\\\61967926_348135315895561_496212973459603456_n.png 486 115 608 269\\n-Dataset/FaceData/processed\\\\Duc viet\\\\152709553_899599430856650_818805157951754296_n.png 276 208 440 403\\n-Dataset/FaceData/processed\\\\Duc viet\\\\61506698_348134895895603_7272087717616287744_n.png 425 303 515 395\\n-Dataset/FaceData/processed\\\\Duc viet\\\\64869534_359570548085371_8201502723321888768_n.png 553 322 874 704\\n-Dataset/FaceData/processed\\\\Duc viet\\\\61848774_348135615895531_3014436068146544640_n.png 262 357 359 474\\n-Dataset/FaceData/processed\\\\Duc viet\\\\152373366_899599367523323_8039073461193180489_n.png 303 446 409 571\\n-Dataset/FaceData/processed\\\\Duc viet\\\\62021360_348135282562231_7688022791626424320_n.png 160 279 271 401\\n-Dataset/FaceData/processed\\\\Duc viet\\\\61560706_348134092562350_1539501885898096640_n.png 393 204 524 364\\n-Dataset/FaceData/processed\\\\Duc viet\\\\62035132_348134362562323_2007170459463843840_n.png 246 345 356 469\\n-Dataset/FaceData/processed\\\\Duc viet\\\\154070237_435134567707863_6078333129900068002_n.png 287 233 370 332\\n-Dataset/FaceData/processed\\\\Duc viet\\\\61584844_348135582562201_7506169027295707136_n.png 362 366 454 476\\n-Dataset/FaceData/processed\\\\Duc viet\\\\61820425_348134402562319_3380097574999425024_n.png 253 384 398 569\\n-Dataset/FaceData/processed\\\\hoang tran phau\\\\phau2.png 369 745 779 1211\\n-Dataset/FaceData/processed\\\\hoang tran phau\\\\img_1.png 237 331 438 596\\n-Dataset/FaceData/processed\\\\hoang tran phau\\\\phau1.png 87 376 1011 1377\\n-Dataset/FaceData/processed\\\\hoang tran phau\\\\phau3.png 1025 714 1156 871\\n-Dataset/FaceData/processed\\\\hoang tran phau\\\\phau.png 220 229 549 593\\n-Dataset/FaceData/processed\\\\hoang tran phau\\\\img.png 965 485 1161 709\\n-Dataset/FaceData/processed\\\\thaongo\\\\thao6.png 663 950 809 1138\\n-Dataset/FaceData/processed\\\\thaongo\\\\thao4.png 713 759 829 909\\n-Dataset/FaceData/processed\\\\thaongo\\\\thao1.png 788 1090 878 1212\\n-Dataset/FaceData/processed\\\\thaongo\\\\thao5.png 667 720 783 870\\n-Dataset/FaceData/processed\\\\thaongo\\\\thao2.png 521 722 668 909\\n-Dataset/FaceData/processed\\\\thaongo\\\\thao7.png\\n-Dataset/FaceData/processed\\\\thaongo\\\\419652962_741170244266451_4914393583094088361_n.png 464 678 574 816\\n-Dataset/FaceData/processed\\\\thaongo\\\\thao3.png 753 753 906 950\\n-Dataset/FaceData/processed\\\\Minh hoa\\\\45761069_299092524035106_5787233926145638400_n.png 708 550 1408 1450\\n-Dataset/FaceData/processed\\\\Minh hoa\\\\72597481_459453121332378_4444718657989246976_n.png 663 747 804 923\\n-Dataset/FaceData/processed\\\\Minh hoa\\\\277588798_1056746241603060_3376911805269669778_n.png 607 866 733 1021\\n-Dataset/FaceData/processed\\\\Minh hoa\\\\51367653_335164410427917_2686636884146257920_n.png 8 46 430 544\\n-Dataset/FaceData/processed\\\\Minh hoa\\\\133049557_769265223684498_4689118252074034370_n.png 547 545 834 911\\n-Dataset/FaceData/processed\\\\Minh hoa\\\\116428895_656623338282021_8457872234875945077_n.png 863 1177 1069 1422\\n-Dataset/FaceData/processed\\\\Minh hoa\\\\258158616_974113876532964_9067509414358086927_n.png 306 197 607 591\\n-Dataset/FaceData/processed\\\\nguyen ngoc thai\\\\thaidemo.png 62 642 489 1174\\n-Dataset/FaceData/processed\\\\nguyen ngoc thai\\\\thai1.png 346 474 919 1157\\n-Dataset/FaceData/processed\\\\nguyen ngoc thai\\\\thai2.png 351 238 551 520\\n-Dataset/FaceData/processed\\\\nguyen ngoc thai\\\\thai3.png 410 744 677 1086\\n-Dataset/FaceData/processed\\\\nguyen ngoc thai\\\\thaidemo2.png 364 488 758 979\\n-Dataset/FaceData/processed\\\\nguyen ngoc thai\\\\thai4.png 335 772 687 1252\\n-Dataset/FaceData/processed\\\\nguyen ngoc thai\\\\thai5.png 210 474 1072 1553\\n-Dataset/FaceData/processed\\\\nguyen ngoc thai\\\\284851180_1033334854278874_6949309560983343387_n.png 997 1596 1149 1779\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\8.png 0 0 124 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\4.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\17.png 2 0 128 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\0.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\18.png 4 0 128 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\20.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\15.png 6 0 127 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\11.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\7.png 0 0 125 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\3.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\10.png 0 0 124 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\14.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\26.png 4 0 127 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\23.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\25.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\28.png 0 0 125 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\29.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\13.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\6.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\1.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\21.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\19.png 16 4 118 119\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\22.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\5.png 11 0 128 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\16.png 2 0 128 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\9.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\27.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\2.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\24.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Quang Hai\\\\12.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\20.png 0 0 177 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\13.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\26.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\27.png 0 0 174 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\29.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\10.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\3.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\38.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\21.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\6.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\8.png 0 0 180 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\4.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\16.png 3 0 173 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\1.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\0.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\22.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\32.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\40.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\14.png 6 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\33.png 0 0 179 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\31.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\9.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\18.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\19.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\34.png 12 0 177 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\15.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\35.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\17.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\12.png 3 0 176 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\28.png 6 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\39.png 0 0 178 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\5.png 4 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\30.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\24.png 0 0 176 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\23.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\7.png 2 18 164 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\37.png 6 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\11.png 0 0 177 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\2.png 0 0 179 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\25.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Hoai linh\\\\36.png 0 0 181 182\\n-Dataset/FaceData/processed\\\\nguyen phuong tram\\\\339263904_1264665414159651_8733650862788543327_n.png 445 499 883 1123\\n-Dataset/FaceData/processed\\\\nguyen phuong tram\\\\anh8.png 290 449 821 1135\\n-Dataset/FaceData/processed\\\\nguyen phuong tram\\\\anh2.png 636 491 1013 1021\\n-Dataset/FaceData/processed\\\\nguyen phuong tram\\\\anh7.png 470 254 794 705\\n-Dataset/FaceData/processed\\\\nguyen phuong tram\\\\337142073_1253839052216597_199657983855233980_n.png 126 3 501 613\\n-Dataset/FaceData/processed\\\\nguyen phuong tram\\\\anh4.png 491 512 713 817\\n-Dataset/FaceData/processed\\\\nguyen phuong tram\\\\339408406_1209323986622559_1237855961637611483_n.png 357 319 814 961\\n-Dataset/FaceData/processed\\\\nguyen phuong tram\\\\339266601_894783791775673_734864429475267886_n.png 470 254 794 705\\n-Dataset/FaceData/processed\\\\nguyen phuong tram\\\\anh1.png 411 559 785 1104\\n-Dataset/FaceData/processed\\\\nguyen phuong tram\\\\anh3.png 647 193 955 626\\n-Dataset/FaceData/processed\\\\nguyen phuong tram\\\\anh5.png 501 560 753 920\\n-Dataset/FaceData/processed\\\\dang thi ha\\\\anh1.png 738 1202 1016 1534\\n-Dataset/FaceData/processed\\\\dang thi ha\\\\demo.png 812 1322 996 1565\\n-Dataset/FaceData/processed\\\\dang thi ha\\\\anh3.png 979 1107 1195 1392\\n-Dataset/FaceData/processed\\\\dang thi ha\\\\img.png 0 808 360 1330\\n-Dataset/FaceData/processed\\\\dang thi ha\\\\anh2.png 815 1234 1097 1551\\n-Dataset/FaceData/processed\\\\dang thi ha\\\\anh4.png 769 896 1151 1320\\n-Dataset/FaceData/processed\\\\dang thi ha\\\\385534676_267391239125906_3185308814281359599_n.png 880 1101 1016 1264\\n-Dataset/FaceData/processed\\\\My Duyen\\\\276281855_728896961615044_4850973774883281965_n.png 295 113 1006 1008\\n-Dataset/FaceData/processed\\\\My Duyen\\\\71477803_179402706564475_6524185163780325376_n.png 472 149 1080 966\\n-Dataset/FaceData/processed\\\\My Duyen\\\\271565569_687653065739434_6695347522364803324_n.png 267 285 363 394\\n-Dataset/FaceData/processed\\\\My Duyen\\\\399161466_1085274189310651_5389319938695371438_n.png\\n-Dataset/FaceData/processed\\\\My Duyen\\\\425727875_1136306777540725_7475412167375191065_n.png 79 0 161 67\\n-Dataset/FaceData/processed\\\\My Duyen\\\\375727668_1053445732493497_6855315188334578963_n.png 968 926 1019 982\\n-Dataset/FaceData/processed\\\\My Duyen\\\\Screenshot 2024-02-08 200137.png 172 325 273 491\\n-Dataset/FaceData/processed\\\\My Duyen\\\\377915813_1055517365619667_3022176625716036504_n.png 595 519 808 816\\n-Dataset/FaceData/processed\\\\My Duyen\\\\383221108_1063489451489125_7303325553687006067_n.png 768 863 899 1018\\n-Dataset/FaceData/processed\\\\My Duyen\\\\240594338_608022267035848_559750156049629888_n.png 387 260 984 1040\\n-Dataset/FaceData/processed\\\\Do hieu\\\\178929889_2957139244608757_1991887332909086037_n (1).png 150 111 463 467\\n-Dataset/FaceData/processed\\\\Do hieu\\\\177993461_2957139491275399_3222091836626291316_n.png 173 329 467 712\\n-Dataset/FaceData/processed\\\\Do hieu\\\\177907728_2957139527942062_5622464185056568311_n.png 129 318 425 697\\n-Dataset/FaceData/processed\\\\Do hieu\\\\314736967_3413393448983332_3470974153489929662_n.png 319 86 526 322\\n-Dataset/FaceData/processed\\\\Do hieu\\\\178929889_2957139244608757_1991887332909086037_n.png 150 111 463 467\\n-Dataset/FaceData/processed\\\\Do hieu\\\\408729291_122109331016134044_5530016628103795106_n.png 400 131 563 330\\n-Dataset/FaceData/processed\\\\Do hieu\\\\176064931_2957139457942069_3035200184642124074_n.png 250 147 530 486\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\18.png 0 0 170 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\35.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\9.png 5 0 164 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\19.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\34.png 3 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\0.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\26.png 3 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\2.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\32.png 0 0 172 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\22.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\15.png 6 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\20.png 0 0 176 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\40.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\28.png 0 0 176 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\4.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\23.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\25.png\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\39.png 0 0 173 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\10.png 1 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\3.png 34 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\14.png 11 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\7.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\38.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\29.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\24.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\31.png 6 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\27.png 9 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\13.png 12 0 177 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\16.png 0 0 174 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\33.png 8 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\37.png 16 0 167 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\12.png 92 60 168 146\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\1.png 0 0 176 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\5.png 3 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\11.png 13 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\21.png 4 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\6.png 0 0 167 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\36.png 0 0 180 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\17.png 1 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\8.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\30.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\32.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\43.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\33.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\38.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\27.png 1 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\30.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\8.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\37.png 4 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\22.png 0 0 180 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\35.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\18.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\26.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\21.png 0 0 178 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\23.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\16.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\9.png 0 0 181 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\36.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\14.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\15.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\11.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\40.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\42.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\2.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\20.png 4 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\31.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\7.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\5.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\25.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\10.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\6.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\4.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\1.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\12.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\24.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\19.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\28.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\0.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\34.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\29.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\3.png 7 1 171 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\17.png 0 0 179 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\39.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\41.png 0 0 178 182\\n-Dataset/FaceData/processed\\\\Dam vinh hung\\\\13.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nam Em\\\\33.png 2 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\4.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\26.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\11.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\28.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\30.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\8.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\40.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\12.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\24.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\32.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\7.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\23.png 1 0 125 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\22.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\21.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\31.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\9.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\0.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\3.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\2.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\38.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\10.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\5.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\18.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\25.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\15.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\29.png 10 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\6.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\35.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\34.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\1.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\20.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\13.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\27.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\19.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\16.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\39.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\17.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\14.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\37.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\36.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Nam Em\\\\41.png 1 0 128 128\\n-Dataset/FaceData/processed\\\\Tran Hoc\\\\90066892_1096495004027148_8085701175137009664_n.png 691 233 829 429\\n-Dataset/FaceData/processed\\\\Tran Hoc\\\\235810118_1494231920920119_422367748034160663_n.png 252 125 1059 1097\\n-Dataset/FaceData/processed\\\\Tran Hoc\\\\107223180_1197468397263141_6372187421696273098_n.png 378 354 507 518\\n-Dataset/FaceData/processed\\\\Tran Hoc\\\\120220333_1261416600868320_4101096592656067221_n.png 297 99 557 437\\n-Dataset/FaceData/processed\\\\truong giang\\\\vtr-4472.png 178 162 301 323\\n-Dataset/FaceData/processed\\\\truong giang\\\\fb_img_1704768450012-1704768746-24-width720height1079.png 566 342 647 442\\n-Dataset/FaceData/processed\\\\truong giang\\\\giang4.png 188 67 322 237\\n-Dataset/FaceData/processed\\\\truong giang\\\\0630_truonggiang_1.png 324 148 437 293\\n-Dataset/FaceData/processed\\\\truong giang\\\\mc-truong-giang-918712.png 465 55 571 195\\n-Dataset/FaceData/processed\\\\truong giang\\\\giang3.png 407 31 506 150\\n-Dataset/FaceData/processed\\\\truong giang\\\\1545311811-862-truong-giang-bat-ngo-dan-dau-de-cu-nam-dien-vien-dien-anh-duoc-yeu-thich-nhat-truonggiang-1545278076-width660height990.png 267 144 436 366\\n-Dataset/FaceData/processed\\\\truong giang\\\\0632_truonggiang_2.png 294 220 457 428\\n-Dataset/FaceData/processed\\\\truong giang\\\\trg1.png 349 113 551 390\\n-Dataset/FaceData/processed\\\\truong giang\\\\fb_img_1704768289216-1704768712-408-width720height960.png 291 241 378 348\\n-Dataset/FaceData/processed\\\\truong giang\\\\vtr-4475.png 203 157 318 303\\n-Dataset/FaceData/processed\\\\truong giang\\\\mc-truong-giang-1229339.png 268 131 399 297\\n-Dataset/FaceData/processed\\\\truong giang\\\\giang1.png 175 18 254 113\\n-Dataset/FaceData/processed\\\\truong giang\\\\A27U7778.png 440 406 606 619\\n-Dataset/FaceData/processed\\\\truong giang\\\\giang2.png 614 63 771 269\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\28.png 0 0 177 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\32.png\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\7.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\18.png 6 0 180 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\36.png 3 0 178 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\11.png 0 0 176 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\9.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\12.png 9 0 182 179\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\20.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\23.png 0 0 181 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\5.png 3 0 171 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\34.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\8.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\37.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\31.png 0 0 179 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\33.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\16.png 1 0 182 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\46.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\4.png 1 0 171 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\1.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\22.png\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\42.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\13.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\17.png 4 0 180 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\10.png 0 0 179 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\21.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\40.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\35.png 0 0 178 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\47.png 0 0 166 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\38.png 0 0 172 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\14.png 0 0 164 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\2.png 0 0 181 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\27.png 6 0 175 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\24.png 2 0 182 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\15.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\25.png 0 0 178 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\26.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\44.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\19.png 3 0 182 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\39.png 0 0 179 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\41.png 0 0 166 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\6.png 6 0 182 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\43.png 2 0 182 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\0.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\30.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\3.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\29.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\45.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\duong thi bich nguyet\\\\nguyet4.png 135 688 643 1341\\n-Dataset/FaceData/processed\\\\duong thi bich nguyet\\\\anh1.png 276 151 594 567\\n-Dataset/FaceData/processed\\\\duong thi bich nguyet\\\\nguyet2.png 562 898 745 1121\\n-Dataset/FaceData/processed\\\\duong thi bich nguyet\\\\nguyet6.png 890 547 1577 1440\\n-Dataset/FaceData/processed\\\\duong thi bich nguyet\\\\nguyet3.png 405 230 693 596\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\36.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\12.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\41.png\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\9.png 3 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\46.png 0 0 175 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\44.png 16 3 167 175\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\23.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\10.png 1 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\42.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\11.png 4 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\40.png 6 0 176 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\17.png 3 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\29.png 0 0 181 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\30.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\18.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\37.png 0 0 176 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\13.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\28.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\3.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\4.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\21.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\47.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\35.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\15.png 1 0 175 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\22.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\24.png 0 0 167 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\14.png 0 0 181 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\19.png 1 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\33.png 4 0 181 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\25.png 0 0 180 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\34.png 0 0 181 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\2.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\20.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\43.png 1 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\39.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\6.png 0 0 181 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\1.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\26.png 3 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\8.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\7.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\27.png 4 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\38.png 6 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\32.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\31.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\5.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\45.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\0.png 0 0 182 182\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\16.png\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\29.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\8.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\36.png 0 0 126 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\34.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\35.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\10.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\23.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\17.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\40.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\24.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\7.png 4 3 115 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\3.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\4.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\12.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\19.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\25.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\38.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\18.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\30.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\28.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\1.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\0.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\14.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\21.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\31.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\13.png 0 0 116 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\11.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\5.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\9.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\41.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\33.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\26.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\39.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\32.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\2.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\16.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\22.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\42.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\15.png 0 0 118 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\27.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\37.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\6.png 0 0 126 128\\n-Dataset/FaceData/processed\\\\Xuan Hinh\\\\20.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Ma bach duy\\\\duy1.png 439 898 1550 2419\\n-Dataset/FaceData/processed\\\\Ma bach duy\\\\duy2.png 355 743 1452 2246\\n-Dataset/FaceData/processed\\\\Ma bach duy\\\\duy3.png 384 760 1399 2073\\n-Dataset/FaceData/processed\\\\Ma bach duy\\\\duy4.png 374 709 1555 2300\\n-Dataset/FaceData/processed\\\\Den Vau\\\\18.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\48.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\60.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\12.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\73.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\29.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\23.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\22.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\56.png 0 0 125 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\54.png 6 3 127 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\25.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\15.png 1 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\16.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\58.png 4 0 127 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\28.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\35.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\50.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\34.png 0 0 119 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\17.png 2 0 124 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\47.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\13.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\71.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\0.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\30.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\72.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\24.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\51.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\68.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\43.png 3 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\31.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\49.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\69.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\65.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\55.png 0 0 124 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\10.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\32.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\44.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\5.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\8.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\64.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\70.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\11.png 0 0 127 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\38.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\33.png\\n-Dataset/FaceData/processed\\\\Den Vau\\\\46.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\2.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\41.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\63.png 0 0 126 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\52.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\37.png\\n-Dataset/FaceData/processed\\\\Den Vau\\\\66.png 0 0 124 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\27.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\4.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\3.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\40.png 0 0 123 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\14.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\26.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\19.png 1 0 126 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\42.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\61.png 4 0 125 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\59.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\36.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\9.png 0 0 127 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\45.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\39.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\7.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\67.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\57.png\\n-Dataset/FaceData/processed\\\\Den Vau\\\\53.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\1.png 4 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\62.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\21.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\20.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Den Vau\\\\6.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\83.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\74.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\8.png 2 0 124 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\30.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\10.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\6.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\79.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\14.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\62.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\85.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\0.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\3.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\23.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\54.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\5.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\57.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\58.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\2.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\52.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\16.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\4.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\50.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\40.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\77.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\20.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\82.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\27.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\68.png 0 0 127 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\15.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\75.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\84.png 0 0 127 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\53.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\22.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\39.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\35.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\1.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\25.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\34.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\17.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\59.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\37.png 2 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\60.png 0 0 126 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\13.png 2 0 127 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\38.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\81.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\42.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\65.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\47.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\36.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\41.png\\n-Dataset/FaceData/processed\\\\Van Dung\\\\32.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\87.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\80.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\12.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\48.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\64.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\7.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\49.png 0 0 126 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\33.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\44.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\21.png 0 0 127 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\26.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\61.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\55.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\18.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\78.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\66.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\71.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\69.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\46.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\73.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\24.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\56.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\29.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\9.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\88.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\45.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\19.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\51.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\63.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\31.png 0 0 126 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\43.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\70.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\76.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\28.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\72.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\11.png 0 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\67.png 4 0 128 128\\n-Dataset/FaceData/processed\\\\Van Dung\\\\86.png 0 0 128 128\\ndiff --git a/Dataset/FaceData/processed/bounding_boxes_68631.txt b/Dataset/FaceData/processed/bounding_boxes_68631.txt\\ndeleted file mode 100644\\nindex 79a99ec..0000000\\n--- a/Dataset/FaceData/processed/bounding_boxes_68631.txt\\n+++ /dev/null\\n@@ -1,23 +0,0 @@\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\22.png\\n-Dataset/FaceData/processed\\\\Bui Anh Tuan\\\\32.png\\n-Dataset/FaceData/processed\\\\My Duyen\\\\399161466_1085274189310651_5389319938695371438_n.png\\n-Dataset/FaceData/processed\\\\Ha Anh Tuan\\\\25.png\\n-Dataset/FaceData/processed\\\\thaongo\\\\thao10.png 337 334 720 837\\n-Dataset/FaceData/processed\\\\thaongo\\\\thao19.png\\n-Dataset/FaceData/processed\\\\thaongo\\\\thao21.png 405 673 929 1375\\n-Dataset/FaceData/processed\\\\thaongo\\\\thao24.png 235 615 768 1320\\n-Dataset/FaceData/processed\\\\thaongo\\\\thao25.png 220 504 774 1224\\n-Dataset/FaceData/processed\\\\thaongo\\\\thao26.png 669 863 791 1009\\n-Dataset/FaceData/processed\\\\thaongo\\\\thao29.png 27 304 531 942\\n-Dataset/FaceData/processed\\\\thaongo\\\\thao31.png 365 547 495 721\\n-Dataset/FaceData/processed\\\\thaongo\\\\thao32.png 305 292 480 509\\n-Dataset/FaceData/processed\\\\thaongo\\\\thao33.png 381 259 578 502\\n-Dataset/FaceData/processed\\\\thaongo\\\\thao34.png 699 964 804 1096\\n-Dataset/FaceData/processed\\\\thaongo\\\\thao35.png 676 975 780 1110\\n-Dataset/FaceData/processed\\\\thaongo\\\\thao7.png\\n-Dataset/FaceData/processed\\\\Den Vau\\\\33.png\\n-Dataset/FaceData/processed\\\\Den Vau\\\\37.png\\n-Dataset/FaceData/processed\\\\Den Vau\\\\57.png\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\16.png\\n-Dataset/FaceData/processed\\\\Nguyen phu trong\\\\41.png\\n-Dataset/FaceData/processed\\\\Van Dung\\\\41.png\\ndiff --git a/Dataset/FaceData/processed/chunghoang/386429669_867969661603917_3228776363804735267_n.png b/Dataset/FaceData/processed/chunghoang/386429669_867969661603917_3228776363804735267_n.png\\ndeleted file mode 100644\\nindex d852186..0000000\\nBinary files a/Dataset/FaceData/processed/chunghoang/386429669_867969661603917_3228776363804735267_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/chunghoang/422737427_390399053474445_3140718471568843261_n.png b/Dataset/FaceData/processed/chunghoang/422737427_390399053474445_3140718471568843261_n.png\\ndeleted file mode 100644\\nindex 37fc627..0000000\\nBinary files a/Dataset/FaceData/processed/chunghoang/422737427_390399053474445_3140718471568843261_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/chunghoang/chung1.png b/Dataset/FaceData/processed/chunghoang/chung1.png\\ndeleted file mode 100644\\nindex ac24d34..0000000\\nBinary files a/Dataset/FaceData/processed/chunghoang/chung1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/chunghoang/chung2.png b/Dataset/FaceData/processed/chunghoang/chung2.png\\ndeleted file mode 100644\\nindex 62a29f7..0000000\\nBinary files a/Dataset/FaceData/processed/chunghoang/chung2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/chunghoang/chung3.png b/Dataset/FaceData/processed/chunghoang/chung3.png\\ndeleted file mode 100644\\nindex ea70cf6..0000000\\nBinary files a/Dataset/FaceData/processed/chunghoang/chung3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/chunghoang/chung4.png b/Dataset/FaceData/processed/chunghoang/chung4.png\\ndeleted file mode 100644\\nindex 56eca73..0000000\\nBinary files a/Dataset/FaceData/processed/chunghoang/chung4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/chunghoang/chung6.png b/Dataset/FaceData/processed/chunghoang/chung6.png\\ndeleted file mode 100644\\nindex 86bf22d..0000000\\nBinary files a/Dataset/FaceData/processed/chunghoang/chung6.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/chunghoang/img.png b/Dataset/FaceData/processed/chunghoang/img.png\\ndeleted file mode 100644\\nindex b0e1035..0000000\\nBinary files a/Dataset/FaceData/processed/chunghoang/img.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/chunghoang/img_1.png b/Dataset/FaceData/processed/chunghoang/img_1.png\\ndeleted file mode 100644\\nindex aec30b0..0000000\\nBinary files a/Dataset/FaceData/processed/chunghoang/img_1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/dang thi ha/385534676_267391239125906_3185308814281359599_n.png b/Dataset/FaceData/processed/dang thi ha/385534676_267391239125906_3185308814281359599_n.png\\ndeleted file mode 100644\\nindex 113284b..0000000\\nBinary files a/Dataset/FaceData/processed/dang thi ha/385534676_267391239125906_3185308814281359599_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/dang thi ha/anh1.png b/Dataset/FaceData/processed/dang thi ha/anh1.png\\ndeleted file mode 100644\\nindex bbe6609..0000000\\nBinary files a/Dataset/FaceData/processed/dang thi ha/anh1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/dang thi ha/anh2.png b/Dataset/FaceData/processed/dang thi ha/anh2.png\\ndeleted file mode 100644\\nindex b003bdf..0000000\\nBinary files a/Dataset/FaceData/processed/dang thi ha/anh2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/dang thi ha/anh3.png b/Dataset/FaceData/processed/dang thi ha/anh3.png\\ndeleted file mode 100644\\nindex c9a7d1f..0000000\\nBinary files a/Dataset/FaceData/processed/dang thi ha/anh3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/dang thi ha/anh4.png b/Dataset/FaceData/processed/dang thi ha/anh4.png\\ndeleted file mode 100644\\nindex cea60d2..0000000\\nBinary files a/Dataset/FaceData/processed/dang thi ha/anh4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/dang thi ha/demo.png b/Dataset/FaceData/processed/dang thi ha/demo.png\\ndeleted file mode 100644\\nindex e09bd2f..0000000\\nBinary files a/Dataset/FaceData/processed/dang thi ha/demo.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/dang thi ha/img.png b/Dataset/FaceData/processed/dang thi ha/img.png\\ndeleted file mode 100644\\nindex 80a07c2..0000000\\nBinary files a/Dataset/FaceData/processed/dang thi ha/img.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/duong thi bich nguyet/anh1.png b/Dataset/FaceData/processed/duong thi bich nguyet/anh1.png\\ndeleted file mode 100644\\nindex fc4009e..0000000\\nBinary files a/Dataset/FaceData/processed/duong thi bich nguyet/anh1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/duong thi bich nguyet/nguyet2.png b/Dataset/FaceData/processed/duong thi bich nguyet/nguyet2.png\\ndeleted file mode 100644\\nindex 34976a7..0000000\\nBinary files a/Dataset/FaceData/processed/duong thi bich nguyet/nguyet2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/duong thi bich nguyet/nguyet3.png b/Dataset/FaceData/processed/duong thi bich nguyet/nguyet3.png\\ndeleted file mode 100644\\nindex 6ed1d8e..0000000\\nBinary files a/Dataset/FaceData/processed/duong thi bich nguyet/nguyet3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/duong thi bich nguyet/nguyet4.png b/Dataset/FaceData/processed/duong thi bich nguyet/nguyet4.png\\ndeleted file mode 100644\\nindex 0421453..0000000\\nBinary files a/Dataset/FaceData/processed/duong thi bich nguyet/nguyet4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/duong thi bich nguyet/nguyet6.png b/Dataset/FaceData/processed/duong thi bich nguyet/nguyet6.png\\ndeleted file mode 100644\\nindex 86bf22d..0000000\\nBinary files a/Dataset/FaceData/processed/duong thi bich nguyet/nguyet6.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/hoang tran phau/img.png b/Dataset/FaceData/processed/hoang tran phau/img.png\\ndeleted file mode 100644\\nindex b1a78ca..0000000\\nBinary files a/Dataset/FaceData/processed/hoang tran phau/img.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/hoang tran phau/img_1.png b/Dataset/FaceData/processed/hoang tran phau/img_1.png\\ndeleted file mode 100644\\nindex d00a156..0000000\\nBinary files a/Dataset/FaceData/processed/hoang tran phau/img_1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/hoang tran phau/phau.png b/Dataset/FaceData/processed/hoang tran phau/phau.png\\ndeleted file mode 100644\\nindex 2bac419..0000000\\nBinary files a/Dataset/FaceData/processed/hoang tran phau/phau.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/hoang tran phau/phau1.png b/Dataset/FaceData/processed/hoang tran phau/phau1.png\\ndeleted file mode 100644\\nindex ced9caa..0000000\\nBinary files a/Dataset/FaceData/processed/hoang tran phau/phau1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/hoang tran phau/phau2.png b/Dataset/FaceData/processed/hoang tran phau/phau2.png\\ndeleted file mode 100644\\nindex 03d822c..0000000\\nBinary files a/Dataset/FaceData/processed/hoang tran phau/phau2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/hoang tran phau/phau3.png b/Dataset/FaceData/processed/hoang tran phau/phau3.png\\ndeleted file mode 100644\\nindex 7d03f2c..0000000\\nBinary files a/Dataset/FaceData/processed/hoang tran phau/phau3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/nguyen ngoc thai/284851180_1033334854278874_6949309560983343387_n.png b/Dataset/FaceData/processed/nguyen ngoc thai/284851180_1033334854278874_6949309560983343387_n.png\\ndeleted file mode 100644\\nindex eab3683..0000000\\nBinary files a/Dataset/FaceData/processed/nguyen ngoc thai/284851180_1033334854278874_6949309560983343387_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/nguyen ngoc thai/thai1.png b/Dataset/FaceData/processed/nguyen ngoc thai/thai1.png\\ndeleted file mode 100644\\nindex e7125b8..0000000\\nBinary files a/Dataset/FaceData/processed/nguyen ngoc thai/thai1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/nguyen ngoc thai/thai2.png b/Dataset/FaceData/processed/nguyen ngoc thai/thai2.png\\ndeleted file mode 100644\\nindex 9e4f424..0000000\\nBinary files a/Dataset/FaceData/processed/nguyen ngoc thai/thai2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/nguyen ngoc thai/thai3.png b/Dataset/FaceData/processed/nguyen ngoc thai/thai3.png\\ndeleted file mode 100644\\nindex 8c05d34..0000000\\nBinary files a/Dataset/FaceData/processed/nguyen ngoc thai/thai3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/nguyen ngoc thai/thai4.png b/Dataset/FaceData/processed/nguyen ngoc thai/thai4.png\\ndeleted file mode 100644\\nindex 2bbdfff..0000000\\nBinary files a/Dataset/FaceData/processed/nguyen ngoc thai/thai4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/nguyen ngoc thai/thai5.png b/Dataset/FaceData/processed/nguyen ngoc thai/thai5.png\\ndeleted file mode 100644\\nindex b6488d0..0000000\\nBinary files a/Dataset/FaceData/processed/nguyen ngoc thai/thai5.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/nguyen ngoc thai/thaidemo.png b/Dataset/FaceData/processed/nguyen ngoc thai/thaidemo.png\\ndeleted file mode 100644\\nindex 8fa5617..0000000\\nBinary files a/Dataset/FaceData/processed/nguyen ngoc thai/thaidemo.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/nguyen ngoc thai/thaidemo2.png b/Dataset/FaceData/processed/nguyen ngoc thai/thaidemo2.png\\ndeleted file mode 100644\\nindex d3a3dd1..0000000\\nBinary files a/Dataset/FaceData/processed/nguyen ngoc thai/thaidemo2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/nguyen phuong tram/337142073_1253839052216597_199657983855233980_n.png b/Dataset/FaceData/processed/nguyen phuong tram/337142073_1253839052216597_199657983855233980_n.png\\ndeleted file mode 100644\\nindex 644313f..0000000\\nBinary files a/Dataset/FaceData/processed/nguyen phuong tram/337142073_1253839052216597_199657983855233980_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/nguyen phuong tram/339263904_1264665414159651_8733650862788543327_n.png b/Dataset/FaceData/processed/nguyen phuong tram/339263904_1264665414159651_8733650862788543327_n.png\\ndeleted file mode 100644\\nindex b801319..0000000\\nBinary files a/Dataset/FaceData/processed/nguyen phuong tram/339263904_1264665414159651_8733650862788543327_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/nguyen phuong tram/339266601_894783791775673_734864429475267886_n.png b/Dataset/FaceData/processed/nguyen phuong tram/339266601_894783791775673_734864429475267886_n.png\\ndeleted file mode 100644\\nindex b68fb7e..0000000\\nBinary files a/Dataset/FaceData/processed/nguyen phuong tram/339266601_894783791775673_734864429475267886_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/nguyen phuong tram/339408406_1209323986622559_1237855961637611483_n.png b/Dataset/FaceData/processed/nguyen phuong tram/339408406_1209323986622559_1237855961637611483_n.png\\ndeleted file mode 100644\\nindex 08f4aa6..0000000\\nBinary files a/Dataset/FaceData/processed/nguyen phuong tram/339408406_1209323986622559_1237855961637611483_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/nguyen phuong tram/anh1.png b/Dataset/FaceData/processed/nguyen phuong tram/anh1.png\\ndeleted file mode 100644\\nindex d5d5a12..0000000\\nBinary files a/Dataset/FaceData/processed/nguyen phuong tram/anh1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/nguyen phuong tram/anh2.png b/Dataset/FaceData/processed/nguyen phuong tram/anh2.png\\ndeleted file mode 100644\\nindex 522e71a..0000000\\nBinary files a/Dataset/FaceData/processed/nguyen phuong tram/anh2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/nguyen phuong tram/anh3.png b/Dataset/FaceData/processed/nguyen phuong tram/anh3.png\\ndeleted file mode 100644\\nindex 2441b79..0000000\\nBinary files a/Dataset/FaceData/processed/nguyen phuong tram/anh3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/nguyen phuong tram/anh4.png b/Dataset/FaceData/processed/nguyen phuong tram/anh4.png\\ndeleted file mode 100644\\nindex 7a43b31..0000000\\nBinary files a/Dataset/FaceData/processed/nguyen phuong tram/anh4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/nguyen phuong tram/anh5.png b/Dataset/FaceData/processed/nguyen phuong tram/anh5.png\\ndeleted file mode 100644\\nindex 3d547c2..0000000\\nBinary files a/Dataset/FaceData/processed/nguyen phuong tram/anh5.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/nguyen phuong tram/anh7.png b/Dataset/FaceData/processed/nguyen phuong tram/anh7.png\\ndeleted file mode 100644\\nindex b68fb7e..0000000\\nBinary files a/Dataset/FaceData/processed/nguyen phuong tram/anh7.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/nguyen phuong tram/anh8.png b/Dataset/FaceData/processed/nguyen phuong tram/anh8.png\\ndeleted file mode 100644\\nindex 5d91445..0000000\\nBinary files a/Dataset/FaceData/processed/nguyen phuong tram/anh8.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/revision_info.txt b/Dataset/FaceData/processed/revision_info.txt\\ndeleted file mode 100644\\nindex 3c0689d..0000000\\n--- a/Dataset/FaceData/processed/revision_info.txt\\n+++ /dev/null\\n@@ -1,7 +0,0 @@\\n-arguments: src/align_dataset_mtcnn.py Dataset/FaceData/raw Dataset/FaceData/processed --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25\\n---------------------\\n-tensorflow version: 2.15.0\\n---------------------\\n-git hash: b\\\'69ff1e149c0d84a123d6516ddd82970e65392608\\\'\\n---------------------\\n-b\\\'diff --git a/Dataset/FaceData/raw/Bui Anh Tuan/0.png b/Dataset/FaceData/raw/Bui Anh Tuan/0.png\\\\nnew file mode 100644\\\\nindex 0000000..2cb8312\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/0.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/1.png b/Dataset/FaceData/raw/Bui Anh Tuan/1.png\\\\nnew file mode 100644\\\\nindex 0000000..d25b764\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/1.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/10.png b/Dataset/FaceData/raw/Bui Anh Tuan/10.png\\\\nnew file mode 100644\\\\nindex 0000000..9091f86\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/10.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/11.png b/Dataset/FaceData/raw/Bui Anh Tuan/11.png\\\\nnew file mode 100644\\\\nindex 0000000..609a368\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/11.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/12.png b/Dataset/FaceData/raw/Bui Anh Tuan/12.png\\\\nnew file mode 100644\\\\nindex 0000000..c0a0b51\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/12.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/13.png b/Dataset/FaceData/raw/Bui Anh Tuan/13.png\\\\nnew file mode 100644\\\\nindex 0000000..b879393\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/13.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/14.png b/Dataset/FaceData/raw/Bui Anh Tuan/14.png\\\\nnew file mode 100644\\\\nindex 0000000..7a1c32f\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/14.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/15.png b/Dataset/FaceData/raw/Bui Anh Tuan/15.png\\\\nnew file mode 100644\\\\nindex 0000000..4d1bf9f\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/15.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/16.png b/Dataset/FaceData/raw/Bui Anh Tuan/16.png\\\\nnew file mode 100644\\\\nindex 0000000..5b7634d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/16.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/17.png b/Dataset/FaceData/raw/Bui Anh Tuan/17.png\\\\nnew file mode 100644\\\\nindex 0000000..416e14a\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/17.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/18.png b/Dataset/FaceData/raw/Bui Anh Tuan/18.png\\\\nnew file mode 100644\\\\nindex 0000000..b047070\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/18.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/19.png b/Dataset/FaceData/raw/Bui Anh Tuan/19.png\\\\nnew file mode 100644\\\\nindex 0000000..b74565a\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/19.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/2.png b/Dataset/FaceData/raw/Bui Anh Tuan/2.png\\\\nnew file mode 100644\\\\nindex 0000000..c9fdb41\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/2.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/20.png b/Dataset/FaceData/raw/Bui Anh Tuan/20.png\\\\nnew file mode 100644\\\\nindex 0000000..8ab6eb1\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/20.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/21.png b/Dataset/FaceData/raw/Bui Anh Tuan/21.png\\\\nnew file mode 100644\\\\nindex 0000000..5d4660b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/21.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/22.png b/Dataset/FaceData/raw/Bui Anh Tuan/22.png\\\\nnew file mode 100644\\\\nindex 0000000..476cbce\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/22.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/23.png b/Dataset/FaceData/raw/Bui Anh Tuan/23.png\\\\nnew file mode 100644\\\\nindex 0000000..f516e12\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/23.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/24.png b/Dataset/FaceData/raw/Bui Anh Tuan/24.png\\\\nnew file mode 100644\\\\nindex 0000000..ce9d477\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/24.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/25.png b/Dataset/FaceData/raw/Bui Anh Tuan/25.png\\\\nnew file mode 100644\\\\nindex 0000000..b9db1d8\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/25.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/26.png b/Dataset/FaceData/raw/Bui Anh Tuan/26.png\\\\nnew file mode 100644\\\\nindex 0000000..e856821\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/26.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/27.png b/Dataset/FaceData/raw/Bui Anh Tuan/27.png\\\\nnew file mode 100644\\\\nindex 0000000..a2eacab\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/27.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/28.png b/Dataset/FaceData/raw/Bui Anh Tuan/28.png\\\\nnew file mode 100644\\\\nindex 0000000..2258040\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/28.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/29.png b/Dataset/FaceData/raw/Bui Anh Tuan/29.png\\\\nnew file mode 100644\\\\nindex 0000000..9705bce\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/29.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/3.png b/Dataset/FaceData/raw/Bui Anh Tuan/3.png\\\\nnew file mode 100644\\\\nindex 0000000..d4c8ae1\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/3.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/30.png b/Dataset/FaceData/raw/Bui Anh Tuan/30.png\\\\nnew file mode 100644\\\\nindex 0000000..4a8790f\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/30.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/31.png b/Dataset/FaceData/raw/Bui Anh Tuan/31.png\\\\nnew file mode 100644\\\\nindex 0000000..653e476\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/31.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/32.png b/Dataset/FaceData/raw/Bui Anh Tuan/32.png\\\\nnew file mode 100644\\\\nindex 0000000..bea3acc\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/32.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/33.png b/Dataset/FaceData/raw/Bui Anh Tuan/33.png\\\\nnew file mode 100644\\\\nindex 0000000..953bc33\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/33.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/34.png b/Dataset/FaceData/raw/Bui Anh Tuan/34.png\\\\nnew file mode 100644\\\\nindex 0000000..d81177c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/34.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/35.png b/Dataset/FaceData/raw/Bui Anh Tuan/35.png\\\\nnew file mode 100644\\\\nindex 0000000..c816d00\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/35.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/36.png b/Dataset/FaceData/raw/Bui Anh Tuan/36.png\\\\nnew file mode 100644\\\\nindex 0000000..4bbb2ed\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/36.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/37.png b/Dataset/FaceData/raw/Bui Anh Tuan/37.png\\\\nnew file mode 100644\\\\nindex 0000000..1a4ec24\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/37.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/38.png b/Dataset/FaceData/raw/Bui Anh Tuan/38.png\\\\nnew file mode 100644\\\\nindex 0000000..2625e91\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/38.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/39.png b/Dataset/FaceData/raw/Bui Anh Tuan/39.png\\\\nnew file mode 100644\\\\nindex 0000000..8a98074\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/39.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/4.png b/Dataset/FaceData/raw/Bui Anh Tuan/4.png\\\\nnew file mode 100644\\\\nindex 0000000..d2b5dce\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/4.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/40.png b/Dataset/FaceData/raw/Bui Anh Tuan/40.png\\\\nnew file mode 100644\\\\nindex 0000000..fd5075d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/40.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/41.png b/Dataset/FaceData/raw/Bui Anh Tuan/41.png\\\\nnew file mode 100644\\\\nindex 0000000..5abc475\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/41.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/42.png b/Dataset/FaceData/raw/Bui Anh Tuan/42.png\\\\nnew file mode 100644\\\\nindex 0000000..33c24a1\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/42.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/43.png b/Dataset/FaceData/raw/Bui Anh Tuan/43.png\\\\nnew file mode 100644\\\\nindex 0000000..dc1090f\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/43.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/44.png b/Dataset/FaceData/raw/Bui Anh Tuan/44.png\\\\nnew file mode 100644\\\\nindex 0000000..0129185\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/44.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/45.png b/Dataset/FaceData/raw/Bui Anh Tuan/45.png\\\\nnew file mode 100644\\\\nindex 0000000..405533b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/45.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/46.png b/Dataset/FaceData/raw/Bui Anh Tuan/46.png\\\\nnew file mode 100644\\\\nindex 0000000..6dec77e\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/46.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/47.png b/Dataset/FaceData/raw/Bui Anh Tuan/47.png\\\\nnew file mode 100644\\\\nindex 0000000..b1f2372\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/47.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/5.png b/Dataset/FaceData/raw/Bui Anh Tuan/5.png\\\\nnew file mode 100644\\\\nindex 0000000..b02a6a0\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/5.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/6.png b/Dataset/FaceData/raw/Bui Anh Tuan/6.png\\\\nnew file mode 100644\\\\nindex 0000000..452eb92\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/6.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/7.png b/Dataset/FaceData/raw/Bui Anh Tuan/7.png\\\\nnew file mode 100644\\\\nindex 0000000..8a43135\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/7.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/8.png b/Dataset/FaceData/raw/Bui Anh Tuan/8.png\\\\nnew file mode 100644\\\\nindex 0000000..aa1a44c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/8.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/9.png b/Dataset/FaceData/raw/Bui Anh Tuan/9.png\\\\nnew file mode 100644\\\\nindex 0000000..c4d6bae\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Bui Anh Tuan/9.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/0.png b/Dataset/FaceData/raw/Dam vinh hung/0.png\\\\nnew file mode 100644\\\\nindex 0000000..4d7e181\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/0.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/1.png b/Dataset/FaceData/raw/Dam vinh hung/1.png\\\\nnew file mode 100644\\\\nindex 0000000..062f015\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/1.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/10.png b/Dataset/FaceData/raw/Dam vinh hung/10.png\\\\nnew file mode 100644\\\\nindex 0000000..ca6b9d4\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/10.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/11.png b/Dataset/FaceData/raw/Dam vinh hung/11.png\\\\nnew file mode 100644\\\\nindex 0000000..887b100\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/11.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/12.png b/Dataset/FaceData/raw/Dam vinh hung/12.png\\\\nnew file mode 100644\\\\nindex 0000000..62b4d1c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/12.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/13.png b/Dataset/FaceData/raw/Dam vinh hung/13.png\\\\nnew file mode 100644\\\\nindex 0000000..eeac293\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/13.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/14.png b/Dataset/FaceData/raw/Dam vinh hung/14.png\\\\nnew file mode 100644\\\\nindex 0000000..e65e57c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/14.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/15.png b/Dataset/FaceData/raw/Dam vinh hung/15.png\\\\nnew file mode 100644\\\\nindex 0000000..8d6cbae\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/15.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/16.png b/Dataset/FaceData/raw/Dam vinh hung/16.png\\\\nnew file mode 100644\\\\nindex 0000000..4794f95\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/16.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/17.png b/Dataset/FaceData/raw/Dam vinh hung/17.png\\\\nnew file mode 100644\\\\nindex 0000000..ea1819b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/17.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/18.png b/Dataset/FaceData/raw/Dam vinh hung/18.png\\\\nnew file mode 100644\\\\nindex 0000000..0169adb\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/18.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/19.png b/Dataset/FaceData/raw/Dam vinh hung/19.png\\\\nnew file mode 100644\\\\nindex 0000000..158e214\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/19.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/2.png b/Dataset/FaceData/raw/Dam vinh hung/2.png\\\\nnew file mode 100644\\\\nindex 0000000..4f1873b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/2.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/20.png b/Dataset/FaceData/raw/Dam vinh hung/20.png\\\\nnew file mode 100644\\\\nindex 0000000..9c20142\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/20.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/21.png b/Dataset/FaceData/raw/Dam vinh hung/21.png\\\\nnew file mode 100644\\\\nindex 0000000..70a723a\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/21.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/22.png b/Dataset/FaceData/raw/Dam vinh hung/22.png\\\\nnew file mode 100644\\\\nindex 0000000..08e99de\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/22.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/23.png b/Dataset/FaceData/raw/Dam vinh hung/23.png\\\\nnew file mode 100644\\\\nindex 0000000..adc1f0c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/23.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/24.png b/Dataset/FaceData/raw/Dam vinh hung/24.png\\\\nnew file mode 100644\\\\nindex 0000000..059b567\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/24.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/25.png b/Dataset/FaceData/raw/Dam vinh hung/25.png\\\\nnew file mode 100644\\\\nindex 0000000..a681a71\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/25.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/26.png b/Dataset/FaceData/raw/Dam vinh hung/26.png\\\\nnew file mode 100644\\\\nindex 0000000..2db3388\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/26.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/27.png b/Dataset/FaceData/raw/Dam vinh hung/27.png\\\\nnew file mode 100644\\\\nindex 0000000..a770776\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/27.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/28.png b/Dataset/FaceData/raw/Dam vinh hung/28.png\\\\nnew file mode 100644\\\\nindex 0000000..2497c4b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/28.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/29.png b/Dataset/FaceData/raw/Dam vinh hung/29.png\\\\nnew file mode 100644\\\\nindex 0000000..36e29b5\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/29.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/3.png b/Dataset/FaceData/raw/Dam vinh hung/3.png\\\\nnew file mode 100644\\\\nindex 0000000..203e0da\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/3.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/30.png b/Dataset/FaceData/raw/Dam vinh hung/30.png\\\\nnew file mode 100644\\\\nindex 0000000..316fbb1\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/30.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/31.png b/Dataset/FaceData/raw/Dam vinh hung/31.png\\\\nnew file mode 100644\\\\nindex 0000000..8d37322\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/31.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/32.png b/Dataset/FaceData/raw/Dam vinh hung/32.png\\\\nnew file mode 100644\\\\nindex 0000000..70e5757\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/32.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/33.png b/Dataset/FaceData/raw/Dam vinh hung/33.png\\\\nnew file mode 100644\\\\nindex 0000000..f295300\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/33.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/34.png b/Dataset/FaceData/raw/Dam vinh hung/34.png\\\\nnew file mode 100644\\\\nindex 0000000..f8385fa\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/34.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/35.png b/Dataset/FaceData/raw/Dam vinh hung/35.png\\\\nnew file mode 100644\\\\nindex 0000000..fc43193\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/35.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/36.png b/Dataset/FaceData/raw/Dam vinh hung/36.png\\\\nnew file mode 100644\\\\nindex 0000000..16abb5b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/36.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/37.png b/Dataset/FaceData/raw/Dam vinh hung/37.png\\\\nnew file mode 100644\\\\nindex 0000000..38dc60b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/37.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/38.png b/Dataset/FaceData/raw/Dam vinh hung/38.png\\\\nnew file mode 100644\\\\nindex 0000000..a322289\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/38.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/39.png b/Dataset/FaceData/raw/Dam vinh hung/39.png\\\\nnew file mode 100644\\\\nindex 0000000..6f1fb3f\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/39.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/4.png b/Dataset/FaceData/raw/Dam vinh hung/4.png\\\\nnew file mode 100644\\\\nindex 0000000..69c5e54\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/4.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/40.png b/Dataset/FaceData/raw/Dam vinh hung/40.png\\\\nnew file mode 100644\\\\nindex 0000000..3bdf602\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/40.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/41.png b/Dataset/FaceData/raw/Dam vinh hung/41.png\\\\nnew file mode 100644\\\\nindex 0000000..accfc7f\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/41.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/42.png b/Dataset/FaceData/raw/Dam vinh hung/42.png\\\\nnew file mode 100644\\\\nindex 0000000..fe90db5\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/42.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/43.png b/Dataset/FaceData/raw/Dam vinh hung/43.png\\\\nnew file mode 100644\\\\nindex 0000000..eee917d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/43.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/5.png b/Dataset/FaceData/raw/Dam vinh hung/5.png\\\\nnew file mode 100644\\\\nindex 0000000..34889d6\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/5.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/6.png b/Dataset/FaceData/raw/Dam vinh hung/6.png\\\\nnew file mode 100644\\\\nindex 0000000..c033cdb\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/6.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/7.png b/Dataset/FaceData/raw/Dam vinh hung/7.png\\\\nnew file mode 100644\\\\nindex 0000000..eeacdc5\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/7.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/8.png b/Dataset/FaceData/raw/Dam vinh hung/8.png\\\\nnew file mode 100644\\\\nindex 0000000..5d66d18\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/8.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/9.png b/Dataset/FaceData/raw/Dam vinh hung/9.png\\\\nnew file mode 100644\\\\nindex 0000000..119af1c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Dam vinh hung/9.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/0.png b/Dataset/FaceData/raw/Den Vau/0.png\\\\nnew file mode 100644\\\\nindex 0000000..0114b01\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/0.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/1.png b/Dataset/FaceData/raw/Den Vau/1.png\\\\nnew file mode 100644\\\\nindex 0000000..e8ab59a\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/1.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/10.png b/Dataset/FaceData/raw/Den Vau/10.png\\\\nnew file mode 100644\\\\nindex 0000000..5c90a66\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/10.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/11.png b/Dataset/FaceData/raw/Den Vau/11.png\\\\nnew file mode 100644\\\\nindex 0000000..1db538f\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/11.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/12.png b/Dataset/FaceData/raw/Den Vau/12.png\\\\nnew file mode 100644\\\\nindex 0000000..17b1d14\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/12.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/13.png b/Dataset/FaceData/raw/Den Vau/13.png\\\\nnew file mode 100644\\\\nindex 0000000..38f674a\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/13.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/14.png b/Dataset/FaceData/raw/Den Vau/14.png\\\\nnew file mode 100644\\\\nindex 0000000..7057040\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/14.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/15.png b/Dataset/FaceData/raw/Den Vau/15.png\\\\nnew file mode 100644\\\\nindex 0000000..118ea82\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/15.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/16.png b/Dataset/FaceData/raw/Den Vau/16.png\\\\nnew file mode 100644\\\\nindex 0000000..b413e22\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/16.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/17.png b/Dataset/FaceData/raw/Den Vau/17.png\\\\nnew file mode 100644\\\\nindex 0000000..def8d32\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/17.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/18.png b/Dataset/FaceData/raw/Den Vau/18.png\\\\nnew file mode 100644\\\\nindex 0000000..040d762\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/18.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/19.png b/Dataset/FaceData/raw/Den Vau/19.png\\\\nnew file mode 100644\\\\nindex 0000000..75aa5bc\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/19.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/2.png b/Dataset/FaceData/raw/Den Vau/2.png\\\\nnew file mode 100644\\\\nindex 0000000..ef6ff8c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/2.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/20.png b/Dataset/FaceData/raw/Den Vau/20.png\\\\nnew file mode 100644\\\\nindex 0000000..f86a682\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/20.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/21.png b/Dataset/FaceData/raw/Den Vau/21.png\\\\nnew file mode 100644\\\\nindex 0000000..b7bf0d2\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/21.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/22.png b/Dataset/FaceData/raw/Den Vau/22.png\\\\nnew file mode 100644\\\\nindex 0000000..06a476c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/22.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/23.png b/Dataset/FaceData/raw/Den Vau/23.png\\\\nnew file mode 100644\\\\nindex 0000000..2caedcb\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/23.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/24.png b/Dataset/FaceData/raw/Den Vau/24.png\\\\nnew file mode 100644\\\\nindex 0000000..34ece7c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/24.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/25.png b/Dataset/FaceData/raw/Den Vau/25.png\\\\nnew file mode 100644\\\\nindex 0000000..e8d5bfe\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/25.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/26.png b/Dataset/FaceData/raw/Den Vau/26.png\\\\nnew file mode 100644\\\\nindex 0000000..9a96eb0\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/26.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/27.png b/Dataset/FaceData/raw/Den Vau/27.png\\\\nnew file mode 100644\\\\nindex 0000000..4d693c7\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/27.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/28.png b/Dataset/FaceData/raw/Den Vau/28.png\\\\nnew file mode 100644\\\\nindex 0000000..eef0f8c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/28.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/29.png b/Dataset/FaceData/raw/Den Vau/29.png\\\\nnew file mode 100644\\\\nindex 0000000..e0cd4f6\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/29.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/3.png b/Dataset/FaceData/raw/Den Vau/3.png\\\\nnew file mode 100644\\\\nindex 0000000..cf48ff8\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/3.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/30.png b/Dataset/FaceData/raw/Den Vau/30.png\\\\nnew file mode 100644\\\\nindex 0000000..cb38643\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/30.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/31.png b/Dataset/FaceData/raw/Den Vau/31.png\\\\nnew file mode 100644\\\\nindex 0000000..d965265\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/31.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/32.png b/Dataset/FaceData/raw/Den Vau/32.png\\\\nnew file mode 100644\\\\nindex 0000000..1a9c23f\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/32.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/33.png b/Dataset/FaceData/raw/Den Vau/33.png\\\\nnew file mode 100644\\\\nindex 0000000..346c03e\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/33.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/34.png b/Dataset/FaceData/raw/Den Vau/34.png\\\\nnew file mode 100644\\\\nindex 0000000..14cffcb\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/34.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/35.png b/Dataset/FaceData/raw/Den Vau/35.png\\\\nnew file mode 100644\\\\nindex 0000000..f514a14\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/35.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/36.png b/Dataset/FaceData/raw/Den Vau/36.png\\\\nnew file mode 100644\\\\nindex 0000000..7a0b6d1\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/36.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/37.png b/Dataset/FaceData/raw/Den Vau/37.png\\\\nnew file mode 100644\\\\nindex 0000000..09566ef\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/37.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/38.png b/Dataset/FaceData/raw/Den Vau/38.png\\\\nnew file mode 100644\\\\nindex 0000000..f37308a\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/38.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/39.png b/Dataset/FaceData/raw/Den Vau/39.png\\\\nnew file mode 100644\\\\nindex 0000000..d4819e0\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/39.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/4.png b/Dataset/FaceData/raw/Den Vau/4.png\\\\nnew file mode 100644\\\\nindex 0000000..c6ba8c2\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/4.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/40.png b/Dataset/FaceData/raw/Den Vau/40.png\\\\nnew file mode 100644\\\\nindex 0000000..81a305d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/40.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/41.png b/Dataset/FaceData/raw/Den Vau/41.png\\\\nnew file mode 100644\\\\nindex 0000000..1e66e4b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/41.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/42.png b/Dataset/FaceData/raw/Den Vau/42.png\\\\nnew file mode 100644\\\\nindex 0000000..50b8df8\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/42.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/43.png b/Dataset/FaceData/raw/Den Vau/43.png\\\\nnew file mode 100644\\\\nindex 0000000..17afae5\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/43.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/44.png b/Dataset/FaceData/raw/Den Vau/44.png\\\\nnew file mode 100644\\\\nindex 0000000..31008d5\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/44.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/45.png b/Dataset/FaceData/raw/Den Vau/45.png\\\\nnew file mode 100644\\\\nindex 0000000..8f2dfc6\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/45.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/46.png b/Dataset/FaceData/raw/Den Vau/46.png\\\\nnew file mode 100644\\\\nindex 0000000..901c19a\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/46.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/47.png b/Dataset/FaceData/raw/Den Vau/47.png\\\\nnew file mode 100644\\\\nindex 0000000..c2df1b8\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/47.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/48.png b/Dataset/FaceData/raw/Den Vau/48.png\\\\nnew file mode 100644\\\\nindex 0000000..68f99e6\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/48.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/49.png b/Dataset/FaceData/raw/Den Vau/49.png\\\\nnew file mode 100644\\\\nindex 0000000..8df3ee8\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/49.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/5.png b/Dataset/FaceData/raw/Den Vau/5.png\\\\nnew file mode 100644\\\\nindex 0000000..adaa574\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/5.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/50.png b/Dataset/FaceData/raw/Den Vau/50.png\\\\nnew file mode 100644\\\\nindex 0000000..21efeb1\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/50.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/51.png b/Dataset/FaceData/raw/Den Vau/51.png\\\\nnew file mode 100644\\\\nindex 0000000..6bc6d41\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/51.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/52.png b/Dataset/FaceData/raw/Den Vau/52.png\\\\nnew file mode 100644\\\\nindex 0000000..4573091\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/52.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/53.png b/Dataset/FaceData/raw/Den Vau/53.png\\\\nnew file mode 100644\\\\nindex 0000000..aed3079\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/53.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/54.png b/Dataset/FaceData/raw/Den Vau/54.png\\\\nnew file mode 100644\\\\nindex 0000000..b2d1440\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/54.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/55.png b/Dataset/FaceData/raw/Den Vau/55.png\\\\nnew file mode 100644\\\\nindex 0000000..4b0449c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/55.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/56.png b/Dataset/FaceData/raw/Den Vau/56.png\\\\nnew file mode 100644\\\\nindex 0000000..97c9f94\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/56.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/57.png b/Dataset/FaceData/raw/Den Vau/57.png\\\\nnew file mode 100644\\\\nindex 0000000..9851533\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/57.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/58.png b/Dataset/FaceData/raw/Den Vau/58.png\\\\nnew file mode 100644\\\\nindex 0000000..b1095ff\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/58.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/59.png b/Dataset/FaceData/raw/Den Vau/59.png\\\\nnew file mode 100644\\\\nindex 0000000..9a55468\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/59.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/6.png b/Dataset/FaceData/raw/Den Vau/6.png\\\\nnew file mode 100644\\\\nindex 0000000..ae41f77\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/6.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/60.png b/Dataset/FaceData/raw/Den Vau/60.png\\\\nnew file mode 100644\\\\nindex 0000000..81363b8\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/60.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/61.png b/Dataset/FaceData/raw/Den Vau/61.png\\\\nnew file mode 100644\\\\nindex 0000000..d3ed57f\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/61.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/62.png b/Dataset/FaceData/raw/Den Vau/62.png\\\\nnew file mode 100644\\\\nindex 0000000..60b8e7d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/62.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/63.png b/Dataset/FaceData/raw/Den Vau/63.png\\\\nnew file mode 100644\\\\nindex 0000000..ac379eb\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/63.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/64.png b/Dataset/FaceData/raw/Den Vau/64.png\\\\nnew file mode 100644\\\\nindex 0000000..37a776b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/64.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/65.png b/Dataset/FaceData/raw/Den Vau/65.png\\\\nnew file mode 100644\\\\nindex 0000000..7c36149\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/65.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/66.png b/Dataset/FaceData/raw/Den Vau/66.png\\\\nnew file mode 100644\\\\nindex 0000000..1b5e22f\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/66.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/67.png b/Dataset/FaceData/raw/Den Vau/67.png\\\\nnew file mode 100644\\\\nindex 0000000..b690225\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/67.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/68.png b/Dataset/FaceData/raw/Den Vau/68.png\\\\nnew file mode 100644\\\\nindex 0000000..193893d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/68.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/69.png b/Dataset/FaceData/raw/Den Vau/69.png\\\\nnew file mode 100644\\\\nindex 0000000..e0a6453\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/69.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/7.png b/Dataset/FaceData/raw/Den Vau/7.png\\\\nnew file mode 100644\\\\nindex 0000000..41cde9a\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/7.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/70.png b/Dataset/FaceData/raw/Den Vau/70.png\\\\nnew file mode 100644\\\\nindex 0000000..a0ba207\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/70.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/71.png b/Dataset/FaceData/raw/Den Vau/71.png\\\\nnew file mode 100644\\\\nindex 0000000..a3bd450\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/71.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/72.png b/Dataset/FaceData/raw/Den Vau/72.png\\\\nnew file mode 100644\\\\nindex 0000000..151b2c7\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/72.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/73.png b/Dataset/FaceData/raw/Den Vau/73.png\\\\nnew file mode 100644\\\\nindex 0000000..e3eb70a\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/73.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/8.png b/Dataset/FaceData/raw/Den Vau/8.png\\\\nnew file mode 100644\\\\nindex 0000000..40f87e5\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/8.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Den Vau/9.png b/Dataset/FaceData/raw/Den Vau/9.png\\\\nnew file mode 100644\\\\nindex 0000000..caf1dca\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Den Vau/9.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Do hieu/176064931_2957139457942069_3035200184642124074_n.jpg b/Dataset/FaceData/raw/Do hieu/176064931_2957139457942069_3035200184642124074_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..fc44e49\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Do hieu/176064931_2957139457942069_3035200184642124074_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Do hieu/177907728_2957139527942062_5622464185056568311_n.jpg b/Dataset/FaceData/raw/Do hieu/177907728_2957139527942062_5622464185056568311_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..6fbae04\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Do hieu/177907728_2957139527942062_5622464185056568311_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Do hieu/177993461_2957139491275399_3222091836626291316_n.jpg b/Dataset/FaceData/raw/Do hieu/177993461_2957139491275399_3222091836626291316_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..8f4696a\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Do hieu/177993461_2957139491275399_3222091836626291316_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Do hieu/178929889_2957139244608757_1991887332909086037_n (1).jpg b/Dataset/FaceData/raw/Do hieu/178929889_2957139244608757_1991887332909086037_n (1).jpg\\\\nnew file mode 100644\\\\nindex 0000000..c743dcf\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Do hieu/178929889_2957139244608757_1991887332909086037_n (1).jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Do hieu/178929889_2957139244608757_1991887332909086037_n.jpg b/Dataset/FaceData/raw/Do hieu/178929889_2957139244608757_1991887332909086037_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..c743dcf\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Do hieu/178929889_2957139244608757_1991887332909086037_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Do hieu/314736967_3413393448983332_3470974153489929662_n.jpg b/Dataset/FaceData/raw/Do hieu/314736967_3413393448983332_3470974153489929662_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..c06ab04\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Do hieu/314736967_3413393448983332_3470974153489929662_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Do hieu/408729291_122109331016134044_5530016628103795106_n.jpg b/Dataset/FaceData/raw/Do hieu/408729291_122109331016134044_5530016628103795106_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..ecebec1\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Do hieu/408729291_122109331016134044_5530016628103795106_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Duc viet/152373366_899599367523323_8039073461193180489_n.jpg b/Dataset/FaceData/raw/Duc viet/152373366_899599367523323_8039073461193180489_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..0ef71af\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Duc viet/152373366_899599367523323_8039073461193180489_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Duc viet/152709553_899599430856650_818805157951754296_n.jpg b/Dataset/FaceData/raw/Duc viet/152709553_899599430856650_818805157951754296_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..88fea06\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Duc viet/152709553_899599430856650_818805157951754296_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Duc viet/154070237_435134567707863_6078333129900068002_n.jpg b/Dataset/FaceData/raw/Duc viet/154070237_435134567707863_6078333129900068002_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..09c51fe\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Duc viet/154070237_435134567707863_6078333129900068002_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Duc viet/61506698_348134895895603_7272087717616287744_n.jpg b/Dataset/FaceData/raw/Duc viet/61506698_348134895895603_7272087717616287744_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..d795c2e\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Duc viet/61506698_348134895895603_7272087717616287744_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Duc viet/61560706_348134092562350_1539501885898096640_n.jpg b/Dataset/FaceData/raw/Duc viet/61560706_348134092562350_1539501885898096640_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e4bb318\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Duc viet/61560706_348134092562350_1539501885898096640_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Duc viet/61584844_348135582562201_7506169027295707136_n.jpg b/Dataset/FaceData/raw/Duc viet/61584844_348135582562201_7506169027295707136_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..21021f2\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Duc viet/61584844_348135582562201_7506169027295707136_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Duc viet/61820425_348134402562319_3380097574999425024_n.jpg b/Dataset/FaceData/raw/Duc viet/61820425_348134402562319_3380097574999425024_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..9340a52\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Duc viet/61820425_348134402562319_3380097574999425024_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Duc viet/61848774_348135615895531_3014436068146544640_n.jpg b/Dataset/FaceData/raw/Duc viet/61848774_348135615895531_3014436068146544640_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..47e11de\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Duc viet/61848774_348135615895531_3014436068146544640_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Duc viet/61967926_348135315895561_496212973459603456_n.jpg b/Dataset/FaceData/raw/Duc viet/61967926_348135315895561_496212973459603456_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..431bbb6\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Duc viet/61967926_348135315895561_496212973459603456_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Duc viet/62021360_348135282562231_7688022791626424320_n.jpg b/Dataset/FaceData/raw/Duc viet/62021360_348135282562231_7688022791626424320_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..801ee1b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Duc viet/62021360_348135282562231_7688022791626424320_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Duc viet/62035132_348134362562323_2007170459463843840_n.jpg b/Dataset/FaceData/raw/Duc viet/62035132_348134362562323_2007170459463843840_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..20c1485\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Duc viet/62035132_348134362562323_2007170459463843840_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Duc viet/64869534_359570548085371_8201502723321888768_n.jpg b/Dataset/FaceData/raw/Duc viet/64869534_359570548085371_8201502723321888768_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..9759210\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Duc viet/64869534_359570548085371_8201502723321888768_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/0.png b/Dataset/FaceData/raw/Ha Anh Tuan/0.png\\\\nnew file mode 100644\\\\nindex 0000000..cf30085\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/0.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/1.png b/Dataset/FaceData/raw/Ha Anh Tuan/1.png\\\\nnew file mode 100644\\\\nindex 0000000..8f38ca0\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/1.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/10.png b/Dataset/FaceData/raw/Ha Anh Tuan/10.png\\\\nnew file mode 100644\\\\nindex 0000000..b57778e\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/10.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/11.png b/Dataset/FaceData/raw/Ha Anh Tuan/11.png\\\\nnew file mode 100644\\\\nindex 0000000..3d6ccab\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/11.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/12.png b/Dataset/FaceData/raw/Ha Anh Tuan/12.png\\\\nnew file mode 100644\\\\nindex 0000000..283089f\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/12.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/13.png b/Dataset/FaceData/raw/Ha Anh Tuan/13.png\\\\nnew file mode 100644\\\\nindex 0000000..68afaf5\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/13.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/14.png b/Dataset/FaceData/raw/Ha Anh Tuan/14.png\\\\nnew file mode 100644\\\\nindex 0000000..b8f40af\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/14.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/15.png b/Dataset/FaceData/raw/Ha Anh Tuan/15.png\\\\nnew file mode 100644\\\\nindex 0000000..b380e16\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/15.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/16.png b/Dataset/FaceData/raw/Ha Anh Tuan/16.png\\\\nnew file mode 100644\\\\nindex 0000000..7eb5056\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/16.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/17.png b/Dataset/FaceData/raw/Ha Anh Tuan/17.png\\\\nnew file mode 100644\\\\nindex 0000000..a5c4df5\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/17.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/18.png b/Dataset/FaceData/raw/Ha Anh Tuan/18.png\\\\nnew file mode 100644\\\\nindex 0000000..9c7e5a5\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/18.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/19.png b/Dataset/FaceData/raw/Ha Anh Tuan/19.png\\\\nnew file mode 100644\\\\nindex 0000000..f105930\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/19.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/2.png b/Dataset/FaceData/raw/Ha Anh Tuan/2.png\\\\nnew file mode 100644\\\\nindex 0000000..b5c0018\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/2.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/20.png b/Dataset/FaceData/raw/Ha Anh Tuan/20.png\\\\nnew file mode 100644\\\\nindex 0000000..4528610\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/20.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/21.png b/Dataset/FaceData/raw/Ha Anh Tuan/21.png\\\\nnew file mode 100644\\\\nindex 0000000..fe37d3e\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/21.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/22.png b/Dataset/FaceData/raw/Ha Anh Tuan/22.png\\\\nnew file mode 100644\\\\nindex 0000000..7ea4956\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/22.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/23.png b/Dataset/FaceData/raw/Ha Anh Tuan/23.png\\\\nnew file mode 100644\\\\nindex 0000000..a773732\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/23.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/24.png b/Dataset/FaceData/raw/Ha Anh Tuan/24.png\\\\nnew file mode 100644\\\\nindex 0000000..24bbbde\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/24.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/25.png b/Dataset/FaceData/raw/Ha Anh Tuan/25.png\\\\nnew file mode 100644\\\\nindex 0000000..4696e1b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/25.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/26.png b/Dataset/FaceData/raw/Ha Anh Tuan/26.png\\\\nnew file mode 100644\\\\nindex 0000000..60f0485\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/26.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/27.png b/Dataset/FaceData/raw/Ha Anh Tuan/27.png\\\\nnew file mode 100644\\\\nindex 0000000..325f875\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/27.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/28.png b/Dataset/FaceData/raw/Ha Anh Tuan/28.png\\\\nnew file mode 100644\\\\nindex 0000000..94bc98b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/28.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/29.png b/Dataset/FaceData/raw/Ha Anh Tuan/29.png\\\\nnew file mode 100644\\\\nindex 0000000..e20504d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/29.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/3.png b/Dataset/FaceData/raw/Ha Anh Tuan/3.png\\\\nnew file mode 100644\\\\nindex 0000000..c09961f\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/3.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/30.png b/Dataset/FaceData/raw/Ha Anh Tuan/30.png\\\\nnew file mode 100644\\\\nindex 0000000..10fc0be\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/30.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/31.png b/Dataset/FaceData/raw/Ha Anh Tuan/31.png\\\\nnew file mode 100644\\\\nindex 0000000..64c3dea\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/31.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/32.png b/Dataset/FaceData/raw/Ha Anh Tuan/32.png\\\\nnew file mode 100644\\\\nindex 0000000..c0265fc\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/32.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/33.png b/Dataset/FaceData/raw/Ha Anh Tuan/33.png\\\\nnew file mode 100644\\\\nindex 0000000..a8244d8\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/33.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/34.png b/Dataset/FaceData/raw/Ha Anh Tuan/34.png\\\\nnew file mode 100644\\\\nindex 0000000..cfd24c4\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/34.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/35.png b/Dataset/FaceData/raw/Ha Anh Tuan/35.png\\\\nnew file mode 100644\\\\nindex 0000000..62ebba1\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/35.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/36.png b/Dataset/FaceData/raw/Ha Anh Tuan/36.png\\\\nnew file mode 100644\\\\nindex 0000000..c4db4a1\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/36.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/37.png b/Dataset/FaceData/raw/Ha Anh Tuan/37.png\\\\nnew file mode 100644\\\\nindex 0000000..51d329b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/37.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/38.png b/Dataset/FaceData/raw/Ha Anh Tuan/38.png\\\\nnew file mode 100644\\\\nindex 0000000..0540fa5\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/38.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/39.png b/Dataset/FaceData/raw/Ha Anh Tuan/39.png\\\\nnew file mode 100644\\\\nindex 0000000..537a614\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/39.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/4.png b/Dataset/FaceData/raw/Ha Anh Tuan/4.png\\\\nnew file mode 100644\\\\nindex 0000000..3ec1bc2\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/4.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/40.png b/Dataset/FaceData/raw/Ha Anh Tuan/40.png\\\\nnew file mode 100644\\\\nindex 0000000..43274ea\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/40.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/5.png b/Dataset/FaceData/raw/Ha Anh Tuan/5.png\\\\nnew file mode 100644\\\\nindex 0000000..2537196\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/5.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/6.png b/Dataset/FaceData/raw/Ha Anh Tuan/6.png\\\\nnew file mode 100644\\\\nindex 0000000..c8e0d16\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/6.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/7.png b/Dataset/FaceData/raw/Ha Anh Tuan/7.png\\\\nnew file mode 100644\\\\nindex 0000000..c5aa103\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/7.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/8.png b/Dataset/FaceData/raw/Ha Anh Tuan/8.png\\\\nnew file mode 100644\\\\nindex 0000000..c8e8a1d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/8.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/9.png b/Dataset/FaceData/raw/Ha Anh Tuan/9.png\\\\nnew file mode 100644\\\\nindex 0000000..0b22929\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ha Anh Tuan/9.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/0.png b/Dataset/FaceData/raw/Hoai linh/0.png\\\\nnew file mode 100644\\\\nindex 0000000..d077b17\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/0.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/1.png b/Dataset/FaceData/raw/Hoai linh/1.png\\\\nnew file mode 100644\\\\nindex 0000000..ae4106b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/1.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/10.png b/Dataset/FaceData/raw/Hoai linh/10.png\\\\nnew file mode 100644\\\\nindex 0000000..e4354f1\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/10.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/11.png b/Dataset/FaceData/raw/Hoai linh/11.png\\\\nnew file mode 100644\\\\nindex 0000000..1d3a991\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/11.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/12.png b/Dataset/FaceData/raw/Hoai linh/12.png\\\\nnew file mode 100644\\\\nindex 0000000..291524d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/12.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/13.png b/Dataset/FaceData/raw/Hoai linh/13.png\\\\nnew file mode 100644\\\\nindex 0000000..7820f07\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/13.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/14.png b/Dataset/FaceData/raw/Hoai linh/14.png\\\\nnew file mode 100644\\\\nindex 0000000..8913da4\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/14.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/15.png b/Dataset/FaceData/raw/Hoai linh/15.png\\\\nnew file mode 100644\\\\nindex 0000000..bafeefa\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/15.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/16.png b/Dataset/FaceData/raw/Hoai linh/16.png\\\\nnew file mode 100644\\\\nindex 0000000..505732e\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/16.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/17.png b/Dataset/FaceData/raw/Hoai linh/17.png\\\\nnew file mode 100644\\\\nindex 0000000..d36a3aa\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/17.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/18.png b/Dataset/FaceData/raw/Hoai linh/18.png\\\\nnew file mode 100644\\\\nindex 0000000..18f8fdb\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/18.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/19.png b/Dataset/FaceData/raw/Hoai linh/19.png\\\\nnew file mode 100644\\\\nindex 0000000..0da507e\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/19.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/2.png b/Dataset/FaceData/raw/Hoai linh/2.png\\\\nnew file mode 100644\\\\nindex 0000000..713c77b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/2.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/20.png b/Dataset/FaceData/raw/Hoai linh/20.png\\\\nnew file mode 100644\\\\nindex 0000000..f1a3723\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/20.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/21.png b/Dataset/FaceData/raw/Hoai linh/21.png\\\\nnew file mode 100644\\\\nindex 0000000..f790491\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/21.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/22.png b/Dataset/FaceData/raw/Hoai linh/22.png\\\\nnew file mode 100644\\\\nindex 0000000..cdee5ce\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/22.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/23.png b/Dataset/FaceData/raw/Hoai linh/23.png\\\\nnew file mode 100644\\\\nindex 0000000..1735d82\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/23.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/24.png b/Dataset/FaceData/raw/Hoai linh/24.png\\\\nnew file mode 100644\\\\nindex 0000000..881f275\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/24.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/25.png b/Dataset/FaceData/raw/Hoai linh/25.png\\\\nnew file mode 100644\\\\nindex 0000000..6c29037\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/25.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/26.png b/Dataset/FaceData/raw/Hoai linh/26.png\\\\nnew file mode 100644\\\\nindex 0000000..5b24dda\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/26.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/27.png b/Dataset/FaceData/raw/Hoai linh/27.png\\\\nnew file mode 100644\\\\nindex 0000000..7933e70\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/27.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/28.png b/Dataset/FaceData/raw/Hoai linh/28.png\\\\nnew file mode 100644\\\\nindex 0000000..a6a63b9\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/28.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/29.png b/Dataset/FaceData/raw/Hoai linh/29.png\\\\nnew file mode 100644\\\\nindex 0000000..aa67cb7\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/29.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/3.png b/Dataset/FaceData/raw/Hoai linh/3.png\\\\nnew file mode 100644\\\\nindex 0000000..2edc3f7\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/3.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/30.png b/Dataset/FaceData/raw/Hoai linh/30.png\\\\nnew file mode 100644\\\\nindex 0000000..a26bd61\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/30.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/31.png b/Dataset/FaceData/raw/Hoai linh/31.png\\\\nnew file mode 100644\\\\nindex 0000000..85624a5\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/31.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/32.png b/Dataset/FaceData/raw/Hoai linh/32.png\\\\nnew file mode 100644\\\\nindex 0000000..627567e\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/32.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/33.png b/Dataset/FaceData/raw/Hoai linh/33.png\\\\nnew file mode 100644\\\\nindex 0000000..31b7f68\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/33.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/34.png b/Dataset/FaceData/raw/Hoai linh/34.png\\\\nnew file mode 100644\\\\nindex 0000000..a1cfe01\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/34.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/35.png b/Dataset/FaceData/raw/Hoai linh/35.png\\\\nnew file mode 100644\\\\nindex 0000000..b739ab9\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/35.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/36.png b/Dataset/FaceData/raw/Hoai linh/36.png\\\\nnew file mode 100644\\\\nindex 0000000..85728d1\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/36.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/37.png b/Dataset/FaceData/raw/Hoai linh/37.png\\\\nnew file mode 100644\\\\nindex 0000000..37dcc83\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/37.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/38.png b/Dataset/FaceData/raw/Hoai linh/38.png\\\\nnew file mode 100644\\\\nindex 0000000..52de9a1\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/38.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/39.png b/Dataset/FaceData/raw/Hoai linh/39.png\\\\nnew file mode 100644\\\\nindex 0000000..432d400\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/39.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/4.png b/Dataset/FaceData/raw/Hoai linh/4.png\\\\nnew file mode 100644\\\\nindex 0000000..708dde0\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/4.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/40.png b/Dataset/FaceData/raw/Hoai linh/40.png\\\\nnew file mode 100644\\\\nindex 0000000..cd8ceaf\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/40.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/5.png b/Dataset/FaceData/raw/Hoai linh/5.png\\\\nnew file mode 100644\\\\nindex 0000000..9a32b7f\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/5.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/6.png b/Dataset/FaceData/raw/Hoai linh/6.png\\\\nnew file mode 100644\\\\nindex 0000000..57e240a\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/6.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/7.png b/Dataset/FaceData/raw/Hoai linh/7.png\\\\nnew file mode 100644\\\\nindex 0000000..89b2bd1\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/7.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/8.png b/Dataset/FaceData/raw/Hoai linh/8.png\\\\nnew file mode 100644\\\\nindex 0000000..07e1261\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/8.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/9.png b/Dataset/FaceData/raw/Hoai linh/9.png\\\\nnew file mode 100644\\\\nindex 0000000..6cbbe61\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Hoai linh/9.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Ma bach duy/duy1.jpg b/Dataset/FaceData/raw/Ma bach duy/duy1.jpg\\\\nnew file mode 100644\\\\nindex 0000000..37fa23e\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ma bach duy/duy1.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Ma bach duy/duy2.jpg b/Dataset/FaceData/raw/Ma bach duy/duy2.jpg\\\\nnew file mode 100644\\\\nindex 0000000..7777494\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ma bach duy/duy2.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Ma bach duy/duy3.jpg b/Dataset/FaceData/raw/Ma bach duy/duy3.jpg\\\\nnew file mode 100644\\\\nindex 0000000..54fe398\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ma bach duy/duy3.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Ma bach duy/duy4.jpg b/Dataset/FaceData/raw/Ma bach duy/duy4.jpg\\\\nnew file mode 100644\\\\nindex 0000000..f142764\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Ma bach duy/duy4.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Minh hoa/116428895_656623338282021_8457872234875945077_n.jpg b/Dataset/FaceData/raw/Minh hoa/116428895_656623338282021_8457872234875945077_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..5c10f98\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Minh hoa/116428895_656623338282021_8457872234875945077_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Minh hoa/133049557_769265223684498_4689118252074034370_n.jpg b/Dataset/FaceData/raw/Minh hoa/133049557_769265223684498_4689118252074034370_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..f147a12\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Minh hoa/133049557_769265223684498_4689118252074034370_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Minh hoa/258158616_974113876532964_9067509414358086927_n.jpg b/Dataset/FaceData/raw/Minh hoa/258158616_974113876532964_9067509414358086927_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..315d5ff\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Minh hoa/258158616_974113876532964_9067509414358086927_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Minh hoa/277588798_1056746241603060_3376911805269669778_n.jpg b/Dataset/FaceData/raw/Minh hoa/277588798_1056746241603060_3376911805269669778_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..a519260\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Minh hoa/277588798_1056746241603060_3376911805269669778_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Minh hoa/45761069_299092524035106_5787233926145638400_n.jpg b/Dataset/FaceData/raw/Minh hoa/45761069_299092524035106_5787233926145638400_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..eb03d78\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Minh hoa/45761069_299092524035106_5787233926145638400_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Minh hoa/51367653_335164410427917_2686636884146257920_n.jpg b/Dataset/FaceData/raw/Minh hoa/51367653_335164410427917_2686636884146257920_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..250356e\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Minh hoa/51367653_335164410427917_2686636884146257920_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Minh hoa/72597481_459453121332378_4444718657989246976_n.jpg b/Dataset/FaceData/raw/Minh hoa/72597481_459453121332378_4444718657989246976_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..3fee978\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Minh hoa/72597481_459453121332378_4444718657989246976_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/My Duyen/240594338_608022267035848_559750156049629888_n.jpg b/Dataset/FaceData/raw/My Duyen/240594338_608022267035848_559750156049629888_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..4821858\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/My Duyen/240594338_608022267035848_559750156049629888_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/My Duyen/271565569_687653065739434_6695347522364803324_n.jpg b/Dataset/FaceData/raw/My Duyen/271565569_687653065739434_6695347522364803324_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..2c6c23f\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/My Duyen/271565569_687653065739434_6695347522364803324_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/My Duyen/276281855_728896961615044_4850973774883281965_n.jpg b/Dataset/FaceData/raw/My Duyen/276281855_728896961615044_4850973774883281965_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..c794969\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/My Duyen/276281855_728896961615044_4850973774883281965_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/My Duyen/375727668_1053445732493497_6855315188334578963_n.jpg b/Dataset/FaceData/raw/My Duyen/375727668_1053445732493497_6855315188334578963_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..6531f1f\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/My Duyen/375727668_1053445732493497_6855315188334578963_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/My Duyen/377915813_1055517365619667_3022176625716036504_n.jpg b/Dataset/FaceData/raw/My Duyen/377915813_1055517365619667_3022176625716036504_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..329fa78\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/My Duyen/377915813_1055517365619667_3022176625716036504_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/My Duyen/383221108_1063489451489125_7303325553687006067_n.jpg b/Dataset/FaceData/raw/My Duyen/383221108_1063489451489125_7303325553687006067_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..5319a1c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/My Duyen/383221108_1063489451489125_7303325553687006067_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/My Duyen/399161466_1085274189310651_5389319938695371438_n.jpg b/Dataset/FaceData/raw/My Duyen/399161466_1085274189310651_5389319938695371438_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..d970ab1\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/My Duyen/399161466_1085274189310651_5389319938695371438_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/My Duyen/425727875_1136306777540725_7475412167375191065_n.jpg b/Dataset/FaceData/raw/My Duyen/425727875_1136306777540725_7475412167375191065_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..4c26ad2\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/My Duyen/425727875_1136306777540725_7475412167375191065_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/My Duyen/71477803_179402706564475_6524185163780325376_n.jpg b/Dataset/FaceData/raw/My Duyen/71477803_179402706564475_6524185163780325376_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..1a811d0\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/My Duyen/71477803_179402706564475_6524185163780325376_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/My Duyen/Screenshot 2024-02-08 200137.png b/Dataset/FaceData/raw/My Duyen/Screenshot 2024-02-08 200137.png\\\\nnew file mode 100644\\\\nindex 0000000..eeeaa4b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/My Duyen/Screenshot 2024-02-08 200137.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/0.png b/Dataset/FaceData/raw/Nam Em/0.png\\\\nnew file mode 100644\\\\nindex 0000000..3f85836\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/0.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/1.png b/Dataset/FaceData/raw/Nam Em/1.png\\\\nnew file mode 100644\\\\nindex 0000000..b368d4c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/1.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/10.png b/Dataset/FaceData/raw/Nam Em/10.png\\\\nnew file mode 100644\\\\nindex 0000000..7d82425\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/10.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/11.png b/Dataset/FaceData/raw/Nam Em/11.png\\\\nnew file mode 100644\\\\nindex 0000000..83d23f9\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/11.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/12.png b/Dataset/FaceData/raw/Nam Em/12.png\\\\nnew file mode 100644\\\\nindex 0000000..c2e1b32\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/12.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/13.png b/Dataset/FaceData/raw/Nam Em/13.png\\\\nnew file mode 100644\\\\nindex 0000000..93a8ce8\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/13.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/14.png b/Dataset/FaceData/raw/Nam Em/14.png\\\\nnew file mode 100644\\\\nindex 0000000..c8ba086\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/14.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/15.png b/Dataset/FaceData/raw/Nam Em/15.png\\\\nnew file mode 100644\\\\nindex 0000000..db0ea3d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/15.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/16.png b/Dataset/FaceData/raw/Nam Em/16.png\\\\nnew file mode 100644\\\\nindex 0000000..d1fa253\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/16.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/17.png b/Dataset/FaceData/raw/Nam Em/17.png\\\\nnew file mode 100644\\\\nindex 0000000..9376f01\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/17.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/18.png b/Dataset/FaceData/raw/Nam Em/18.png\\\\nnew file mode 100644\\\\nindex 0000000..d958f8f\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/18.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/19.png b/Dataset/FaceData/raw/Nam Em/19.png\\\\nnew file mode 100644\\\\nindex 0000000..5f70694\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/19.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/2.png b/Dataset/FaceData/raw/Nam Em/2.png\\\\nnew file mode 100644\\\\nindex 0000000..5aa9812\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/2.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/20.png b/Dataset/FaceData/raw/Nam Em/20.png\\\\nnew file mode 100644\\\\nindex 0000000..8e4c692\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/20.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/21.png b/Dataset/FaceData/raw/Nam Em/21.png\\\\nnew file mode 100644\\\\nindex 0000000..e9e68d2\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/21.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/22.png b/Dataset/FaceData/raw/Nam Em/22.png\\\\nnew file mode 100644\\\\nindex 0000000..1dbfba4\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/22.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/23.png b/Dataset/FaceData/raw/Nam Em/23.png\\\\nnew file mode 100644\\\\nindex 0000000..d204f07\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/23.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/24.png b/Dataset/FaceData/raw/Nam Em/24.png\\\\nnew file mode 100644\\\\nindex 0000000..44c88e8\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/24.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/25.png b/Dataset/FaceData/raw/Nam Em/25.png\\\\nnew file mode 100644\\\\nindex 0000000..56e76a5\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/25.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/26.png b/Dataset/FaceData/raw/Nam Em/26.png\\\\nnew file mode 100644\\\\nindex 0000000..fb4f36c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/26.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/27.png b/Dataset/FaceData/raw/Nam Em/27.png\\\\nnew file mode 100644\\\\nindex 0000000..4898fd1\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/27.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/28.png b/Dataset/FaceData/raw/Nam Em/28.png\\\\nnew file mode 100644\\\\nindex 0000000..eb29914\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/28.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/29.png b/Dataset/FaceData/raw/Nam Em/29.png\\\\nnew file mode 100644\\\\nindex 0000000..fbed1bd\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/29.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/3.png b/Dataset/FaceData/raw/Nam Em/3.png\\\\nnew file mode 100644\\\\nindex 0000000..915e775\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/3.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/30.png b/Dataset/FaceData/raw/Nam Em/30.png\\\\nnew file mode 100644\\\\nindex 0000000..075d317\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/30.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/31.png b/Dataset/FaceData/raw/Nam Em/31.png\\\\nnew file mode 100644\\\\nindex 0000000..b8cc242\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/31.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/32.png b/Dataset/FaceData/raw/Nam Em/32.png\\\\nnew file mode 100644\\\\nindex 0000000..1d17733\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/32.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/33.png b/Dataset/FaceData/raw/Nam Em/33.png\\\\nnew file mode 100644\\\\nindex 0000000..a7ff820\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/33.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/34.png b/Dataset/FaceData/raw/Nam Em/34.png\\\\nnew file mode 100644\\\\nindex 0000000..ee5f107\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/34.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/35.png b/Dataset/FaceData/raw/Nam Em/35.png\\\\nnew file mode 100644\\\\nindex 0000000..ac81719\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/35.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/36.png b/Dataset/FaceData/raw/Nam Em/36.png\\\\nnew file mode 100644\\\\nindex 0000000..a05d3d5\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/36.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/37.png b/Dataset/FaceData/raw/Nam Em/37.png\\\\nnew file mode 100644\\\\nindex 0000000..92d4f2e\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/37.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/38.png b/Dataset/FaceData/raw/Nam Em/38.png\\\\nnew file mode 100644\\\\nindex 0000000..7cbc9b0\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/38.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/39.png b/Dataset/FaceData/raw/Nam Em/39.png\\\\nnew file mode 100644\\\\nindex 0000000..a20014c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/39.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/4.png b/Dataset/FaceData/raw/Nam Em/4.png\\\\nnew file mode 100644\\\\nindex 0000000..0fb452e\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/4.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/40.png b/Dataset/FaceData/raw/Nam Em/40.png\\\\nnew file mode 100644\\\\nindex 0000000..080826c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/40.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/41.png b/Dataset/FaceData/raw/Nam Em/41.png\\\\nnew file mode 100644\\\\nindex 0000000..a6faa48\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/41.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/5.png b/Dataset/FaceData/raw/Nam Em/5.png\\\\nnew file mode 100644\\\\nindex 0000000..5bf3168\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/5.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/6.png b/Dataset/FaceData/raw/Nam Em/6.png\\\\nnew file mode 100644\\\\nindex 0000000..00c0655\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/6.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/7.png b/Dataset/FaceData/raw/Nam Em/7.png\\\\nnew file mode 100644\\\\nindex 0000000..8d5892d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/7.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/8.png b/Dataset/FaceData/raw/Nam Em/8.png\\\\nnew file mode 100644\\\\nindex 0000000..29b4f2d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/8.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nam Em/9.png b/Dataset/FaceData/raw/Nam Em/9.png\\\\nnew file mode 100644\\\\nindex 0000000..bdcb671\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nam Em/9.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/0.png b/Dataset/FaceData/raw/Nguyen phu trong/0.png\\\\nnew file mode 100644\\\\nindex 0000000..976e984\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/0.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/1.png b/Dataset/FaceData/raw/Nguyen phu trong/1.png\\\\nnew file mode 100644\\\\nindex 0000000..4f79532\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/1.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/10.png b/Dataset/FaceData/raw/Nguyen phu trong/10.png\\\\nnew file mode 100644\\\\nindex 0000000..e9ea96c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/10.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/11.png b/Dataset/FaceData/raw/Nguyen phu trong/11.png\\\\nnew file mode 100644\\\\nindex 0000000..8444d05\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/11.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/12.png b/Dataset/FaceData/raw/Nguyen phu trong/12.png\\\\nnew file mode 100644\\\\nindex 0000000..bba1419\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/12.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/13.png b/Dataset/FaceData/raw/Nguyen phu trong/13.png\\\\nnew file mode 100644\\\\nindex 0000000..97b46a3\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/13.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/14.png b/Dataset/FaceData/raw/Nguyen phu trong/14.png\\\\nnew file mode 100644\\\\nindex 0000000..aa70e6a\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/14.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/15.png b/Dataset/FaceData/raw/Nguyen phu trong/15.png\\\\nnew file mode 100644\\\\nindex 0000000..f6b4932\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/15.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/16.png b/Dataset/FaceData/raw/Nguyen phu trong/16.png\\\\nnew file mode 100644\\\\nindex 0000000..a8bbb6d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/16.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/17.png b/Dataset/FaceData/raw/Nguyen phu trong/17.png\\\\nnew file mode 100644\\\\nindex 0000000..a0a99be\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/17.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/18.png b/Dataset/FaceData/raw/Nguyen phu trong/18.png\\\\nnew file mode 100644\\\\nindex 0000000..f46d72c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/18.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/19.png b/Dataset/FaceData/raw/Nguyen phu trong/19.png\\\\nnew file mode 100644\\\\nindex 0000000..ccc12c7\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/19.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/2.png b/Dataset/FaceData/raw/Nguyen phu trong/2.png\\\\nnew file mode 100644\\\\nindex 0000000..0ba9303\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/2.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/20.png b/Dataset/FaceData/raw/Nguyen phu trong/20.png\\\\nnew file mode 100644\\\\nindex 0000000..0a81161\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/20.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/21.png b/Dataset/FaceData/raw/Nguyen phu trong/21.png\\\\nnew file mode 100644\\\\nindex 0000000..c8a7165\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/21.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/22.png b/Dataset/FaceData/raw/Nguyen phu trong/22.png\\\\nnew file mode 100644\\\\nindex 0000000..4eeec1d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/22.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/23.png b/Dataset/FaceData/raw/Nguyen phu trong/23.png\\\\nnew file mode 100644\\\\nindex 0000000..58220d7\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/23.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/24.png b/Dataset/FaceData/raw/Nguyen phu trong/24.png\\\\nnew file mode 100644\\\\nindex 0000000..8f46da4\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/24.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/25.png b/Dataset/FaceData/raw/Nguyen phu trong/25.png\\\\nnew file mode 100644\\\\nindex 0000000..e4c119e\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/25.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/26.png b/Dataset/FaceData/raw/Nguyen phu trong/26.png\\\\nnew file mode 100644\\\\nindex 0000000..b4f5ef2\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/26.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/27.png b/Dataset/FaceData/raw/Nguyen phu trong/27.png\\\\nnew file mode 100644\\\\nindex 0000000..fb0431a\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/27.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/28.png b/Dataset/FaceData/raw/Nguyen phu trong/28.png\\\\nnew file mode 100644\\\\nindex 0000000..5755fa1\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/28.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/29.png b/Dataset/FaceData/raw/Nguyen phu trong/29.png\\\\nnew file mode 100644\\\\nindex 0000000..c048cdd\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/29.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/3.png b/Dataset/FaceData/raw/Nguyen phu trong/3.png\\\\nnew file mode 100644\\\\nindex 0000000..6df31c4\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/3.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/30.png b/Dataset/FaceData/raw/Nguyen phu trong/30.png\\\\nnew file mode 100644\\\\nindex 0000000..14d0da8\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/30.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/31.png b/Dataset/FaceData/raw/Nguyen phu trong/31.png\\\\nnew file mode 100644\\\\nindex 0000000..5f42334\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/31.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/32.png b/Dataset/FaceData/raw/Nguyen phu trong/32.png\\\\nnew file mode 100644\\\\nindex 0000000..6db206e\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/32.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/33.png b/Dataset/FaceData/raw/Nguyen phu trong/33.png\\\\nnew file mode 100644\\\\nindex 0000000..2cc421b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/33.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/34.png b/Dataset/FaceData/raw/Nguyen phu trong/34.png\\\\nnew file mode 100644\\\\nindex 0000000..24425b9\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/34.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/35.png b/Dataset/FaceData/raw/Nguyen phu trong/35.png\\\\nnew file mode 100644\\\\nindex 0000000..6443185\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/35.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/36.png b/Dataset/FaceData/raw/Nguyen phu trong/36.png\\\\nnew file mode 100644\\\\nindex 0000000..479c39c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/36.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/37.png b/Dataset/FaceData/raw/Nguyen phu trong/37.png\\\\nnew file mode 100644\\\\nindex 0000000..ac32025\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/37.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/38.png b/Dataset/FaceData/raw/Nguyen phu trong/38.png\\\\nnew file mode 100644\\\\nindex 0000000..0f4a752\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/38.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/39.png b/Dataset/FaceData/raw/Nguyen phu trong/39.png\\\\nnew file mode 100644\\\\nindex 0000000..5f670ae\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/39.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/4.png b/Dataset/FaceData/raw/Nguyen phu trong/4.png\\\\nnew file mode 100644\\\\nindex 0000000..89cf6b5\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/4.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/40.png b/Dataset/FaceData/raw/Nguyen phu trong/40.png\\\\nnew file mode 100644\\\\nindex 0000000..d8192e2\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/40.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/41.png b/Dataset/FaceData/raw/Nguyen phu trong/41.png\\\\nnew file mode 100644\\\\nindex 0000000..f47c1f9\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/41.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/42.png b/Dataset/FaceData/raw/Nguyen phu trong/42.png\\\\nnew file mode 100644\\\\nindex 0000000..12c8d9b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/42.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/43.png b/Dataset/FaceData/raw/Nguyen phu trong/43.png\\\\nnew file mode 100644\\\\nindex 0000000..b7c5b7b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/43.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/44.png b/Dataset/FaceData/raw/Nguyen phu trong/44.png\\\\nnew file mode 100644\\\\nindex 0000000..493053e\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/44.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/45.png b/Dataset/FaceData/raw/Nguyen phu trong/45.png\\\\nnew file mode 100644\\\\nindex 0000000..7248c04\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/45.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/46.png b/Dataset/FaceData/raw/Nguyen phu trong/46.png\\\\nnew file mode 100644\\\\nindex 0000000..048a5b2\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/46.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/47.png b/Dataset/FaceData/raw/Nguyen phu trong/47.png\\\\nnew file mode 100644\\\\nindex 0000000..5c4b6e6\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/47.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/5.png b/Dataset/FaceData/raw/Nguyen phu trong/5.png\\\\nnew file mode 100644\\\\nindex 0000000..446d6b7\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/5.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/6.png b/Dataset/FaceData/raw/Nguyen phu trong/6.png\\\\nnew file mode 100644\\\\nindex 0000000..990ec82\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/6.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/7.png b/Dataset/FaceData/raw/Nguyen phu trong/7.png\\\\nnew file mode 100644\\\\nindex 0000000..71af50e\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/7.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/8.png b/Dataset/FaceData/raw/Nguyen phu trong/8.png\\\\nnew file mode 100644\\\\nindex 0000000..787185b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/8.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/9.png b/Dataset/FaceData/raw/Nguyen phu trong/9.png\\\\nnew file mode 100644\\\\nindex 0000000..33ee782\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Nguyen phu trong/9.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/0.png b/Dataset/FaceData/raw/Quang Hai/0.png\\\\nnew file mode 100644\\\\nindex 0000000..a6d2f9b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/0.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/1.png b/Dataset/FaceData/raw/Quang Hai/1.png\\\\nnew file mode 100644\\\\nindex 0000000..577a6c8\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/1.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/10.png b/Dataset/FaceData/raw/Quang Hai/10.png\\\\nnew file mode 100644\\\\nindex 0000000..02996f7\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/10.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/11.png b/Dataset/FaceData/raw/Quang Hai/11.png\\\\nnew file mode 100644\\\\nindex 0000000..4aabdc7\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/11.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/12.png b/Dataset/FaceData/raw/Quang Hai/12.png\\\\nnew file mode 100644\\\\nindex 0000000..d9fe5a2\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/12.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/13.png b/Dataset/FaceData/raw/Quang Hai/13.png\\\\nnew file mode 100644\\\\nindex 0000000..4d666d1\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/13.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/14.png b/Dataset/FaceData/raw/Quang Hai/14.png\\\\nnew file mode 100644\\\\nindex 0000000..75f6024\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/14.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/15.png b/Dataset/FaceData/raw/Quang Hai/15.png\\\\nnew file mode 100644\\\\nindex 0000000..6024976\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/15.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/16.png b/Dataset/FaceData/raw/Quang Hai/16.png\\\\nnew file mode 100644\\\\nindex 0000000..2e004d0\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/16.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/17.png b/Dataset/FaceData/raw/Quang Hai/17.png\\\\nnew file mode 100644\\\\nindex 0000000..6821caf\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/17.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/18.png b/Dataset/FaceData/raw/Quang Hai/18.png\\\\nnew file mode 100644\\\\nindex 0000000..afa82bd\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/18.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/19.png b/Dataset/FaceData/raw/Quang Hai/19.png\\\\nnew file mode 100644\\\\nindex 0000000..7f85c49\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/19.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/2.png b/Dataset/FaceData/raw/Quang Hai/2.png\\\\nnew file mode 100644\\\\nindex 0000000..07aae1b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/2.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/20.png b/Dataset/FaceData/raw/Quang Hai/20.png\\\\nnew file mode 100644\\\\nindex 0000000..180098e\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/20.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/21.png b/Dataset/FaceData/raw/Quang Hai/21.png\\\\nnew file mode 100644\\\\nindex 0000000..95da114\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/21.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/22.png b/Dataset/FaceData/raw/Quang Hai/22.png\\\\nnew file mode 100644\\\\nindex 0000000..2970246\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/22.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/23.png b/Dataset/FaceData/raw/Quang Hai/23.png\\\\nnew file mode 100644\\\\nindex 0000000..1ad6b85\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/23.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/24.png b/Dataset/FaceData/raw/Quang Hai/24.png\\\\nnew file mode 100644\\\\nindex 0000000..983a361\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/24.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/25.png b/Dataset/FaceData/raw/Quang Hai/25.png\\\\nnew file mode 100644\\\\nindex 0000000..6d557f1\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/25.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/26.png b/Dataset/FaceData/raw/Quang Hai/26.png\\\\nnew file mode 100644\\\\nindex 0000000..e34d23f\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/26.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/27.png b/Dataset/FaceData/raw/Quang Hai/27.png\\\\nnew file mode 100644\\\\nindex 0000000..342077c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/27.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/28.png b/Dataset/FaceData/raw/Quang Hai/28.png\\\\nnew file mode 100644\\\\nindex 0000000..6fb2afc\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/28.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/29.png b/Dataset/FaceData/raw/Quang Hai/29.png\\\\nnew file mode 100644\\\\nindex 0000000..caed707\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/29.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/3.png b/Dataset/FaceData/raw/Quang Hai/3.png\\\\nnew file mode 100644\\\\nindex 0000000..a0de1f4\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/3.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/4.png b/Dataset/FaceData/raw/Quang Hai/4.png\\\\nnew file mode 100644\\\\nindex 0000000..aa00799\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/4.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/5.png b/Dataset/FaceData/raw/Quang Hai/5.png\\\\nnew file mode 100644\\\\nindex 0000000..2618781\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/5.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/6.png b/Dataset/FaceData/raw/Quang Hai/6.png\\\\nnew file mode 100644\\\\nindex 0000000..37f4a9d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/6.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/7.png b/Dataset/FaceData/raw/Quang Hai/7.png\\\\nnew file mode 100644\\\\nindex 0000000..8476564\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/7.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/8.png b/Dataset/FaceData/raw/Quang Hai/8.png\\\\nnew file mode 100644\\\\nindex 0000000..1f1a863\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/8.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/9.png b/Dataset/FaceData/raw/Quang Hai/9.png\\\\nnew file mode 100644\\\\nindex 0000000..ff757a4\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Quang Hai/9.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Tran Hoc/107223180_1197468397263141_6372187421696273098_n.jpg b/Dataset/FaceData/raw/Tran Hoc/107223180_1197468397263141_6372187421696273098_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..05b9968\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Tran Hoc/107223180_1197468397263141_6372187421696273098_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Tran Hoc/120220333_1261416600868320_4101096592656067221_n.jpg b/Dataset/FaceData/raw/Tran Hoc/120220333_1261416600868320_4101096592656067221_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..57129f8\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Tran Hoc/120220333_1261416600868320_4101096592656067221_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Tran Hoc/235810118_1494231920920119_422367748034160663_n.jpg b/Dataset/FaceData/raw/Tran Hoc/235810118_1494231920920119_422367748034160663_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..749b272\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Tran Hoc/235810118_1494231920920119_422367748034160663_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Tran Hoc/90066892_1096495004027148_8085701175137009664_n.jpg b/Dataset/FaceData/raw/Tran Hoc/90066892_1096495004027148_8085701175137009664_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e9751de\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Tran Hoc/90066892_1096495004027148_8085701175137009664_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/0.png b/Dataset/FaceData/raw/Van Dung/0.png\\\\nnew file mode 100644\\\\nindex 0000000..fb573d8\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/0.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/1.png b/Dataset/FaceData/raw/Van Dung/1.png\\\\nnew file mode 100644\\\\nindex 0000000..afebc3c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/1.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/10.png b/Dataset/FaceData/raw/Van Dung/10.png\\\\nnew file mode 100644\\\\nindex 0000000..91653e1\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/10.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/11.png b/Dataset/FaceData/raw/Van Dung/11.png\\\\nnew file mode 100644\\\\nindex 0000000..3b1117b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/11.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/12.png b/Dataset/FaceData/raw/Van Dung/12.png\\\\nnew file mode 100644\\\\nindex 0000000..f6fc72b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/12.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/13.png b/Dataset/FaceData/raw/Van Dung/13.png\\\\nnew file mode 100644\\\\nindex 0000000..dd98255\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/13.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/14.png b/Dataset/FaceData/raw/Van Dung/14.png\\\\nnew file mode 100644\\\\nindex 0000000..052a8b7\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/14.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/15.png b/Dataset/FaceData/raw/Van Dung/15.png\\\\nnew file mode 100644\\\\nindex 0000000..2fd5f14\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/15.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/16.png b/Dataset/FaceData/raw/Van Dung/16.png\\\\nnew file mode 100644\\\\nindex 0000000..ad10e4f\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/16.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/17.png b/Dataset/FaceData/raw/Van Dung/17.png\\\\nnew file mode 100644\\\\nindex 0000000..726b38e\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/17.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/18.png b/Dataset/FaceData/raw/Van Dung/18.png\\\\nnew file mode 100644\\\\nindex 0000000..72f8314\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/18.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/19.png b/Dataset/FaceData/raw/Van Dung/19.png\\\\nnew file mode 100644\\\\nindex 0000000..935b936\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/19.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/2.png b/Dataset/FaceData/raw/Van Dung/2.png\\\\nnew file mode 100644\\\\nindex 0000000..13ff3ad\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/2.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/20.png b/Dataset/FaceData/raw/Van Dung/20.png\\\\nnew file mode 100644\\\\nindex 0000000..789c33e\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/20.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/21.png b/Dataset/FaceData/raw/Van Dung/21.png\\\\nnew file mode 100644\\\\nindex 0000000..7595297\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/21.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/22.png b/Dataset/FaceData/raw/Van Dung/22.png\\\\nnew file mode 100644\\\\nindex 0000000..2111edf\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/22.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/23.png b/Dataset/FaceData/raw/Van Dung/23.png\\\\nnew file mode 100644\\\\nindex 0000000..305a232\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/23.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/24.png b/Dataset/FaceData/raw/Van Dung/24.png\\\\nnew file mode 100644\\\\nindex 0000000..8e91ae6\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/24.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/25.png b/Dataset/FaceData/raw/Van Dung/25.png\\\\nnew file mode 100644\\\\nindex 0000000..efb1a4b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/25.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/26.png b/Dataset/FaceData/raw/Van Dung/26.png\\\\nnew file mode 100644\\\\nindex 0000000..bb677de\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/26.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/27.png b/Dataset/FaceData/raw/Van Dung/27.png\\\\nnew file mode 100644\\\\nindex 0000000..3ea1790\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/27.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/28.png b/Dataset/FaceData/raw/Van Dung/28.png\\\\nnew file mode 100644\\\\nindex 0000000..eec7817\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/28.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/29.png b/Dataset/FaceData/raw/Van Dung/29.png\\\\nnew file mode 100644\\\\nindex 0000000..c967c22\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/29.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/3.png b/Dataset/FaceData/raw/Van Dung/3.png\\\\nnew file mode 100644\\\\nindex 0000000..8cdccba\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/3.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/30.png b/Dataset/FaceData/raw/Van Dung/30.png\\\\nnew file mode 100644\\\\nindex 0000000..9e8e926\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/30.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/31.png b/Dataset/FaceData/raw/Van Dung/31.png\\\\nnew file mode 100644\\\\nindex 0000000..ba76211\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/31.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/32.png b/Dataset/FaceData/raw/Van Dung/32.png\\\\nnew file mode 100644\\\\nindex 0000000..5f0c082\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/32.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/33.png b/Dataset/FaceData/raw/Van Dung/33.png\\\\nnew file mode 100644\\\\nindex 0000000..d010b1b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/33.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/34.png b/Dataset/FaceData/raw/Van Dung/34.png\\\\nnew file mode 100644\\\\nindex 0000000..2fc326e\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/34.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/35.png b/Dataset/FaceData/raw/Van Dung/35.png\\\\nnew file mode 100644\\\\nindex 0000000..14a1d9b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/35.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/36.png b/Dataset/FaceData/raw/Van Dung/36.png\\\\nnew file mode 100644\\\\nindex 0000000..5bceec7\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/36.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/37.png b/Dataset/FaceData/raw/Van Dung/37.png\\\\nnew file mode 100644\\\\nindex 0000000..8627b2c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/37.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/38.png b/Dataset/FaceData/raw/Van Dung/38.png\\\\nnew file mode 100644\\\\nindex 0000000..3d69fd3\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/38.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/39.png b/Dataset/FaceData/raw/Van Dung/39.png\\\\nnew file mode 100644\\\\nindex 0000000..7c52a65\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/39.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/4.png b/Dataset/FaceData/raw/Van Dung/4.png\\\\nnew file mode 100644\\\\nindex 0000000..bd5ec4b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/4.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/40.png b/Dataset/FaceData/raw/Van Dung/40.png\\\\nnew file mode 100644\\\\nindex 0000000..037c910\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/40.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/41.png b/Dataset/FaceData/raw/Van Dung/41.png\\\\nnew file mode 100644\\\\nindex 0000000..7f3ed0d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/41.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/42.png b/Dataset/FaceData/raw/Van Dung/42.png\\\\nnew file mode 100644\\\\nindex 0000000..8f38805\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/42.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/43.png b/Dataset/FaceData/raw/Van Dung/43.png\\\\nnew file mode 100644\\\\nindex 0000000..b3f87d0\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/43.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/44.png b/Dataset/FaceData/raw/Van Dung/44.png\\\\nnew file mode 100644\\\\nindex 0000000..7da54c7\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/44.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/45.png b/Dataset/FaceData/raw/Van Dung/45.png\\\\nnew file mode 100644\\\\nindex 0000000..54af81a\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/45.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/46.png b/Dataset/FaceData/raw/Van Dung/46.png\\\\nnew file mode 100644\\\\nindex 0000000..b9bf46a\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/46.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/47.png b/Dataset/FaceData/raw/Van Dung/47.png\\\\nnew file mode 100644\\\\nindex 0000000..40c7d56\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/47.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/48.png b/Dataset/FaceData/raw/Van Dung/48.png\\\\nnew file mode 100644\\\\nindex 0000000..3b12754\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/48.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/49.png b/Dataset/FaceData/raw/Van Dung/49.png\\\\nnew file mode 100644\\\\nindex 0000000..de7a734\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/49.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/5.png b/Dataset/FaceData/raw/Van Dung/5.png\\\\nnew file mode 100644\\\\nindex 0000000..441750d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/5.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/50.png b/Dataset/FaceData/raw/Van Dung/50.png\\\\nnew file mode 100644\\\\nindex 0000000..29aa6db\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/50.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/51.png b/Dataset/FaceData/raw/Van Dung/51.png\\\\nnew file mode 100644\\\\nindex 0000000..c242452\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/51.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/52.png b/Dataset/FaceData/raw/Van Dung/52.png\\\\nnew file mode 100644\\\\nindex 0000000..33b91c1\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/52.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/53.png b/Dataset/FaceData/raw/Van Dung/53.png\\\\nnew file mode 100644\\\\nindex 0000000..857c2ed\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/53.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/54.png b/Dataset/FaceData/raw/Van Dung/54.png\\\\nnew file mode 100644\\\\nindex 0000000..9d6bd7a\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/54.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/55.png b/Dataset/FaceData/raw/Van Dung/55.png\\\\nnew file mode 100644\\\\nindex 0000000..c2e3edf\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/55.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/56.png b/Dataset/FaceData/raw/Van Dung/56.png\\\\nnew file mode 100644\\\\nindex 0000000..3377934\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/56.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/57.png b/Dataset/FaceData/raw/Van Dung/57.png\\\\nnew file mode 100644\\\\nindex 0000000..e918362\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/57.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/58.png b/Dataset/FaceData/raw/Van Dung/58.png\\\\nnew file mode 100644\\\\nindex 0000000..bf4207d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/58.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/59.png b/Dataset/FaceData/raw/Van Dung/59.png\\\\nnew file mode 100644\\\\nindex 0000000..5dfed2c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/59.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/6.png b/Dataset/FaceData/raw/Van Dung/6.png\\\\nnew file mode 100644\\\\nindex 0000000..8d43cdd\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/6.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/60.png b/Dataset/FaceData/raw/Van Dung/60.png\\\\nnew file mode 100644\\\\nindex 0000000..aa63e20\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/60.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/61.png b/Dataset/FaceData/raw/Van Dung/61.png\\\\nnew file mode 100644\\\\nindex 0000000..ecc2328\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/61.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/62.png b/Dataset/FaceData/raw/Van Dung/62.png\\\\nnew file mode 100644\\\\nindex 0000000..fd3a0c9\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/62.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/63.png b/Dataset/FaceData/raw/Van Dung/63.png\\\\nnew file mode 100644\\\\nindex 0000000..482a0ef\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/63.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/64.png b/Dataset/FaceData/raw/Van Dung/64.png\\\\nnew file mode 100644\\\\nindex 0000000..3a05341\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/64.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/65.png b/Dataset/FaceData/raw/Van Dung/65.png\\\\nnew file mode 100644\\\\nindex 0000000..50bb2d8\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/65.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/66.png b/Dataset/FaceData/raw/Van Dung/66.png\\\\nnew file mode 100644\\\\nindex 0000000..ad5b14b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/66.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/67.png b/Dataset/FaceData/raw/Van Dung/67.png\\\\nnew file mode 100644\\\\nindex 0000000..5b40e28\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/67.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/68.png b/Dataset/FaceData/raw/Van Dung/68.png\\\\nnew file mode 100644\\\\nindex 0000000..98b3c29\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/68.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/69.png b/Dataset/FaceData/raw/Van Dung/69.png\\\\nnew file mode 100644\\\\nindex 0000000..89b487c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/69.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/7.png b/Dataset/FaceData/raw/Van Dung/7.png\\\\nnew file mode 100644\\\\nindex 0000000..43abdc9\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/7.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/70.png b/Dataset/FaceData/raw/Van Dung/70.png\\\\nnew file mode 100644\\\\nindex 0000000..a9c08a6\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/70.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/71.png b/Dataset/FaceData/raw/Van Dung/71.png\\\\nnew file mode 100644\\\\nindex 0000000..a3e80b3\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/71.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/72.png b/Dataset/FaceData/raw/Van Dung/72.png\\\\nnew file mode 100644\\\\nindex 0000000..1d6af0b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/72.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/73.png b/Dataset/FaceData/raw/Van Dung/73.png\\\\nnew file mode 100644\\\\nindex 0000000..e0e48ad\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/73.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/74.png b/Dataset/FaceData/raw/Van Dung/74.png\\\\nnew file mode 100644\\\\nindex 0000000..2e3b0e3\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/74.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/75.png b/Dataset/FaceData/raw/Van Dung/75.png\\\\nnew file mode 100644\\\\nindex 0000000..9f9bdab\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/75.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/76.png b/Dataset/FaceData/raw/Van Dung/76.png\\\\nnew file mode 100644\\\\nindex 0000000..6fb8eef\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/76.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/77.png b/Dataset/FaceData/raw/Van Dung/77.png\\\\nnew file mode 100644\\\\nindex 0000000..b1bb266\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/77.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/78.png b/Dataset/FaceData/raw/Van Dung/78.png\\\\nnew file mode 100644\\\\nindex 0000000..0c93be7\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/78.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/79.png b/Dataset/FaceData/raw/Van Dung/79.png\\\\nnew file mode 100644\\\\nindex 0000000..3f6c196\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/79.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/8.png b/Dataset/FaceData/raw/Van Dung/8.png\\\\nnew file mode 100644\\\\nindex 0000000..358f044\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/8.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/80.png b/Dataset/FaceData/raw/Van Dung/80.png\\\\nnew file mode 100644\\\\nindex 0000000..a15fbed\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/80.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/81.png b/Dataset/FaceData/raw/Van Dung/81.png\\\\nnew file mode 100644\\\\nindex 0000000..68c2d89\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/81.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/82.png b/Dataset/FaceData/raw/Van Dung/82.png\\\\nnew file mode 100644\\\\nindex 0000000..5ce98d2\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/82.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/83.png b/Dataset/FaceData/raw/Van Dung/83.png\\\\nnew file mode 100644\\\\nindex 0000000..97eee8f\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/83.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/84.png b/Dataset/FaceData/raw/Van Dung/84.png\\\\nnew file mode 100644\\\\nindex 0000000..54d6b3a\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/84.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/85.png b/Dataset/FaceData/raw/Van Dung/85.png\\\\nnew file mode 100644\\\\nindex 0000000..89c8cbc\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/85.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/86.png b/Dataset/FaceData/raw/Van Dung/86.png\\\\nnew file mode 100644\\\\nindex 0000000..7719d4f\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/86.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/87.png b/Dataset/FaceData/raw/Van Dung/87.png\\\\nnew file mode 100644\\\\nindex 0000000..cfcbba9\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/87.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/88.png b/Dataset/FaceData/raw/Van Dung/88.png\\\\nnew file mode 100644\\\\nindex 0000000..ea92fa7\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/88.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Van Dung/9.png b/Dataset/FaceData/raw/Van Dung/9.png\\\\nnew file mode 100644\\\\nindex 0000000..eb7946c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Van Dung/9.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/0.png b/Dataset/FaceData/raw/Xuan Hinh/0.png\\\\nnew file mode 100644\\\\nindex 0000000..688659b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/0.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/1.png b/Dataset/FaceData/raw/Xuan Hinh/1.png\\\\nnew file mode 100644\\\\nindex 0000000..7c4d3ba\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/1.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/10.png b/Dataset/FaceData/raw/Xuan Hinh/10.png\\\\nnew file mode 100644\\\\nindex 0000000..ffc6cc4\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/10.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/11.png b/Dataset/FaceData/raw/Xuan Hinh/11.png\\\\nnew file mode 100644\\\\nindex 0000000..9eefb5d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/11.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/12.png b/Dataset/FaceData/raw/Xuan Hinh/12.png\\\\nnew file mode 100644\\\\nindex 0000000..d658bcd\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/12.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/13.png b/Dataset/FaceData/raw/Xuan Hinh/13.png\\\\nnew file mode 100644\\\\nindex 0000000..436bc30\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/13.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/14.png b/Dataset/FaceData/raw/Xuan Hinh/14.png\\\\nnew file mode 100644\\\\nindex 0000000..2300065\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/14.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/15.png b/Dataset/FaceData/raw/Xuan Hinh/15.png\\\\nnew file mode 100644\\\\nindex 0000000..e891a1f\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/15.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/16.png b/Dataset/FaceData/raw/Xuan Hinh/16.png\\\\nnew file mode 100644\\\\nindex 0000000..19e9d74\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/16.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/17.png b/Dataset/FaceData/raw/Xuan Hinh/17.png\\\\nnew file mode 100644\\\\nindex 0000000..80ce171\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/17.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/18.png b/Dataset/FaceData/raw/Xuan Hinh/18.png\\\\nnew file mode 100644\\\\nindex 0000000..d73ba47\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/18.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/19.png b/Dataset/FaceData/raw/Xuan Hinh/19.png\\\\nnew file mode 100644\\\\nindex 0000000..279c9d1\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/19.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/2.png b/Dataset/FaceData/raw/Xuan Hinh/2.png\\\\nnew file mode 100644\\\\nindex 0000000..517fba9\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/2.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/20.png b/Dataset/FaceData/raw/Xuan Hinh/20.png\\\\nnew file mode 100644\\\\nindex 0000000..266b493\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/20.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/21.png b/Dataset/FaceData/raw/Xuan Hinh/21.png\\\\nnew file mode 100644\\\\nindex 0000000..f37666b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/21.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/22.png b/Dataset/FaceData/raw/Xuan Hinh/22.png\\\\nnew file mode 100644\\\\nindex 0000000..a35741d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/22.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/23.png b/Dataset/FaceData/raw/Xuan Hinh/23.png\\\\nnew file mode 100644\\\\nindex 0000000..968cb20\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/23.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/24.png b/Dataset/FaceData/raw/Xuan Hinh/24.png\\\\nnew file mode 100644\\\\nindex 0000000..40b3ff9\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/24.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/25.png b/Dataset/FaceData/raw/Xuan Hinh/25.png\\\\nnew file mode 100644\\\\nindex 0000000..bd445d8\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/25.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/26.png b/Dataset/FaceData/raw/Xuan Hinh/26.png\\\\nnew file mode 100644\\\\nindex 0000000..17a720f\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/26.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/27.png b/Dataset/FaceData/raw/Xuan Hinh/27.png\\\\nnew file mode 100644\\\\nindex 0000000..4933cf1\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/27.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/28.png b/Dataset/FaceData/raw/Xuan Hinh/28.png\\\\nnew file mode 100644\\\\nindex 0000000..d9049b4\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/28.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/29.png b/Dataset/FaceData/raw/Xuan Hinh/29.png\\\\nnew file mode 100644\\\\nindex 0000000..58fd1f0\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/29.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/3.png b/Dataset/FaceData/raw/Xuan Hinh/3.png\\\\nnew file mode 100644\\\\nindex 0000000..991c986\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/3.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/30.png b/Dataset/FaceData/raw/Xuan Hinh/30.png\\\\nnew file mode 100644\\\\nindex 0000000..7fb03a8\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/30.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/31.png b/Dataset/FaceData/raw/Xuan Hinh/31.png\\\\nnew file mode 100644\\\\nindex 0000000..0c4727d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/31.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/32.png b/Dataset/FaceData/raw/Xuan Hinh/32.png\\\\nnew file mode 100644\\\\nindex 0000000..dfe6ed6\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/32.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/33.png b/Dataset/FaceData/raw/Xuan Hinh/33.png\\\\nnew file mode 100644\\\\nindex 0000000..297ac7e\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/33.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/34.png b/Dataset/FaceData/raw/Xuan Hinh/34.png\\\\nnew file mode 100644\\\\nindex 0000000..7f60484\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/34.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/35.png b/Dataset/FaceData/raw/Xuan Hinh/35.png\\\\nnew file mode 100644\\\\nindex 0000000..4cb7b00\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/35.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/36.png b/Dataset/FaceData/raw/Xuan Hinh/36.png\\\\nnew file mode 100644\\\\nindex 0000000..6a32e5d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/36.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/37.png b/Dataset/FaceData/raw/Xuan Hinh/37.png\\\\nnew file mode 100644\\\\nindex 0000000..a90334a\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/37.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/38.png b/Dataset/FaceData/raw/Xuan Hinh/38.png\\\\nnew file mode 100644\\\\nindex 0000000..4080070\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/38.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/39.png b/Dataset/FaceData/raw/Xuan Hinh/39.png\\\\nnew file mode 100644\\\\nindex 0000000..746a244\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/39.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/4.png b/Dataset/FaceData/raw/Xuan Hinh/4.png\\\\nnew file mode 100644\\\\nindex 0000000..d33c18c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/4.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/40.png b/Dataset/FaceData/raw/Xuan Hinh/40.png\\\\nnew file mode 100644\\\\nindex 0000000..58ec201\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/40.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/41.png b/Dataset/FaceData/raw/Xuan Hinh/41.png\\\\nnew file mode 100644\\\\nindex 0000000..32fcb66\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/41.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/42.png b/Dataset/FaceData/raw/Xuan Hinh/42.png\\\\nnew file mode 100644\\\\nindex 0000000..464f602\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/42.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/5.png b/Dataset/FaceData/raw/Xuan Hinh/5.png\\\\nnew file mode 100644\\\\nindex 0000000..35a7ca6\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/5.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/6.png b/Dataset/FaceData/raw/Xuan Hinh/6.png\\\\nnew file mode 100644\\\\nindex 0000000..1694a98\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/6.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/7.png b/Dataset/FaceData/raw/Xuan Hinh/7.png\\\\nnew file mode 100644\\\\nindex 0000000..978e648\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/7.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/8.png b/Dataset/FaceData/raw/Xuan Hinh/8.png\\\\nnew file mode 100644\\\\nindex 0000000..5091129\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/8.png differ\\\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/9.png b/Dataset/FaceData/raw/Xuan Hinh/9.png\\\\nnew file mode 100644\\\\nindex 0000000..7c21026\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/Xuan Hinh/9.png differ\\\\ndiff --git a/Dataset/FaceData/raw/chunghoang/386429669_867969661603917_3228776363804735267_n.jpg b/Dataset/FaceData/raw/chunghoang/386429669_867969661603917_3228776363804735267_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..657c225\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/chunghoang/386429669_867969661603917_3228776363804735267_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/chunghoang/422737427_390399053474445_3140718471568843261_n.jpg b/Dataset/FaceData/raw/chunghoang/422737427_390399053474445_3140718471568843261_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..acc31cb\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/chunghoang/422737427_390399053474445_3140718471568843261_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/chunghoang/chung1.jpg b/Dataset/FaceData/raw/chunghoang/chung1.jpg\\\\nnew file mode 100644\\\\nindex 0000000..932e752\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/chunghoang/chung1.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/chunghoang/chung2.jpg b/Dataset/FaceData/raw/chunghoang/chung2.jpg\\\\nnew file mode 100644\\\\nindex 0000000..25d7b3f\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/chunghoang/chung2.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/chunghoang/chung3.jpg b/Dataset/FaceData/raw/chunghoang/chung3.jpg\\\\nnew file mode 100644\\\\nindex 0000000..0bf6301\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/chunghoang/chung3.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/chunghoang/chung4.jpg b/Dataset/FaceData/raw/chunghoang/chung4.jpg\\\\nnew file mode 100644\\\\nindex 0000000..173372b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/chunghoang/chung4.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/chunghoang/chung6.jpg b/Dataset/FaceData/raw/chunghoang/chung6.jpg\\\\nnew file mode 100644\\\\nindex 0000000..fe9dbb3\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/chunghoang/chung6.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/chunghoang/img.png b/Dataset/FaceData/raw/chunghoang/img.png\\\\nnew file mode 100644\\\\nindex 0000000..7bd09e6\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/chunghoang/img.png differ\\\\ndiff --git a/Dataset/FaceData/raw/chunghoang/img_1.png b/Dataset/FaceData/raw/chunghoang/img_1.png\\\\nnew file mode 100644\\\\nindex 0000000..4a05c16\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/chunghoang/img_1.png differ\\\\ndiff --git a/Dataset/FaceData/raw/dang thi ha/385534676_267391239125906_3185308814281359599_n.jpg b/Dataset/FaceData/raw/dang thi ha/385534676_267391239125906_3185308814281359599_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..8d75de8\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/dang thi ha/385534676_267391239125906_3185308814281359599_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/dang thi ha/anh1.jpg b/Dataset/FaceData/raw/dang thi ha/anh1.jpg\\\\nnew file mode 100644\\\\nindex 0000000..8756a35\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/dang thi ha/anh1.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/dang thi ha/anh2.jpg b/Dataset/FaceData/raw/dang thi ha/anh2.jpg\\\\nnew file mode 100644\\\\nindex 0000000..34cfdc6\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/dang thi ha/anh2.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/dang thi ha/anh3.jpg b/Dataset/FaceData/raw/dang thi ha/anh3.jpg\\\\nnew file mode 100644\\\\nindex 0000000..7b82c56\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/dang thi ha/anh3.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/dang thi ha/anh4.jpg b/Dataset/FaceData/raw/dang thi ha/anh4.jpg\\\\nnew file mode 100644\\\\nindex 0000000..bc3bd67\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/dang thi ha/anh4.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/dang thi ha/demo.jpg b/Dataset/FaceData/raw/dang thi ha/demo.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e02f72c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/dang thi ha/demo.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/dang thi ha/img.png b/Dataset/FaceData/raw/dang thi ha/img.png\\\\nnew file mode 100644\\\\nindex 0000000..0878f40\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/dang thi ha/img.png differ\\\\ndiff --git a/Dataset/FaceData/raw/duong thi bich nguyet/anh1.jpg b/Dataset/FaceData/raw/duong thi bich nguyet/anh1.jpg\\\\nnew file mode 100644\\\\nindex 0000000..c4b7f26\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/duong thi bich nguyet/anh1.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/duong thi bich nguyet/nguyet2.jpg b/Dataset/FaceData/raw/duong thi bich nguyet/nguyet2.jpg\\\\nnew file mode 100644\\\\nindex 0000000..43d497d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/duong thi bich nguyet/nguyet2.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/duong thi bich nguyet/nguyet3.jpg b/Dataset/FaceData/raw/duong thi bich nguyet/nguyet3.jpg\\\\nnew file mode 100644\\\\nindex 0000000..c56ecd2\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/duong thi bich nguyet/nguyet3.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/duong thi bich nguyet/nguyet4.jpg b/Dataset/FaceData/raw/duong thi bich nguyet/nguyet4.jpg\\\\nnew file mode 100644\\\\nindex 0000000..49050c7\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/duong thi bich nguyet/nguyet4.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/duong thi bich nguyet/nguyet6.jpg b/Dataset/FaceData/raw/duong thi bich nguyet/nguyet6.jpg\\\\nnew file mode 100644\\\\nindex 0000000..fe9dbb3\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/duong thi bich nguyet/nguyet6.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/hoang tran phau/img.png b/Dataset/FaceData/raw/hoang tran phau/img.png\\\\nnew file mode 100644\\\\nindex 0000000..a32763c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/hoang tran phau/img.png differ\\\\ndiff --git a/Dataset/FaceData/raw/hoang tran phau/img_1.png b/Dataset/FaceData/raw/hoang tran phau/img_1.png\\\\nnew file mode 100644\\\\nindex 0000000..5268947\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/hoang tran phau/img_1.png differ\\\\ndiff --git a/Dataset/FaceData/raw/hoang tran phau/phau.jpg b/Dataset/FaceData/raw/hoang tran phau/phau.jpg\\\\nnew file mode 100644\\\\nindex 0000000..dc71c2e\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/hoang tran phau/phau.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/hoang tran phau/phau1.jpg b/Dataset/FaceData/raw/hoang tran phau/phau1.jpg\\\\nnew file mode 100644\\\\nindex 0000000..59dda85\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/hoang tran phau/phau1.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/hoang tran phau/phau2.jpg b/Dataset/FaceData/raw/hoang tran phau/phau2.jpg\\\\nnew file mode 100644\\\\nindex 0000000..496c617\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/hoang tran phau/phau2.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/hoang tran phau/phau3.jpg b/Dataset/FaceData/raw/hoang tran phau/phau3.jpg\\\\nnew file mode 100644\\\\nindex 0000000..a3cee71\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/hoang tran phau/phau3.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/nguyen ngoc thai/284851180_1033334854278874_6949309560983343387_n.jpg b/Dataset/FaceData/raw/nguyen ngoc thai/284851180_1033334854278874_6949309560983343387_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..8fdff26\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/nguyen ngoc thai/284851180_1033334854278874_6949309560983343387_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/nguyen ngoc thai/thai1.jpg b/Dataset/FaceData/raw/nguyen ngoc thai/thai1.jpg\\\\nnew file mode 100644\\\\nindex 0000000..0c5ae9b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/nguyen ngoc thai/thai1.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/nguyen ngoc thai/thai2.jpg b/Dataset/FaceData/raw/nguyen ngoc thai/thai2.jpg\\\\nnew file mode 100644\\\\nindex 0000000..146e507\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/nguyen ngoc thai/thai2.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/nguyen ngoc thai/thai3.jpg b/Dataset/FaceData/raw/nguyen ngoc thai/thai3.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e31754c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/nguyen ngoc thai/thai3.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/nguyen ngoc thai/thai4.jpg b/Dataset/FaceData/raw/nguyen ngoc thai/thai4.jpg\\\\nnew file mode 100644\\\\nindex 0000000..7acec9d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/nguyen ngoc thai/thai4.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/nguyen ngoc thai/thai5.jpg b/Dataset/FaceData/raw/nguyen ngoc thai/thai5.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e7c2e52\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/nguyen ngoc thai/thai5.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/nguyen ngoc thai/thaidemo.jpg b/Dataset/FaceData/raw/nguyen ngoc thai/thaidemo.jpg\\\\nnew file mode 100644\\\\nindex 0000000..02e09d2\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/nguyen ngoc thai/thaidemo.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/nguyen ngoc thai/thaidemo2.jpg b/Dataset/FaceData/raw/nguyen ngoc thai/thaidemo2.jpg\\\\nnew file mode 100644\\\\nindex 0000000..10ed53b\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/nguyen ngoc thai/thaidemo2.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/nguyen phuong tram/337142073_1253839052216597_199657983855233980_n.jpg b/Dataset/FaceData/raw/nguyen phuong tram/337142073_1253839052216597_199657983855233980_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..3bbe7ae\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/nguyen phuong tram/337142073_1253839052216597_199657983855233980_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/nguyen phuong tram/339263904_1264665414159651_8733650862788543327_n.jpg b/Dataset/FaceData/raw/nguyen phuong tram/339263904_1264665414159651_8733650862788543327_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..c21775d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/nguyen phuong tram/339263904_1264665414159651_8733650862788543327_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/nguyen phuong tram/339266601_894783791775673_734864429475267886_n.jpg b/Dataset/FaceData/raw/nguyen phuong tram/339266601_894783791775673_734864429475267886_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..9f36aff\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/nguyen phuong tram/339266601_894783791775673_734864429475267886_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/nguyen phuong tram/339408406_1209323986622559_1237855961637611483_n.jpg b/Dataset/FaceData/raw/nguyen phuong tram/339408406_1209323986622559_1237855961637611483_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..cb89e2c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/nguyen phuong tram/339408406_1209323986622559_1237855961637611483_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/nguyen phuong tram/anh1.jpg b/Dataset/FaceData/raw/nguyen phuong tram/anh1.jpg\\\\nnew file mode 100644\\\\nindex 0000000..ab550bb\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/nguyen phuong tram/anh1.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/nguyen phuong tram/anh2.jpg b/Dataset/FaceData/raw/nguyen phuong tram/anh2.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e6c34e6\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/nguyen phuong tram/anh2.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/nguyen phuong tram/anh3.jpg b/Dataset/FaceData/raw/nguyen phuong tram/anh3.jpg\\\\nnew file mode 100644\\\\nindex 0000000..acd6426\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/nguyen phuong tram/anh3.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/nguyen phuong tram/anh4.jpg b/Dataset/FaceData/raw/nguyen phuong tram/anh4.jpg\\\\nnew file mode 100644\\\\nindex 0000000..f200dbf\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/nguyen phuong tram/anh4.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/nguyen phuong tram/anh5.jpg b/Dataset/FaceData/raw/nguyen phuong tram/anh5.jpg\\\\nnew file mode 100644\\\\nindex 0000000..b7cb2a0\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/nguyen phuong tram/anh5.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/nguyen phuong tram/anh7.jpg b/Dataset/FaceData/raw/nguyen phuong tram/anh7.jpg\\\\nnew file mode 100644\\\\nindex 0000000..9f36aff\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/nguyen phuong tram/anh7.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/nguyen phuong tram/anh8.jpg b/Dataset/FaceData/raw/nguyen phuong tram/anh8.jpg\\\\nnew file mode 100644\\\\nindex 0000000..4414420\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/nguyen phuong tram/anh8.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/thaongo/419652962_741170244266451_4914393583094088361_n.jpg b/Dataset/FaceData/raw/thaongo/419652962_741170244266451_4914393583094088361_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..a5439fb\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/thaongo/419652962_741170244266451_4914393583094088361_n.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao1.jpg b/Dataset/FaceData/raw/thaongo/thao1.jpg\\\\nnew file mode 100644\\\\nindex 0000000..1cdbc85\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/thaongo/thao1.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao10.jpg b/Dataset/FaceData/raw/thaongo/thao10.jpg\\\\nnew file mode 100644\\\\nindex 0000000..be28633\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/thaongo/thao10.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao19.jpg b/Dataset/FaceData/raw/thaongo/thao19.jpg\\\\nnew file mode 100644\\\\nindex 0000000..db3c5ed\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/thaongo/thao19.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao2.jpg b/Dataset/FaceData/raw/thaongo/thao2.jpg\\\\nnew file mode 100644\\\\nindex 0000000..1a64dcb\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/thaongo/thao2.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao21.jpg b/Dataset/FaceData/raw/thaongo/thao21.jpg\\\\nnew file mode 100644\\\\nindex 0000000..4157376\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/thaongo/thao21.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao24.jpg b/Dataset/FaceData/raw/thaongo/thao24.jpg\\\\nnew file mode 100644\\\\nindex 0000000..9fc20d4\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/thaongo/thao24.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao25.jpg b/Dataset/FaceData/raw/thaongo/thao25.jpg\\\\nnew file mode 100644\\\\nindex 0000000..dc6fa05\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/thaongo/thao25.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao26.jpg b/Dataset/FaceData/raw/thaongo/thao26.jpg\\\\nnew file mode 100644\\\\nindex 0000000..29c071c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/thaongo/thao26.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao29.jpg b/Dataset/FaceData/raw/thaongo/thao29.jpg\\\\nnew file mode 100644\\\\nindex 0000000..529d863\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/thaongo/thao29.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao3.jpg b/Dataset/FaceData/raw/thaongo/thao3.jpg\\\\nnew file mode 100644\\\\nindex 0000000..def734d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/thaongo/thao3.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao31.jpg b/Dataset/FaceData/raw/thaongo/thao31.jpg\\\\nnew file mode 100644\\\\nindex 0000000..978b359\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/thaongo/thao31.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao32.jpg b/Dataset/FaceData/raw/thaongo/thao32.jpg\\\\nnew file mode 100644\\\\nindex 0000000..176e54d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/thaongo/thao32.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao33.jpg b/Dataset/FaceData/raw/thaongo/thao33.jpg\\\\nnew file mode 100644\\\\nindex 0000000..b17923f\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/thaongo/thao33.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao34.jpg b/Dataset/FaceData/raw/thaongo/thao34.jpg\\\\nnew file mode 100644\\\\nindex 0000000..5104ac1\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/thaongo/thao34.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao35.jpg b/Dataset/FaceData/raw/thaongo/thao35.jpg\\\\nnew file mode 100644\\\\nindex 0000000..f2929d7\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/thaongo/thao35.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao4.jpg b/Dataset/FaceData/raw/thaongo/thao4.jpg\\\\nnew file mode 100644\\\\nindex 0000000..b1d0083\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/thaongo/thao4.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao5.jpg b/Dataset/FaceData/raw/thaongo/thao5.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e099c98\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/thaongo/thao5.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao6.jpg b/Dataset/FaceData/raw/thaongo/thao6.jpg\\\\nnew file mode 100644\\\\nindex 0000000..4c1a83e\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/thaongo/thao6.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao7.jpg b/Dataset/FaceData/raw/thaongo/thao7.jpg\\\\nnew file mode 100644\\\\nindex 0000000..1daf930\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/thaongo/thao7.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/tran nhat truong/truong1.jpg b/Dataset/FaceData/raw/tran nhat truong/truong1.jpg\\\\nnew file mode 100644\\\\nindex 0000000..f3a03ad\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/tran nhat truong/truong1.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/truong giang/0630_truonggiang_1.jpg b/Dataset/FaceData/raw/truong giang/0630_truonggiang_1.jpg\\\\nnew file mode 100644\\\\nindex 0000000..df05ae9\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/truong giang/0630_truonggiang_1.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/truong giang/0632_truonggiang_2.jpg b/Dataset/FaceData/raw/truong giang/0632_truonggiang_2.jpg\\\\nnew file mode 100644\\\\nindex 0000000..d847b59\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/truong giang/0632_truonggiang_2.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/truong giang/1545311811-862-truong-giang-bat-ngo-dan-dau-de-cu-nam-dien-vien-dien-anh-duoc-yeu-thich-nhat-truonggiang-1545278076-width660height990.jpg b/Dataset/FaceData/raw/truong giang/1545311811-862-truong-giang-bat-ngo-dan-dau-de-cu-nam-dien-vien-dien-anh-duoc-yeu-thich-nhat-truonggiang-1545278076-width660height990.jpg\\\\nnew file mode 100644\\\\nindex 0000000..bfe5872\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/truong giang/1545311811-862-truong-giang-bat-ngo-dan-dau-de-cu-nam-dien-vien-dien-anh-duoc-yeu-thich-nhat-truonggiang-1545278076-width660height990.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/truong giang/A27U7778.jpg b/Dataset/FaceData/raw/truong giang/A27U7778.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e8d102c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/truong giang/A27U7778.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/truong giang/fb_img_1704768289216-1704768712-408-width720height960.jpg b/Dataset/FaceData/raw/truong giang/fb_img_1704768289216-1704768712-408-width720height960.jpg\\\\nnew file mode 100644\\\\nindex 0000000..b55736d\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/truong giang/fb_img_1704768289216-1704768712-408-width720height960.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/truong giang/fb_img_1704768450012-1704768746-24-width720height1079.jpg b/Dataset/FaceData/raw/truong giang/fb_img_1704768450012-1704768746-24-width720height1079.jpg\\\\nnew file mode 100644\\\\nindex 0000000..3253faa\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/truong giang/fb_img_1704768450012-1704768746-24-width720height1079.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/truong giang/giang1.jpg b/Dataset/FaceData/raw/truong giang/giang1.jpg\\\\nnew file mode 100644\\\\nindex 0000000..db2b7ad\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/truong giang/giang1.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/truong giang/giang2.jpg b/Dataset/FaceData/raw/truong giang/giang2.jpg\\\\nnew file mode 100644\\\\nindex 0000000..770e8f8\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/truong giang/giang2.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/truong giang/giang3.jpg b/Dataset/FaceData/raw/truong giang/giang3.jpg\\\\nnew file mode 100644\\\\nindex 0000000..f4f0b5f\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/truong giang/giang3.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/truong giang/giang4.jpg b/Dataset/FaceData/raw/truong giang/giang4.jpg\\\\nnew file mode 100644\\\\nindex 0000000..1b86637\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/truong giang/giang4.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/truong giang/mc-truong-giang-1229339.jpg b/Dataset/FaceData/raw/truong giang/mc-truong-giang-1229339.jpg\\\\nnew file mode 100644\\\\nindex 0000000..5f90889\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/truong giang/mc-truong-giang-1229339.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/truong giang/mc-truong-giang-918712.jpg b/Dataset/FaceData/raw/truong giang/mc-truong-giang-918712.jpg\\\\nnew file mode 100644\\\\nindex 0000000..04b7d09\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/truong giang/mc-truong-giang-918712.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/truong giang/trg1 b/Dataset/FaceData/raw/truong giang/trg1\\\\nnew file mode 100644\\\\nindex 0000000..ac83601\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/truong giang/trg1 differ\\\\ndiff --git a/Dataset/FaceData/raw/truong giang/vtr-4472.jpg b/Dataset/FaceData/raw/truong giang/vtr-4472.jpg\\\\nnew file mode 100644\\\\nindex 0000000..d6dba0c\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/truong giang/vtr-4472.jpg differ\\\\ndiff --git a/Dataset/FaceData/raw/truong giang/vtr-4475.jpg b/Dataset/FaceData/raw/truong giang/vtr-4475.jpg\\\\nnew file mode 100644\\\\nindex 0000000..804a3f7\\\\nBinary files /dev/null and b/Dataset/FaceData/raw/truong giang/vtr-4475.jpg differ\\\\ndiff --git a/Models/20180402-114759.pb b/Models/20180402-114759.pb\\\\nnew file mode 100644\\\\nindex 0000000..39b4ed7\\\\nBinary files /dev/null and b/Models/20180402-114759.pb differ\\\\ndiff --git a/Models/model-20180402-114759.ckpt-275.data-00000-of-00001 b/Models/model-20180402-114759.ckpt-275.data-00000-of-00001\\\\nnew file mode 100644\\\\nindex 0000000..6160198\\\\nBinary files /dev/null and b/Models/model-20180402-114759.ckpt-275.data-00000-of-00001 differ\\\\ndiff --git a/Models/model-20180402-114759.ckpt-275.index b/Models/model-20180402-114759.ckpt-275.index\\\\nnew file mode 100644\\\\nindex 0000000..e2b346c\\\\nBinary files /dev/null and b/Models/model-20180402-114759.ckpt-275.index differ\\\\ndiff --git a/Models/model-20180402-114759.meta b/Models/model-20180402-114759.meta\\\\nnew file mode 100644\\\\nindex 0000000..abffaef\\\\nBinary files /dev/null and b/Models/model-20180402-114759.meta differ\\\\ndiff --git a/README.md b/README.md\\\\ndeleted file mode 100644\\\\nindex 16ec29c..0000000\\\\n--- a/README.md\\\\n+++ /dev/null\\\\n@@ -1,11 +0,0 @@\\\\n-# MiAI_FaceRecog_3\\\\n-Nh\\\\xe1\\\\xba\\\\xadn di\\\\xe1\\\\xbb\\\\x87n khu\\\\xc3\\\\xb4n m\\\\xe1\\\\xba\\\\xb7t kh\\\\xc3\\\\xa1 chu\\\\xe1\\\\xba\\\\xa9n x\\\\xc3\\\\xa1c b\\\\xe1\\\\xba\\\\xb1ng MTCNN v\\\\xc3\\\\xa0 Facenet!\\\\n-Ch\\\\xe1\\\\xba\\\\xa1y tr\\\\xc3\\\\xaan Tensorflow 2.x\\\\n-\\\\n-Article link: http://miai.vn/2019/09/11/face-recog-2-0-nhan-dien-khuon-mat-trong-video-bang-mtcnn-va-facenet/\\\\n-\\\\n-#M\\\\xc3\\\\xacAI \\\\n-Fanpage: http://facebook.com/miaiblog<br>\\\\n-Group trao \\\\xc4\\\\x91\\\\xe1\\\\xbb\\\\x95i, chia s\\\\xe1\\\\xba\\\\xbb: https://www.facebook.com/groups/miaigroup<br>\\\\n-Website: http://ainoodle.tech<br>\\\\n-Youtube: http://bit.ly/miaiyoutube<br>\\\\ndiff --git a/face/Bui Anh Tuan/0.png b/face/Bui Anh Tuan/0.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/1.png b/face/Bui Anh Tuan/1.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/10.png b/face/Bui Anh Tuan/10.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/11.png b/face/Bui Anh Tuan/11.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/12.png b/face/Bui Anh Tuan/12.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/13.png b/face/Bui Anh Tuan/13.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/14.png b/face/Bui Anh Tuan/14.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/15.png b/face/Bui Anh Tuan/15.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/16.png b/face/Bui Anh Tuan/16.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/17.png b/face/Bui Anh Tuan/17.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/18.png b/face/Bui Anh Tuan/18.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/19.png b/face/Bui Anh Tuan/19.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/2.png b/face/Bui Anh Tuan/2.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/20.png b/face/Bui Anh Tuan/20.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/21.png b/face/Bui Anh Tuan/21.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/22.png b/face/Bui Anh Tuan/22.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/23.png b/face/Bui Anh Tuan/23.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/24.png b/face/Bui Anh Tuan/24.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/25.png b/face/Bui Anh Tuan/25.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/26.png b/face/Bui Anh Tuan/26.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/27.png b/face/Bui Anh Tuan/27.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/28.png b/face/Bui Anh Tuan/28.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/29.png b/face/Bui Anh Tuan/29.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/3.png b/face/Bui Anh Tuan/3.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/30.png b/face/Bui Anh Tuan/30.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/31.png b/face/Bui Anh Tuan/31.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/32.png b/face/Bui Anh Tuan/32.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/33.png b/face/Bui Anh Tuan/33.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/34.png b/face/Bui Anh Tuan/34.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/35.png b/face/Bui Anh Tuan/35.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/36.png b/face/Bui Anh Tuan/36.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/37.png b/face/Bui Anh Tuan/37.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/38.png b/face/Bui Anh Tuan/38.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/39.png b/face/Bui Anh Tuan/39.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/4.png b/face/Bui Anh Tuan/4.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/40.png b/face/Bui Anh Tuan/40.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/41.png b/face/Bui Anh Tuan/41.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/42.png b/face/Bui Anh Tuan/42.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/43.png b/face/Bui Anh Tuan/43.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/44.png b/face/Bui Anh Tuan/44.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/45.png b/face/Bui Anh Tuan/45.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/46.png b/face/Bui Anh Tuan/46.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/47.png b/face/Bui Anh Tuan/47.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/5.png b/face/Bui Anh Tuan/5.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/6.png b/face/Bui Anh Tuan/6.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/7.png b/face/Bui Anh Tuan/7.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/8.png b/face/Bui Anh Tuan/8.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Bui Anh Tuan/9.png b/face/Bui Anh Tuan/9.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/0.png b/face/Dam vinh hung/0.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/1.png b/face/Dam vinh hung/1.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/10.png b/face/Dam vinh hung/10.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/11.png b/face/Dam vinh hung/11.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/12.png b/face/Dam vinh hung/12.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/13.png b/face/Dam vinh hung/13.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/14.png b/face/Dam vinh hung/14.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/15.png b/face/Dam vinh hung/15.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/16.png b/face/Dam vinh hung/16.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/17.png b/face/Dam vinh hung/17.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/18.png b/face/Dam vinh hung/18.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/19.png b/face/Dam vinh hung/19.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/2.png b/face/Dam vinh hung/2.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/20.png b/face/Dam vinh hung/20.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/21.png b/face/Dam vinh hung/21.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/22.png b/face/Dam vinh hung/22.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/23.png b/face/Dam vinh hung/23.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/24.png b/face/Dam vinh hung/24.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/25.png b/face/Dam vinh hung/25.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/26.png b/face/Dam vinh hung/26.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/27.png b/face/Dam vinh hung/27.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/28.png b/face/Dam vinh hung/28.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/29.png b/face/Dam vinh hung/29.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/3.png b/face/Dam vinh hung/3.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/30.png b/face/Dam vinh hung/30.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/31.png b/face/Dam vinh hung/31.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/32.png b/face/Dam vinh hung/32.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/33.png b/face/Dam vinh hung/33.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/34.png b/face/Dam vinh hung/34.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/35.png b/face/Dam vinh hung/35.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/36.png b/face/Dam vinh hung/36.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/37.png b/face/Dam vinh hung/37.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/38.png b/face/Dam vinh hung/38.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/39.png b/face/Dam vinh hung/39.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/4.png b/face/Dam vinh hung/4.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/40.png b/face/Dam vinh hung/40.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/41.png b/face/Dam vinh hung/41.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/42.png b/face/Dam vinh hung/42.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/43.png b/face/Dam vinh hung/43.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/5.png b/face/Dam vinh hung/5.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/6.png b/face/Dam vinh hung/6.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/7.png b/face/Dam vinh hung/7.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/8.png b/face/Dam vinh hung/8.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Dam vinh hung/9.png b/face/Dam vinh hung/9.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/0.png b/face/Den Vau/0.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/1.png b/face/Den Vau/1.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/10.png b/face/Den Vau/10.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/11.png b/face/Den Vau/11.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/12.png b/face/Den Vau/12.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/13.png b/face/Den Vau/13.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/14.png b/face/Den Vau/14.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/15.png b/face/Den Vau/15.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/16.png b/face/Den Vau/16.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/17.png b/face/Den Vau/17.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/18.png b/face/Den Vau/18.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/19.png b/face/Den Vau/19.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/2.png b/face/Den Vau/2.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/20.png b/face/Den Vau/20.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/21.png b/face/Den Vau/21.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/22.png b/face/Den Vau/22.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/23.png b/face/Den Vau/23.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/24.png b/face/Den Vau/24.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/25.png b/face/Den Vau/25.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/26.png b/face/Den Vau/26.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/27.png b/face/Den Vau/27.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/28.png b/face/Den Vau/28.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/29.png b/face/Den Vau/29.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/3.png b/face/Den Vau/3.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/30.png b/face/Den Vau/30.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/31.png b/face/Den Vau/31.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/32.png b/face/Den Vau/32.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/33.png b/face/Den Vau/33.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/34.png b/face/Den Vau/34.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/35.png b/face/Den Vau/35.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/36.png b/face/Den Vau/36.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/37.png b/face/Den Vau/37.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/38.png b/face/Den Vau/38.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/39.png b/face/Den Vau/39.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/4.png b/face/Den Vau/4.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/40.png b/face/Den Vau/40.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/41.png b/face/Den Vau/41.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/42.png b/face/Den Vau/42.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/43.png b/face/Den Vau/43.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/44.png b/face/Den Vau/44.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/45.png b/face/Den Vau/45.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/46.png b/face/Den Vau/46.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/47.png b/face/Den Vau/47.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/48.png b/face/Den Vau/48.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/49.png b/face/Den Vau/49.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/5.png b/face/Den Vau/5.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/50.png b/face/Den Vau/50.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/51.png b/face/Den Vau/51.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/52.png b/face/Den Vau/52.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/53.png b/face/Den Vau/53.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/54.png b/face/Den Vau/54.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/55.png b/face/Den Vau/55.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/56.png b/face/Den Vau/56.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/57.png b/face/Den Vau/57.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/58.png b/face/Den Vau/58.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/59.png b/face/Den Vau/59.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/6.png b/face/Den Vau/6.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/60.png b/face/Den Vau/60.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/61.png b/face/Den Vau/61.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/62.png b/face/Den Vau/62.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/63.png b/face/Den Vau/63.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/64.png b/face/Den Vau/64.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/65.png b/face/Den Vau/65.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/66.png b/face/Den Vau/66.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/67.png b/face/Den Vau/67.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/68.png b/face/Den Vau/68.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/69.png b/face/Den Vau/69.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/7.png b/face/Den Vau/7.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/70.png b/face/Den Vau/70.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/71.png b/face/Den Vau/71.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/72.png b/face/Den Vau/72.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/73.png b/face/Den Vau/73.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/8.png b/face/Den Vau/8.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Den Vau/9.png b/face/Den Vau/9.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Do hieu/176064931_2957139457942069_3035200184642124074_n.jpg b/face/Do hieu/176064931_2957139457942069_3035200184642124074_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Do hieu/177907728_2957139527942062_5622464185056568311_n.jpg b/face/Do hieu/177907728_2957139527942062_5622464185056568311_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Do hieu/177993461_2957139491275399_3222091836626291316_n.jpg b/face/Do hieu/177993461_2957139491275399_3222091836626291316_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Do hieu/178929889_2957139244608757_1991887332909086037_n (1).jpg b/face/Do hieu/178929889_2957139244608757_1991887332909086037_n (1).jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Do hieu/178929889_2957139244608757_1991887332909086037_n.jpg b/face/Do hieu/178929889_2957139244608757_1991887332909086037_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Do hieu/314736967_3413393448983332_3470974153489929662_n.jpg b/face/Do hieu/314736967_3413393448983332_3470974153489929662_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Do hieu/408729291_122109331016134044_5530016628103795106_n.jpg b/face/Do hieu/408729291_122109331016134044_5530016628103795106_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Duc viet/152373366_899599367523323_8039073461193180489_n.jpg b/face/Duc viet/152373366_899599367523323_8039073461193180489_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Duc viet/152709553_899599430856650_818805157951754296_n.jpg b/face/Duc viet/152709553_899599430856650_818805157951754296_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Duc viet/154070237_435134567707863_6078333129900068002_n.jpg b/face/Duc viet/154070237_435134567707863_6078333129900068002_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Duc viet/61506698_348134895895603_7272087717616287744_n.jpg b/face/Duc viet/61506698_348134895895603_7272087717616287744_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Duc viet/61560706_348134092562350_1539501885898096640_n.jpg b/face/Duc viet/61560706_348134092562350_1539501885898096640_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Duc viet/61584844_348135582562201_7506169027295707136_n.jpg b/face/Duc viet/61584844_348135582562201_7506169027295707136_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Duc viet/61820425_348134402562319_3380097574999425024_n.jpg b/face/Duc viet/61820425_348134402562319_3380097574999425024_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Duc viet/61848774_348135615895531_3014436068146544640_n.jpg b/face/Duc viet/61848774_348135615895531_3014436068146544640_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Duc viet/61967926_348135315895561_496212973459603456_n.jpg b/face/Duc viet/61967926_348135315895561_496212973459603456_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Duc viet/62021360_348135282562231_7688022791626424320_n.jpg b/face/Duc viet/62021360_348135282562231_7688022791626424320_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Duc viet/62035132_348134362562323_2007170459463843840_n.jpg b/face/Duc viet/62035132_348134362562323_2007170459463843840_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Duc viet/64869534_359570548085371_8201502723321888768_n.jpg b/face/Duc viet/64869534_359570548085371_8201502723321888768_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/0.png b/face/Ha Anh Tuan/0.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/1.png b/face/Ha Anh Tuan/1.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/10.png b/face/Ha Anh Tuan/10.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/11.png b/face/Ha Anh Tuan/11.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/12.png b/face/Ha Anh Tuan/12.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/13.png b/face/Ha Anh Tuan/13.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/14.png b/face/Ha Anh Tuan/14.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/15.png b/face/Ha Anh Tuan/15.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/16.png b/face/Ha Anh Tuan/16.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/17.png b/face/Ha Anh Tuan/17.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/18.png b/face/Ha Anh Tuan/18.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/19.png b/face/Ha Anh Tuan/19.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/2.png b/face/Ha Anh Tuan/2.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/20.png b/face/Ha Anh Tuan/20.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/21.png b/face/Ha Anh Tuan/21.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/22.png b/face/Ha Anh Tuan/22.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/23.png b/face/Ha Anh Tuan/23.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/24.png b/face/Ha Anh Tuan/24.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/25.png b/face/Ha Anh Tuan/25.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/26.png b/face/Ha Anh Tuan/26.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/27.png b/face/Ha Anh Tuan/27.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/28.png b/face/Ha Anh Tuan/28.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/29.png b/face/Ha Anh Tuan/29.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/3.png b/face/Ha Anh Tuan/3.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/30.png b/face/Ha Anh Tuan/30.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/31.png b/face/Ha Anh Tuan/31.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/32.png b/face/Ha Anh Tuan/32.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/33.png b/face/Ha Anh Tuan/33.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/34.png b/face/Ha Anh Tuan/34.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/35.png b/face/Ha Anh Tuan/35.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/36.png b/face/Ha Anh Tuan/36.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/37.png b/face/Ha Anh Tuan/37.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/38.png b/face/Ha Anh Tuan/38.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/39.png b/face/Ha Anh Tuan/39.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/4.png b/face/Ha Anh Tuan/4.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/40.png b/face/Ha Anh Tuan/40.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/5.png b/face/Ha Anh Tuan/5.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/6.png b/face/Ha Anh Tuan/6.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/7.png b/face/Ha Anh Tuan/7.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/8.png b/face/Ha Anh Tuan/8.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ha Anh Tuan/9.png b/face/Ha Anh Tuan/9.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/0.png b/face/Hoai linh/0.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/1.png b/face/Hoai linh/1.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/10.png b/face/Hoai linh/10.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/11.png b/face/Hoai linh/11.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/12.png b/face/Hoai linh/12.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/13.png b/face/Hoai linh/13.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/14.png b/face/Hoai linh/14.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/15.png b/face/Hoai linh/15.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/16.png b/face/Hoai linh/16.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/17.png b/face/Hoai linh/17.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/18.png b/face/Hoai linh/18.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/19.png b/face/Hoai linh/19.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/2.png b/face/Hoai linh/2.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/20.png b/face/Hoai linh/20.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/21.png b/face/Hoai linh/21.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/22.png b/face/Hoai linh/22.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/23.png b/face/Hoai linh/23.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/24.png b/face/Hoai linh/24.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/25.png b/face/Hoai linh/25.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/26.png b/face/Hoai linh/26.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/27.png b/face/Hoai linh/27.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/28.png b/face/Hoai linh/28.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/29.png b/face/Hoai linh/29.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/3.png b/face/Hoai linh/3.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/30.png b/face/Hoai linh/30.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/31.png b/face/Hoai linh/31.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/32.png b/face/Hoai linh/32.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/33.png b/face/Hoai linh/33.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/34.png b/face/Hoai linh/34.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/35.png b/face/Hoai linh/35.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/36.png b/face/Hoai linh/36.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/37.png b/face/Hoai linh/37.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/38.png b/face/Hoai linh/38.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/39.png b/face/Hoai linh/39.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/4.png b/face/Hoai linh/4.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/40.png b/face/Hoai linh/40.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/5.png b/face/Hoai linh/5.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/6.png b/face/Hoai linh/6.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/7.png b/face/Hoai linh/7.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/8.png b/face/Hoai linh/8.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Hoai linh/9.png b/face/Hoai linh/9.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ma bach duy/duy1.jpg b/face/Ma bach duy/duy1.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ma bach duy/duy2.jpg b/face/Ma bach duy/duy2.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ma bach duy/duy3.jpg b/face/Ma bach duy/duy3.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Ma bach duy/duy4.jpg b/face/Ma bach duy/duy4.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Minh hoa/116428895_656623338282021_8457872234875945077_n.jpg b/face/Minh hoa/116428895_656623338282021_8457872234875945077_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Minh hoa/133049557_769265223684498_4689118252074034370_n.jpg b/face/Minh hoa/133049557_769265223684498_4689118252074034370_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Minh hoa/258158616_974113876532964_9067509414358086927_n.jpg b/face/Minh hoa/258158616_974113876532964_9067509414358086927_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Minh hoa/277588798_1056746241603060_3376911805269669778_n.jpg b/face/Minh hoa/277588798_1056746241603060_3376911805269669778_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Minh hoa/45761069_299092524035106_5787233926145638400_n.jpg b/face/Minh hoa/45761069_299092524035106_5787233926145638400_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Minh hoa/51367653_335164410427917_2686636884146257920_n.jpg b/face/Minh hoa/51367653_335164410427917_2686636884146257920_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Minh hoa/72597481_459453121332378_4444718657989246976_n.jpg b/face/Minh hoa/72597481_459453121332378_4444718657989246976_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/My Duyen/240594338_608022267035848_559750156049629888_n.jpg b/face/My Duyen/240594338_608022267035848_559750156049629888_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/My Duyen/271565569_687653065739434_6695347522364803324_n.jpg b/face/My Duyen/271565569_687653065739434_6695347522364803324_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/My Duyen/276281855_728896961615044_4850973774883281965_n.jpg b/face/My Duyen/276281855_728896961615044_4850973774883281965_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/My Duyen/375727668_1053445732493497_6855315188334578963_n.jpg b/face/My Duyen/375727668_1053445732493497_6855315188334578963_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/My Duyen/377915813_1055517365619667_3022176625716036504_n.jpg b/face/My Duyen/377915813_1055517365619667_3022176625716036504_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/My Duyen/383221108_1063489451489125_7303325553687006067_n.jpg b/face/My Duyen/383221108_1063489451489125_7303325553687006067_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/My Duyen/399161466_1085274189310651_5389319938695371438_n.jpg b/face/My Duyen/399161466_1085274189310651_5389319938695371438_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/My Duyen/425727875_1136306777540725_7475412167375191065_n.jpg b/face/My Duyen/425727875_1136306777540725_7475412167375191065_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/My Duyen/71477803_179402706564475_6524185163780325376_n.jpg b/face/My Duyen/71477803_179402706564475_6524185163780325376_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/0.png b/face/Nam Em/0.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/1.png b/face/Nam Em/1.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/10.png b/face/Nam Em/10.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/11.png b/face/Nam Em/11.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/12.png b/face/Nam Em/12.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/13.png b/face/Nam Em/13.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/14.png b/face/Nam Em/14.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/15.png b/face/Nam Em/15.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/16.png b/face/Nam Em/16.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/17.png b/face/Nam Em/17.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/18.png b/face/Nam Em/18.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/19.png b/face/Nam Em/19.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/2.png b/face/Nam Em/2.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/20.png b/face/Nam Em/20.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/21.png b/face/Nam Em/21.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/22.png b/face/Nam Em/22.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/23.png b/face/Nam Em/23.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/24.png b/face/Nam Em/24.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/25.png b/face/Nam Em/25.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/26.png b/face/Nam Em/26.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/27.png b/face/Nam Em/27.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/28.png b/face/Nam Em/28.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/29.png b/face/Nam Em/29.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/3.png b/face/Nam Em/3.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/30.png b/face/Nam Em/30.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/31.png b/face/Nam Em/31.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/32.png b/face/Nam Em/32.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/33.png b/face/Nam Em/33.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/34.png b/face/Nam Em/34.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/35.png b/face/Nam Em/35.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/36.png b/face/Nam Em/36.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/37.png b/face/Nam Em/37.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/38.png b/face/Nam Em/38.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/39.png b/face/Nam Em/39.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/4.png b/face/Nam Em/4.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/40.png b/face/Nam Em/40.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/41.png b/face/Nam Em/41.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/5.png b/face/Nam Em/5.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/6.png b/face/Nam Em/6.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/7.png b/face/Nam Em/7.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/8.png b/face/Nam Em/8.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nam Em/9.png b/face/Nam Em/9.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/0.png b/face/Nguyen phu trong/0.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/1.png b/face/Nguyen phu trong/1.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/10.png b/face/Nguyen phu trong/10.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/11.png b/face/Nguyen phu trong/11.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/12.png b/face/Nguyen phu trong/12.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/13.png b/face/Nguyen phu trong/13.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/14.png b/face/Nguyen phu trong/14.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/15.png b/face/Nguyen phu trong/15.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/16.png b/face/Nguyen phu trong/16.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/17.png b/face/Nguyen phu trong/17.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/18.png b/face/Nguyen phu trong/18.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/19.png b/face/Nguyen phu trong/19.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/2.png b/face/Nguyen phu trong/2.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/20.png b/face/Nguyen phu trong/20.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/21.png b/face/Nguyen phu trong/21.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/22.png b/face/Nguyen phu trong/22.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/23.png b/face/Nguyen phu trong/23.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/24.png b/face/Nguyen phu trong/24.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/25.png b/face/Nguyen phu trong/25.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/26.png b/face/Nguyen phu trong/26.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/27.png b/face/Nguyen phu trong/27.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/28.png b/face/Nguyen phu trong/28.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/29.png b/face/Nguyen phu trong/29.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/3.png b/face/Nguyen phu trong/3.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/30.png b/face/Nguyen phu trong/30.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/31.png b/face/Nguyen phu trong/31.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/32.png b/face/Nguyen phu trong/32.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/33.png b/face/Nguyen phu trong/33.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/34.png b/face/Nguyen phu trong/34.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/35.png b/face/Nguyen phu trong/35.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/36.png b/face/Nguyen phu trong/36.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/37.png b/face/Nguyen phu trong/37.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/38.png b/face/Nguyen phu trong/38.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/39.png b/face/Nguyen phu trong/39.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/4.png b/face/Nguyen phu trong/4.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/40.png b/face/Nguyen phu trong/40.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/41.png b/face/Nguyen phu trong/41.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/42.png b/face/Nguyen phu trong/42.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/43.png b/face/Nguyen phu trong/43.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/44.png b/face/Nguyen phu trong/44.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/45.png b/face/Nguyen phu trong/45.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/46.png b/face/Nguyen phu trong/46.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/47.png b/face/Nguyen phu trong/47.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/5.png b/face/Nguyen phu trong/5.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/6.png b/face/Nguyen phu trong/6.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/7.png b/face/Nguyen phu trong/7.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/8.png b/face/Nguyen phu trong/8.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Nguyen phu trong/9.png b/face/Nguyen phu trong/9.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/0.png b/face/Quang Hai/0.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/1.png b/face/Quang Hai/1.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/10.png b/face/Quang Hai/10.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/11.png b/face/Quang Hai/11.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/12.png b/face/Quang Hai/12.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/13.png b/face/Quang Hai/13.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/14.png b/face/Quang Hai/14.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/15.png b/face/Quang Hai/15.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/16.png b/face/Quang Hai/16.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/17.png b/face/Quang Hai/17.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/18.png b/face/Quang Hai/18.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/19.png b/face/Quang Hai/19.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/2.png b/face/Quang Hai/2.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/20.png b/face/Quang Hai/20.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/21.png b/face/Quang Hai/21.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/22.png b/face/Quang Hai/22.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/23.png b/face/Quang Hai/23.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/24.png b/face/Quang Hai/24.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/25.png b/face/Quang Hai/25.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/26.png b/face/Quang Hai/26.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/27.png b/face/Quang Hai/27.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/28.png b/face/Quang Hai/28.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/29.png b/face/Quang Hai/29.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/3.png b/face/Quang Hai/3.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/4.png b/face/Quang Hai/4.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/5.png b/face/Quang Hai/5.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/6.png b/face/Quang Hai/6.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/7.png b/face/Quang Hai/7.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/8.png b/face/Quang Hai/8.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Quang Hai/9.png b/face/Quang Hai/9.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Tran Hoc/107223180_1197468397263141_6372187421696273098_n.jpg b/face/Tran Hoc/107223180_1197468397263141_6372187421696273098_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Tran Hoc/120220333_1261416600868320_4101096592656067221_n.jpg b/face/Tran Hoc/120220333_1261416600868320_4101096592656067221_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Tran Hoc/235810118_1494231920920119_422367748034160663_n.jpg b/face/Tran Hoc/235810118_1494231920920119_422367748034160663_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Tran Hoc/90066892_1096495004027148_8085701175137009664_n.jpg b/face/Tran Hoc/90066892_1096495004027148_8085701175137009664_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/0.png b/face/Van Dung/0.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/1.png b/face/Van Dung/1.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/10.png b/face/Van Dung/10.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/11.png b/face/Van Dung/11.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/12.png b/face/Van Dung/12.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/13.png b/face/Van Dung/13.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/14.png b/face/Van Dung/14.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/15.png b/face/Van Dung/15.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/16.png b/face/Van Dung/16.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/17.png b/face/Van Dung/17.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/18.png b/face/Van Dung/18.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/19.png b/face/Van Dung/19.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/2.png b/face/Van Dung/2.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/20.png b/face/Van Dung/20.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/21.png b/face/Van Dung/21.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/22.png b/face/Van Dung/22.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/23.png b/face/Van Dung/23.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/24.png b/face/Van Dung/24.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/25.png b/face/Van Dung/25.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/26.png b/face/Van Dung/26.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/27.png b/face/Van Dung/27.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/28.png b/face/Van Dung/28.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/29.png b/face/Van Dung/29.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/3.png b/face/Van Dung/3.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/30.png b/face/Van Dung/30.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/31.png b/face/Van Dung/31.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/32.png b/face/Van Dung/32.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/33.png b/face/Van Dung/33.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/34.png b/face/Van Dung/34.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/35.png b/face/Van Dung/35.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/36.png b/face/Van Dung/36.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/37.png b/face/Van Dung/37.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/38.png b/face/Van Dung/38.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/39.png b/face/Van Dung/39.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/4.png b/face/Van Dung/4.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/40.png b/face/Van Dung/40.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/41.png b/face/Van Dung/41.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/42.png b/face/Van Dung/42.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/43.png b/face/Van Dung/43.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/44.png b/face/Van Dung/44.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/45.png b/face/Van Dung/45.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/46.png b/face/Van Dung/46.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/47.png b/face/Van Dung/47.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/48.png b/face/Van Dung/48.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/49.png b/face/Van Dung/49.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/5.png b/face/Van Dung/5.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/50.png b/face/Van Dung/50.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/51.png b/face/Van Dung/51.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/52.png b/face/Van Dung/52.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/53.png b/face/Van Dung/53.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/54.png b/face/Van Dung/54.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/55.png b/face/Van Dung/55.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/56.png b/face/Van Dung/56.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/57.png b/face/Van Dung/57.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/58.png b/face/Van Dung/58.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/59.png b/face/Van Dung/59.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/6.png b/face/Van Dung/6.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/60.png b/face/Van Dung/60.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/61.png b/face/Van Dung/61.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/62.png b/face/Van Dung/62.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/63.png b/face/Van Dung/63.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/64.png b/face/Van Dung/64.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/65.png b/face/Van Dung/65.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/66.png b/face/Van Dung/66.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/67.png b/face/Van Dung/67.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/68.png b/face/Van Dung/68.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/69.png b/face/Van Dung/69.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/7.png b/face/Van Dung/7.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/70.png b/face/Van Dung/70.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/71.png b/face/Van Dung/71.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/72.png b/face/Van Dung/72.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/73.png b/face/Van Dung/73.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/74.png b/face/Van Dung/74.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/75.png b/face/Van Dung/75.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/76.png b/face/Van Dung/76.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/77.png b/face/Van Dung/77.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/78.png b/face/Van Dung/78.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/79.png b/face/Van Dung/79.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/8.png b/face/Van Dung/8.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/80.png b/face/Van Dung/80.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/81.png b/face/Van Dung/81.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/82.png b/face/Van Dung/82.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/83.png b/face/Van Dung/83.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/84.png b/face/Van Dung/84.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/85.png b/face/Van Dung/85.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/86.png b/face/Van Dung/86.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/87.png b/face/Van Dung/87.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/88.png b/face/Van Dung/88.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Van Dung/9.png b/face/Van Dung/9.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/0.png b/face/Xuan Hinh/0.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/1.png b/face/Xuan Hinh/1.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/10.png b/face/Xuan Hinh/10.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/11.png b/face/Xuan Hinh/11.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/12.png b/face/Xuan Hinh/12.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/13.png b/face/Xuan Hinh/13.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/14.png b/face/Xuan Hinh/14.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/15.png b/face/Xuan Hinh/15.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/16.png b/face/Xuan Hinh/16.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/17.png b/face/Xuan Hinh/17.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/18.png b/face/Xuan Hinh/18.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/19.png b/face/Xuan Hinh/19.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/2.png b/face/Xuan Hinh/2.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/20.png b/face/Xuan Hinh/20.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/21.png b/face/Xuan Hinh/21.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/22.png b/face/Xuan Hinh/22.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/23.png b/face/Xuan Hinh/23.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/24.png b/face/Xuan Hinh/24.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/25.png b/face/Xuan Hinh/25.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/26.png b/face/Xuan Hinh/26.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/27.png b/face/Xuan Hinh/27.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/28.png b/face/Xuan Hinh/28.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/29.png b/face/Xuan Hinh/29.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/3.png b/face/Xuan Hinh/3.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/30.png b/face/Xuan Hinh/30.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/31.png b/face/Xuan Hinh/31.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/32.png b/face/Xuan Hinh/32.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/33.png b/face/Xuan Hinh/33.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/34.png b/face/Xuan Hinh/34.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/35.png b/face/Xuan Hinh/35.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/36.png b/face/Xuan Hinh/36.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/37.png b/face/Xuan Hinh/37.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/38.png b/face/Xuan Hinh/38.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/39.png b/face/Xuan Hinh/39.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/4.png b/face/Xuan Hinh/4.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/40.png b/face/Xuan Hinh/40.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/41.png b/face/Xuan Hinh/41.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/42.png b/face/Xuan Hinh/42.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/5.png b/face/Xuan Hinh/5.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/6.png b/face/Xuan Hinh/6.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/7.png b/face/Xuan Hinh/7.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/8.png b/face/Xuan Hinh/8.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/Xuan Hinh/9.png b/face/Xuan Hinh/9.png\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/chunghoang/386429669_867969661603917_3228776363804735267_n.jpg b/face/chunghoang/386429669_867969661603917_3228776363804735267_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/chunghoang/422737427_390399053474445_3140718471568843261_n.jpg b/face/chunghoang/422737427_390399053474445_3140718471568843261_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/chunghoang/chung1.jpg b/face/chunghoang/chung1.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/chunghoang/chung2.jpg b/face/chunghoang/chung2.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/chunghoang/chung3.jpg b/face/chunghoang/chung3.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/chunghoang/chung4.jpg b/face/chunghoang/chung4.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/chunghoang/chung6.jpg b/face/chunghoang/chung6.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/dang thi ha/385534676_267391239125906_3185308814281359599_n.jpg b/face/dang thi ha/385534676_267391239125906_3185308814281359599_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/dang thi ha/anh1.jpg b/face/dang thi ha/anh1.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/dang thi ha/anh2.jpg b/face/dang thi ha/anh2.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/dang thi ha/anh3.jpg b/face/dang thi ha/anh3.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/dang thi ha/anh4.jpg b/face/dang thi ha/anh4.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/dang thi ha/demo.jpg b/face/dang thi ha/demo.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/duong thi bich nguyet/anh1.jpg b/face/duong thi bich nguyet/anh1.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/duong thi bich nguyet/nguyet2.jpg b/face/duong thi bich nguyet/nguyet2.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/duong thi bich nguyet/nguyet3.jpg b/face/duong thi bich nguyet/nguyet3.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/duong thi bich nguyet/nguyet4.jpg b/face/duong thi bich nguyet/nguyet4.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/duong thi bich nguyet/nguyet6.jpg b/face/duong thi bich nguyet/nguyet6.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/hoang tran phau/phau.jpg b/face/hoang tran phau/phau.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/hoang tran phau/phau1.jpg b/face/hoang tran phau/phau1.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/hoang tran phau/phau2.jpg b/face/hoang tran phau/phau2.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/hoang tran phau/phau3.jpg b/face/hoang tran phau/phau3.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/nguyen ngoc thai/284851180_1033334854278874_6949309560983343387_n.jpg b/face/nguyen ngoc thai/284851180_1033334854278874_6949309560983343387_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/nguyen ngoc thai/thai1.jpg b/face/nguyen ngoc thai/thai1.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/nguyen ngoc thai/thai2.jpg b/face/nguyen ngoc thai/thai2.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/nguyen ngoc thai/thai3.jpg b/face/nguyen ngoc thai/thai3.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/nguyen ngoc thai/thai4.jpg b/face/nguyen ngoc thai/thai4.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/nguyen ngoc thai/thai5.jpg b/face/nguyen ngoc thai/thai5.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/nguyen ngoc thai/thaidemo.jpg b/face/nguyen ngoc thai/thaidemo.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/nguyen ngoc thai/thaidemo2.jpg b/face/nguyen ngoc thai/thaidemo2.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/nguyen phuong tram/337142073_1253839052216597_199657983855233980_n.jpg b/face/nguyen phuong tram/337142073_1253839052216597_199657983855233980_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/nguyen phuong tram/339263904_1264665414159651_8733650862788543327_n.jpg b/face/nguyen phuong tram/339263904_1264665414159651_8733650862788543327_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/nguyen phuong tram/339266601_894783791775673_734864429475267886_n.jpg b/face/nguyen phuong tram/339266601_894783791775673_734864429475267886_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/nguyen phuong tram/339408406_1209323986622559_1237855961637611483_n.jpg b/face/nguyen phuong tram/339408406_1209323986622559_1237855961637611483_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/nguyen phuong tram/anh1.jpg b/face/nguyen phuong tram/anh1.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/nguyen phuong tram/anh2.jpg b/face/nguyen phuong tram/anh2.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/nguyen phuong tram/anh3.jpg b/face/nguyen phuong tram/anh3.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/nguyen phuong tram/anh4.jpg b/face/nguyen phuong tram/anh4.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/nguyen phuong tram/anh5.jpg b/face/nguyen phuong tram/anh5.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/nguyen phuong tram/anh7.jpg b/face/nguyen phuong tram/anh7.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/nguyen phuong tram/anh8.jpg b/face/nguyen phuong tram/anh8.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/thaongo/419652962_741170244266451_4914393583094088361_n.jpg b/face/thaongo/419652962_741170244266451_4914393583094088361_n.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/thaongo/thao1.jpg b/face/thaongo/thao1.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/thaongo/thao2.jpg b/face/thaongo/thao2.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/thaongo/thao3.jpg b/face/thaongo/thao3.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/thaongo/thao4.jpg b/face/thaongo/thao4.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/thaongo/thao5.jpg b/face/thaongo/thao5.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/thaongo/thao6.jpg b/face/thaongo/thao6.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/thaongo/thao7.jpg b/face/thaongo/thao7.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/tran nhat truong/truong1.jpg b/face/tran nhat truong/truong1.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/truong giang/0630_truonggiang_1.jpg b/face/truong giang/0630_truonggiang_1.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/truong giang/0632_truonggiang_2.jpg b/face/truong giang/0632_truonggiang_2.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/truong giang/1545311811-862-truong-giang-bat-ngo-dan-dau-de-cu-nam-dien-vien-dien-anh-duoc-yeu-thich-nhat-truonggiang-1545278076-width660height990.jpg b/face/truong giang/1545311811-862-truong-giang-bat-ngo-dan-dau-de-cu-nam-dien-vien-dien-anh-duoc-yeu-thich-nhat-truonggiang-1545278076-width660height990.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/truong giang/A27U7778.jpg b/face/truong giang/A27U7778.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/truong giang/fb_img_1704768289216-1704768712-408-width720height960.jpg b/face/truong giang/fb_img_1704768289216-1704768712-408-width720height960.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/truong giang/fb_img_1704768450012-1704768746-24-width720height1079.jpg b/face/truong giang/fb_img_1704768450012-1704768746-24-width720height1079.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/truong giang/giang1.jpg b/face/truong giang/giang1.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/truong giang/giang2.jpg b/face/truong giang/giang2.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/truong giang/giang3.jpg b/face/truong giang/giang3.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/truong giang/giang4.jpg b/face/truong giang/giang4.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/truong giang/mc-truong-giang-1229339.jpg b/face/truong giang/mc-truong-giang-1229339.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/truong giang/mc-truong-giang-918712.jpg b/face/truong giang/mc-truong-giang-918712.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/truong giang/trg1 b/face/truong giang/trg1\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/truong giang/vtr-4472.jpg b/face/truong giang/vtr-4472.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/face/truong giang/vtr-4475.jpg b/face/truong giang/vtr-4475.jpg\\\\nnew file mode 100644\\\\nindex 0000000..e69de29\\\\ndiff --git a/src/__init__.py b/src/__init__.py\\\\ndeleted file mode 100644\\\\nindex efa6252..0000000\\\\n--- a/src/__init__.py\\\\n+++ /dev/null\\\\n@@ -1,2 +0,0 @@\\\\n-# flake8: noqa\\\\n-\\\\ndiff --git a/src/a b/src/a\\\\ndeleted file mode 100644\\\\nindex 8b13789..0000000\\\\n--- a/src/a\\\\n+++ /dev/null\\\\n@@ -1 +0,0 @@\\\\n-\\\\ndiff --git a/src/calculate_filtering_metrics.py b/src/calculate_filtering_metrics.py\\\\ndeleted file mode 100644\\\\nindex f60b9ae..0000000\\\\n--- a/src/calculate_filtering_metrics.py\\\\n+++ /dev/null\\\\n@@ -1,128 +0,0 @@\\\\n-"""Calculate filtering metrics for a dataset and store in a .hdf file.\\\\n-"""\\\\n-# MIT License\\\\n-# \\\\n-# Copyright (c) 2016 David Sandberg\\\\n-# \\\\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\n-# of this software and associated documentation files (the "Software"), to deal\\\\n-# in the Software without restriction, including without limitation the rights\\\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\n-# copies of the Software, and to permit persons to whom the Software is\\\\n-# furnished to do so, subject to the following conditions:\\\\n-# \\\\n-# The above copyright notice and this permission notice shall be included in all\\\\n-# copies or substantial portions of the Software.\\\\n-# \\\\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\n-# SOFTWARE.\\\\n-\\\\n-from __future__ import absolute_import\\\\n-from __future__ import division\\\\n-from __future__ import print_function\\\\n-\\\\n-import tensorflow as tf\\\\n-import numpy as np\\\\n-import argparse\\\\n-import facenet\\\\n-import os\\\\n-import sys\\\\n-import time\\\\n-import h5py\\\\n-import math\\\\n-from tensorflow.python.platform import gfile\\\\n-from six import iteritems\\\\n-\\\\n-def main(args):\\\\n-    dataset = facenet.get_dataset(args.dataset_dir)\\\\n-  \\\\n-    with tf.Graph().as_default():\\\\n-      \\\\n-        # Get a list of image paths and their labels\\\\n-        image_list, label_list = facenet.get_image_paths_and_labels(dataset)\\\\n-        nrof_images = len(image_list)\\\\n-        image_indices = range(nrof_images)\\\\n-\\\\n-        image_batch, label_batch = facenet.read_and_augment_data(image_list,\\\\n-            image_indices, args.image_size, args.batch_size, None, \\\\n-            False, False, False, nrof_preprocess_threads=4, shuffle=False)\\\\n-        \\\\n-        model_exp = os.path.expanduser(args.model_file)\\\\n-        with gfile.FastGFile(model_exp,\\\\\\\'rb\\\\\\\') as f:\\\\n-            graph_def = tf.GraphDef()\\\\n-            graph_def.ParseFromString(f.read())\\\\n-            input_map={\\\\\\\'input\\\\\\\':image_batch, \\\\\\\'phase_train\\\\\\\':False}\\\\n-            tf.import_graph_def(graph_def, input_map=input_map, name=\\\\\\\'net\\\\\\\')\\\\n-        \\\\n-        embeddings = tf.get_default_graph().get_tensor_by_name("net/embeddings:0")\\\\n-\\\\n-        with tf.Session() as sess:\\\\n-            tf.train.start_queue_runners(sess=sess)\\\\n-                \\\\n-            embedding_size = int(embeddings.get_shape()[1])\\\\n-            nrof_batches = int(math.ceil(nrof_images / args.batch_size))\\\\n-            nrof_classes = len(dataset)\\\\n-            label_array = np.array(label_list)\\\\n-            class_names = [cls.name for cls in dataset]\\\\n-            nrof_examples_per_class = [ len(cls.image_paths) for cls in dataset ]\\\\n-            class_variance = np.zeros((nrof_classes,))\\\\n-            class_center = np.zeros((nrof_classes,embedding_size))\\\\n-            distance_to_center = np.ones((len(label_list),))*np.NaN\\\\n-            emb_array = np.zeros((0,embedding_size))\\\\n-            idx_array = np.zeros((0,), dtype=np.int32)\\\\n-            lab_array = np.zeros((0,), dtype=np.int32)\\\\n-            index_arr = np.append(0, np.cumsum(nrof_examples_per_class))\\\\n-            for i in range(nrof_batches):\\\\n-                t = time.time()\\\\n-                emb, idx = sess.run([embeddings, label_batch])\\\\n-                emb_array = np.append(emb_array, emb, axis=0)\\\\n-                idx_array = np.append(idx_array, idx, axis=0)\\\\n-                lab_array = np.append(lab_array, label_array[idx], axis=0)\\\\n-                for cls in set(lab_array):\\\\n-                    cls_idx = np.where(lab_array==cls)[0]\\\\n-                    if cls_idx.shape[0]==nrof_examples_per_class[cls]:\\\\n-                        # We have calculated all the embeddings for this class\\\\n-                        i2 = np.argsort(idx_array[cls_idx])\\\\n-                        emb_class = emb_array[cls_idx,:]\\\\n-                        emb_sort = emb_class[i2,:]\\\\n-                        center = np.mean(emb_sort, axis=0)\\\\n-                        diffs = emb_sort - center\\\\n-                        dists_sqr = np.sum(np.square(diffs), axis=1)\\\\n-                        class_variance[cls] = np.mean(dists_sqr)\\\\n-                        class_center[cls,:] = center\\\\n-                        distance_to_center[index_arr[cls]:index_arr[cls+1]] = np.sqrt(dists_sqr)\\\\n-                        emb_array = np.delete(emb_array, cls_idx, axis=0)\\\\n-                        idx_array = np.delete(idx_array, cls_idx, axis=0)\\\\n-                        lab_array = np.delete(lab_array, cls_idx, axis=0)\\\\n-\\\\n-                        \\\\n-                print(\\\\\\\'Batch %d in %.3f seconds\\\\\\\' % (i, time.time()-t))\\\\n-                \\\\n-            print(\\\\\\\'Writing filtering data to %s\\\\\\\' % args.data_file_name)\\\\n-            mdict = {\\\\\\\'class_names\\\\\\\':class_names, \\\\\\\'image_list\\\\\\\':image_list, \\\\\\\'label_list\\\\\\\':label_list, \\\\\\\'distance_to_center\\\\\\\':distance_to_center }\\\\n-            with h5py.File(args.data_file_name, \\\\\\\'w\\\\\\\') as f:\\\\n-                for key, value in iteritems(mdict):\\\\n-                    f.create_dataset(key, data=value)\\\\n-                        \\\\n-def parse_arguments(argv):\\\\n-    parser = argparse.ArgumentParser()\\\\n-    \\\\n-    parser.add_argument(\\\\\\\'dataset_dir\\\\\\\', type=str,\\\\n-        help=\\\\\\\'Path to the directory containing aligned dataset.\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'model_file\\\\\\\', type=str,\\\\n-        help=\\\\\\\'File containing the frozen model in protobuf (.pb) format to use for feature extraction.\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'data_file_name\\\\\\\', type=str,\\\\n-        help=\\\\\\\'The name of the file to store filtering data in.\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--image_size\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Image size.\\\\\\\', default=160)\\\\n-    parser.add_argument(\\\\\\\'--batch_size\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Number of images to process in a batch.\\\\\\\', default=90)\\\\n-    return parser.parse_args(argv)\\\\n-\\\\n-if __name__ == \\\\\\\'__main__\\\\\\\':\\\\n-    main(parse_arguments(sys.argv[1:]))\\\\ndiff --git a/src/classifier.py b/src/classifier.py\\\\nindex 6a176a4..be144fe 100644\\\\n--- a/src/classifier.py\\\\n+++ b/src/classifier.py\\\\n@@ -64,9 +64,10 @@ def main(args):\\\\n             print(\\\\\\\'Number of classes: %d\\\\\\\' % len(dataset))\\\\n             print(\\\\\\\'Number of images: %d\\\\\\\' % len(paths))\\\\n             \\\\n-            # Load the model\\\\n-            print(\\\\\\\'Loading feature extraction model\\\\\\\')\\\\n-            facenet.load_model(args.model)\\\\n+            # Load the Models\\\\n+            print(\\\\\\\'Loading feature extraction Models\\\\\\\')\\\\n+            facenet.load_model(args.Models)\\\\n+\\\\n             \\\\n             # Get input and output tensors\\\\n             images_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("input:0")\\\\n@@ -98,10 +99,10 @@ def main(args):\\\\n                 # Create a list of class names\\\\n                 class_names = [ cls.name.replace(\\\\\\\'_\\\\\\\', \\\\\\\' \\\\\\\') for cls in dataset]\\\\n \\\\n-                # Saving classifier model\\\\n+                # Saving classifier Models\\\\n                 with open(classifier_filename_exp, \\\\\\\'wb\\\\\\\') as outfile:\\\\n                     pickle.dump((model, class_names), outfile)\\\\n-                print(\\\\\\\'Saved classifier model to file "%s"\\\\\\\' % classifier_filename_exp)\\\\n+                print(\\\\\\\'Saved classifier Models to file "%s"\\\\\\\' % classifier_filename_exp)\\\\n                 \\\\n             elif (args.mode==\\\\\\\'CLASSIFY\\\\\\\'):\\\\n                 # Classify images\\\\n@@ -109,7 +110,7 @@ def main(args):\\\\n                 with open(classifier_filename_exp, \\\\\\\'rb\\\\\\\') as infile:\\\\n                     (model, class_names) = pickle.load(infile)\\\\n \\\\n-                print(\\\\\\\'Loaded classifier model from file "%s"\\\\\\\' % classifier_filename_exp)\\\\n+                print(\\\\\\\'Loaded classifier Models from file "%s"\\\\\\\' % classifier_filename_exp)\\\\n \\\\n                 predictions = model.predict_proba(emb_array)\\\\n                 best_class_indices = np.argmax(predictions, axis=1)\\\\n@@ -140,13 +141,13 @@ def parse_arguments(argv):\\\\n     \\\\n     parser.add_argument(\\\\\\\'mode\\\\\\\', type=str, choices=[\\\\\\\'TRAIN\\\\\\\', \\\\\\\'CLASSIFY\\\\\\\'],\\\\n         help=\\\\\\\'Indicates if a new classifier should be trained or a classification \\\\\\\' + \\\\n-        \\\\\\\'model should be used for classification\\\\\\\', default=\\\\\\\'CLASSIFY\\\\\\\')\\\\n+        \\\\\\\'Models should be used for classification\\\\\\\', default=\\\\\\\'CLASSIFY\\\\\\\')\\\\n     parser.add_argument(\\\\\\\'data_dir\\\\\\\', type=str,\\\\n         help=\\\\\\\'Path to the data directory containing aligned LFW face patches.\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'model\\\\\\\', type=str, \\\\n-        help=\\\\\\\'Could be either a directory containing the meta_file and ckpt_file or a model protobuf (.pb) file\\\\\\\')\\\\n+    parser.add_argument(\\\\\\\'Models\\\\\\\', type=str,\\\\n+        help=\\\\\\\'Could be either a directory containing the meta_file and ckpt_file or a Models protobuf (.pb) file\\\\\\\')\\\\n     parser.add_argument(\\\\\\\'classifier_filename\\\\\\\', \\\\n-        help=\\\\\\\'Classifier model file name as a pickle (.pkl) file. \\\\\\\' + \\\\n+        help=\\\\\\\'Classifier Models file name as a pickle (.pkl) file. \\\\\\\' +\\\\n         \\\\\\\'For training this is the output and for classification this is an input.\\\\\\\')\\\\n     parser.add_argument(\\\\\\\'--use_split_dataset\\\\\\\', \\\\n         help=\\\\\\\'Indicates that the dataset specified by data_dir should be split into a training and test set. \\\\\\\' +  \\\\ndiff --git a/src/compare.py b/src/compare.py\\\\ndeleted file mode 100644\\\\nindex bc53cc4..0000000\\\\n--- a/src/compare.py\\\\n+++ /dev/null\\\\n@@ -1,130 +0,0 @@\\\\n-"""Performs face alignment and calculates L2 distance between the embeddings of images."""\\\\n-\\\\n-# MIT License\\\\n-# \\\\n-# Copyright (c) 2016 David Sandberg\\\\n-# \\\\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\n-# of this software and associated documentation files (the "Software"), to deal\\\\n-# in the Software without restriction, including without limitation the rights\\\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\n-# copies of the Software, and to permit persons to whom the Software is\\\\n-# furnished to do so, subject to the following conditions:\\\\n-# \\\\n-# The above copyright notice and this permission notice shall be included in all\\\\n-# copies or substantial portions of the Software.\\\\n-# \\\\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\n-# SOFTWARE.\\\\n-\\\\n-from __future__ import absolute_import\\\\n-from __future__ import division\\\\n-from __future__ import print_function\\\\n-\\\\n-from scipy import misc\\\\n-import tensorflow as tf\\\\n-import numpy as np\\\\n-import sys\\\\n-import os\\\\n-import copy\\\\n-import argparse\\\\n-import facenet\\\\n-import align.detect_face\\\\n-\\\\n-def main(args):\\\\n-\\\\n-    images = load_and_align_data(args.image_files, args.image_size, args.margin, args.gpu_memory_fraction)\\\\n-    with tf.Graph().as_default():\\\\n-\\\\n-        with tf.Session() as sess:\\\\n-      \\\\n-            # Load the model\\\\n-            facenet.load_model(args.model)\\\\n-    \\\\n-            # Get input and output tensors\\\\n-            images_placeholder = tf.get_default_graph().get_tensor_by_name("input:0")\\\\n-            embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")\\\\n-            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:0")\\\\n-\\\\n-            # Run forward pass to calculate embeddings\\\\n-            feed_dict = { images_placeholder: images, phase_train_placeholder:False }\\\\n-            emb = sess.run(embeddings, feed_dict=feed_dict)\\\\n-            \\\\n-            nrof_images = len(args.image_files)\\\\n-\\\\n-            print(\\\\\\\'Images:\\\\\\\')\\\\n-            for i in range(nrof_images):\\\\n-                print(\\\\\\\'%1d: %s\\\\\\\' % (i, args.image_files[i]))\\\\n-            print(\\\\\\\'\\\\\\\')\\\\n-            \\\\n-            # Print distance matrix\\\\n-            print(\\\\\\\'Distance matrix\\\\\\\')\\\\n-            print(\\\\\\\'    \\\\\\\', end=\\\\\\\'\\\\\\\')\\\\n-            for i in range(nrof_images):\\\\n-                print(\\\\\\\'    %1d     \\\\\\\' % i, end=\\\\\\\'\\\\\\\')\\\\n-            print(\\\\\\\'\\\\\\\')\\\\n-            for i in range(nrof_images):\\\\n-                print(\\\\\\\'%1d  \\\\\\\' % i, end=\\\\\\\'\\\\\\\')\\\\n-                for j in range(nrof_images):\\\\n-                    dist = np.sqrt(np.sum(np.square(np.subtract(emb[i,:], emb[j,:]))))\\\\n-                    print(\\\\\\\'  %1.4f  \\\\\\\' % dist, end=\\\\\\\'\\\\\\\')\\\\n-                print(\\\\\\\'\\\\\\\')\\\\n-            \\\\n-            \\\\n-def load_and_align_data(image_paths, image_size, margin, gpu_memory_fraction):\\\\n-\\\\n-    minsize = 20 # minimum size of face\\\\n-    threshold = [ 0.6, 0.7, 0.7 ]  # three steps\\\\\\\'s threshold\\\\n-    factor = 0.709 # scale factor\\\\n-    \\\\n-    print(\\\\\\\'Creating networks and loading parameters\\\\\\\')\\\\n-    with tf.Graph().as_default():\\\\n-        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_memory_fraction)\\\\n-        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\\\\n-        with sess.as_default():\\\\n-            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)\\\\n-  \\\\n-    tmp_image_paths=copy.copy(image_paths)\\\\n-    img_list = []\\\\n-    for image in tmp_image_paths:\\\\n-        img = misc.imread(os.path.expanduser(image), mode=\\\\\\\'RGB\\\\\\\')\\\\n-        img_size = np.asarray(img.shape)[0:2]\\\\n-        bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\\\\n-        if len(bounding_boxes) < 1:\\\\n-          image_paths.remove(image)\\\\n-          print("can\\\\\\\'t detect face, remove ", image)\\\\n-          continue\\\\n-        det = np.squeeze(bounding_boxes[0,0:4])\\\\n-        bb = np.zeros(4, dtype=np.int32)\\\\n-        bb[0] = np.maximum(det[0]-margin/2, 0)\\\\n-        bb[1] = np.maximum(det[1]-margin/2, 0)\\\\n-        bb[2] = np.minimum(det[2]+margin/2, img_size[1])\\\\n-        bb[3] = np.minimum(det[3]+margin/2, img_size[0])\\\\n-        cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\\\\n-        aligned = misc.imresize(cropped, (image_size, image_size), interp=\\\\\\\'bilinear\\\\\\\')\\\\n-        prewhitened = facenet.prewhiten(aligned)\\\\n-        img_list.append(prewhitened)\\\\n-    images = np.stack(img_list)\\\\n-    return images\\\\n-\\\\n-def parse_arguments(argv):\\\\n-    parser = argparse.ArgumentParser()\\\\n-    \\\\n-    parser.add_argument(\\\\\\\'model\\\\\\\', type=str, \\\\n-        help=\\\\\\\'Could be either a directory containing the meta_file and ckpt_file or a model protobuf (.pb) file\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'image_files\\\\\\\', type=str, nargs=\\\\\\\'+\\\\\\\', help=\\\\\\\'Images to compare\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--image_size\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Image size (height, width) in pixels.\\\\\\\', default=160)\\\\n-    parser.add_argument(\\\\\\\'--margin\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Margin for the crop around the bounding box (height, width) in pixels.\\\\\\\', default=44)\\\\n-    parser.add_argument(\\\\\\\'--gpu_memory_fraction\\\\\\\', type=float,\\\\n-        help=\\\\\\\'Upper bound on the amount of GPU memory that will be used by the process.\\\\\\\', default=1.0)\\\\n-    return parser.parse_args(argv)\\\\n-\\\\n-if __name__ == \\\\\\\'__main__\\\\\\\':\\\\n-    main(parse_arguments(sys.argv[1:]))\\\\ndiff --git a/src/decode_msceleb_dataset.py b/src/decode_msceleb_dataset.py\\\\ndeleted file mode 100644\\\\nindex 4556bfa..0000000\\\\n--- a/src/decode_msceleb_dataset.py\\\\n+++ /dev/null\\\\n@@ -1,87 +0,0 @@\\\\n-"""Decode the MsCelebV1 dataset in TSV (tab separated values) format downloaded from\\\\n-https://www.microsoft.com/en-us/research/project/ms-celeb-1m-challenge-recognizing-one-million-celebrities-real-world/\\\\n-"""\\\\n-# MIT License\\\\n-# \\\\n-# Copyright (c) 2016 David Sandberg\\\\n-# \\\\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\n-# of this software and associated documentation files (the "Software"), to deal\\\\n-# in the Software without restriction, including without limitation the rights\\\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\n-# copies of the Software, and to permit persons to whom the Software is\\\\n-# furnished to do so, subject to the following conditions:\\\\n-# \\\\n-# The above copyright notice and this permission notice shall be included in all\\\\n-# copies or substantial portions of the Software.\\\\n-# \\\\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\n-# SOFTWARE.\\\\n-\\\\n-from __future__ import absolute_import\\\\n-from __future__ import division\\\\n-from __future__ import print_function\\\\n-\\\\n-from scipy import misc\\\\n-import numpy as np\\\\n-import base64\\\\n-import sys\\\\n-import os\\\\n-import cv2\\\\n-import argparse\\\\n-import facenet\\\\n-\\\\n-\\\\n-# File format: text files, each line is an image record containing 6 columns, delimited by TAB.\\\\n-# Column1: Freebase MID\\\\n-# Column2: Query/Name\\\\n-# Column3: ImageSearchRank\\\\n-# Column4: ImageURL\\\\n-# Column5: PageURL\\\\n-# Column6: ImageData_Base64Encoded\\\\n-\\\\n-def main(args):\\\\n-    output_dir = os.path.expanduser(args.output_dir)\\\\n-  \\\\n-    if not os.path.exists(output_dir):\\\\n-        os.mkdir(output_dir)\\\\n-  \\\\n-    # Store some git revision info in a text file in the output directory\\\\n-    src_path,_ = os.path.split(os.path.realpath(__file__))\\\\n-    facenet.store_revision_info(src_path, output_dir, \\\\\\\' \\\\\\\'.join(sys.argv))\\\\n-    \\\\n-    i = 0\\\\n-    for f in args.tsv_files:\\\\n-        for line in f:\\\\n-            fields = line.split(\\\\\\\'\\\\\\\\t\\\\\\\')\\\\n-            class_dir = fields[0]\\\\n-            img_name = fields[1] + \\\\\\\'-\\\\\\\' + fields[4] + \\\\\\\'.\\\\\\\' + args.output_format\\\\n-            img_string = fields[5]\\\\n-            img_dec_string = base64.b64decode(img_string)\\\\n-            img_data = np.fromstring(img_dec_string, dtype=np.uint8)\\\\n-            img = cv2.imdecode(img_data, cv2.IMREAD_COLOR) #pylint: disable=maybe-no-member\\\\n-            if args.size:\\\\n-                img = misc.imresize(img, (args.size, args.size), interp=\\\\\\\'bilinear\\\\\\\')\\\\n-            full_class_dir = os.path.join(output_dir, class_dir)\\\\n-            if not os.path.exists(full_class_dir):\\\\n-                os.mkdir(full_class_dir)\\\\n-            full_path = os.path.join(full_class_dir, img_name.replace(\\\\\\\'/\\\\\\\',\\\\\\\'_\\\\\\\'))\\\\n-            cv2.imwrite(full_path, img) #pylint: disable=maybe-no-member\\\\n-            print(\\\\\\\'%8d: %s\\\\\\\' % (i, full_path))\\\\n-            i += 1\\\\n-  \\\\n-if __name__ == \\\\\\\'__main__\\\\\\\':\\\\n-    parser = argparse.ArgumentParser()\\\\n-\\\\n-    parser.add_argument(\\\\\\\'output_dir\\\\\\\', type=str, help=\\\\\\\'Output base directory for the image dataset\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'tsv_files\\\\\\\', type=argparse.FileType(\\\\\\\'r\\\\\\\'), nargs=\\\\\\\'+\\\\\\\', help=\\\\\\\'Input TSV file name(s)\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--size\\\\\\\', type=int, help=\\\\\\\'Images are resized to the given size\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--output_format\\\\\\\', type=str, help=\\\\\\\'Format of the output images\\\\\\\', default=\\\\\\\'png\\\\\\\', choices=[\\\\\\\'png\\\\\\\', \\\\\\\'jpg\\\\\\\'])\\\\n-\\\\n-    main(parser.parse_args())\\\\n-\\\\ndiff --git a/src/download_and_extract.py b/src/download_and_extract.py\\\\ndeleted file mode 100644\\\\nindex a835ac2..0000000\\\\n--- a/src/download_and_extract.py\\\\n+++ /dev/null\\\\n@@ -1,51 +0,0 @@\\\\n-import requests\\\\n-import zipfile\\\\n-import os\\\\n-\\\\n-model_dict = {\\\\n-    \\\\\\\'lfw-subset\\\\\\\':      \\\\\\\'1B5BQUZuJO-paxdN8UclxeHAR1WnR_Tzi\\\\\\\', \\\\n-    \\\\\\\'20170131-234652\\\\\\\': \\\\\\\'0B5MzpY9kBtDVSGM0RmVET2EwVEk\\\\\\\',\\\\n-    \\\\\\\'20170216-091149\\\\\\\': \\\\\\\'0B5MzpY9kBtDVTGZjcWkzT3pldDA\\\\\\\',\\\\n-    \\\\\\\'20170512-110547\\\\\\\': \\\\\\\'0B5MzpY9kBtDVZ2RpVDYwWmxoSUk\\\\\\\',\\\\n-    \\\\\\\'20180402-114759\\\\\\\': \\\\\\\'1EXPBSXwTaqrSC0OhUdXNmKSh9qJUQ55-\\\\\\\'\\\\n-    }\\\\n-\\\\n-def download_and_extract_file(model_name, data_dir):\\\\n-    file_id = model_dict[model_name]\\\\n-    destination = os.path.join(data_dir, model_name + \\\\\\\'.zip\\\\\\\')\\\\n-    if not os.path.exists(destination):\\\\n-        print(\\\\\\\'Downloading file to %s\\\\\\\' % destination)\\\\n-        download_file_from_google_drive(file_id, destination)\\\\n-        with zipfile.ZipFile(destination, \\\\\\\'r\\\\\\\') as zip_ref:\\\\n-            print(\\\\\\\'Extracting file to %s\\\\\\\' % data_dir)\\\\n-            zip_ref.extractall(data_dir)\\\\n-\\\\n-def download_file_from_google_drive(file_id, destination):\\\\n-    \\\\n-        URL = "https://drive.google.com/uc?export=download"\\\\n-    \\\\n-        session = requests.Session()\\\\n-    \\\\n-        response = session.get(URL, params = { \\\\\\\'id\\\\\\\' : file_id }, stream = True)\\\\n-        token = get_confirm_token(response)\\\\n-    \\\\n-        if token:\\\\n-            params = { \\\\\\\'id\\\\\\\' : file_id, \\\\\\\'confirm\\\\\\\' : token }\\\\n-            response = session.get(URL, params = params, stream = True)\\\\n-    \\\\n-        save_response_content(response, destination)    \\\\n-\\\\n-def get_confirm_token(response):\\\\n-    for key, value in response.cookies.items():\\\\n-        if key.startswith(\\\\\\\'download_warning\\\\\\\'):\\\\n-            return value\\\\n-\\\\n-    return None\\\\n-\\\\n-def save_response_content(response, destination):\\\\n-    CHUNK_SIZE = 32768\\\\n-\\\\n-    with open(destination, "wb") as f:\\\\n-        for chunk in response.iter_content(CHUNK_SIZE):\\\\n-            if chunk: # filter out keep-alive new chunks\\\\n-                f.write(chunk)\\\\ndiff --git a/src/face_rec_cam.py b/src/face_cam.py\\\\nsimilarity index 93%\\\\nrename from src/face_rec_cam.py\\\\nrename to src/face_cam.py\\\\nindex 1a425a5..91daf5d 100644\\\\n--- a/src/face_rec_cam.py\\\\n+++ b/src/face_cam.py\\\\n@@ -47,14 +47,14 @@ def main():\\\\n \\\\n         with sess.as_default():\\\\n \\\\n-            # Load the model\\\\n-            print(\\\\\\\'Loading feature extraction model\\\\\\\')\\\\n+            # Load the Models\\\\n+            print(\\\\\\\'Loading feature extraction Models\\\\\\\')\\\\n             facenet.load_model(FACENET_MODEL_PATH)\\\\n \\\\n             # Get input and output tensors\\\\n-            images_placeholder = tf.get_default_graph().get_tensor_by_name("input:0")\\\\n-            embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")\\\\n-            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:0")\\\\n+            images_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("input:0")\\\\n+            embeddings = tf.compat.v1.get_default_graph().get_tensor_by_name("embeddings:0")\\\\n+            phase_train_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("phase_train:0")\\\\n             embedding_size = embeddings.get_shape()[1]\\\\n \\\\n             pnet, rnet, onet = align.detect_face.create_mtcnn(sess, "src/align")\\\\n@@ -130,5 +130,6 @@ def main():\\\\n             cap.release()\\\\n             cv2.destroyAllWindows()\\\\n \\\\n-\\\\n main()\\\\n+\\\\n+\\\\ndiff --git a/src/face_rec.py b/src/face_rec.py\\\\nindex f92cccf..390ca11 100644\\\\n--- a/src/face_rec.py\\\\n+++ b/src/face_rec.py\\\\n@@ -17,10 +17,6 @@ from sklearn.svm import SVC\\\\n \\\\n \\\\n def main():\\\\n-    parser = argparse.ArgumentParser()\\\\n-    parser.add_argument(\\\\\\\'--path\\\\\\\', help=\\\\\\\'Path of the video you want to test on.\\\\\\\', default=0)\\\\n-    args = parser.parse_args()\\\\n-    \\\\n     # Cai dat cac tham so can thiet\\\\n     MINSIZE = 20\\\\n     THRESHOLD = [0.6, 0.7, 0.7]\\\\n@@ -28,30 +24,31 @@ def main():\\\\n     IMAGE_SIZE = 182\\\\n     INPUT_IMAGE_SIZE = 160\\\\n     CLASSIFIER_PATH = \\\\\\\'Models/facemodel.pkl\\\\\\\'\\\\n-    VIDEO_PATH = args.path\\\\n+    VIDEO_PATH = r"C:\\\\\\\\Users\\\\\\\\57\\\\\\\\Pictures\\\\\\\\Screenshots\\\\\\\\ma\\\\\\\\420079008_24530410413273537_6536068650415664819_n.mp4"  # \\\\xc4\\\\x90\\\\xc6\\\\xb0\\\\xe1\\\\xbb\\\\x9dng d\\\\xe1\\\\xba\\\\xabn \\\\xc4\\\\x91\\\\xe1\\\\xba\\\\xbfn video c\\\\xe1\\\\xbb\\\\xa7a b\\\\xe1\\\\xba\\\\xa1n\\\\n     FACENET_MODEL_PATH = \\\\\\\'Models/20180402-114759.pb\\\\\\\'\\\\n \\\\n-    # Load model da train de nhan dien khuon mat - thuc chat la classifier\\\\n+    # Load Models da train de nhan dien khuon mat - thuc chat la classifier\\\\n     with open(CLASSIFIER_PATH, \\\\\\\'rb\\\\\\\') as file:\\\\n         model, class_names = pickle.load(file)\\\\n     print("Custom Classifier, Successfully loaded")\\\\n \\\\n-    with tf.Graph().as_default():\\\\n+    with tf.compat.v1.Graph().as_default():\\\\n \\\\n         # Cai dat GPU neu co\\\\n         gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.6)\\\\n-        sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\\\\n+        sess = tf.compat.v1.Session(\\\\n+            config=tf.compat.v1.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\\\\n \\\\n         with sess.as_default():\\\\n \\\\n-            # Load model MTCNN phat hien khuon mat\\\\n-            print(\\\\\\\'Loading feature extraction model\\\\\\\')\\\\n+            # Load Models MTCNN phat hien khuon mat\\\\n+            print(\\\\\\\'Loading feature extraction Models\\\\\\\')\\\\n             facenet.load_model(FACENET_MODEL_PATH)\\\\n \\\\n             # Lay tensor input va output\\\\n-            images_placeholder = tf.get_default_graph().get_tensor_by_name("input:0")\\\\n-            embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")\\\\n-            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:0")\\\\n+            images_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("input:0")\\\\n+            embeddings = tf.compat.v1.get_default_graph().get_tensor_by_name("embeddings:0")\\\\n+            phase_train_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("phase_train:0")\\\\n             embedding_size = embeddings.get_shape()[1]\\\\n \\\\n             # Cai dat cac mang con\\\\n@@ -90,13 +87,13 @@ def main():\\\\n                             scaled_reshape = scaled.reshape(-1, INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE, 3)\\\\n                             feed_dict = {images_placeholder: scaled_reshape, phase_train_placeholder: False}\\\\n                             emb_array = sess.run(embeddings, feed_dict=feed_dict)\\\\n-                            \\\\n-                            # Dua vao model de classifier\\\\n+\\\\n+                            # Dua vao Models de classifier\\\\n                             predictions = model.predict_proba(emb_array)\\\\n                             best_class_indices = np.argmax(predictions, axis=1)\\\\n                             best_class_probabilities = predictions[\\\\n                                 np.arange(len(best_class_indices)), best_class_indices]\\\\n-                            \\\\n+\\\\n                             # Lay ra ten va ty le % cua class co ty le cao nhat\\\\n                             best_name = class_names[best_class_indices[0]]\\\\n                             print("Name: {}, Probability: {}".format(best_name, best_class_probabilities))\\\\n@@ -112,7 +109,7 @@ def main():\\\\n                             else:\\\\n                                 # Con neu <=0.5 thi hien thi Unknow\\\\n                                 name = "Unknown"\\\\n-                                \\\\n+\\\\n                             # Viet text len tren frame    \\\\n                             cv2.putText(frame, name, (text_x, text_y), cv2.FONT_HERSHEY_COMPLEX_SMALL,\\\\n                                         1, (255, 255, 255), thickness=1, lineType=2)\\\\ndiff --git a/src/face_rec_flask.py b/src/face_rec_flask.py\\\\ndeleted file mode 100644\\\\nindex aaf7193..0000000\\\\n--- a/src/face_rec_flask.py\\\\n+++ /dev/null\\\\n@@ -1,118 +0,0 @@\\\\n-from __future__ import absolute_import\\\\n-from __future__ import division\\\\n-from __future__ import print_function\\\\n-\\\\n-from flask import Flask\\\\n-from flask import render_template , request\\\\n-from flask_cors import CORS, cross_origin\\\\n-import tensorflow as tf\\\\n-import argparse\\\\n-import facenet\\\\n-import os\\\\n-import sys\\\\n-import math\\\\n-import pickle\\\\n-import align.detect_face\\\\n-import numpy as np\\\\n-import cv2\\\\n-import collections\\\\n-from sklearn.svm import SVC\\\\n-import base64\\\\n-\\\\n-MINSIZE = 20\\\\n-THRESHOLD = [0.6, 0.7, 0.7]\\\\n-FACTOR = 0.709\\\\n-IMAGE_SIZE = 182\\\\n-INPUT_IMAGE_SIZE = 160\\\\n-CLASSIFIER_PATH = \\\\\\\'../Models/facemodel.pkl\\\\\\\'\\\\n-FACENET_MODEL_PATH = \\\\\\\'../Models/20180402-114759.pb\\\\\\\'\\\\n-\\\\n-# Load The Custom Classifier\\\\n-with open(CLASSIFIER_PATH, \\\\\\\'rb\\\\\\\') as file:\\\\n-    model, class_names = pickle.load(file)\\\\n-print("Custom Classifier, Successfully loaded")\\\\n-\\\\n-tf.Graph().as_default()\\\\n-\\\\n-# Cai dat GPU neu co\\\\n-gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.6)\\\\n-sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\\\\n-\\\\n-\\\\n-# Load the model\\\\n-print(\\\\\\\'Loading feature extraction model\\\\\\\')\\\\n-facenet.load_model(FACENET_MODEL_PATH)\\\\n-\\\\n-# Get input and output tensors\\\\n-images_placeholder = tf.get_default_graph().get_tensor_by_name("input:0")\\\\n-embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")\\\\n-phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:0")\\\\n-embedding_size = embeddings.get_shape()[1]\\\\n-pnet, rnet, onet = align.detect_face.create_mtcnn(sess, "align")\\\\n-\\\\n-\\\\n-\\\\n-app = Flask(__name__)\\\\n-CORS(app)\\\\n-\\\\n-\\\\n-\\\\n-@app.route(\\\\\\\'/\\\\\\\')\\\\n-@cross_origin()\\\\n-def index():\\\\n-    return "OK!";\\\\n-\\\\n-@app.route(\\\\\\\'/recog\\\\\\\', methods=[\\\\\\\'POST\\\\\\\'])\\\\n-@cross_origin()\\\\n-def upload_img_file():\\\\n-    if request.method == \\\\\\\'POST\\\\\\\':\\\\n-        # base 64\\\\n-        name="Unknown"\\\\n-        f = request.form.get(\\\\\\\'image\\\\\\\')\\\\n-        w = int(request.form.get(\\\\\\\'w\\\\\\\'))\\\\n-        h = int(request.form.get(\\\\\\\'h\\\\\\\'))\\\\n-\\\\n-        decoded_string = base64.b64decode(f)\\\\n-        frame = np.fromstring(decoded_string, dtype=np.uint8)\\\\n-        #frame = frame.reshape(w,h,3)\\\\n-        frame = cv2.imdecode(frame, cv2.IMREAD_ANYCOLOR)  # cv2.IMREAD_COLOR in OpenCV 3.1\\\\n-\\\\n-        bounding_boxes, _ = align.detect_face.detect_face(frame, MINSIZE, pnet, rnet, onet, THRESHOLD, FACTOR)\\\\n-\\\\n-        faces_found = bounding_boxes.shape[0]\\\\n-\\\\n-        if faces_found > 0:\\\\n-            det = bounding_boxes[:, 0:4]\\\\n-            bb = np.zeros((faces_found, 4), dtype=np.int32)\\\\n-            for i in range(faces_found):\\\\n-                bb[i][0] = det[i][0]\\\\n-                bb[i][1] = det[i][1]\\\\n-                bb[i][2] = det[i][2]\\\\n-                bb[i][3] = det[i][3]\\\\n-                cropped = frame\\\\n-                #cropped = frame[bb[i][1]:bb[i][3], bb[i][0]:bb[i][2], :]\\\\n-                scaled = cv2.resize(cropped, (INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE),\\\\n-                                    interpolation=cv2.INTER_CUBIC)\\\\n-                scaled = facenet.prewhiten(scaled)\\\\n-                scaled_reshape = scaled.reshape(-1, INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE, 3)\\\\n-                feed_dict = {images_placeholder: scaled_reshape, phase_train_placeholder: False}\\\\n-                emb_array = sess.run(embeddings, feed_dict=feed_dict)\\\\n-                predictions = model.predict_proba(emb_array)\\\\n-                best_class_indices = np.argmax(predictions, axis=1)\\\\n-                best_class_probabilities = predictions[\\\\n-                    np.arange(len(best_class_indices)), best_class_indices]\\\\n-                best_name = class_names[best_class_indices[0]]\\\\n-                print("Name: {}, Probability: {}".format(best_name, best_class_probabilities))\\\\n-\\\\n-                if best_class_probabilities > 0.8:\\\\n-                    name = class_names[best_class_indices[0]]\\\\n-                else:\\\\n-                    name = "Unknown"\\\\n-\\\\n-\\\\n-        return name;\\\\n-\\\\n-\\\\n-if __name__ == \\\\\\\'__main__\\\\\\\':\\\\n-    app.run(debug=True, host=\\\\\\\'0.0.0.0\\\\\\\',port=\\\\\\\'8000\\\\\\\')\\\\n-\\\\ndiff --git a/src/facenet.py b/src/facenet.py\\\\nindex 26a4e3d..42354d1 100644\\\\n--- a/src/facenet.py\\\\n+++ b/src/facenet.py\\\\n@@ -363,7 +363,7 @@ def split_dataset(dataset, split_ratio, min_nrof_images_per_class, mode):\\\\n     return train_set, test_set\\\\n \\\\n def load_model(model, input_map=None):\\\\n-    # Check if the model is a model directory (containing a metagraph and a checkpoint file)\\\\n+    # Check if the Models is a Models directory (containing a metagraph and a checkpoint file)\\\\n     #  or if it is a protobuf file with a frozen graph\\\\n     model_exp = os.path.expanduser(model)\\\\n     if (os.path.isfile(model_exp)):\\\\n@@ -386,9 +386,9 @@ def get_model_filenames(model_dir):\\\\n     files = os.listdir(model_dir)\\\\n     meta_files = [s for s in files if s.endswith(\\\\\\\'.meta\\\\\\\')]\\\\n     if len(meta_files)==0:\\\\n-        raise ValueError(\\\\\\\'No meta file found in the model directory (%s)\\\\\\\' % model_dir)\\\\n+        raise ValueError(\\\\\\\'No meta file found in the Models directory (%s)\\\\\\\' % model_dir)\\\\n     elif len(meta_files)>1:\\\\n-        raise ValueError(\\\\\\\'There should not be more than one meta file in the model directory (%s)\\\\\\\' % model_dir)\\\\n+        raise ValueError(\\\\\\\'There should not be more than one meta file in the Models directory (%s)\\\\\\\' % model_dir)\\\\n     meta_file = meta_files[0]\\\\n     ckpt = tf.train.get_checkpoint_state(model_dir)\\\\n     if ckpt and ckpt.model_checkpoint_path:\\\\n@@ -398,7 +398,7 @@ def get_model_filenames(model_dir):\\\\n     meta_files = [s for s in files if \\\\\\\'.ckpt\\\\\\\' in s]\\\\n     max_step = -1\\\\n     for f in files:\\\\n-        step_str = re.match(r\\\\\\\'(^model-[\\\\\\\\w\\\\\\\\- ]+.ckpt-(\\\\\\\\d+))\\\\\\\', f)\\\\n+        step_str = re.match(r\\\\\\\'(^Models-[\\\\\\\\w\\\\\\\\- ]+.ckpt-(\\\\\\\\d+))\\\\\\\', f)\\\\n         if step_str is not None and len(step_str.groups())>=2:\\\\n             step = int(step_str.groups()[1])\\\\n             if step > max_step:\\\\ndiff --git a/src/freeze_graph.py b/src/freeze_graph.py\\\\ndeleted file mode 100644\\\\nindex 3584c18..0000000\\\\n--- a/src/freeze_graph.py\\\\n+++ /dev/null\\\\n@@ -1,103 +0,0 @@\\\\n-"""Imports a model metagraph and checkpoint file, converts the variables to constants\\\\n-and exports the model as a graphdef protobuf\\\\n-"""\\\\n-# MIT License\\\\n-# \\\\n-# Copyright (c) 2016 David Sandberg\\\\n-# \\\\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\n-# of this software and associated documentation files (the "Software"), to deal\\\\n-# in the Software without restriction, including without limitation the rights\\\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\n-# copies of the Software, and to permit persons to whom the Software is\\\\n-# furnished to do so, subject to the following conditions:\\\\n-# \\\\n-# The above copyright notice and this permission notice shall be included in all\\\\n-# copies or substantial portions of the Software.\\\\n-# \\\\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\n-# SOFTWARE.\\\\n-\\\\n-from __future__ import absolute_import\\\\n-from __future__ import division\\\\n-from __future__ import print_function\\\\n-\\\\n-from tensorflow.python.framework import graph_util\\\\n-import tensorflow as tf\\\\n-import argparse\\\\n-import os\\\\n-import sys\\\\n-import facenet\\\\n-from six.moves import xrange  # @UnresolvedImport\\\\n-\\\\n-def main(args):\\\\n-    with tf.Graph().as_default():\\\\n-        with tf.Session() as sess:\\\\n-            # Load the model metagraph and checkpoint\\\\n-            print(\\\\\\\'Model directory: %s\\\\\\\' % args.model_dir)\\\\n-            meta_file, ckpt_file = facenet.get_model_filenames(os.path.expanduser(args.model_dir))\\\\n-            \\\\n-            print(\\\\\\\'Metagraph file: %s\\\\\\\' % meta_file)\\\\n-            print(\\\\\\\'Checkpoint file: %s\\\\\\\' % ckpt_file)\\\\n-\\\\n-            model_dir_exp = os.path.expanduser(args.model_dir)\\\\n-            saver = tf.train.import_meta_graph(os.path.join(model_dir_exp, meta_file), clear_devices=True)\\\\n-            tf.get_default_session().run(tf.global_variables_initializer())\\\\n-            tf.get_default_session().run(tf.local_variables_initializer())\\\\n-            saver.restore(tf.get_default_session(), os.path.join(model_dir_exp, ckpt_file))\\\\n-            \\\\n-            # Retrieve the protobuf graph definition and fix the batch norm nodes\\\\n-            input_graph_def = sess.graph.as_graph_def()\\\\n-            \\\\n-            # Freeze the graph def\\\\n-            output_graph_def = freeze_graph_def(sess, input_graph_def, \\\\\\\'embeddings,label_batch\\\\\\\')\\\\n-\\\\n-        # Serialize and dump the output graph to the filesystem\\\\n-        with tf.gfile.GFile(args.output_file, \\\\\\\'wb\\\\\\\') as f:\\\\n-            f.write(output_graph_def.SerializeToString())\\\\n-        print("%d ops in the final graph: %s" % (len(output_graph_def.node), args.output_file))\\\\n-        \\\\n-def freeze_graph_def(sess, input_graph_def, output_node_names):\\\\n-    for node in input_graph_def.node:\\\\n-        if node.op == \\\\\\\'RefSwitch\\\\\\\':\\\\n-            node.op = \\\\\\\'Switch\\\\\\\'\\\\n-            for index in xrange(len(node.input)):\\\\n-                if \\\\\\\'moving_\\\\\\\' in node.input[index]:\\\\n-                    node.input[index] = node.input[index] + \\\\\\\'/read\\\\\\\'\\\\n-        elif node.op == \\\\\\\'AssignSub\\\\\\\':\\\\n-            node.op = \\\\\\\'Sub\\\\\\\'\\\\n-            if \\\\\\\'use_locking\\\\\\\' in node.attr: del node.attr[\\\\\\\'use_locking\\\\\\\']\\\\n-        elif node.op == \\\\\\\'AssignAdd\\\\\\\':\\\\n-            node.op = \\\\\\\'Add\\\\\\\'\\\\n-            if \\\\\\\'use_locking\\\\\\\' in node.attr: del node.attr[\\\\\\\'use_locking\\\\\\\']\\\\n-    \\\\n-    # Get the list of important nodes\\\\n-    whitelist_names = []\\\\n-    for node in input_graph_def.node:\\\\n-        if (node.name.startswith(\\\\\\\'InceptionResnet\\\\\\\') or node.name.startswith(\\\\\\\'embeddings\\\\\\\') or \\\\n-                node.name.startswith(\\\\\\\'image_batch\\\\\\\') or node.name.startswith(\\\\\\\'label_batch\\\\\\\') or\\\\n-                node.name.startswith(\\\\\\\'phase_train\\\\\\\') or node.name.startswith(\\\\\\\'Logits\\\\\\\')):\\\\n-            whitelist_names.append(node.name)\\\\n-\\\\n-    # Replace all the variables in the graph with constants of the same values\\\\n-    output_graph_def = graph_util.convert_variables_to_constants(\\\\n-        sess, input_graph_def, output_node_names.split(","),\\\\n-        variable_names_whitelist=whitelist_names)\\\\n-    return output_graph_def\\\\n-  \\\\n-def parse_arguments(argv):\\\\n-    parser = argparse.ArgumentParser()\\\\n-    \\\\n-    parser.add_argument(\\\\\\\'model_dir\\\\\\\', type=str, \\\\n-        help=\\\\\\\'Directory containing the metagraph (.meta) file and the checkpoint (ckpt) file containing model parameters\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'output_file\\\\\\\', type=str, \\\\n-        help=\\\\\\\'Filename for the exported graphdef protobuf (.pb)\\\\\\\')\\\\n-    return parser.parse_args(argv)\\\\n-\\\\n-if __name__ == \\\\\\\'__main__\\\\\\\':\\\\n-    main(parse_arguments(sys.argv[1:]))\\\\ndiff --git a/src/generative/a b/src/generative/a\\\\ndeleted file mode 100644\\\\nindex 8b13789..0000000\\\\n--- a/src/generative/a\\\\n+++ /dev/null\\\\n@@ -1 +0,0 @@\\\\n-\\\\ndiff --git a/src/generative/calculate_attribute_vectors.py b/src/generative/calculate_attribute_vectors.py\\\\ndeleted file mode 100644\\\\nindex 8fe3ead..0000000\\\\n--- a/src/generative/calculate_attribute_vectors.py\\\\n+++ /dev/null\\\\n@@ -1,200 +0,0 @@\\\\n-# MIT License\\\\n-# \\\\n-# Copyright (c) 2017 David Sandberg\\\\n-# \\\\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\n-# of this software and associated documentation files (the "Software"), to deal\\\\n-# in the Software without restriction, including without limitation the rights\\\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\n-# copies of the Software, and to permit persons to whom the Software is\\\\n-# furnished to do so, subject to the following conditions:\\\\n-# \\\\n-# The above copyright notice and this permission notice shall be included in all\\\\n-# copies or substantial portions of the Software.\\\\n-# \\\\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\n-# SOFTWARE.\\\\n-\\\\n-"""Calculate average latent variables (here called attribute vectors) \\\\n-for the different attributes in CelebA\\\\n-"""\\\\n-from __future__ import absolute_import\\\\n-from __future__ import division\\\\n-from __future__ import print_function\\\\n-\\\\n-import tensorflow as tf\\\\n-import sys\\\\n-import argparse\\\\n-import importlib\\\\n-import facenet\\\\n-import os\\\\n-import numpy as np\\\\n-import math\\\\n-import time\\\\n-import h5py\\\\n-from six import iteritems\\\\n-\\\\n-def main(args):\\\\n-  \\\\n-    img_mean = np.array([134.10714722, 102.52040863, 87.15436554])\\\\n-    img_stddev = np.sqrt(np.array([3941.30175781, 2856.94287109, 2519.35791016]))\\\\n-    \\\\n-    vae_checkpoint = os.path.expanduser(args.vae_checkpoint)\\\\n-    \\\\n-    fields, attribs_dict = read_annotations(args.annotations_filename)\\\\n-    \\\\n-    vae_def = importlib.import_module(args.vae_def)\\\\n-    vae = vae_def.Vae(args.latent_var_size)\\\\n-    gen_image_size = vae.get_image_size()\\\\n-\\\\n-    with tf.Graph().as_default():\\\\n-        tf.set_random_seed(args.seed)\\\\n-        \\\\n-        image_list = facenet.get_image_paths(os.path.expanduser(args.data_dir))\\\\n-        \\\\n-        # Get attributes for images\\\\n-        nrof_attributes = len(fields)\\\\n-        attribs_list = []\\\\n-        for img in image_list:\\\\n-            key = os.path.split(img)[1].split(\\\\\\\'.\\\\\\\')[0]\\\\n-            attr = attribs_dict[key]\\\\n-            assert len(attr)==nrof_attributes\\\\n-            attribs_list.append(attr)\\\\n-            \\\\n-        # Create the input queue\\\\n-        index_list = range(len(image_list))\\\\n-        input_queue = tf.train.slice_input_producer([image_list, attribs_list, index_list], num_epochs=1, shuffle=False)        \\\\n-        \\\\n-        nrof_preprocess_threads = 4\\\\n-        image_per_thread = []\\\\n-        for _ in range(nrof_preprocess_threads):\\\\n-            filename = input_queue[0]\\\\n-            file_contents = tf.read_file(filename)\\\\n-            image = tf.image.decode_image(file_contents, channels=3)\\\\n-            image = tf.image.resize_image_with_crop_or_pad(image, 160, 160)\\\\n-            #image = tf.image.resize_images(image, (64,64))\\\\n-            image.set_shape((args.image_size, args.image_size, 3))\\\\n-            attrib = input_queue[1]\\\\n-            attrib.set_shape((nrof_attributes,))\\\\n-            image = tf.cast(image, tf.float32)\\\\n-            image_per_thread.append([image, attrib, input_queue[2]])\\\\n-    \\\\n-        images, attribs, indices = tf.train.batch_join(\\\\n-            image_per_thread, batch_size=args.batch_size, \\\\n-            shapes=[(args.image_size, args.image_size, 3), (nrof_attributes,), ()], enqueue_many=False,\\\\n-            capacity=4 * nrof_preprocess_threads * args.batch_size,\\\\n-            allow_smaller_final_batch=True)\\\\n-        \\\\n-        # Normalize\\\\n-        images_norm = (images-img_mean) / img_stddev\\\\n-\\\\n-        # Resize to appropriate size for the encoder \\\\n-        images_norm_resize = tf.image.resize_images(images_norm, (gen_image_size,gen_image_size))\\\\n-        \\\\n-        # Create encoder network\\\\n-        mean, log_variance = vae.encoder(images_norm_resize, True)\\\\n-        \\\\n-        epsilon = tf.random_normal((tf.shape(mean)[0], args.latent_var_size))\\\\n-        std = tf.exp(log_variance/2)\\\\n-        latent_var = mean + epsilon * std\\\\n-        \\\\n-        # Create a saver\\\\n-        saver = tf.train.Saver(tf.trainable_variables(), max_to_keep=3)\\\\n-        \\\\n-        # Start running operations on the Graph\\\\n-        gpu_memory_fraction = 1.0\\\\n-        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_memory_fraction)\\\\n-        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\\\\n-        sess.run(tf.global_variables_initializer())\\\\n-        sess.run(tf.local_variables_initializer())\\\\n-        coord = tf.train.Coordinator()\\\\n-        tf.train.start_queue_runners(coord=coord, sess=sess)\\\\n-        \\\\n-\\\\n-        with sess.as_default():\\\\n-          \\\\n-            if vae_checkpoint:\\\\n-                print(\\\\\\\'Restoring VAE checkpoint: %s\\\\\\\' % vae_checkpoint)\\\\n-                saver.restore(sess, vae_checkpoint)\\\\n-           \\\\n-            nrof_images = len(image_list)\\\\n-            nrof_batches = int(math.ceil(len(image_list) / args.batch_size))\\\\n-            latent_vars = np.zeros((nrof_images, args.latent_var_size))\\\\n-            attributes = np.zeros((nrof_images, nrof_attributes))\\\\n-            for i in range(nrof_batches):\\\\n-                start_time = time.time()\\\\n-                latent_var_, attribs_, indices_ = sess.run([latent_var, attribs, indices])\\\\n-                latent_vars[indices_,:] = latent_var_\\\\n-                attributes[indices_,:] = attribs_\\\\n-                duration = time.time() - start_time\\\\n-                print(\\\\\\\'Batch %d/%d: %.3f seconds\\\\\\\' % (i+1, nrof_batches, duration))\\\\n-            # NOTE: This will print the \\\\\\\'Out of range\\\\\\\' warning if the last batch is not full,\\\\n-            #  as described by https://github.com/tensorflow/tensorflow/issues/8330\\\\n-             \\\\n-            # Calculate average change in the latent variable when each attribute changes\\\\n-            attribute_vectors = np.zeros((nrof_attributes, args.latent_var_size), np.float32)\\\\n-            for i in range(nrof_attributes):\\\\n-                pos_idx = np.argwhere(attributes[:,i]==1)[:,0]\\\\n-                neg_idx = np.argwhere(attributes[:,i]==-1)[:,0]\\\\n-                pos_avg = np.mean(latent_vars[pos_idx,:], 0)\\\\n-                neg_avg = np.mean(latent_vars[neg_idx,:], 0)\\\\n-                attribute_vectors[i,:] = pos_avg - neg_avg\\\\n-            \\\\n-            filename = os.path.expanduser(args.output_filename)\\\\n-            print(\\\\\\\'Writing attribute vectors, latent variables and attributes to %s\\\\\\\' % filename)\\\\n-            mdict = {\\\\\\\'latent_vars\\\\\\\':latent_vars, \\\\\\\'attributes\\\\\\\':attributes, \\\\n-                     \\\\\\\'fields\\\\\\\':fields, \\\\\\\'attribute_vectors\\\\\\\':attribute_vectors }\\\\n-            with h5py.File(filename, \\\\\\\'w\\\\\\\') as f:\\\\n-                for key, value in iteritems(mdict):\\\\n-                    f.create_dataset(key, data=value)\\\\n-                    \\\\n-                    \\\\n-def read_annotations(filename):\\\\n-    attribs = {}    \\\\n-    with open(filename, \\\\\\\'r\\\\\\\') as f:\\\\n-        for i, line in enumerate(f.readlines()):\\\\n-            if i==0:\\\\n-                continue  # First line is the number of entries in the file\\\\n-            elif i==1:\\\\n-                fields = line.strip().split() # Second line is the field names\\\\n-            else:\\\\n-                line = line.split()\\\\n-                img_name = line[0].split(\\\\\\\'.\\\\\\\')[0]\\\\n-                img_attribs = map(int, line[1:])\\\\n-                attribs[img_name] = img_attribs\\\\n-    return fields, attribs\\\\n-\\\\n-def parse_arguments(argv):\\\\n-    parser = argparse.ArgumentParser()\\\\n-    \\\\n-    parser.add_argument(\\\\\\\'vae_def\\\\\\\', type=str,\\\\n-        help=\\\\\\\'Model definition for the variational autoencoder. Points to a module containing the definition.\\\\\\\', \\\\n-        default=\\\\\\\'src.generative.models.dfc_vae\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'vae_checkpoint\\\\\\\', type=str,\\\\n-        help=\\\\\\\'Checkpoint file of a pre-trained variational autoencoder.\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'data_dir\\\\\\\', type=str,\\\\n-        help=\\\\\\\'Path to the directory containing aligned face patches for the CelebA dataset.\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'annotations_filename\\\\\\\', type=str,\\\\n-        help=\\\\\\\'Path to the annotations file\\\\\\\',\\\\n-        default=\\\\\\\'/media/deep/datasets/CelebA/Anno/list_attr_celeba.txt\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'output_filename\\\\\\\', type=str,\\\\n-        help=\\\\\\\'Filename to use for the file containing the attribute vectors.\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--batch_size\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Number of images to process in a batch.\\\\\\\', default=128)\\\\n-    parser.add_argument(\\\\\\\'--image_size\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Image size (height, width) in pixels.\\\\\\\', default=64)\\\\n-    parser.add_argument(\\\\\\\'--latent_var_size\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Dimensionality of the latent variable.\\\\\\\', default=100)\\\\n-    parser.add_argument(\\\\\\\'--seed\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Random seed.\\\\\\\', default=666)\\\\n-\\\\n-    return parser.parse_args(argv)\\\\n-  \\\\n-    \\\\n-if __name__ == \\\\\\\'__main__\\\\\\\':\\\\n-    main(parse_arguments(sys.argv[1:]))\\\\ndiff --git a/src/generative/models/a b/src/generative/models/a\\\\ndeleted file mode 100644\\\\nindex 8b13789..0000000\\\\n--- a/src/generative/models/a\\\\n+++ /dev/null\\\\n@@ -1 +0,0 @@\\\\n-\\\\ndiff --git a/src/generative/models/dfc_vae.py b/src/generative/models/dfc_vae.py\\\\ndeleted file mode 100644\\\\nindex b4450f2..0000000\\\\n--- a/src/generative/models/dfc_vae.py\\\\n+++ /dev/null\\\\n@@ -1,92 +0,0 @@\\\\n-# MIT License\\\\n-# \\\\n-# Copyright (c) 2017 David Sandberg\\\\n-# \\\\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\n-# of this software and associated documentation files (the "Software"), to deal\\\\n-# in the Software without restriction, including without limitation the rights\\\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\n-# copies of the Software, and to permit persons to whom the Software is\\\\n-# furnished to do so, subject to the following conditions:\\\\n-# \\\\n-# The above copyright notice and this permission notice shall be included in all\\\\n-# copies or substantial portions of the Software.\\\\n-# \\\\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\n-# SOFTWARE.\\\\n-\\\\n-"""Variational autoencoder based on the paper \\\\n-\\\\\\\'Deep Feature Consistent Variational Autoencoder\\\\\\\'\\\\n-(https://arxiv.org/pdf/1610.00291.pdf)\\\\n-"""\\\\n-\\\\n-from __future__ import absolute_import\\\\n-from __future__ import division\\\\n-from __future__ import print_function\\\\n-\\\\n-import tensorflow as tf\\\\n-import tensorflow.contrib.slim as slim\\\\n-import generative.models.vae_base  # @UnresolvedImport\\\\n-\\\\n-\\\\n-class Vae(generative.models.vae_base.Vae):\\\\n-  \\\\n-    def __init__(self, latent_variable_dim):\\\\n-        super(Vae, self).__init__(latent_variable_dim, 64)\\\\n-  \\\\n-    def encoder(self, images, is_training):\\\\n-        activation_fn = leaky_relu  # tf.nn.relu\\\\n-        weight_decay = 0.0\\\\n-        with tf.variable_scope(\\\\\\\'encoder\\\\\\\'):\\\\n-            with slim.arg_scope([slim.batch_norm],\\\\n-                                is_training=is_training):\\\\n-                with slim.arg_scope([slim.conv2d, slim.fully_connected],\\\\n-                                    weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\\\\n-                                    weights_regularizer=slim.l2_regularizer(weight_decay),\\\\n-                                    normalizer_fn=slim.batch_norm,\\\\n-                                    normalizer_params=self.batch_norm_params):\\\\n-                    net = slim.conv2d(images, 32, [4, 4], 2, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_1\\\\\\\')\\\\n-                    net = slim.conv2d(net, 64, [4, 4], 2, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_2\\\\\\\')\\\\n-                    net = slim.conv2d(net, 128, [4, 4], 2, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_3\\\\\\\')\\\\n-                    net = slim.conv2d(net, 256, [4, 4], 2, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_4\\\\\\\')\\\\n-                    net = slim.flatten(net)\\\\n-                    fc1 = slim.fully_connected(net, self.latent_variable_dim, activation_fn=None, normalizer_fn=None, scope=\\\\\\\'Fc_1\\\\\\\')\\\\n-                    fc2 = slim.fully_connected(net, self.latent_variable_dim, activation_fn=None, normalizer_fn=None, scope=\\\\\\\'Fc_2\\\\\\\')\\\\n-        return fc1, fc2\\\\n-      \\\\n-    def decoder(self, latent_var, is_training):\\\\n-        activation_fn = leaky_relu  # tf.nn.relu\\\\n-        weight_decay = 0.0 \\\\n-        with tf.variable_scope(\\\\\\\'decoder\\\\\\\'):\\\\n-            with slim.arg_scope([slim.batch_norm],\\\\n-                                is_training=is_training):\\\\n-                with slim.arg_scope([slim.conv2d, slim.fully_connected],\\\\n-                                    weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\\\\n-                                    weights_regularizer=slim.l2_regularizer(weight_decay),\\\\n-                                    normalizer_fn=slim.batch_norm,\\\\n-                                    normalizer_params=self.batch_norm_params):\\\\n-                    net = slim.fully_connected(latent_var, 4096, activation_fn=None, normalizer_fn=None, scope=\\\\\\\'Fc_1\\\\\\\')\\\\n-                    net = tf.reshape(net, [-1,4,4,256], name=\\\\\\\'Reshape\\\\\\\')\\\\n-                    \\\\n-                    net = tf.image.resize_nearest_neighbor(net, size=(8,8), name=\\\\\\\'Upsample_1\\\\\\\')\\\\n-                    net = slim.conv2d(net, 128, [3, 3], 1, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_1\\\\\\\')\\\\n-            \\\\n-                    net = tf.image.resize_nearest_neighbor(net, size=(16,16), name=\\\\\\\'Upsample_2\\\\\\\')\\\\n-                    net = slim.conv2d(net, 64, [3, 3], 1, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_2\\\\\\\')\\\\n-            \\\\n-                    net = tf.image.resize_nearest_neighbor(net, size=(32,32), name=\\\\\\\'Upsample_3\\\\\\\')\\\\n-                    net = slim.conv2d(net, 32, [3, 3], 1, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_3\\\\\\\')\\\\n-            \\\\n-                    net = tf.image.resize_nearest_neighbor(net, size=(64,64), name=\\\\\\\'Upsample_4\\\\\\\')\\\\n-                    net = slim.conv2d(net, 3, [3, 3], 1, activation_fn=None, scope=\\\\\\\'Conv2d_4\\\\\\\')\\\\n-                \\\\n-        return net\\\\n-      \\\\n-def leaky_relu(x):\\\\n-    return tf.maximum(0.1*x,x)\\\\n-  \\\\n\\\\\\\\ No newline at end of file\\\\ndiff --git a/src/generative/models/dfc_vae_large.py b/src/generative/models/dfc_vae_large.py\\\\ndeleted file mode 100644\\\\nindex aa8e8b7..0000000\\\\n--- a/src/generative/models/dfc_vae_large.py\\\\n+++ /dev/null\\\\n@@ -1,95 +0,0 @@\\\\n-# MIT License\\\\n-# \\\\n-# Copyright (c) 2017 David Sandberg\\\\n-# \\\\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\n-# of this software and associated documentation files (the "Software"), to deal\\\\n-# in the Software without restriction, including without limitation the rights\\\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\n-# copies of the Software, and to permit persons to whom the Software is\\\\n-# furnished to do so, subject to the following conditions:\\\\n-# \\\\n-# The above copyright notice and this permission notice shall be included in all\\\\n-# copies or substantial portions of the Software.\\\\n-# \\\\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\n-# SOFTWARE.\\\\n-\\\\n-"""Variational autoencoder based on the paper \\\\n-\\\\\\\'Deep Feature Consistent Variational Autoencoder\\\\\\\'\\\\n-(https://arxiv.org/pdf/1610.00291.pdf) but with a larger image size (128x128 pixels)\\\\n-"""\\\\n-\\\\n-from __future__ import absolute_import\\\\n-from __future__ import division\\\\n-from __future__ import print_function\\\\n-\\\\n-import tensorflow as tf\\\\n-import tensorflow.contrib.slim as slim\\\\n-import generative.models.vae_base  # @UnresolvedImport\\\\n-\\\\n-\\\\n-class Vae(generative.models.vae_base.Vae):\\\\n-  \\\\n-    def __init__(self, latent_variable_dim):\\\\n-        super(Vae, self).__init__(latent_variable_dim, 128)\\\\n-        \\\\n-      \\\\n-    def encoder(self, images, is_training):\\\\n-        activation_fn = leaky_relu  # tf.nn.relu\\\\n-        weight_decay = 0.0\\\\n-        with tf.variable_scope(\\\\\\\'encoder\\\\\\\'):\\\\n-            with slim.arg_scope([slim.batch_norm],\\\\n-                                is_training=is_training):\\\\n-                with slim.arg_scope([slim.conv2d, slim.fully_connected],\\\\n-                                    weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\\\\n-                                    weights_regularizer=slim.l2_regularizer(weight_decay),\\\\n-                                    normalizer_fn=slim.batch_norm,\\\\n-                                    normalizer_params=self.batch_norm_params):\\\\n-                    net = slim.conv2d(images, 32, [4, 4], 2, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_1\\\\\\\')\\\\n-                    net = slim.conv2d(net, 64, [4, 4], 2, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_2\\\\\\\')\\\\n-                    net = slim.conv2d(net, 128, [4, 4], 2, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_3\\\\\\\')\\\\n-                    net = slim.conv2d(net, 256, [4, 4], 2, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_4\\\\\\\')\\\\n-                    net = slim.conv2d(net, 512, [4, 4], 2, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_5\\\\\\\')\\\\n-                    net = slim.flatten(net)\\\\n-                    fc1 = slim.fully_connected(net, self.latent_variable_dim, activation_fn=None, normalizer_fn=None, scope=\\\\\\\'Fc_1\\\\\\\')\\\\n-                    fc2 = slim.fully_connected(net, self.latent_variable_dim, activation_fn=None, normalizer_fn=None, scope=\\\\\\\'Fc_2\\\\\\\')\\\\n-        return fc1, fc2\\\\n-      \\\\n-    def decoder(self, latent_var, is_training):\\\\n-        activation_fn = leaky_relu  # tf.nn.relu\\\\n-        weight_decay = 0.0 \\\\n-        with tf.variable_scope(\\\\\\\'decoder\\\\\\\'):\\\\n-            with slim.arg_scope([slim.batch_norm],\\\\n-                                is_training=is_training):\\\\n-                with slim.arg_scope([slim.conv2d, slim.fully_connected],\\\\n-                                    weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\\\\n-                                    weights_regularizer=slim.l2_regularizer(weight_decay),\\\\n-                                    normalizer_fn=slim.batch_norm,\\\\n-                                    normalizer_params=self.batch_norm_params):\\\\n-                    net = slim.fully_connected(latent_var, 4096, activation_fn=None, normalizer_fn=None, scope=\\\\\\\'Fc_1\\\\\\\')\\\\n-                    net = tf.reshape(net, [-1,4,4,256], name=\\\\\\\'Reshape\\\\\\\')\\\\n-                    \\\\n-                    net = tf.image.resize_nearest_neighbor(net, size=(8,8), name=\\\\\\\'Upsample_1\\\\\\\')\\\\n-                    net = slim.conv2d(net, 128, [3, 3], 1, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_1\\\\\\\')\\\\n-            \\\\n-                    net = tf.image.resize_nearest_neighbor(net, size=(16,16), name=\\\\\\\'Upsample_2\\\\\\\')\\\\n-                    net = slim.conv2d(net, 64, [3, 3], 1, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_2\\\\\\\')\\\\n-            \\\\n-                    net = tf.image.resize_nearest_neighbor(net, size=(32,32), name=\\\\\\\'Upsample_3\\\\\\\')\\\\n-                    net = slim.conv2d(net, 32, [3, 3], 1, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_3\\\\\\\')\\\\n-            \\\\n-                    net = tf.image.resize_nearest_neighbor(net, size=(64,64), name=\\\\\\\'Upsample_4\\\\\\\')\\\\n-                    net = slim.conv2d(net, 3, [3, 3], 1, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_4\\\\\\\')\\\\n-                \\\\n-                    net = tf.image.resize_nearest_neighbor(net, size=(128,128), name=\\\\\\\'Upsample_5\\\\\\\')\\\\n-                    net = slim.conv2d(net, 3, [3, 3], 1, activation_fn=None, scope=\\\\\\\'Conv2d_5\\\\\\\')\\\\n-        return net\\\\n-\\\\n-def leaky_relu(x):\\\\n-    return tf.maximum(0.1*x,x)  \\\\ndiff --git a/src/generative/models/dfc_vae_resnet.py b/src/generative/models/dfc_vae_resnet.py\\\\ndeleted file mode 100644\\\\nindex 7c2f52c..0000000\\\\n--- a/src/generative/models/dfc_vae_resnet.py\\\\n+++ /dev/null\\\\n@@ -1,110 +0,0 @@\\\\n-# MIT License\\\\n-# \\\\n-# Copyright (c) 2017 David Sandberg\\\\n-# \\\\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\n-# of this software and associated documentation files (the "Software"), to deal\\\\n-# in the Software without restriction, including without limitation the rights\\\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\n-# copies of the Software, and to permit persons to whom the Software is\\\\n-# furnished to do so, subject to the following conditions:\\\\n-# \\\\n-# The above copyright notice and this permission notice shall be included in all\\\\n-# copies or substantial portions of the Software.\\\\n-# \\\\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\n-# SOFTWARE.\\\\n-\\\\n-"""Variational autoencoder based on the paper \\\\n-\\\\\\\'Deep Feature Consistent Variational Autoencoder\\\\\\\'\\\\n-(https://arxiv.org/pdf/1610.00291.pdf)\\\\n-"""\\\\n-\\\\n-from __future__ import absolute_import\\\\n-from __future__ import division\\\\n-from __future__ import print_function\\\\n-\\\\n-import tensorflow as tf\\\\n-import tensorflow.contrib.slim as slim\\\\n-import generative.models.vae_base  # @UnresolvedImport\\\\n-\\\\n-\\\\n-class Vae(generative.models.vae_base.Vae):\\\\n-  \\\\n-    def __init__(self, latent_variable_dim):\\\\n-        super(Vae, self).__init__(latent_variable_dim, 64)\\\\n-  \\\\n-    def encoder(self, images, is_training):\\\\n-        activation_fn = leaky_relu  # tf.nn.relu\\\\n-        weight_decay = 0.0\\\\n-        with tf.variable_scope(\\\\\\\'encoder\\\\\\\'):\\\\n-            with slim.arg_scope([slim.batch_norm],\\\\n-                                is_training=is_training):\\\\n-                with slim.arg_scope([slim.conv2d, slim.fully_connected],\\\\n-                                    weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\\\\n-                                    weights_regularizer=slim.l2_regularizer(weight_decay),\\\\n-                                    normalizer_fn=slim.batch_norm,\\\\n-                                    normalizer_params=self.batch_norm_params):\\\\n-                    net = images\\\\n-                    \\\\n-                    net = slim.conv2d(net, 32, [4, 4], 2, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_1a\\\\\\\')\\\\n-                    net = slim.repeat(net, 3, conv2d_block, 0.1, 32, [4, 4], 1, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_1b\\\\\\\')\\\\n-                    \\\\n-                    net = slim.conv2d(net, 64, [4, 4], 2, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_2a\\\\\\\')\\\\n-                    net = slim.repeat(net, 3, conv2d_block, 0.1, 64, [4, 4], 1, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_2b\\\\\\\')\\\\n-\\\\n-                    net = slim.conv2d(net, 128, [4, 4], 2, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_3a\\\\\\\')\\\\n-                    net = slim.repeat(net, 3, conv2d_block, 0.1, 128, [4, 4], 1, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_3b\\\\\\\')\\\\n-\\\\n-                    net = slim.conv2d(net, 256, [4, 4], 2, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_4a\\\\\\\')\\\\n-                    net = slim.repeat(net, 3, conv2d_block, 0.1, 256, [4, 4], 1, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_4b\\\\\\\')\\\\n-                    \\\\n-                    net = slim.flatten(net)\\\\n-                    fc1 = slim.fully_connected(net, self.latent_variable_dim, activation_fn=None, normalizer_fn=None, scope=\\\\\\\'Fc_1\\\\\\\')\\\\n-                    fc2 = slim.fully_connected(net, self.latent_variable_dim, activation_fn=None, normalizer_fn=None, scope=\\\\\\\'Fc_2\\\\\\\')\\\\n-        return fc1, fc2\\\\n-      \\\\n-    def decoder(self, latent_var, is_training):\\\\n-        activation_fn = leaky_relu  # tf.nn.relu\\\\n-        weight_decay = 0.0 \\\\n-        with tf.variable_scope(\\\\\\\'decoder\\\\\\\'):\\\\n-            with slim.arg_scope([slim.batch_norm],\\\\n-                                is_training=is_training):\\\\n-                with slim.arg_scope([slim.conv2d, slim.fully_connected],\\\\n-                                    weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\\\\n-                                    weights_regularizer=slim.l2_regularizer(weight_decay),\\\\n-                                    normalizer_fn=slim.batch_norm,\\\\n-                                    normalizer_params=self.batch_norm_params):\\\\n-                    net = slim.fully_connected(latent_var, 4096, activation_fn=None, normalizer_fn=None, scope=\\\\\\\'Fc_1\\\\\\\')\\\\n-                    net = tf.reshape(net, [-1,4,4,256], name=\\\\\\\'Reshape\\\\\\\')\\\\n-                    \\\\n-                    net = tf.image.resize_nearest_neighbor(net, size=(8,8), name=\\\\\\\'Upsample_1\\\\\\\')\\\\n-                    net = slim.conv2d(net, 128, [3, 3], 1, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_1a\\\\\\\')\\\\n-                    net = slim.repeat(net, 3, conv2d_block, 0.1, 128, [3, 3], 1, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_1b\\\\\\\')\\\\n-            \\\\n-                    net = tf.image.resize_nearest_neighbor(net, size=(16,16), name=\\\\\\\'Upsample_2\\\\\\\')\\\\n-                    net = slim.conv2d(net, 64, [3, 3], 1, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_2a\\\\\\\')\\\\n-                    net = slim.repeat(net, 3, conv2d_block, 0.1, 64, [3, 3], 1, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_2b\\\\\\\')\\\\n-            \\\\n-                    net = tf.image.resize_nearest_neighbor(net, size=(32,32), name=\\\\\\\'Upsample_3\\\\\\\')\\\\n-                    net = slim.conv2d(net, 32, [3, 3], 1, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_3a\\\\\\\')\\\\n-                    net = slim.repeat(net, 3, conv2d_block, 0.1, 32, [3, 3], 1, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_3b\\\\\\\')\\\\n-            \\\\n-                    net = tf.image.resize_nearest_neighbor(net, size=(64,64), name=\\\\\\\'Upsample_4\\\\\\\')\\\\n-                    net = slim.conv2d(net, 3, [3, 3], 1, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_4a\\\\\\\')\\\\n-                    net = slim.repeat(net, 3, conv2d_block, 0.1, 3, [3, 3], 1, activation_fn=activation_fn, scope=\\\\\\\'Conv2d_4b\\\\\\\')\\\\n-                    net = slim.conv2d(net, 3, [3, 3], 1, activation_fn=None, scope=\\\\\\\'Conv2d_4c\\\\\\\')\\\\n-                \\\\n-        return net\\\\n-      \\\\n-def conv2d_block(inp, scale, *args, **kwargs):\\\\n-    return inp + slim.conv2d(inp, *args, **kwargs) * scale\\\\n-\\\\n-def leaky_relu(x):\\\\n-    return tf.maximum(0.1*x,x)\\\\n-  \\\\n\\\\\\\\ No newline at end of file\\\\ndiff --git a/src/generative/models/vae_base.py b/src/generative/models/vae_base.py\\\\ndeleted file mode 100644\\\\nindex 7437251..0000000\\\\n--- a/src/generative/models/vae_base.py\\\\n+++ /dev/null\\\\n@@ -1,58 +0,0 @@\\\\n-# MIT License\\\\n-# \\\\n-# Copyright (c) 2017 David Sandberg\\\\n-# \\\\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\n-# of this software and associated documentation files (the "Software"), to deal\\\\n-# in the Software without restriction, including without limitation the rights\\\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\n-# copies of the Software, and to permit persons to whom the Software is\\\\n-# furnished to do so, subject to the following conditions:\\\\n-# \\\\n-# The above copyright notice and this permission notice shall be included in all\\\\n-# copies or substantial portions of the Software.\\\\n-# \\\\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\n-# SOFTWARE.\\\\n-\\\\n-"""Base class for variational autoencoders containing an encoder and a decoder\\\\n-"""\\\\n-\\\\n-from __future__ import absolute_import\\\\n-from __future__ import division\\\\n-from __future__ import print_function\\\\n-\\\\n-import tensorflow as tf\\\\n-\\\\n-class Vae(object):\\\\n-  \\\\n-    def __init__(self, latent_variable_dim, image_size):\\\\n-        self.latent_variable_dim = latent_variable_dim\\\\n-        self.image_size = image_size\\\\n-        self.batch_norm_params = {\\\\n-        # Decay for the moving averages.\\\\n-        \\\\\\\'decay\\\\\\\': 0.995,\\\\n-        # epsilon to prevent 0s in variance.\\\\n-        \\\\\\\'epsilon\\\\\\\': 0.001,\\\\n-        # force in-place updates of mean and variance estimates\\\\n-        \\\\\\\'updates_collections\\\\\\\': None,\\\\n-        # Moving averages ends up in the trainable variables collection\\\\n-        \\\\\\\'variables_collections\\\\\\\': [ tf.GraphKeys.TRAINABLE_VARIABLES ],\\\\n-    }\\\\n-  \\\\n-    def encoder(self, images, is_training):\\\\n-        # Must be overridden in implementation classes\\\\n-        raise NotImplementedError\\\\n-      \\\\n-    def decoder(self, latent_var, is_training):\\\\n-        # Must be overridden in implementation classes\\\\n-        raise NotImplementedError\\\\n-\\\\n-    def get_image_size(self):\\\\n-        return self.image_size\\\\n-        \\\\n\\\\\\\\ No newline at end of file\\\\ndiff --git a/src/generative/modify_attribute.py b/src/generative/modify_attribute.py\\\\ndeleted file mode 100644\\\\nindex 8187cff..0000000\\\\n--- a/src/generative/modify_attribute.py\\\\n+++ /dev/null\\\\n@@ -1,142 +0,0 @@\\\\n-# MIT License\\\\n-# \\\\n-# Copyright (c) 2017 David Sandberg\\\\n-# \\\\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\n-# of this software and associated documentation files (the "Software"), to deal\\\\n-# in the Software without restriction, including without limitation the rights\\\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\n-# copies of the Software, and to permit persons to whom the Software is\\\\n-# furnished to do so, subject to the following conditions:\\\\n-# \\\\n-# The above copyright notice and this permission notice shall be included in all\\\\n-# copies or substantial portions of the Software.\\\\n-# \\\\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\n-# SOFTWARE.\\\\n-\\\\n-"""Modify attributes of images using attribute vectors calculated using\\\\n-\\\\\\\'calculate_attribute_vectors.py\\\\\\\'. Images are generated from latent variables of\\\\n-the CelebA dataset.\\\\n-"""\\\\n-from __future__ import absolute_import\\\\n-from __future__ import division\\\\n-from __future__ import print_function\\\\n-\\\\n-import tensorflow as tf\\\\n-import sys\\\\n-import argparse\\\\n-import importlib\\\\n-import facenet\\\\n-import os\\\\n-import numpy as np\\\\n-import h5py\\\\n-import math\\\\n-from scipy import misc\\\\n-\\\\n-def main(args):\\\\n-  \\\\n-    img_mean = np.array([134.10714722, 102.52040863, 87.15436554])\\\\n-    img_stddev = np.sqrt(np.array([3941.30175781, 2856.94287109, 2519.35791016]))\\\\n-    \\\\n-    vae_def = importlib.import_module(args.vae_def)\\\\n-    vae = vae_def.Vae(args.latent_var_size)\\\\n-    gen_image_size = vae.get_image_size()\\\\n-\\\\n-    with tf.Graph().as_default():\\\\n-        tf.set_random_seed(args.seed)\\\\n-        \\\\n-        images = tf.placeholder(tf.float32, shape=(None,gen_image_size,gen_image_size,3), name=\\\\\\\'input\\\\\\\')\\\\n-        \\\\n-        # Normalize\\\\n-        images_norm = (images-img_mean) / img_stddev\\\\n-\\\\n-        # Resize to appropriate size for the encoder \\\\n-        images_norm_resize = tf.image.resize_images(images_norm, (gen_image_size,gen_image_size))\\\\n-        \\\\n-        # Create encoder network\\\\n-        mean, log_variance = vae.encoder(images_norm_resize, True)\\\\n-        \\\\n-        epsilon = tf.random_normal((tf.shape(mean)[0], args.latent_var_size))\\\\n-        std = tf.exp(log_variance/2)\\\\n-        latent_var = mean + epsilon * std\\\\n-        \\\\n-        # Create decoder\\\\n-        reconstructed_norm = vae.decoder(latent_var, False)\\\\n-        \\\\n-        # Un-normalize\\\\n-        reconstructed = (reconstructed_norm*img_stddev) + img_mean\\\\n-\\\\n-        # Create a saver\\\\n-        saver = tf.train.Saver(tf.trainable_variables(), max_to_keep=3)\\\\n-        \\\\n-        # Start running operations on the Graph\\\\n-        gpu_memory_fraction = 1.0\\\\n-        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_memory_fraction)\\\\n-        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\\\\n-        sess.run(tf.global_variables_initializer())\\\\n-        sess.run(tf.local_variables_initializer())\\\\n-        coord = tf.train.Coordinator()\\\\n-        tf.train.start_queue_runners(coord=coord, sess=sess)\\\\n-        \\\\n-\\\\n-        with sess.as_default():\\\\n-          \\\\n-            vae_checkpoint = os.path.expanduser(args.vae_checkpoint)\\\\n-            print(\\\\\\\'Restoring VAE checkpoint: %s\\\\\\\' % vae_checkpoint)\\\\n-            saver.restore(sess, vae_checkpoint)\\\\n-           \\\\n-            filename = os.path.expanduser(args.attributes_filename)\\\\n-            with h5py.File(filename,\\\\\\\'r\\\\\\\') as f:\\\\n-                latent_vars = np.array(f.get(\\\\\\\'latent_vars\\\\\\\'))\\\\n-                attributes = np.array(f.get(\\\\\\\'attributes\\\\\\\'))\\\\n-                #fields = np.array(f.get(\\\\\\\'fields\\\\\\\'))\\\\n-                attribute_vectors = np.array(f.get(\\\\\\\'attribute_vectors\\\\\\\'))\\\\n-\\\\n-            # Reconstruct faces while adding varying amount of the selected attribute vector\\\\n-            attribute_index = 31 # 31: \\\\\\\'Smiling\\\\\\\'\\\\n-            image_indices = [8,11,13,18,19,26,31,39,47,54,56,57,58,59,60,73]\\\\n-            nrof_images = len(image_indices)\\\\n-            nrof_interp_steps = 10\\\\n-            sweep_latent_var = np.zeros((nrof_interp_steps*nrof_images, args.latent_var_size), np.float32)\\\\n-            for j in range(nrof_images):\\\\n-                image_index = image_indices[j]\\\\n-                idx = np.argwhere(attributes[:,attribute_index]==-1)[image_index,0]\\\\n-                for i in range(nrof_interp_steps):\\\\n-                    sweep_latent_var[i+nrof_interp_steps*j,:] = latent_vars[idx,:] + 5.0*i/nrof_interp_steps*attribute_vectors[attribute_index,:]\\\\n-                \\\\n-            recon = sess.run(reconstructed, feed_dict={latent_var:sweep_latent_var})\\\\n-            \\\\n-            img = facenet.put_images_on_grid(recon, shape=(nrof_interp_steps*2,int(math.ceil(nrof_images/2))))\\\\n-            \\\\n-            image_filename = os.path.expanduser(args.output_image_filename)\\\\n-            print(\\\\\\\'Writing generated image to %s\\\\\\\' % image_filename)\\\\n-            misc.imsave(image_filename, img)\\\\n-\\\\n-                    \\\\n-def parse_arguments(argv):\\\\n-    parser = argparse.ArgumentParser()\\\\n-    \\\\n-    parser.add_argument(\\\\\\\'vae_def\\\\\\\', type=str,\\\\n-        help=\\\\\\\'Model definition for the variational autoencoder. Points to a module containing the definition.\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'vae_checkpoint\\\\\\\', type=str,\\\\n-        help=\\\\\\\'Checkpoint file of a pre-trained variational autoencoder.\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'attributes_filename\\\\\\\', type=str,\\\\n-        help=\\\\\\\'The file containing the attribute vectors, as generated by calculate_attribute_vectors.py.\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'output_image_filename\\\\\\\', type=str,\\\\n-        help=\\\\\\\'File to write the generated image to.\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--latent_var_size\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Dimensionality of the latent variable.\\\\\\\', default=100)\\\\n-    parser.add_argument(\\\\\\\'--seed\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Random seed.\\\\\\\', default=666)\\\\n-\\\\n-    return parser.parse_args(argv)\\\\n-  \\\\n-    \\\\n-if __name__ == \\\\\\\'__main__\\\\\\\':\\\\n-    main(parse_arguments(sys.argv[1:]))\\\\ndiff --git a/src/generative/train_vae.py b/src/generative/train_vae.py\\\\ndeleted file mode 100644\\\\nindex c3c882f..0000000\\\\n--- a/src/generative/train_vae.py\\\\n+++ /dev/null\\\\n@@ -1,284 +0,0 @@\\\\n-# MIT License\\\\n-# \\\\n-# Copyright (c) 2017 David Sandberg\\\\n-# \\\\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\n-# of this software and associated documentation files (the "Software"), to deal\\\\n-# in the Software without restriction, including without limitation the rights\\\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\n-# copies of the Software, and to permit persons to whom the Software is\\\\n-# furnished to do so, subject to the following conditions:\\\\n-# \\\\n-# The above copyright notice and this permission notice shall be included in all\\\\n-# copies or substantial portions of the Software.\\\\n-# \\\\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\n-# SOFTWARE.\\\\n-\\\\n-"""Train a Variational Autoencoder\\\\n-"""\\\\n-from __future__ import absolute_import\\\\n-from __future__ import division\\\\n-from __future__ import print_function\\\\n-\\\\n-import tensorflow as tf\\\\n-import tensorflow.contrib.slim as slim\\\\n-import sys\\\\n-import time\\\\n-import importlib\\\\n-import argparse\\\\n-import facenet\\\\n-import numpy as np\\\\n-import h5py\\\\n-import os\\\\n-from datetime import datetime\\\\n-from scipy import misc\\\\n-from six import iteritems\\\\n-\\\\n-def main(args):\\\\n-  \\\\n-    img_mean = np.array([134.10714722, 102.52040863, 87.15436554])\\\\n-    img_stddev = np.sqrt(np.array([3941.30175781, 2856.94287109, 2519.35791016]))\\\\n-  \\\\n-    vae_def = importlib.import_module(args.vae_def)\\\\n-    vae = vae_def.Vae(args.latent_var_size)\\\\n-    gen_image_size = vae.get_image_size()\\\\n-\\\\n-    subdir = datetime.strftime(datetime.now(), \\\\\\\'%Y%m%d-%H%M%S\\\\\\\')\\\\n-    model_dir = os.path.join(os.path.expanduser(args.models_base_dir), subdir)\\\\n-    if not os.path.isdir(model_dir):  # Create the model directory if it doesn\\\\\\\'t exist\\\\n-        os.makedirs(model_dir)\\\\n-    log_file_name = os.path.join(model_dir, \\\\\\\'logs.h5\\\\\\\')\\\\n-    \\\\n-    # Write arguments to a text file\\\\n-    facenet.write_arguments_to_file(args, os.path.join(model_dir, \\\\\\\'arguments.txt\\\\\\\'))\\\\n-        \\\\n-    # Store some git revision info in a text file in the log directory\\\\n-    src_path,_ = os.path.split(os.path.realpath(__file__))\\\\n-    facenet.store_revision_info(src_path, model_dir, \\\\\\\' \\\\\\\'.join(sys.argv))\\\\n-    \\\\n-    with tf.Graph().as_default():\\\\n-        tf.set_random_seed(args.seed)\\\\n-        global_step = tf.Variable(0, trainable=False)\\\\n-        \\\\n-        train_set = facenet.get_dataset(args.data_dir)\\\\n-        image_list, _ = facenet.get_image_paths_and_labels(train_set)\\\\n-        \\\\n-        # Create the input queue\\\\n-        input_queue = tf.train.string_input_producer(image_list, shuffle=True)\\\\n-    \\\\n-        nrof_preprocess_threads = 4\\\\n-        image_per_thread = []\\\\n-        for _ in range(nrof_preprocess_threads):\\\\n-            file_contents = tf.read_file(input_queue.dequeue())\\\\n-            image = tf.image.decode_image(file_contents, channels=3)\\\\n-            image = tf.image.resize_image_with_crop_or_pad(image, args.input_image_size, args.input_image_size)\\\\n-            image.set_shape((args.input_image_size, args.input_image_size, 3))\\\\n-            image = tf.cast(image, tf.float32)\\\\n-            #pylint: disable=no-member\\\\n-            image_per_thread.append([image])\\\\n-    \\\\n-        images = tf.train.batch_join(\\\\n-            image_per_thread, batch_size=args.batch_size,\\\\n-            capacity=4 * nrof_preprocess_threads * args.batch_size,\\\\n-            allow_smaller_final_batch=False)\\\\n-        \\\\n-        # Normalize\\\\n-        images_norm = (images-img_mean) / img_stddev\\\\n-\\\\n-        # Resize to appropriate size for the encoder \\\\n-        images_norm_resize = tf.image.resize_images(images_norm, (gen_image_size,gen_image_size))\\\\n-        \\\\n-        # Create encoder network\\\\n-        mean, log_variance = vae.encoder(images_norm_resize, True)\\\\n-        \\\\n-        epsilon = tf.random_normal((tf.shape(mean)[0], args.latent_var_size))\\\\n-        std = tf.exp(log_variance/2)\\\\n-        latent_var = mean + epsilon * std\\\\n-        \\\\n-        # Create decoder network\\\\n-        reconstructed_norm = vae.decoder(latent_var, True)\\\\n-        \\\\n-        # Un-normalize\\\\n-        reconstructed = (reconstructed_norm*img_stddev) + img_mean\\\\n-        \\\\n-        # Create reconstruction loss\\\\n-        if args.reconstruction_loss_type==\\\\\\\'PLAIN\\\\\\\':\\\\n-            images_resize = tf.image.resize_images(images, (gen_image_size,gen_image_size))\\\\n-            reconstruction_loss = tf.reduce_mean(tf.reduce_sum(tf.pow(images_resize - reconstructed,2)))\\\\n-        elif args.reconstruction_loss_type==\\\\\\\'PERCEPTUAL\\\\\\\':\\\\n-            network = importlib.import_module(args.model_def)\\\\n-\\\\n-            reconstructed_norm_resize = tf.image.resize_images(reconstructed_norm, (args.input_image_size,args.input_image_size))\\\\n-\\\\n-            # Stack images from both the input batch and the reconstructed batch in a new tensor \\\\n-            shp = [-1] + images_norm.get_shape().as_list()[1:]\\\\n-            input_images = tf.reshape(tf.stack([images_norm, reconstructed_norm_resize], axis=0), shp)\\\\n-            _, end_points = network.inference(input_images, 1.0, \\\\n-                phase_train=False, bottleneck_layer_size=128, weight_decay=0.0)\\\\n-\\\\n-            # Get a list of feature names to use for loss terms\\\\n-            feature_names = args.loss_features.replace(\\\\\\\' \\\\\\\', \\\\\\\'\\\\\\\').split(\\\\\\\',\\\\\\\')\\\\n-\\\\n-            # Calculate L2 loss between original and reconstructed images in feature space\\\\n-            reconstruction_loss_list = []\\\\n-            for feature_name in feature_names:\\\\n-                feature_flat = slim.flatten(end_points[feature_name])\\\\n-                image_feature, reconstructed_feature = tf.unstack(tf.reshape(feature_flat, [2,args.batch_size,-1]), num=2, axis=0)\\\\n-                reconstruction_loss = tf.reduce_mean(tf.reduce_sum(tf.pow(image_feature-reconstructed_feature, 2)), name=feature_name+\\\\\\\'_loss\\\\\\\')\\\\n-                reconstruction_loss_list.append(reconstruction_loss)\\\\n-            # Sum up the losses in for the different features\\\\n-            reconstruction_loss = tf.add_n(reconstruction_loss_list, \\\\\\\'reconstruction_loss\\\\\\\')\\\\n-        else:\\\\n-            pass\\\\n-        \\\\n-        # Create KL divergence loss\\\\n-        kl_loss = kl_divergence_loss(mean, log_variance)\\\\n-        kl_loss_mean = tf.reduce_mean(kl_loss)\\\\n-        \\\\n-        total_loss = args.alfa*kl_loss_mean + args.beta*reconstruction_loss\\\\n-        \\\\n-        learning_rate = tf.train.exponential_decay(args.initial_learning_rate, global_step,\\\\n-            args.learning_rate_decay_steps, args.learning_rate_decay_factor, staircase=True)\\\\n-        \\\\n-        # Calculate gradients and make sure not to include parameters for the perceptual loss model\\\\n-        opt = tf.train.AdamOptimizer(learning_rate)\\\\n-        grads = opt.compute_gradients(total_loss, var_list=get_variables_to_train())\\\\n-        \\\\n-        # Apply gradients\\\\n-        apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\\\\n-        with tf.control_dependencies([apply_gradient_op]):\\\\n-            train_op = tf.no_op(name=\\\\\\\'train\\\\\\\')\\\\n-\\\\n-        # Create a saver\\\\n-        saver = tf.train.Saver(tf.trainable_variables(), max_to_keep=3)\\\\n-        \\\\n-        facenet_saver = tf.train.Saver(get_facenet_variables_to_restore())\\\\n-\\\\n-        # Start running operations on the Graph\\\\n-        gpu_memory_fraction = 1.0\\\\n-        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_memory_fraction)\\\\n-        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\\\\n-        sess.run(tf.global_variables_initializer())\\\\n-        sess.run(tf.local_variables_initializer())\\\\n-        coord = tf.train.Coordinator()\\\\n-        tf.train.start_queue_runners(coord=coord, sess=sess)\\\\n-\\\\n-        with sess.as_default():\\\\n-            \\\\n-            if args.reconstruction_loss_type==\\\\\\\'PERCEPTUAL\\\\\\\':\\\\n-                if not args.pretrained_model:\\\\n-                    raise ValueError(\\\\\\\'A pretrained model must be specified when using perceptual loss\\\\\\\')\\\\n-                pretrained_model_exp = os.path.expanduser(args.pretrained_model)\\\\n-                print(\\\\\\\'Restoring pretrained model: %s\\\\\\\' % pretrained_model_exp)\\\\n-                facenet_saver.restore(sess, pretrained_model_exp)\\\\n-          \\\\n-            log = {\\\\n-                \\\\\\\'total_loss\\\\\\\': np.zeros((0,), np.float),\\\\n-                \\\\\\\'reconstruction_loss\\\\\\\': np.zeros((0,), np.float),\\\\n-                \\\\\\\'kl_loss\\\\\\\': np.zeros((0,), np.float),\\\\n-                \\\\\\\'learning_rate\\\\\\\': np.zeros((0,), np.float),\\\\n-                }\\\\n-            \\\\n-            step = 0\\\\n-            print(\\\\\\\'Running training\\\\\\\')\\\\n-            while step < args.max_nrof_steps:\\\\n-                start_time = time.time()\\\\n-                step += 1\\\\n-                save_state = step>0 and (step % args.save_every_n_steps==0 or step==args.max_nrof_steps)\\\\n-                if save_state:\\\\n-                    _, reconstruction_loss_, kl_loss_mean_, total_loss_, learning_rate_, rec_ = sess.run(\\\\n-                          [train_op, reconstruction_loss, kl_loss_mean, total_loss, learning_rate, reconstructed])\\\\n-                    img = facenet.put_images_on_grid(rec_, shape=(16,8))\\\\n-                    misc.imsave(os.path.join(model_dir, \\\\\\\'reconstructed_%06d.png\\\\\\\' % step), img)\\\\n-                else:\\\\n-                    _, reconstruction_loss_, kl_loss_mean_, total_loss_, learning_rate_ = sess.run(\\\\n-                          [train_op, reconstruction_loss, kl_loss_mean, total_loss, learning_rate])\\\\n-                log[\\\\\\\'total_loss\\\\\\\'] = np.append(log[\\\\\\\'total_loss\\\\\\\'], total_loss_)\\\\n-                log[\\\\\\\'reconstruction_loss\\\\\\\'] = np.append(log[\\\\\\\'reconstruction_loss\\\\\\\'], reconstruction_loss_)\\\\n-                log[\\\\\\\'kl_loss\\\\\\\'] = np.append(log[\\\\\\\'kl_loss\\\\\\\'], kl_loss_mean_)\\\\n-                log[\\\\\\\'learning_rate\\\\\\\'] = np.append(log[\\\\\\\'learning_rate\\\\\\\'], learning_rate_)\\\\n-\\\\n-                duration = time.time() - start_time\\\\n-                print(\\\\\\\'Step: %d \\\\\\\\tTime: %.3f \\\\\\\\trec_loss: %.3f \\\\\\\\tkl_loss: %.3f \\\\\\\\ttotal_loss: %.3f\\\\\\\' % (step, duration, reconstruction_loss_, kl_loss_mean_, total_loss_))\\\\n-\\\\n-                if save_state:\\\\n-                    print(\\\\\\\'Saving checkpoint file\\\\\\\')\\\\n-                    checkpoint_path = os.path.join(model_dir, \\\\\\\'model.ckpt\\\\\\\')\\\\n-                    saver.save(sess, checkpoint_path, global_step=step, write_meta_graph=False)\\\\n-                    print(\\\\\\\'Saving log\\\\\\\')\\\\n-                    with h5py.File(log_file_name, \\\\\\\'w\\\\\\\') as f:\\\\n-                        for key, value in iteritems(log):\\\\n-                            f.create_dataset(key, data=value)\\\\n-\\\\n-def get_variables_to_train():\\\\n-    train_variables = []\\\\n-    for var in tf.trainable_variables():\\\\n-        if \\\\\\\'Inception\\\\\\\' not in var.name:\\\\n-            train_variables.append(var)\\\\n-    return train_variables\\\\n-\\\\n-def get_facenet_variables_to_restore():\\\\n-    facenet_variables = []\\\\n-    for var in tf.global_variables():\\\\n-        if var.name.startswith(\\\\\\\'Inception\\\\\\\'):\\\\n-            if \\\\\\\'Adam\\\\\\\' not in var.name:\\\\n-                facenet_variables.append(var)\\\\n-    return facenet_variables\\\\n-\\\\n-def kl_divergence_loss(mean, log_variance):\\\\n-    kl = 0.5 * tf.reduce_sum( tf.exp(log_variance) + tf.square(mean) - 1.0 - log_variance, reduction_indices = 1)\\\\n-    return kl\\\\n-\\\\n-def parse_arguments(argv):\\\\n-    parser = argparse.ArgumentParser()\\\\n-    \\\\n-    parser.add_argument(\\\\\\\'vae_def\\\\\\\', type=str,\\\\n-        help=\\\\\\\'Model definition for the variational autoencoder. Points to a module containing the definition.\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'data_dir\\\\\\\', type=str,\\\\n-        help=\\\\\\\'Path to the data directory containing aligned face patches.\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'model_def\\\\\\\', type=str,\\\\n-        help=\\\\\\\'Model definition. Points to a module containing the definition of the inference graph.\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'pretrained_model\\\\\\\', type=str,\\\\n-        help=\\\\\\\'Pretrained model to use to calculate features for perceptual loss.\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--models_base_dir\\\\\\\', type=str,\\\\n-        help=\\\\\\\'Directory where to write trained models and checkpoints.\\\\\\\', default=\\\\\\\'~/vae\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--loss_features\\\\\\\', type=str,\\\\n-        help=\\\\\\\'Comma separated list of features to use for perceptual loss. Features should be defined \\\\\\\' +\\\\n-          \\\\\\\'in the end_points dictionary.\\\\\\\', default=\\\\\\\'Conv2d_1a_3x3,Conv2d_2a_3x3, Conv2d_2b_3x3\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--reconstruction_loss_type\\\\\\\', type=str, choices=[\\\\\\\'PLAIN\\\\\\\', \\\\\\\'PERCEPTUAL\\\\\\\'],\\\\n-        help=\\\\\\\'The type of reconstruction loss to use\\\\\\\', default=\\\\\\\'PERCEPTUAL\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--max_nrof_steps\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Number of steps to run.\\\\\\\', default=50000)\\\\n-    parser.add_argument(\\\\\\\'--save_every_n_steps\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Number of steps between storing of model checkpoint and log files\\\\\\\', default=500)\\\\n-    parser.add_argument(\\\\\\\'--batch_size\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Number of images to process in a batch.\\\\\\\', default=128)\\\\n-    parser.add_argument(\\\\\\\'--input_image_size\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Image size of input images (height, width) in pixels. If perceptual loss is used this \\\\\\\' \\\\n-        + \\\\\\\'should be the input image size for the perceptual loss model\\\\\\\', default=160)\\\\n-    parser.add_argument(\\\\\\\'--latent_var_size\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Dimensionality of the latent variable.\\\\\\\', default=100)\\\\n-    parser.add_argument(\\\\\\\'--initial_learning_rate\\\\\\\', type=float,\\\\n-        help=\\\\\\\'Initial learning rate.\\\\\\\', default=0.0005)\\\\n-    parser.add_argument(\\\\\\\'--learning_rate_decay_steps\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Number of steps between learning rate decay.\\\\\\\', default=1)\\\\n-    parser.add_argument(\\\\\\\'--learning_rate_decay_factor\\\\\\\', type=float,\\\\n-        help=\\\\\\\'Learning rate decay factor.\\\\\\\', default=1.0)\\\\n-    parser.add_argument(\\\\\\\'--seed\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Random seed.\\\\\\\', default=666)\\\\n-    parser.add_argument(\\\\\\\'--alfa\\\\\\\', type=float,\\\\n-        help=\\\\\\\'Kullback-Leibler divergence loss factor.\\\\\\\', default=1.0)\\\\n-    parser.add_argument(\\\\\\\'--beta\\\\\\\', type=float,\\\\n-        help=\\\\\\\'Reconstruction loss factor.\\\\\\\', default=0.5)\\\\n-    \\\\n-    return parser.parse_args(argv)\\\\n-  \\\\n-    \\\\n-if __name__ == \\\\\\\'__main__\\\\\\\':\\\\n-    main(parse_arguments(sys.argv[1:]))\\\\ndiff --git a/src/lfw.py b/src/lfw.py\\\\ndeleted file mode 100644\\\\nindex 9194433..0000000\\\\n--- a/src/lfw.py\\\\n+++ /dev/null\\\\n@@ -1,86 +0,0 @@\\\\n-"""Helper for evaluation on the Labeled Faces in the Wild dataset \\\\n-"""\\\\n-\\\\n-# MIT License\\\\n-# \\\\n-# Copyright (c) 2016 David Sandberg\\\\n-# \\\\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\n-# of this software and associated documentation files (the "Software"), to deal\\\\n-# in the Software without restriction, including without limitation the rights\\\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\n-# copies of the Software, and to permit persons to whom the Software is\\\\n-# furnished to do so, subject to the following conditions:\\\\n-# \\\\n-# The above copyright notice and this permission notice shall be included in all\\\\n-# copies or substantial portions of the Software.\\\\n-# \\\\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\n-# SOFTWARE.\\\\n-\\\\n-from __future__ import absolute_import\\\\n-from __future__ import division\\\\n-from __future__ import print_function\\\\n-\\\\n-import os\\\\n-import numpy as np\\\\n-import facenet\\\\n-\\\\n-def evaluate(embeddings, actual_issame, nrof_folds=10, distance_metric=0, subtract_mean=False):\\\\n-    # Calculate evaluation metrics\\\\n-    thresholds = np.arange(0, 4, 0.01)\\\\n-    embeddings1 = embeddings[0::2]\\\\n-    embeddings2 = embeddings[1::2]\\\\n-    tpr, fpr, accuracy = facenet.calculate_roc(thresholds, embeddings1, embeddings2,\\\\n-        np.asarray(actual_issame), nrof_folds=nrof_folds, distance_metric=distance_metric, subtract_mean=subtract_mean)\\\\n-    thresholds = np.arange(0, 4, 0.001)\\\\n-    val, val_std, far = facenet.calculate_val(thresholds, embeddings1, embeddings2,\\\\n-        np.asarray(actual_issame), 1e-3, nrof_folds=nrof_folds, distance_metric=distance_metric, subtract_mean=subtract_mean)\\\\n-    return tpr, fpr, accuracy, val, val_std, far\\\\n-\\\\n-def get_paths(lfw_dir, pairs):\\\\n-    nrof_skipped_pairs = 0\\\\n-    path_list = []\\\\n-    issame_list = []\\\\n-    for pair in pairs:\\\\n-        if len(pair) == 3:\\\\n-            path0 = add_extension(os.path.join(lfw_dir, pair[0], pair[0] + \\\\\\\'_\\\\\\\' + \\\\\\\'%04d\\\\\\\' % int(pair[1])))\\\\n-            path1 = add_extension(os.path.join(lfw_dir, pair[0], pair[0] + \\\\\\\'_\\\\\\\' + \\\\\\\'%04d\\\\\\\' % int(pair[2])))\\\\n-            issame = True\\\\n-        elif len(pair) == 4:\\\\n-            path0 = add_extension(os.path.join(lfw_dir, pair[0], pair[0] + \\\\\\\'_\\\\\\\' + \\\\\\\'%04d\\\\\\\' % int(pair[1])))\\\\n-            path1 = add_extension(os.path.join(lfw_dir, pair[2], pair[2] + \\\\\\\'_\\\\\\\' + \\\\\\\'%04d\\\\\\\' % int(pair[3])))\\\\n-            issame = False\\\\n-        if os.path.exists(path0) and os.path.exists(path1):    # Only add the pair if both paths exist\\\\n-            path_list += (path0,path1)\\\\n-            issame_list.append(issame)\\\\n-        else:\\\\n-            nrof_skipped_pairs += 1\\\\n-    if nrof_skipped_pairs>0:\\\\n-        print(\\\\\\\'Skipped %d image pairs\\\\\\\' % nrof_skipped_pairs)\\\\n-    \\\\n-    return path_list, issame_list\\\\n-  \\\\n-def add_extension(path):\\\\n-    if os.path.exists(path+\\\\\\\'.jpg\\\\\\\'):\\\\n-        return path+\\\\\\\'.jpg\\\\\\\'\\\\n-    elif os.path.exists(path+\\\\\\\'.png\\\\\\\'):\\\\n-        return path+\\\\\\\'.png\\\\\\\'\\\\n-    else:\\\\n-        raise RuntimeError(\\\\\\\'No file "%s" with extension png or jpg.\\\\\\\' % path)\\\\n-\\\\n-def read_pairs(pairs_filename):\\\\n-    pairs = []\\\\n-    with open(pairs_filename, \\\\\\\'r\\\\\\\') as f:\\\\n-        for line in f.readlines()[1:]:\\\\n-            pair = line.strip().split()\\\\n-            pairs.append(pair)\\\\n-    return np.array(pairs)\\\\n-\\\\n-\\\\n-\\\\ndiff --git a/src/main.py b/src/main.py\\\\nnew file mode 100644\\\\nindex 0000000..829b128\\\\n--- /dev/null\\\\n+++ b/src/main.py\\\\n@@ -0,0 +1,234 @@\\\\n+import cv2\\\\n+import numpy as np\\\\n+import os\\\\n+import tensorflow as tf\\\\n+import facenet\\\\n+import align.detect_face\\\\n+import pickle\\\\n+from tkinter import *\\\\n+from tkinter import filedialog\\\\n+from PIL import Image, ImageTk\\\\n+import tkinter as tk\\\\n+from deepface import DeepFace\\\\n+\\\\n+## code cat anh khuon mat tu anh goc :\\\\n+python src/align_dataset_mtcnn.py  Dataset/FaceData/raw Dataset/FaceData/processed --image_size 160 --margin 32  --random_order --gpu_memory_fraction 0.25\\\\n+## code tao model :\\\\n+#python src/classifier.py TRAIN Dataset/FaceData/processed Models/20180402-114759.pb Models/facemodel.pkl --batch_size 1000\\\\n+class FaceRecognitionApp:\\\\n+    def __init__(self, root):\\\\n+        self.root = root\\\\n+        self.root.title("Nh\\\\xe1\\\\xba\\\\xadn di\\\\xe1\\\\xbb\\\\x87n khu\\\\xc3\\\\xb4n m\\\\xe1\\\\xba\\\\xb7t")\\\\n+\\\\n+        # Load background image\\\\n+        background_image = Image.open(r"D:\\\\\\\\ma\\\\\\\\back.jpg")  # \\\\xc4\\\\x90\\\\xc6\\\\xb0\\\\xe1\\\\xbb\\\\x9dng d\\\\xe1\\\\xba\\\\xabn \\\\xc4\\\\x91\\\\xe1\\\\xba\\\\xbfn h\\\\xc3\\\\xacnh n\\\\xe1\\\\xbb\\\\x81n\\\\n+        bg_width, bg_height = background_image.size\\\\n+\\\\n+        # Set screen width and height\\\\n+        screen_width = 700\\\\n+        screen_height = 400\\\\n+\\\\n+        # Calculate scale factor for the background image\\\\n+        width_scale = screen_width / bg_width\\\\n+        height_scale = screen_height / bg_height\\\\n+        scale_factor = max(width_scale, height_scale)\\\\n+\\\\n+        # Resize background image to fit the screen\\\\n+        new_width = int(bg_width * scale_factor)\\\\n+        new_height = int(bg_height * scale_factor)\\\\n+        background_image = background_image.resize((new_width, new_height), Image.LANCZOS)\\\\n+\\\\n+        # Convert background image to PhotoImage\\\\n+        background_photo = ImageTk.PhotoImage(background_image)\\\\n+\\\\n+        # Create a label for the background image\\\\n+        background_label = Label(root, image=background_photo)\\\\n+        background_label.image = background_photo\\\\n+        background_label.place(x=0, y=0, relwidth=1, relheight=1)  # Fill the entire window\\\\n+\\\\n+        # Fix the size of the window\\\\n+        self.root.geometry(f"{screen_width}x{screen_height}+0+0")\\\\n+\\\\n+        # Load the face recognition model\\\\n+        self.load_model()\\\\n+\\\\n+        # Initialize image label\\\\n+        self.image_label = Label(root)\\\\n+        self.image_label.place(x=10, y=10)\\\\n+\\\\n+        # Initialize buttons\\\\n+        self.choose_image_button = Button(root, text="T\\\\xe1\\\\xba\\\\xa3i \\\\xe1\\\\xba\\\\xa3nh l\\\\xc3\\\\xaan", command=self.choose_image)\\\\n+        self.choose_image_button.pack(pady=5, anchor=NE)\\\\n+\\\\n+        self.detect_image_button = Button(root, text="Ki\\\\xe1\\\\xbb\\\\x83m tra h\\\\xc3\\\\xacnh \\\\xe1\\\\xba\\\\xa3nh", command=self.detect_faces_image)\\\\n+        self.detect_image_button.pack(pady=5, anchor=NE)\\\\n+\\\\n+        # Initialize buttons for camera and video\\\\n+        self.open_camera_button = Button(root, text="M\\\\xe1\\\\xbb\\\\x9f camera", command=self.open_camera)\\\\n+        self.open_camera_button.pack(pady=5, anchor=NE)\\\\n+        self.camera_opened = False\\\\n+\\\\n+        self.load_video_button = Button(root, text="T\\\\xe1\\\\xba\\\\xa3i video", command=self.load_video)\\\\n+        self.load_video_button.pack(pady=5, anchor=NE)\\\\n+        self.video_opened = False\\\\n+\\\\n+        # Initialize results label as a Text widget\\\\n+        self.results_label = Text(root, width=40, height=10)\\\\n+        self.results_label.pack(pady=5, anchor=NE)\\\\n+\\\\n+    def load_model(self):\\\\n+        # Load paths to classifier and FaceNet model\\\\n+        self.CLASSIFIER_PATH = \\\\\\\'../Models/facemodel.pkl\\\\\\\'  # \\\\xc4\\\\x90\\\\xc6\\\\xb0\\\\xe1\\\\xbb\\\\x9dng d\\\\xe1\\\\xba\\\\xabn \\\\xc4\\\\x91\\\\xe1\\\\xba\\\\xbfn file classifier\\\\n+        self.FACENET_MODEL_PATH = \\\\\\\'../Models/20180402-114759.pb\\\\\\\'  # \\\\xc4\\\\x90\\\\xc6\\\\xb0\\\\xe1\\\\xbb\\\\x9dng d\\\\xe1\\\\xba\\\\xabn \\\\xc4\\\\x91\\\\xe1\\\\xba\\\\xbfn file FaceNet model\\\\n+\\\\n+        # Load classifier model\\\\n+        with open(self.CLASSIFIER_PATH, \\\\\\\'rb\\\\\\\') as file:\\\\n+            self.model, self.class_names = pickle.load(file)\\\\n+        print("Loaded face recognition model")\\\\n+\\\\n+        # Load FaceNet model\\\\n+        with tf.Graph().as_default():\\\\n+            self.sess = tf.compat.v1.Session()\\\\n+            facenet.load_model(self.FACENET_MODEL_PATH)\\\\n+            self.images_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("input:0")\\\\n+            self.embeddings = tf.compat.v1.get_default_graph().get_tensor_by_name("embeddings:0")\\\\n+            self.phase_train_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("phase_train:0")\\\\n+            self.mtcnn_pnet, self.mtcnn_rnet, self.mtcnn_onet = align.detect_face.create_mtcnn(self.sess, None)\\\\n+\\\\n+    def choose_image(self):\\\\n+        self.image_path = filedialog.askopenfilename()\\\\n+        if self.image_path:\\\\n+            image_pil = Image.open(self.image_path)\\\\n+            resized_image = image_pil.resize((300, 300), Image.LANCZOS)\\\\n+            image = ImageTk.PhotoImage(resized_image)\\\\n+            self.image_label.configure(image=image)\\\\n+            self.image_label.image = image\\\\n+            self.results_label.delete(\\\\\\\'1.0\\\\\\\', END)  # Clear the results label\\\\n+\\\\n+    def detect_faces_image(self):\\\\n+        if hasattr(self, \\\\\\\'image_path\\\\\\\'):\\\\n+            image = cv2.imread(self.image_path)\\\\n+            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\\\\n+            self.detect_faces(image)\\\\n+\\\\n+    def detect_faces(self, image):\\\\n+        # Clear the detected names list before detecting new faces\\\\n+        self.detected_names = []\\\\n+        self.face_info_list = []\\\\n+        self.counter = 1  # Initialize counter for face numbering\\\\n+\\\\n+        bounding_boxes, _ = align.detect_face.detect_face(image, 20, self.mtcnn_pnet, self.mtcnn_rnet, self.mtcnn_onet,\\\\n+                                                          [0.6, 0.7, 0.7], 0.709)\\\\n+        faces_found = bounding_boxes.shape[0]\\\\n+\\\\n+        if faces_found > 0:\\\\n+            for bbox in bounding_boxes:\\\\n+                det = np.squeeze(bbox[0:4])\\\\n+                bb = np.zeros(4, dtype=np.int32)\\\\n+                bb[0] = np.maximum(det[0], 0)\\\\n+                bb[1] = np.maximum(det[1], 0)\\\\n+                bb[2] = np.minimum(det[2], image.shape[1])\\\\n+                bb[3] = np.minimum(det[3], image.shape[0])\\\\n+\\\\n+                cropped = image[bb[1]:bb[3], bb[0]:bb[2], :]\\\\n+                scaled = cv2.resize(cropped, (160, 160), interpolation=cv2.INTER_CUBIC)\\\\n+                scaled = facenet.prewhiten(scaled)\\\\n+                scaled_reshape = scaled.reshape(-1, 160, 160, 3)\\\\n+\\\\n+                feed_dict = {self.images_placeholder: scaled_reshape, self.phase_train_placeholder: False}\\\\n+                emb_array = self.sess.run(self.embeddings, feed_dict=feed_dict)\\\\n+                predictions = self.model.predict_proba(emb_array)\\\\n+                best_class_indices = np.argmax(predictions, axis=1)\\\\n+                best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\\\\n+\\\\n+                # Check if the best class probability is above a certain threshold\\\\n+                if best_class_probabilities >= 0.2:\\\\n+                    best_name = self.class_names[best_class_indices[0]]\\\\n+                else:\\\\n+                    best_name = "Ch\\\\xc6\\\\xb0a x\\\\xc3\\\\xa1c \\\\xc4\\\\x91\\\\xe1\\\\xbb\\\\x8bnh"\\\\n+\\\\n+                cv2.rectangle(image, (bb[0], bb[1]), (bb[2], bb[3]), (0, 255, 0), 2)\\\\n+\\\\n+                # Draw number on the image\\\\n+                if self.counter >= 1:\\\\n+                    cv2.putText(image, str(self.counter), (bb[0], bb[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255),\\\\n+                                2, cv2.LINE_AA)\\\\n+\\\\n+                # Add the detected face names to the list\\\\n+                if self.counter >= 1:\\\\n+                    self.detected_names.append(f"  {self.counter}: {best_name}")\\\\n+                else:\\\\n+                    self.detected_names.append(best_name)\\\\n+\\\\n+                self.counter += 1  # Increment the counter\\\\n+\\\\n+            image = Image.fromarray(image)\\\\n+            image = ImageTk.PhotoImage(image.resize((300, 300), Image.LANCZOS))\\\\n+            self.image_label.configure(image=image)\\\\n+            self.image_label.image = image\\\\n+            self.results_label.delete(\\\\\\\'1.0\\\\\\\', END)  # Clear the results label\\\\n+            self.results_label.insert(END, "T\\\\xc3\\\\xaan khu\\\\xc3\\\\xb4n m\\\\xe1\\\\xba\\\\xb7t \\\\xc4\\\\x91\\\\xc6\\\\xb0\\\\xe1\\\\xbb\\\\xa3c nh\\\\xe1\\\\xba\\\\xadn d\\\\xe1\\\\xba\\\\xa1ng:\\\\\\\\n" + "\\\\\\\\n".join(self.detected_names))\\\\n+        else:\\\\n+            self.results_label.delete(\\\\\\\'1.0\\\\\\\', END)\\\\n+            self.results_label.insert(END, "Kh\\\\xc3\\\\xb4ng c\\\\xc3\\\\xb3 khu\\\\xc3\\\\xb4n m\\\\xe1\\\\xba\\\\xb7t \\\\xc4\\\\x91\\\\xc6\\\\xb0\\\\xe1\\\\xbb\\\\xa3c ph\\\\xc3\\\\xa1t hi\\\\xe1\\\\xbb\\\\x87n.")\\\\n+\\\\n+    def open_camera(self):\\\\n+        if not self.camera_opened:\\\\n+            self.cap = cv2.VideoCapture(0)\\\\n+            self.camera_opened = True\\\\n+            self.open_camera_button.config(text="T\\\\xe1\\\\xba\\\\xaft Camera")\\\\n+            self.detect_faces_camera(self.cap)\\\\n+        else:\\\\n+            self.camera_opened = False\\\\n+            self.cap.release()\\\\n+            self.open_camera_button.config(text="M\\\\xe1\\\\xbb\\\\x9f Camera")\\\\n+\\\\n+    def load_video(self):\\\\n+        if not self.video_opened:\\\\n+            video_path = filedialog.askopenfilename()\\\\n+            if video_path:\\\\n+                self.cap = cv2.VideoCapture(video_path)\\\\n+                self.video_opened = True\\\\n+                self.load_video_button.config(text="D\\\\xe1\\\\xbb\\\\xabng video")\\\\n+                self.detect_faces_camera(self.cap)\\\\n+        else:\\\\n+            self.video_opened = False\\\\n+            self.cap.release()\\\\n+            self.load_video_button.config(text="T\\\\xe1\\\\xba\\\\xa3i video ")\\\\n+\\\\n+    def detect_faces_camera(self, cap):\\\\n+        self.camera_window = tk.Toplevel(self.root)  # S\\\\xe1\\\\xbb\\\\xad d\\\\xe1\\\\xbb\\\\xa5ng self.root thay v\\\\xc3\\\\xac self.master\\\\n+        self.camera_window.title("Cam v\\\\xc3\\\\xa0 xem video ")\\\\n+\\\\n+        self.image_label = tk.Label(self.camera_window)\\\\n+        self.image_label.pack()\\\\n+\\\\n+        while cap.isOpened():\\\\n+            ret, frame = cap.read()\\\\n+            if ret:\\\\n+                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\\\\n+                self.detect_faces(frame)\\\\n+\\\\n+                frame = Image.fromarray(frame)\\\\n+                frame = ImageTk.PhotoImage(frame.resize((300, 300), Image.LANCZOS))\\\\n+                self.image_label.configure(image=frame)\\\\n+                self.image_label.image = frame\\\\n+\\\\n+                self.camera_window.update()\\\\n+\\\\n+                if cv2.waitKey(1) & 0xFF == ord(\\\\\\\'q\\\\\\\'):\\\\n+                    break\\\\n+            else:\\\\n+                break\\\\n+\\\\n+        cap.release()\\\\n+        cv2.destroyAllWindows()\\\\n+\\\\n+\\\\n+def main():\\\\n+    root = Tk()\\\\n+    app = FaceRecognitionApp(root)\\\\n+    root.mainloop()\\\\n+\\\\n+if __name__ == "__main__":\\\\n+    main()\\\\ndiff --git a/src/models/__init__.py b/src/models/__init__.py\\\\ndeleted file mode 100644\\\\nindex efa6252..0000000\\\\n--- a/src/models/__init__.py\\\\n+++ /dev/null\\\\n@@ -1,2 +0,0 @@\\\\n-# flake8: noqa\\\\n-\\\\ndiff --git a/src/models/a b/src/models/a\\\\ndeleted file mode 100644\\\\nindex 8b13789..0000000\\\\n--- a/src/models/a\\\\n+++ /dev/null\\\\n@@ -1 +0,0 @@\\\\n-\\\\ndiff --git a/src/models/dummy.py b/src/models/dummy.py\\\\ndeleted file mode 100644\\\\nindex 7afe1ef..0000000\\\\n--- a/src/models/dummy.py\\\\n+++ /dev/null\\\\n@@ -1,54 +0,0 @@\\\\n-"""Dummy model used only for testing\\\\n-"""\\\\n-# MIT License\\\\n-# \\\\n-# Copyright (c) 2016 David Sandberg\\\\n-# \\\\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\n-# of this software and associated documentation files (the "Software"), to deal\\\\n-# in the Software without restriction, including without limitation the rights\\\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\n-# copies of the Software, and to permit persons to whom the Software is\\\\n-# furnished to do so, subject to the following conditions:\\\\n-# \\\\n-# The above copyright notice and this permission notice shall be included in all\\\\n-# copies or substantial portions of the Software.\\\\n-# \\\\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\n-# SOFTWARE.\\\\n-\\\\n-from __future__ import absolute_import\\\\n-from __future__ import division\\\\n-from __future__ import print_function\\\\n-\\\\n-import tensorflow as tf\\\\n-import tensorflow.contrib.slim as slim\\\\n-import numpy as np\\\\n-  \\\\n-def inference(images, keep_probability, phase_train=True,  # @UnusedVariable\\\\n-              bottleneck_layer_size=128, bottleneck_layer_activation=None, weight_decay=0.0, reuse=None):  # @UnusedVariable\\\\n-    batch_norm_params = {\\\\n-        # Decay for the moving averages.\\\\n-        \\\\\\\'decay\\\\\\\': 0.995,\\\\n-        # epsilon to prevent 0s in variance.\\\\n-        \\\\\\\'epsilon\\\\\\\': 0.001,\\\\n-        # force in-place updates of mean and variance estimates\\\\n-        \\\\\\\'updates_collections\\\\\\\': None,\\\\n-        # Moving averages ends up in the trainable variables collection\\\\n-        \\\\\\\'variables_collections\\\\\\\': [ tf.GraphKeys.TRAINABLE_VARIABLES ],\\\\n-    }\\\\n-    \\\\n-    with slim.arg_scope([slim.conv2d, slim.fully_connected],\\\\n-                        weights_initializer=tf.truncated_normal_initializer(stddev=0.1),\\\\n-                        weights_regularizer=slim.l2_regularizer(weight_decay),\\\\n-                        normalizer_fn=slim.batch_norm,\\\\n-                        normalizer_params=batch_norm_params):\\\\n-        size = np.prod(images.get_shape()[1:].as_list())\\\\n-        net = slim.fully_connected(tf.reshape(images, (-1,size)), bottleneck_layer_size, activation_fn=None, \\\\n-                scope=\\\\\\\'Bottleneck\\\\\\\', reuse=False)\\\\n-        return net, None\\\\ndiff --git a/src/models/inception_resnet_v1.py b/src/models/inception_resnet_v1.py\\\\ndeleted file mode 100644\\\\nindex 475e81b..0000000\\\\n--- a/src/models/inception_resnet_v1.py\\\\n+++ /dev/null\\\\n@@ -1,246 +0,0 @@\\\\n-# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\\\\n-#\\\\n-# Licensed under the Apache License, Version 2.0 (the "License");\\\\n-# you may not use this file except in compliance with the License.\\\\n-# You may obtain a copy of the License at\\\\n-#\\\\n-# http://www.apache.org/licenses/LICENSE-2.0\\\\n-#\\\\n-# Unless required by applicable law or agreed to in writing, software\\\\n-# distributed under the License is distributed on an "AS IS" BASIS,\\\\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\\\n-# See the License for the specific language governing permissions and\\\\n-# limitations under the License.\\\\n-# ==============================================================================\\\\n-\\\\n-"""Contains the definition of the Inception Resnet V1 architecture.\\\\n-As described in http://arxiv.org/abs/1602.07261.\\\\n-  Inception-v4, Inception-ResNet and the Impact of Residual Connections\\\\n-    on Learning\\\\n-  Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alex Alemi\\\\n-"""\\\\n-from __future__ import absolute_import\\\\n-from __future__ import division\\\\n-from __future__ import print_function\\\\n-\\\\n-import tensorflow as tf\\\\n-import tensorflow.contrib.slim as slim\\\\n-\\\\n-# Inception-Resnet-A\\\\n-def block35(net, scale=1.0, activation_fn=tf.nn.relu, scope=None, reuse=None):\\\\n-    """Builds the 35x35 resnet block."""\\\\n-    with tf.variable_scope(scope, \\\\\\\'Block35\\\\\\\', [net], reuse=reuse):\\\\n-        with tf.variable_scope(\\\\\\\'Branch_0\\\\\\\'):\\\\n-            tower_conv = slim.conv2d(net, 32, 1, scope=\\\\\\\'Conv2d_1x1\\\\\\\')\\\\n-        with tf.variable_scope(\\\\\\\'Branch_1\\\\\\\'):\\\\n-            tower_conv1_0 = slim.conv2d(net, 32, 1, scope=\\\\\\\'Conv2d_0a_1x1\\\\\\\')\\\\n-            tower_conv1_1 = slim.conv2d(tower_conv1_0, 32, 3, scope=\\\\\\\'Conv2d_0b_3x3\\\\\\\')\\\\n-        with tf.variable_scope(\\\\\\\'Branch_2\\\\\\\'):\\\\n-            tower_conv2_0 = slim.conv2d(net, 32, 1, scope=\\\\\\\'Conv2d_0a_1x1\\\\\\\')\\\\n-            tower_conv2_1 = slim.conv2d(tower_conv2_0, 32, 3, scope=\\\\\\\'Conv2d_0b_3x3\\\\\\\')\\\\n-            tower_conv2_2 = slim.conv2d(tower_conv2_1, 32, 3, scope=\\\\\\\'Conv2d_0c_3x3\\\\\\\')\\\\n-        mixed = tf.concat([tower_conv, tower_conv1_1, tower_conv2_2], 3)\\\\n-        up = slim.conv2d(mixed, net.get_shape()[3], 1, normalizer_fn=None,\\\\n-                         activation_fn=None, scope=\\\\\\\'Conv2d_1x1\\\\\\\')\\\\n-        net += scale * up\\\\n-        if activation_fn:\\\\n-            net = activation_fn(net)\\\\n-    return net\\\\n-\\\\n-# Inception-Resnet-B\\\\n-def block17(net, scale=1.0, activation_fn=tf.nn.relu, scope=None, reuse=None):\\\\n-    """Builds the 17x17 resnet block."""\\\\n-    with tf.variable_scope(scope, \\\\\\\'Block17\\\\\\\', [net], reuse=reuse):\\\\n-        with tf.variable_scope(\\\\\\\'Branch_0\\\\\\\'):\\\\n-            tower_conv = slim.conv2d(net, 128, 1, scope=\\\\\\\'Conv2d_1x1\\\\\\\')\\\\n-        with tf.variable_scope(\\\\\\\'Branch_1\\\\\\\'):\\\\n-            tower_conv1_0 = slim.conv2d(net, 128, 1, scope=\\\\\\\'Conv2d_0a_1x1\\\\\\\')\\\\n-            tower_conv1_1 = slim.conv2d(tower_conv1_0, 128, [1, 7],\\\\n-                                        scope=\\\\\\\'Conv2d_0b_1x7\\\\\\\')\\\\n-            tower_conv1_2 = slim.conv2d(tower_conv1_1, 128, [7, 1],\\\\n-                                        scope=\\\\\\\'Conv2d_0c_7x1\\\\\\\')\\\\n-        mixed = tf.concat([tower_conv, tower_conv1_2], 3)\\\\n-        up = slim.conv2d(mixed, net.get_shape()[3], 1, normalizer_fn=None,\\\\n-                         activation_fn=None, scope=\\\\\\\'Conv2d_1x1\\\\\\\')\\\\n-        net += scale * up\\\\n-        if activation_fn:\\\\n-            net = activation_fn(net)\\\\n-    return net\\\\n-\\\\n-\\\\n-# Inception-Resnet-C\\\\n-def block8(net, scale=1.0, activation_fn=tf.nn.relu, scope=None, reuse=None):\\\\n-    """Builds the 8x8 resnet block."""\\\\n-    with tf.variable_scope(scope, \\\\\\\'Block8\\\\\\\', [net], reuse=reuse):\\\\n-        with tf.variable_scope(\\\\\\\'Branch_0\\\\\\\'):\\\\n-            tower_conv = slim.conv2d(net, 192, 1, scope=\\\\\\\'Conv2d_1x1\\\\\\\')\\\\n-        with tf.variable_scope(\\\\\\\'Branch_1\\\\\\\'):\\\\n-            tower_conv1_0 = slim.conv2d(net, 192, 1, scope=\\\\\\\'Conv2d_0a_1x1\\\\\\\')\\\\n-            tower_conv1_1 = slim.conv2d(tower_conv1_0, 192, [1, 3],\\\\n-                                        scope=\\\\\\\'Conv2d_0b_1x3\\\\\\\')\\\\n-            tower_conv1_2 = slim.conv2d(tower_conv1_1, 192, [3, 1],\\\\n-                                        scope=\\\\\\\'Conv2d_0c_3x1\\\\\\\')\\\\n-        mixed = tf.concat([tower_conv, tower_conv1_2], 3)\\\\n-        up = slim.conv2d(mixed, net.get_shape()[3], 1, normalizer_fn=None,\\\\n-                         activation_fn=None, scope=\\\\\\\'Conv2d_1x1\\\\\\\')\\\\n-        net += scale * up\\\\n-        if activation_fn:\\\\n-            net = activation_fn(net)\\\\n-    return net\\\\n-  \\\\n-def reduction_a(net, k, l, m, n):\\\\n-    with tf.variable_scope(\\\\\\\'Branch_0\\\\\\\'):\\\\n-        tower_conv = slim.conv2d(net, n, 3, stride=2, padding=\\\\\\\'VALID\\\\\\\',\\\\n-                                 scope=\\\\\\\'Conv2d_1a_3x3\\\\\\\')\\\\n-    with tf.variable_scope(\\\\\\\'Branch_1\\\\\\\'):\\\\n-        tower_conv1_0 = slim.conv2d(net, k, 1, scope=\\\\\\\'Conv2d_0a_1x1\\\\\\\')\\\\n-        tower_conv1_1 = slim.conv2d(tower_conv1_0, l, 3,\\\\n-                                    scope=\\\\\\\'Conv2d_0b_3x3\\\\\\\')\\\\n-        tower_conv1_2 = slim.conv2d(tower_conv1_1, m, 3,\\\\n-                                    stride=2, padding=\\\\\\\'VALID\\\\\\\',\\\\n-                                    scope=\\\\\\\'Conv2d_1a_3x3\\\\\\\')\\\\n-    with tf.variable_scope(\\\\\\\'Branch_2\\\\\\\'):\\\\n-        tower_pool = slim.max_pool2d(net, 3, stride=2, padding=\\\\\\\'VALID\\\\\\\',\\\\n-                                     scope=\\\\\\\'MaxPool_1a_3x3\\\\\\\')\\\\n-    net = tf.concat([tower_conv, tower_conv1_2, tower_pool], 3)\\\\n-    return net\\\\n-\\\\n-def reduction_b(net):\\\\n-    with tf.variable_scope(\\\\\\\'Branch_0\\\\\\\'):\\\\n-        tower_conv = slim.conv2d(net, 256, 1, scope=\\\\\\\'Conv2d_0a_1x1\\\\\\\')\\\\n-        tower_conv_1 = slim.conv2d(tower_conv, 384, 3, stride=2,\\\\n-                                   padding=\\\\\\\'VALID\\\\\\\', scope=\\\\\\\'Conv2d_1a_3x3\\\\\\\')\\\\n-    with tf.variable_scope(\\\\\\\'Branch_1\\\\\\\'):\\\\n-        tower_conv1 = slim.conv2d(net, 256, 1, scope=\\\\\\\'Conv2d_0a_1x1\\\\\\\')\\\\n-        tower_conv1_1 = slim.conv2d(tower_conv1, 256, 3, stride=2,\\\\n-                                    padding=\\\\\\\'VALID\\\\\\\', scope=\\\\\\\'Conv2d_1a_3x3\\\\\\\')\\\\n-    with tf.variable_scope(\\\\\\\'Branch_2\\\\\\\'):\\\\n-        tower_conv2 = slim.conv2d(net, 256, 1, scope=\\\\\\\'Conv2d_0a_1x1\\\\\\\')\\\\n-        tower_conv2_1 = slim.conv2d(tower_conv2, 256, 3,\\\\n-                                    scope=\\\\\\\'Conv2d_0b_3x3\\\\\\\')\\\\n-        tower_conv2_2 = slim.conv2d(tower_conv2_1, 256, 3, stride=2,\\\\n-                                    padding=\\\\\\\'VALID\\\\\\\', scope=\\\\\\\'Conv2d_1a_3x3\\\\\\\')\\\\n-    with tf.variable_scope(\\\\\\\'Branch_3\\\\\\\'):\\\\n-        tower_pool = slim.max_pool2d(net, 3, stride=2, padding=\\\\\\\'VALID\\\\\\\',\\\\n-                                     scope=\\\\\\\'MaxPool_1a_3x3\\\\\\\')\\\\n-    net = tf.concat([tower_conv_1, tower_conv1_1,\\\\n-                        tower_conv2_2, tower_pool], 3)\\\\n-    return net\\\\n-  \\\\n-def inference(images, keep_probability, phase_train=True, \\\\n-              bottleneck_layer_size=128, weight_decay=0.0, reuse=None):\\\\n-    batch_norm_params = {\\\\n-        # Decay for the moving averages.\\\\n-        \\\\\\\'decay\\\\\\\': 0.995,\\\\n-        # epsilon to prevent 0s in variance.\\\\n-        \\\\\\\'epsilon\\\\\\\': 0.001,\\\\n-        # force in-place updates of mean and variance estimates\\\\n-        \\\\\\\'updates_collections\\\\\\\': None,\\\\n-        # Moving averages ends up in the trainable variables collection\\\\n-        \\\\\\\'variables_collections\\\\\\\': [ tf.GraphKeys.TRAINABLE_VARIABLES ],\\\\n-    }\\\\n-    \\\\n-    with slim.arg_scope([slim.conv2d, slim.fully_connected],\\\\n-                        weights_initializer=slim.initializers.xavier_initializer(), \\\\n-                        weights_regularizer=slim.l2_regularizer(weight_decay),\\\\n-                        normalizer_fn=slim.batch_norm,\\\\n-                        normalizer_params=batch_norm_params):\\\\n-        return inception_resnet_v1(images, is_training=phase_train,\\\\n-              dropout_keep_prob=keep_probability, bottleneck_layer_size=bottleneck_layer_size, reuse=reuse)\\\\n-\\\\n-\\\\n-def inception_resnet_v1(inputs, is_training=True,\\\\n-                        dropout_keep_prob=0.8,\\\\n-                        bottleneck_layer_size=128,\\\\n-                        reuse=None, \\\\n-                        scope=\\\\\\\'InceptionResnetV1\\\\\\\'):\\\\n-    """Creates the Inception Resnet V1 model.\\\\n-    Args:\\\\n-      inputs: a 4-D tensor of size [batch_size, height, width, 3].\\\\n-      num_classes: number of predicted classes.\\\\n-      is_training: whether is training or not.\\\\n-      dropout_keep_prob: float, the fraction to keep before final layer.\\\\n-      reuse: whether or not the network and its variables should be reused. To be\\\\n-        able to reuse \\\\\\\'scope\\\\\\\' must be given.\\\\n-      scope: Optional variable_scope.\\\\n-    Returns:\\\\n-      logits: the logits outputs of the model.\\\\n-      end_points: the set of end_points from the inception model.\\\\n-    """\\\\n-    end_points = {}\\\\n-  \\\\n-    with tf.variable_scope(scope, \\\\\\\'InceptionResnetV1\\\\\\\', [inputs], reuse=reuse):\\\\n-        with slim.arg_scope([slim.batch_norm, slim.dropout],\\\\n-                            is_training=is_training):\\\\n-            with slim.arg_scope([slim.conv2d, slim.max_pool2d, slim.avg_pool2d],\\\\n-                                stride=1, padding=\\\\\\\'SAME\\\\\\\'):\\\\n-      \\\\n-                # 149 x 149 x 32\\\\n-                net = slim.conv2d(inputs, 32, 3, stride=2, padding=\\\\\\\'VALID\\\\\\\',\\\\n-                                  scope=\\\\\\\'Conv2d_1a_3x3\\\\\\\')\\\\n-                end_points[\\\\\\\'Conv2d_1a_3x3\\\\\\\'] = net\\\\n-                # 147 x 147 x 32\\\\n-                net = slim.conv2d(net, 32, 3, padding=\\\\\\\'VALID\\\\\\\',\\\\n-                                  scope=\\\\\\\'Conv2d_2a_3x3\\\\\\\')\\\\n-                end_points[\\\\\\\'Conv2d_2a_3x3\\\\\\\'] = net\\\\n-                # 147 x 147 x 64\\\\n-                net = slim.conv2d(net, 64, 3, scope=\\\\\\\'Conv2d_2b_3x3\\\\\\\')\\\\n-                end_points[\\\\\\\'Conv2d_2b_3x3\\\\\\\'] = net\\\\n-                # 73 x 73 x 64\\\\n-                net = slim.max_pool2d(net, 3, stride=2, padding=\\\\\\\'VALID\\\\\\\',\\\\n-                                      scope=\\\\\\\'MaxPool_3a_3x3\\\\\\\')\\\\n-                end_points[\\\\\\\'MaxPool_3a_3x3\\\\\\\'] = net\\\\n-                # 73 x 73 x 80\\\\n-                net = slim.conv2d(net, 80, 1, padding=\\\\\\\'VALID\\\\\\\',\\\\n-                                  scope=\\\\\\\'Conv2d_3b_1x1\\\\\\\')\\\\n-                end_points[\\\\\\\'Conv2d_3b_1x1\\\\\\\'] = net\\\\n-                # 71 x 71 x 192\\\\n-                net = slim.conv2d(net, 192, 3, padding=\\\\\\\'VALID\\\\\\\',\\\\n-                                  scope=\\\\\\\'Conv2d_4a_3x3\\\\\\\')\\\\n-                end_points[\\\\\\\'Conv2d_4a_3x3\\\\\\\'] = net\\\\n-                # 35 x 35 x 256\\\\n-                net = slim.conv2d(net, 256, 3, stride=2, padding=\\\\\\\'VALID\\\\\\\',\\\\n-                                  scope=\\\\\\\'Conv2d_4b_3x3\\\\\\\')\\\\n-                end_points[\\\\\\\'Conv2d_4b_3x3\\\\\\\'] = net\\\\n-                \\\\n-                # 5 x Inception-resnet-A\\\\n-                net = slim.repeat(net, 5, block35, scale=0.17)\\\\n-                end_points[\\\\\\\'Mixed_5a\\\\\\\'] = net\\\\n-        \\\\n-                # Reduction-A\\\\n-                with tf.variable_scope(\\\\\\\'Mixed_6a\\\\\\\'):\\\\n-                    net = reduction_a(net, 192, 192, 256, 384)\\\\n-                end_points[\\\\\\\'Mixed_6a\\\\\\\'] = net\\\\n-                \\\\n-                # 10 x Inception-Resnet-B\\\\n-                net = slim.repeat(net, 10, block17, scale=0.10)\\\\n-                end_points[\\\\\\\'Mixed_6b\\\\\\\'] = net\\\\n-                \\\\n-                # Reduction-B\\\\n-                with tf.variable_scope(\\\\\\\'Mixed_7a\\\\\\\'):\\\\n-                    net = reduction_b(net)\\\\n-                end_points[\\\\\\\'Mixed_7a\\\\\\\'] = net\\\\n-                \\\\n-                # 5 x Inception-Resnet-C\\\\n-                net = slim.repeat(net, 5, block8, scale=0.20)\\\\n-                end_points[\\\\\\\'Mixed_8a\\\\\\\'] = net\\\\n-                \\\\n-                net = block8(net, activation_fn=None)\\\\n-                end_points[\\\\\\\'Mixed_8b\\\\\\\'] = net\\\\n-                \\\\n-                with tf.variable_scope(\\\\\\\'Logits\\\\\\\'):\\\\n-                    end_points[\\\\\\\'PrePool\\\\\\\'] = net\\\\n-                    #pylint: disable=no-member\\\\n-                    net = slim.avg_pool2d(net, net.get_shape()[1:3], padding=\\\\\\\'VALID\\\\\\\',\\\\n-                                          scope=\\\\\\\'AvgPool_1a_8x8\\\\\\\')\\\\n-                    net = slim.flatten(net)\\\\n-          \\\\n-                    net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\\\\n-                                       scope=\\\\\\\'Dropout\\\\\\\')\\\\n-          \\\\n-                    end_points[\\\\\\\'PreLogitsFlatten\\\\\\\'] = net\\\\n-                \\\\n-                net = slim.fully_connected(net, bottleneck_layer_size, activation_fn=None, \\\\n-                        scope=\\\\\\\'Bottleneck\\\\\\\', reuse=False)\\\\n-  \\\\n-    return net, end_points\\\\ndiff --git a/src/models/inception_resnet_v2.py b/src/models/inception_resnet_v2.py\\\\ndeleted file mode 100644\\\\nindex 0fb176f..0000000\\\\n--- a/src/models/inception_resnet_v2.py\\\\n+++ /dev/null\\\\n@@ -1,255 +0,0 @@\\\\n-# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\\\\n-#\\\\n-# Licensed under the Apache License, Version 2.0 (the "License");\\\\n-# you may not use this file except in compliance with the License.\\\\n-# You may obtain a copy of the License at\\\\n-#\\\\n-# http://www.apache.org/licenses/LICENSE-2.0\\\\n-#\\\\n-# Unless required by applicable law or agreed to in writing, software\\\\n-# distributed under the License is distributed on an "AS IS" BASIS,\\\\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\\\\n-# See the License for the specific language governing permissions and\\\\n-# limitations under the License.\\\\n-# ==============================================================================\\\\n-\\\\n-"""Contains the definition of the Inception Resnet V2 architecture.\\\\n-As described in http://arxiv.org/abs/1602.07261.\\\\n-  Inception-v4, Inception-ResNet and the Impact of Residual Connections\\\\n-    on Learning\\\\n-  Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alex Alemi\\\\n-"""\\\\n-from __future__ import absolute_import\\\\n-from __future__ import division\\\\n-from __future__ import print_function\\\\n-\\\\n-import tensorflow as tf\\\\n-import tensorflow.contrib.slim as slim\\\\n-\\\\n-# Inception-Resnet-A\\\\n-def block35(net, scale=1.0, activation_fn=tf.nn.relu, scope=None, reuse=None):\\\\n-    """Builds the 35x35 resnet block."""\\\\n-    with tf.variable_scope(scope, \\\\\\\'Block35\\\\\\\', [net], reuse=reuse):\\\\n-        with tf.variable_scope(\\\\\\\'Branch_0\\\\\\\'):\\\\n-            tower_conv = slim.conv2d(net, 32, 1, scope=\\\\\\\'Conv2d_1x1\\\\\\\')\\\\n-        with tf.variable_scope(\\\\\\\'Branch_1\\\\\\\'):\\\\n-            tower_conv1_0 = slim.conv2d(net, 32, 1, scope=\\\\\\\'Conv2d_0a_1x1\\\\\\\')\\\\n-            tower_conv1_1 = slim.conv2d(tower_conv1_0, 32, 3, scope=\\\\\\\'Conv2d_0b_3x3\\\\\\\')\\\\n-        with tf.variable_scope(\\\\\\\'Branch_2\\\\\\\'):\\\\n-            tower_conv2_0 = slim.conv2d(net, 32, 1, scope=\\\\\\\'Conv2d_0a_1x1\\\\\\\')\\\\n-            tower_conv2_1 = slim.conv2d(tower_conv2_0, 48, 3, scope=\\\\\\\'Conv2d_0b_3x3\\\\\\\')\\\\n-            tower_conv2_2 = slim.conv2d(tower_conv2_1, 64, 3, scope=\\\\\\\'Conv2d_0c_3x3\\\\\\\')\\\\n-        mixed = tf.concat([tower_conv, tower_conv1_1, tower_conv2_2], 3)\\\\n-        up = slim.conv2d(mixed, net.get_shape()[3], 1, normalizer_fn=None,\\\\n-                         activation_fn=None, scope=\\\\\\\'Conv2d_1x1\\\\\\\')\\\\n-        net += scale * up\\\\n-        if activation_fn:\\\\n-            net = activation_fn(net)\\\\n-    return net\\\\n-\\\\n-# Inception-Resnet-B\\\\n-def block17(net, scale=1.0, activation_fn=tf.nn.relu, scope=None, reuse=None):\\\\n-    """Builds the 17x17 resnet block."""\\\\n-    with tf.variable_scope(scope, \\\\\\\'Block17\\\\\\\', [net], reuse=reuse):\\\\n-        with tf.variable_scope(\\\\\\\'Branch_0\\\\\\\'):\\\\n-            tower_conv = slim.conv2d(net, 192, 1, scope=\\\\\\\'Conv2d_1x1\\\\\\\')\\\\n-        with tf.variable_scope(\\\\\\\'Branch_1\\\\\\\'):\\\\n-            tower_conv1_0 = slim.conv2d(net, 128, 1, scope=\\\\\\\'Conv2d_0a_1x1\\\\\\\')\\\\n-            tower_conv1_1 = slim.conv2d(tower_conv1_0, 160, [1, 7],\\\\n-                                        scope=\\\\\\\'Conv2d_0b_1x7\\\\\\\')\\\\n-            tower_conv1_2 = slim.conv2d(tower_conv1_1, 192, [7, 1],\\\\n-                                        scope=\\\\\\\'Conv2d_0c_7x1\\\\\\\')\\\\n-        mixed = tf.concat([tower_conv, tower_conv1_2], 3)\\\\n-        up = slim.conv2d(mixed, net.get_shape()[3], 1, normalizer_fn=None,\\\\n-                         activation_fn=None, scope=\\\\\\\'Conv2d_1x1\\\\\\\')\\\\n-        net += scale * up\\\\n-        if activation_fn:\\\\n-            net = activation_fn(net)\\\\n-    return net\\\\n-\\\\n-\\\\n-# Inception-Resnet-C\\\\n-def block8(net, scale=1.0, activation_fn=tf.nn.relu, scope=None, reuse=None):\\\\n-    """Builds the 8x8 resnet block."""\\\\n-    with tf.variable_scope(scope, \\\\\\\'Block8\\\\\\\', [net], reuse=reuse):\\\\n-        with tf.variable_scope(\\\\\\\'Branch_0\\\\\\\'):\\\\n-            tower_conv = slim.conv2d(net, 192, 1, scope=\\\\\\\'Conv2d_1x1\\\\\\\')\\\\n-        with tf.variable_scope(\\\\\\\'Branch_1\\\\\\\'):\\\\n-            tower_conv1_0 = slim.conv2d(net, 192, 1, scope=\\\\\\\'Conv2d_0a_1x1\\\\\\\')\\\\n-            tower_conv1_1 = slim.conv2d(tower_conv1_0, 224, [1, 3],\\\\n-                                        scope=\\\\\\\'Conv2d_0b_1x3\\\\\\\')\\\\n-            tower_conv1_2 = slim.conv2d(tower_conv1_1, 256, [3, 1],\\\\n-                                        scope=\\\\\\\'Conv2d_0c_3x1\\\\\\\')\\\\n-        mixed = tf.concat([tower_conv, tower_conv1_2], 3)\\\\n-        up = slim.conv2d(mixed, net.get_shape()[3], 1, normalizer_fn=None,\\\\n-                         activation_fn=None, scope=\\\\\\\'Conv2d_1x1\\\\\\\')\\\\n-        net += scale * up\\\\n-        if activation_fn:\\\\n-            net = activation_fn(net)\\\\n-    return net\\\\n-  \\\\n-def inference(images, keep_probability, phase_train=True, \\\\n-              bottleneck_layer_size=128, weight_decay=0.0, reuse=None):\\\\n-    batch_norm_params = {\\\\n-        # Decay for the moving averages.\\\\n-        \\\\\\\'decay\\\\\\\': 0.995,\\\\n-        # epsilon to prevent 0s in variance.\\\\n-        \\\\\\\'epsilon\\\\\\\': 0.001,\\\\n-        # force in-place updates of mean and variance estimates\\\\n-        \\\\\\\'updates_collections\\\\\\\': None,\\\\n-        # Moving averages ends up in the trainable variables collection\\\\n-        \\\\\\\'variables_collections\\\\\\\': [ tf.GraphKeys.TRAINABLE_VARIABLES ],\\\\n-}\\\\n-    with slim.arg_scope([slim.conv2d, slim.fully_connected],\\\\n-                        weights_initializer=slim.initializers.xavier_initializer(), \\\\n-                        weights_regularizer=slim.l2_regularizer(weight_decay),\\\\n-                        normalizer_fn=slim.batch_norm,\\\\n-                        normalizer_params=batch_norm_params):\\\\n-        return inception_resnet_v2(images, is_training=phase_train,\\\\n-              dropout_keep_prob=keep_probability, bottleneck_layer_size=bottleneck_layer_size, reuse=reuse)\\\\n-\\\\n-\\\\n-def inception_resnet_v2(inputs, is_training=True,\\\\n-                        dropout_keep_prob=0.8,\\\\n-                        bottleneck_layer_size=128,\\\\n-                        reuse=None,\\\\n-                        scope=\\\\\\\'InceptionResnetV2\\\\\\\'):\\\\n-    """Creates the Inception Resnet V2 model.\\\\n-    Args:\\\\n-      inputs: a 4-D tensor of size [batch_size, height, width, 3].\\\\n-      num_classes: number of predicted classes.\\\\n-      is_training: whether is training or not.\\\\n-      dropout_keep_prob: float, the fraction to keep before final layer.\\\\n-      reuse: whether or not the network and its variables should be reused. To be\\\\n-        able to reuse \\\\\\\'scope\\\\\\\' must be given.\\\\n-      scope: Optional variable_scope.\\\\n-    Returns:\\\\n-      logits: the logits outputs of the model.\\\\n-      end_points: the set of end_points from the inception model.\\\\n-    """\\\\n-    end_points = {}\\\\n-  \\\\n-    with tf.variable_scope(scope, \\\\\\\'InceptionResnetV2\\\\\\\', [inputs], reuse=reuse):\\\\n-        with slim.arg_scope([slim.batch_norm, slim.dropout],\\\\n-                            is_training=is_training):\\\\n-            with slim.arg_scope([slim.conv2d, slim.max_pool2d, slim.avg_pool2d],\\\\n-                                stride=1, padding=\\\\\\\'SAME\\\\\\\'):\\\\n-      \\\\n-                # 149 x 149 x 32\\\\n-                net = slim.conv2d(inputs, 32, 3, stride=2, padding=\\\\\\\'VALID\\\\\\\',\\\\n-                                  scope=\\\\\\\'Conv2d_1a_3x3\\\\\\\')\\\\n-                end_points[\\\\\\\'Conv2d_1a_3x3\\\\\\\'] = net\\\\n-                # 147 x 147 x 32\\\\n-                net = slim.conv2d(net, 32, 3, padding=\\\\\\\'VALID\\\\\\\',\\\\n-                                  scope=\\\\\\\'Conv2d_2a_3x3\\\\\\\')\\\\n-                end_points[\\\\\\\'Conv2d_2a_3x3\\\\\\\'] = net\\\\n-                # 147 x 147 x 64\\\\n-                net = slim.conv2d(net, 64, 3, scope=\\\\\\\'Conv2d_2b_3x3\\\\\\\')\\\\n-                end_points[\\\\\\\'Conv2d_2b_3x3\\\\\\\'] = net\\\\n-                # 73 x 73 x 64\\\\n-                net = slim.max_pool2d(net, 3, stride=2, padding=\\\\\\\'VALID\\\\\\\',\\\\n-                                      scope=\\\\\\\'MaxPool_3a_3x3\\\\\\\')\\\\n-                end_points[\\\\\\\'MaxPool_3a_3x3\\\\\\\'] = net\\\\n-                # 73 x 73 x 80\\\\n-                net = slim.conv2d(net, 80, 1, padding=\\\\\\\'VALID\\\\\\\',\\\\n-                                  scope=\\\\\\\'Conv2d_3b_1x1\\\\\\\')\\\\n-                end_points[\\\\\\\'Conv2d_3b_1x1\\\\\\\'] = net\\\\n-                # 71 x 71 x 192\\\\n-                net = slim.conv2d(net, 192, 3, padding=\\\\\\\'VALID\\\\\\\',\\\\n-                                  scope=\\\\\\\'Conv2d_4a_3x3\\\\\\\')\\\\n-                end_points[\\\\\\\'Conv2d_4a_3x3\\\\\\\'] = net\\\\n-                # 35 x 35 x 192\\\\n-                net = slim.max_pool2d(net, 3, stride=2, padding=\\\\\\\'VALID\\\\\\\',\\\\n-                                      scope=\\\\\\\'MaxPool_5a_3x3\\\\\\\')\\\\n-                end_points[\\\\\\\'MaxPool_5a_3x3\\\\\\\'] = net\\\\n-        \\\\n-                # 35 x 35 x 320\\\\n-                with tf.variable_scope(\\\\\\\'Mixed_5b\\\\\\\'):\\\\n-                    with tf.variable_scope(\\\\\\\'Branch_0\\\\\\\'):\\\\n-                        tower_conv = slim.conv2d(net, 96, 1, scope=\\\\\\\'Conv2d_1x1\\\\\\\')\\\\n-                    with tf.variable_scope(\\\\\\\'Branch_1\\\\\\\'):\\\\n-                        tower_conv1_0 = slim.conv2d(net, 48, 1, scope=\\\\\\\'Conv2d_0a_1x1\\\\\\\')\\\\n-                        tower_conv1_1 = slim.conv2d(tower_conv1_0, 64, 5,\\\\n-                                                    scope=\\\\\\\'Conv2d_0b_5x5\\\\\\\')\\\\n-                    with tf.variable_scope(\\\\\\\'Branch_2\\\\\\\'):\\\\n-                        tower_conv2_0 = slim.conv2d(net, 64, 1, scope=\\\\\\\'Conv2d_0a_1x1\\\\\\\')\\\\n-                        tower_conv2_1 = slim.conv2d(tower_conv2_0, 96, 3,\\\\n-                                                    scope=\\\\\\\'Conv2d_0b_3x3\\\\\\\')\\\\n-                        tower_conv2_2 = slim.conv2d(tower_conv2_1, 96, 3,\\\\n-                                                    scope=\\\\\\\'Conv2d_0c_3x3\\\\\\\')\\\\n-                    with tf.variable_scope(\\\\\\\'Branch_3\\\\\\\'):\\\\n-                        tower_pool = slim.avg_pool2d(net, 3, stride=1, padding=\\\\\\\'SAME\\\\\\\',\\\\n-                                                     scope=\\\\\\\'AvgPool_0a_3x3\\\\\\\')\\\\n-                        tower_pool_1 = slim.conv2d(tower_pool, 64, 1,\\\\n-                                                   scope=\\\\\\\'Conv2d_0b_1x1\\\\\\\')\\\\n-                    net = tf.concat([tower_conv, tower_conv1_1,\\\\n-                                        tower_conv2_2, tower_pool_1], 3)\\\\n-        \\\\n-                end_points[\\\\\\\'Mixed_5b\\\\\\\'] = net\\\\n-                net = slim.repeat(net, 10, block35, scale=0.17)\\\\n-        \\\\n-                # 17 x 17 x 1024\\\\n-                with tf.variable_scope(\\\\\\\'Mixed_6a\\\\\\\'):\\\\n-                    with tf.variable_scope(\\\\\\\'Branch_0\\\\\\\'):\\\\n-                        tower_conv = slim.conv2d(net, 384, 3, stride=2, padding=\\\\\\\'VALID\\\\\\\',\\\\n-                                                 scope=\\\\\\\'Conv2d_1a_3x3\\\\\\\')\\\\n-                    with tf.variable_scope(\\\\\\\'Branch_1\\\\\\\'):\\\\n-                        tower_conv1_0 = slim.conv2d(net, 256, 1, scope=\\\\\\\'Conv2d_0a_1x1\\\\\\\')\\\\n-                        tower_conv1_1 = slim.conv2d(tower_conv1_0, 256, 3,\\\\n-                                                    scope=\\\\\\\'Conv2d_0b_3x3\\\\\\\')\\\\n-                        tower_conv1_2 = slim.conv2d(tower_conv1_1, 384, 3,\\\\n-                                                    stride=2, padding=\\\\\\\'VALID\\\\\\\',\\\\n-                                                    scope=\\\\\\\'Conv2d_1a_3x3\\\\\\\')\\\\n-                    with tf.variable_scope(\\\\\\\'Branch_2\\\\\\\'):\\\\n-                        tower_pool = slim.max_pool2d(net, 3, stride=2, padding=\\\\\\\'VALID\\\\\\\',\\\\n-                                                     scope=\\\\\\\'MaxPool_1a_3x3\\\\\\\')\\\\n-                    net = tf.concat([tower_conv, tower_conv1_2, tower_pool], 3)\\\\n-        \\\\n-                end_points[\\\\\\\'Mixed_6a\\\\\\\'] = net\\\\n-                net = slim.repeat(net, 20, block17, scale=0.10)\\\\n-        \\\\n-                with tf.variable_scope(\\\\\\\'Mixed_7a\\\\\\\'):\\\\n-                    with tf.variable_scope(\\\\\\\'Branch_0\\\\\\\'):\\\\n-                        tower_conv = slim.conv2d(net, 256, 1, scope=\\\\\\\'Conv2d_0a_1x1\\\\\\\')\\\\n-                        tower_conv_1 = slim.conv2d(tower_conv, 384, 3, stride=2,\\\\n-                                                   padding=\\\\\\\'VALID\\\\\\\', scope=\\\\\\\'Conv2d_1a_3x3\\\\\\\')\\\\n-                    with tf.variable_scope(\\\\\\\'Branch_1\\\\\\\'):\\\\n-                        tower_conv1 = slim.conv2d(net, 256, 1, scope=\\\\\\\'Conv2d_0a_1x1\\\\\\\')\\\\n-                        tower_conv1_1 = slim.conv2d(tower_conv1, 288, 3, stride=2,\\\\n-                                                    padding=\\\\\\\'VALID\\\\\\\', scope=\\\\\\\'Conv2d_1a_3x3\\\\\\\')\\\\n-                    with tf.variable_scope(\\\\\\\'Branch_2\\\\\\\'):\\\\n-                        tower_conv2 = slim.conv2d(net, 256, 1, scope=\\\\\\\'Conv2d_0a_1x1\\\\\\\')\\\\n-                        tower_conv2_1 = slim.conv2d(tower_conv2, 288, 3,\\\\n-                                                    scope=\\\\\\\'Conv2d_0b_3x3\\\\\\\')\\\\n-                        tower_conv2_2 = slim.conv2d(tower_conv2_1, 320, 3, stride=2,\\\\n-                                                    padding=\\\\\\\'VALID\\\\\\\', scope=\\\\\\\'Conv2d_1a_3x3\\\\\\\')\\\\n-                    with tf.variable_scope(\\\\\\\'Branch_3\\\\\\\'):\\\\n-                        tower_pool = slim.max_pool2d(net, 3, stride=2, padding=\\\\\\\'VALID\\\\\\\',\\\\n-                                                     scope=\\\\\\\'MaxPool_1a_3x3\\\\\\\')\\\\n-                    net = tf.concat([tower_conv_1, tower_conv1_1,\\\\n-                                        tower_conv2_2, tower_pool], 3)\\\\n-        \\\\n-                end_points[\\\\\\\'Mixed_7a\\\\\\\'] = net\\\\n-        \\\\n-                net = slim.repeat(net, 9, block8, scale=0.20)\\\\n-                net = block8(net, activation_fn=None)\\\\n-        \\\\n-                net = slim.conv2d(net, 1536, 1, scope=\\\\\\\'Conv2d_7b_1x1\\\\\\\')\\\\n-                end_points[\\\\\\\'Conv2d_7b_1x1\\\\\\\'] = net\\\\n-        \\\\n-                with tf.variable_scope(\\\\\\\'Logits\\\\\\\'):\\\\n-                    end_points[\\\\\\\'PrePool\\\\\\\'] = net\\\\n-                    #pylint: disable=no-member\\\\n-                    net = slim.avg_pool2d(net, net.get_shape()[1:3], padding=\\\\\\\'VALID\\\\\\\',\\\\n-                                          scope=\\\\\\\'AvgPool_1a_8x8\\\\\\\')\\\\n-                    net = slim.flatten(net)\\\\n-          \\\\n-                    net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\\\\n-                                       scope=\\\\\\\'Dropout\\\\\\\')\\\\n-          \\\\n-                    end_points[\\\\\\\'PreLogitsFlatten\\\\\\\'] = net\\\\n-                \\\\n-                net = slim.fully_connected(net, bottleneck_layer_size, activation_fn=None, \\\\n-                        scope=\\\\\\\'Bottleneck\\\\\\\', reuse=False)\\\\n-  \\\\n-    return net, end_points\\\\ndiff --git a/src/models/squeezenet.py b/src/models/squeezenet.py\\\\ndeleted file mode 100644\\\\nindex ae117e1..0000000\\\\n--- a/src/models/squeezenet.py\\\\n+++ /dev/null\\\\n@@ -1,67 +0,0 @@\\\\n-from __future__ import absolute_import\\\\n-from __future__ import division\\\\n-from __future__ import print_function\\\\n-\\\\n-import tensorflow as tf\\\\n-import tensorflow.contrib.slim as slim\\\\n-\\\\n-def fire_module(inputs,\\\\n-                squeeze_depth,\\\\n-                expand_depth,\\\\n-                reuse=None,\\\\n-                scope=None,\\\\n-                outputs_collections=None):\\\\n-    with tf.variable_scope(scope, \\\\\\\'fire\\\\\\\', [inputs], reuse=reuse):\\\\n-        with slim.arg_scope([slim.conv2d, slim.max_pool2d],\\\\n-                            outputs_collections=None):\\\\n-            net = squeeze(inputs, squeeze_depth)\\\\n-            outputs = expand(net, expand_depth)\\\\n-            return outputs\\\\n-\\\\n-def squeeze(inputs, num_outputs):\\\\n-    return slim.conv2d(inputs, num_outputs, [1, 1], stride=1, scope=\\\\\\\'squeeze\\\\\\\')\\\\n-\\\\n-def expand(inputs, num_outputs):\\\\n-    with tf.variable_scope(\\\\\\\'expand\\\\\\\'):\\\\n-        e1x1 = slim.conv2d(inputs, num_outputs, [1, 1], stride=1, scope=\\\\\\\'1x1\\\\\\\')\\\\n-        e3x3 = slim.conv2d(inputs, num_outputs, [3, 3], scope=\\\\\\\'3x3\\\\\\\')\\\\n-    return tf.concat([e1x1, e3x3], 3)\\\\n-\\\\n-def inference(images, keep_probability, phase_train=True, bottleneck_layer_size=128, weight_decay=0.0, reuse=None):\\\\n-    batch_norm_params = {\\\\n-        # Decay for the moving averages.\\\\n-        \\\\\\\'decay\\\\\\\': 0.995,\\\\n-        # epsilon to prevent 0s in variance.\\\\n-        \\\\\\\'epsilon\\\\\\\': 0.001,\\\\n-        # force in-place updates of mean and variance estimates\\\\n-        \\\\\\\'updates_collections\\\\\\\': None,\\\\n-        # Moving averages ends up in the trainable variables collection\\\\n-        \\\\\\\'variables_collections\\\\\\\': [ tf.GraphKeys.TRAINABLE_VARIABLES ],\\\\n-    }\\\\n-    with slim.arg_scope([slim.conv2d, slim.fully_connected],\\\\n-                        weights_initializer=slim.xavier_initializer_conv2d(uniform=True),\\\\n-                        weights_regularizer=slim.l2_regularizer(weight_decay),\\\\n-                        normalizer_fn=slim.batch_norm,\\\\n-                        normalizer_params=batch_norm_params):\\\\n-        with tf.variable_scope(\\\\\\\'squeezenet\\\\\\\', [images], reuse=reuse):\\\\n-            with slim.arg_scope([slim.batch_norm, slim.dropout],\\\\n-                                is_training=phase_train):\\\\n-                net = slim.conv2d(images, 96, [7, 7], stride=2, scope=\\\\\\\'conv1\\\\\\\')\\\\n-                net = slim.max_pool2d(net, [3, 3], stride=2, scope=\\\\\\\'maxpool1\\\\\\\')\\\\n-                net = fire_module(net, 16, 64, scope=\\\\\\\'fire2\\\\\\\')\\\\n-                net = fire_module(net, 16, 64, scope=\\\\\\\'fire3\\\\\\\')\\\\n-                net = fire_module(net, 32, 128, scope=\\\\\\\'fire4\\\\\\\')\\\\n-                net = slim.max_pool2d(net, [2, 2], stride=2, scope=\\\\\\\'maxpool4\\\\\\\')\\\\n-                net = fire_module(net, 32, 128, scope=\\\\\\\'fire5\\\\\\\')\\\\n-                net = fire_module(net, 48, 192, scope=\\\\\\\'fire6\\\\\\\')\\\\n-                net = fire_module(net, 48, 192, scope=\\\\\\\'fire7\\\\\\\')\\\\n-                net = fire_module(net, 64, 256, scope=\\\\\\\'fire8\\\\\\\')\\\\n-                net = slim.max_pool2d(net, [3, 3], stride=2, scope=\\\\\\\'maxpool8\\\\\\\')\\\\n-                net = fire_module(net, 64, 256, scope=\\\\\\\'fire9\\\\\\\')\\\\n-                net = slim.dropout(net, keep_probability)\\\\n-                net = slim.conv2d(net, 1000, [1, 1], activation_fn=None, normalizer_fn=None, scope=\\\\\\\'conv10\\\\\\\')\\\\n-                net = slim.avg_pool2d(net, net.get_shape()[1:3], scope=\\\\\\\'avgpool10\\\\\\\')\\\\n-                net = tf.squeeze(net, [1, 2], name=\\\\\\\'logits\\\\\\\')\\\\n-                net = slim.fully_connected(net, bottleneck_layer_size, activation_fn=None, \\\\n-                        scope=\\\\\\\'Bottleneck\\\\\\\', reuse=False)\\\\n-    return net, None\\\\ndiff --git a/src/train_softmax.py b/src/train_softmax.py\\\\ndeleted file mode 100644\\\\nindex 6b0b28b..0000000\\\\n--- a/src/train_softmax.py\\\\n+++ /dev/null\\\\n@@ -1,580 +0,0 @@\\\\n-"""Training a face recognizer with TensorFlow using softmax cross entropy loss\\\\n-"""\\\\n-# MIT License\\\\n-# \\\\n-# Copyright (c) 2016 David Sandberg\\\\n-# \\\\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\n-# of this software and associated documentation files (the "Software"), to deal\\\\n-# in the Software without restriction, including without limitation the rights\\\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\n-# copies of the Software, and to permit persons to whom the Software is\\\\n-# furnished to do so, subject to the following conditions:\\\\n-# \\\\n-# The above copyright notice and this permission notice shall be included in all\\\\n-# copies or substantial portions of the Software.\\\\n-# \\\\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\n-# SOFTWARE.\\\\n-\\\\n-from __future__ import absolute_import\\\\n-from __future__ import division\\\\n-from __future__ import print_function\\\\n-\\\\n-from datetime import datetime\\\\n-import os.path\\\\n-import time\\\\n-import sys\\\\n-import random\\\\n-import tensorflow as tf\\\\n-import numpy as np\\\\n-import importlib\\\\n-import argparse\\\\n-import facenet\\\\n-import lfw\\\\n-import h5py\\\\n-import math\\\\n-import tensorflow.contrib.slim as slim\\\\n-from tensorflow.python.ops import data_flow_ops\\\\n-from tensorflow.python.framework import ops\\\\n-from tensorflow.python.ops import array_ops\\\\n-\\\\n-def main(args):\\\\n-  \\\\n-    network = importlib.import_module(args.model_def)\\\\n-    image_size = (args.image_size, args.image_size)\\\\n-\\\\n-    subdir = datetime.strftime(datetime.now(), \\\\\\\'%Y%m%d-%H%M%S\\\\\\\')\\\\n-    log_dir = os.path.join(os.path.expanduser(args.logs_base_dir), subdir)\\\\n-    if not os.path.isdir(log_dir):  # Create the log directory if it doesn\\\\\\\'t exist\\\\n-        os.makedirs(log_dir)\\\\n-    model_dir = os.path.join(os.path.expanduser(args.models_base_dir), subdir)\\\\n-    if not os.path.isdir(model_dir):  # Create the model directory if it doesn\\\\\\\'t exist\\\\n-        os.makedirs(model_dir)\\\\n-\\\\n-    stat_file_name = os.path.join(log_dir, \\\\\\\'stat.h5\\\\\\\')\\\\n-\\\\n-    # Write arguments to a text file\\\\n-    facenet.write_arguments_to_file(args, os.path.join(log_dir, \\\\\\\'arguments.txt\\\\\\\'))\\\\n-        \\\\n-    # Store some git revision info in a text file in the log directory\\\\n-    src_path,_ = os.path.split(os.path.realpath(__file__))\\\\n-    facenet.store_revision_info(src_path, log_dir, \\\\\\\' \\\\\\\'.join(sys.argv))\\\\n-\\\\n-    np.random.seed(seed=args.seed)\\\\n-    random.seed(args.seed)\\\\n-    dataset = facenet.get_dataset(args.data_dir)\\\\n-    if args.filter_filename:\\\\n-        dataset = filter_dataset(dataset, os.path.expanduser(args.filter_filename), \\\\n-            args.filter_percentile, args.filter_min_nrof_images_per_class)\\\\n-        \\\\n-    if args.validation_set_split_ratio>0.0:\\\\n-        train_set, val_set = facenet.split_dataset(dataset, args.validation_set_split_ratio, args.min_nrof_val_images_per_class, \\\\\\\'SPLIT_IMAGES\\\\\\\')\\\\n-    else:\\\\n-        train_set, val_set = dataset, []\\\\n-        \\\\n-    nrof_classes = len(train_set)\\\\n-    \\\\n-    print(\\\\\\\'Model directory: %s\\\\\\\' % model_dir)\\\\n-    print(\\\\\\\'Log directory: %s\\\\\\\' % log_dir)\\\\n-    pretrained_model = None\\\\n-    if args.pretrained_model:\\\\n-        pretrained_model = os.path.expanduser(args.pretrained_model)\\\\n-        print(\\\\\\\'Pre-trained model: %s\\\\\\\' % pretrained_model)\\\\n-    \\\\n-    if args.lfw_dir:\\\\n-        print(\\\\\\\'LFW directory: %s\\\\\\\' % args.lfw_dir)\\\\n-        # Read the file containing the pairs used for testing\\\\n-        pairs = lfw.read_pairs(os.path.expanduser(args.lfw_pairs))\\\\n-        # Get the paths for the corresponding images\\\\n-        lfw_paths, actual_issame = lfw.get_paths(os.path.expanduser(args.lfw_dir), pairs)\\\\n-    \\\\n-    with tf.Graph().as_default():\\\\n-        tf.set_random_seed(args.seed)\\\\n-        global_step = tf.Variable(0, trainable=False)\\\\n-        \\\\n-        # Get a list of image paths and their labels\\\\n-        image_list, label_list = facenet.get_image_paths_and_labels(train_set)\\\\n-        assert len(image_list)>0, \\\\\\\'The training set should not be empty\\\\\\\'\\\\n-        \\\\n-        val_image_list, val_label_list = facenet.get_image_paths_and_labels(val_set)\\\\n-\\\\n-        # Create a queue that produces indices into the image_list and label_list \\\\n-        labels = ops.convert_to_tensor(label_list, dtype=tf.int32)\\\\n-        range_size = array_ops.shape(labels)[0]\\\\n-        index_queue = tf.train.range_input_producer(range_size, num_epochs=None,\\\\n-                             shuffle=True, seed=None, capacity=32)\\\\n-        \\\\n-        index_dequeue_op = index_queue.dequeue_many(args.batch_size*args.epoch_size, \\\\\\\'index_dequeue\\\\\\\')\\\\n-        \\\\n-        learning_rate_placeholder = tf.placeholder(tf.float32, name=\\\\\\\'learning_rate\\\\\\\')\\\\n-        batch_size_placeholder = tf.placeholder(tf.int32, name=\\\\\\\'batch_size\\\\\\\')\\\\n-        phase_train_placeholder = tf.placeholder(tf.bool, name=\\\\\\\'phase_train\\\\\\\')\\\\n-        image_paths_placeholder = tf.placeholder(tf.string, shape=(None,1), name=\\\\\\\'image_paths\\\\\\\')\\\\n-        labels_placeholder = tf.placeholder(tf.int32, shape=(None,1), name=\\\\\\\'labels\\\\\\\')\\\\n-        control_placeholder = tf.placeholder(tf.int32, shape=(None,1), name=\\\\\\\'control\\\\\\\')\\\\n-        \\\\n-        nrof_preprocess_threads = 4\\\\n-        input_queue = data_flow_ops.FIFOQueue(capacity=2000000,\\\\n-                                    dtypes=[tf.string, tf.int32, tf.int32],\\\\n-                                    shapes=[(1,), (1,), (1,)],\\\\n-                                    shared_name=None, name=None)\\\\n-        enqueue_op = input_queue.enqueue_many([image_paths_placeholder, labels_placeholder, control_placeholder], name=\\\\\\\'enqueue_op\\\\\\\')\\\\n-        image_batch, label_batch = facenet.create_input_pipeline(input_queue, image_size, nrof_preprocess_threads, batch_size_placeholder)\\\\n-\\\\n-        image_batch = tf.identity(image_batch, \\\\\\\'image_batch\\\\\\\')\\\\n-        image_batch = tf.identity(image_batch, \\\\\\\'input\\\\\\\')\\\\n-        label_batch = tf.identity(label_batch, \\\\\\\'label_batch\\\\\\\')\\\\n-        \\\\n-        print(\\\\\\\'Number of classes in training set: %d\\\\\\\' % nrof_classes)\\\\n-        print(\\\\\\\'Number of examples in training set: %d\\\\\\\' % len(image_list))\\\\n-\\\\n-        print(\\\\\\\'Number of classes in validation set: %d\\\\\\\' % len(val_set))\\\\n-        print(\\\\\\\'Number of examples in validation set: %d\\\\\\\' % len(val_image_list))\\\\n-        \\\\n-        print(\\\\\\\'Building training graph\\\\\\\')\\\\n-        \\\\n-        # Build the inference graph\\\\n-        prelogits, _ = network.inference(image_batch, args.keep_probability, \\\\n-            phase_train=phase_train_placeholder, bottleneck_layer_size=args.embedding_size, \\\\n-            weight_decay=args.weight_decay)\\\\n-        logits = slim.fully_connected(prelogits, len(train_set), activation_fn=None, \\\\n-                weights_initializer=slim.initializers.xavier_initializer(), \\\\n-                weights_regularizer=slim.l2_regularizer(args.weight_decay),\\\\n-                scope=\\\\\\\'Logits\\\\\\\', reuse=False)\\\\n-\\\\n-        embeddings = tf.nn.l2_normalize(prelogits, 1, 1e-10, name=\\\\\\\'embeddings\\\\\\\')\\\\n-\\\\n-        # Norm for the prelogits\\\\n-        eps = 1e-4\\\\n-        prelogits_norm = tf.reduce_mean(tf.norm(tf.abs(prelogits)+eps, ord=args.prelogits_norm_p, axis=1))\\\\n-        tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, prelogits_norm * args.prelogits_norm_loss_factor)\\\\n-\\\\n-        # Add center loss\\\\n-        prelogits_center_loss, _ = facenet.center_loss(prelogits, label_batch, args.center_loss_alfa, nrof_classes)\\\\n-        tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, prelogits_center_loss * args.center_loss_factor)\\\\n-\\\\n-        learning_rate = tf.train.exponential_decay(learning_rate_placeholder, global_step,\\\\n-            args.learning_rate_decay_epochs*args.epoch_size, args.learning_rate_decay_factor, staircase=True)\\\\n-        tf.summary.scalar(\\\\\\\'learning_rate\\\\\\\', learning_rate)\\\\n-\\\\n-        # Calculate the average cross entropy loss across the batch\\\\n-        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\\\\n-            labels=label_batch, logits=logits, name=\\\\\\\'cross_entropy_per_example\\\\\\\')\\\\n-        cross_entropy_mean = tf.reduce_mean(cross_entropy, name=\\\\\\\'cross_entropy\\\\\\\')\\\\n-        tf.add_to_collection(\\\\\\\'losses\\\\\\\', cross_entropy_mean)\\\\n-        \\\\n-        correct_prediction = tf.cast(tf.equal(tf.argmax(logits, 1), tf.cast(label_batch, tf.int64)), tf.float32)\\\\n-        accuracy = tf.reduce_mean(correct_prediction)\\\\n-        \\\\n-        # Calculate the total losses\\\\n-        regularization_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\\\\n-        total_loss = tf.add_n([cross_entropy_mean] + regularization_losses, name=\\\\\\\'total_loss\\\\\\\')\\\\n-\\\\n-        # Build a Graph that trains the model with one batch of examples and updates the model parameters\\\\n-        train_op = facenet.train(total_loss, global_step, args.optimizer, \\\\n-            learning_rate, args.moving_average_decay, tf.global_variables(), args.log_histograms)\\\\n-        \\\\n-        # Create a saver\\\\n-        saver = tf.train.Saver(tf.trainable_variables(), max_to_keep=3)\\\\n-\\\\n-        # Build the summary operation based on the TF collection of Summaries.\\\\n-        summary_op = tf.summary.merge_all()\\\\n-\\\\n-        # Start running operations on the Graph.\\\\n-        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\\\\n-        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\\\\n-        sess.run(tf.global_variables_initializer())\\\\n-        sess.run(tf.local_variables_initializer())\\\\n-        summary_writer = tf.summary.FileWriter(log_dir, sess.graph)\\\\n-        coord = tf.train.Coordinator()\\\\n-        tf.train.start_queue_runners(coord=coord, sess=sess)\\\\n-\\\\n-        with sess.as_default():\\\\n-\\\\n-            if pretrained_model:\\\\n-                print(\\\\\\\'Restoring pretrained model: %s\\\\\\\' % pretrained_model)\\\\n-                saver.restore(sess, pretrained_model)\\\\n-\\\\n-            # Training and validation loop\\\\n-            print(\\\\\\\'Running training\\\\\\\')\\\\n-            nrof_steps = args.max_nrof_epochs*args.epoch_size\\\\n-            nrof_val_samples = int(math.ceil(args.max_nrof_epochs / args.validate_every_n_epochs))   # Validate every validate_every_n_epochs as well as in the last epoch\\\\n-            stat = {\\\\n-                \\\\\\\'loss\\\\\\\': np.zeros((nrof_steps,), np.float32),\\\\n-                \\\\\\\'center_loss\\\\\\\': np.zeros((nrof_steps,), np.float32),\\\\n-                \\\\\\\'reg_loss\\\\\\\': np.zeros((nrof_steps,), np.float32),\\\\n-                \\\\\\\'xent_loss\\\\\\\': np.zeros((nrof_steps,), np.float32),\\\\n-                \\\\\\\'prelogits_norm\\\\\\\': np.zeros((nrof_steps,), np.float32),\\\\n-                \\\\\\\'accuracy\\\\\\\': np.zeros((nrof_steps,), np.float32),\\\\n-                \\\\\\\'val_loss\\\\\\\': np.zeros((nrof_val_samples,), np.float32),\\\\n-                \\\\\\\'val_xent_loss\\\\\\\': np.zeros((nrof_val_samples,), np.float32),\\\\n-                \\\\\\\'val_accuracy\\\\\\\': np.zeros((nrof_val_samples,), np.float32),\\\\n-                \\\\\\\'lfw_accuracy\\\\\\\': np.zeros((args.max_nrof_epochs,), np.float32),\\\\n-                \\\\\\\'lfw_valrate\\\\\\\': np.zeros((args.max_nrof_epochs,), np.float32),\\\\n-                \\\\\\\'learning_rate\\\\\\\': np.zeros((args.max_nrof_epochs,), np.float32),\\\\n-                \\\\\\\'time_train\\\\\\\': np.zeros((args.max_nrof_epochs,), np.float32),\\\\n-                \\\\\\\'time_validate\\\\\\\': np.zeros((args.max_nrof_epochs,), np.float32),\\\\n-                \\\\\\\'time_evaluate\\\\\\\': np.zeros((args.max_nrof_epochs,), np.float32),\\\\n-                \\\\\\\'prelogits_hist\\\\\\\': np.zeros((args.max_nrof_epochs, 1000), np.float32),\\\\n-              }\\\\n-            for epoch in range(1,args.max_nrof_epochs+1):\\\\n-                step = sess.run(global_step, feed_dict=None)\\\\n-                # Train for one epoch\\\\n-                t = time.time()\\\\n-                cont = train(args, sess, epoch, image_list, label_list, index_dequeue_op, enqueue_op, image_paths_placeholder, labels_placeholder,\\\\n-                    learning_rate_placeholder, phase_train_placeholder, batch_size_placeholder, control_placeholder, global_step, \\\\n-                    total_loss, train_op, summary_op, summary_writer, regularization_losses, args.learning_rate_schedule_file,\\\\n-                    stat, cross_entropy_mean, accuracy, learning_rate,\\\\n-                    prelogits, prelogits_center_loss, args.random_rotate, args.random_crop, args.random_flip, prelogits_norm, args.prelogits_hist_max, args.use_fixed_image_standardization)\\\\n-                stat[\\\\\\\'time_train\\\\\\\'][epoch-1] = time.time() - t\\\\n-                \\\\n-                if not cont:\\\\n-                    break\\\\n-                  \\\\n-                t = time.time()\\\\n-                if len(val_image_list)>0 and ((epoch-1) % args.validate_every_n_epochs == args.validate_every_n_epochs-1 or epoch==args.max_nrof_epochs):\\\\n-                    validate(args, sess, epoch, val_image_list, val_label_list, enqueue_op, image_paths_placeholder, labels_placeholder, control_placeholder,\\\\n-                        phase_train_placeholder, batch_size_placeholder, \\\\n-                        stat, total_loss, regularization_losses, cross_entropy_mean, accuracy, args.validate_every_n_epochs, args.use_fixed_image_standardization)\\\\n-                stat[\\\\\\\'time_validate\\\\\\\'][epoch-1] = time.time() - t\\\\n-\\\\n-                # Save variables and the metagraph if it doesn\\\\\\\'t exist already\\\\n-                save_variables_and_metagraph(sess, saver, summary_writer, model_dir, subdir, epoch)\\\\n-\\\\n-                # Evaluate on LFW\\\\n-                t = time.time()\\\\n-                if args.lfw_dir:\\\\n-                    evaluate(sess, enqueue_op, image_paths_placeholder, labels_placeholder, phase_train_placeholder, batch_size_placeholder, control_placeholder, \\\\n-                        embeddings, label_batch, lfw_paths, actual_issame, args.lfw_batch_size, args.lfw_nrof_folds, log_dir, step, summary_writer, stat, epoch, \\\\n-                        args.lfw_distance_metric, args.lfw_subtract_mean, args.lfw_use_flipped_images, args.use_fixed_image_standardization)\\\\n-                stat[\\\\\\\'time_evaluate\\\\\\\'][epoch-1] = time.time() - t\\\\n-\\\\n-                print(\\\\\\\'Saving statistics\\\\\\\')\\\\n-                with h5py.File(stat_file_name, \\\\\\\'w\\\\\\\') as f:\\\\n-                    for key, value in stat.iteritems():\\\\n-                        f.create_dataset(key, data=value)\\\\n-    \\\\n-    return model_dir\\\\n-  \\\\n-def find_threshold(var, percentile):\\\\n-    hist, bin_edges = np.histogram(var, 100)\\\\n-    cdf = np.float32(np.cumsum(hist)) / np.sum(hist)\\\\n-    bin_centers = (bin_edges[:-1]+bin_edges[1:])/2\\\\n-    #plt.plot(bin_centers, cdf)\\\\n-    threshold = np.interp(percentile*0.01, cdf, bin_centers)\\\\n-    return threshold\\\\n-  \\\\n-def filter_dataset(dataset, data_filename, percentile, min_nrof_images_per_class):\\\\n-    with h5py.File(data_filename,\\\\\\\'r\\\\\\\') as f:\\\\n-        distance_to_center = np.array(f.get(\\\\\\\'distance_to_center\\\\\\\'))\\\\n-        label_list = np.array(f.get(\\\\\\\'label_list\\\\\\\'))\\\\n-        image_list = np.array(f.get(\\\\\\\'image_list\\\\\\\'))\\\\n-        distance_to_center_threshold = find_threshold(distance_to_center, percentile)\\\\n-        indices = np.where(distance_to_center>=distance_to_center_threshold)[0]\\\\n-        filtered_dataset = dataset\\\\n-        removelist = []\\\\n-        for i in indices:\\\\n-            label = label_list[i]\\\\n-            image = image_list[i]\\\\n-            if image in filtered_dataset[label].image_paths:\\\\n-                filtered_dataset[label].image_paths.remove(image)\\\\n-            if len(filtered_dataset[label].image_paths)<min_nrof_images_per_class:\\\\n-                removelist.append(label)\\\\n-\\\\n-        ix = sorted(list(set(removelist)), reverse=True)\\\\n-        for i in ix:\\\\n-            del(filtered_dataset[i])\\\\n-\\\\n-    return filtered_dataset\\\\n-  \\\\n-def train(args, sess, epoch, image_list, label_list, index_dequeue_op, enqueue_op, image_paths_placeholder, labels_placeholder, \\\\n-      learning_rate_placeholder, phase_train_placeholder, batch_size_placeholder, control_placeholder, step, \\\\n-      loss, train_op, summary_op, summary_writer, reg_losses, learning_rate_schedule_file, \\\\n-      stat, cross_entropy_mean, accuracy, \\\\n-      learning_rate, prelogits, prelogits_center_loss, random_rotate, random_crop, random_flip, prelogits_norm, prelogits_hist_max, use_fixed_image_standardization):\\\\n-    batch_number = 0\\\\n-    \\\\n-    if args.learning_rate>0.0:\\\\n-        lr = args.learning_rate\\\\n-    else:\\\\n-        lr = facenet.get_learning_rate_from_file(learning_rate_schedule_file, epoch)\\\\n-        \\\\n-    if lr<=0:\\\\n-        return False \\\\n-\\\\n-    index_epoch = sess.run(index_dequeue_op)\\\\n-    label_epoch = np.array(label_list)[index_epoch]\\\\n-    image_epoch = np.array(image_list)[index_epoch]\\\\n-    \\\\n-    # Enqueue one epoch of image paths and labels\\\\n-    labels_array = np.expand_dims(np.array(label_epoch),1)\\\\n-    image_paths_array = np.expand_dims(np.array(image_epoch),1)\\\\n-    control_value = facenet.RANDOM_ROTATE * random_rotate + facenet.RANDOM_CROP * random_crop + facenet.RANDOM_FLIP * random_flip + facenet.FIXED_STANDARDIZATION * use_fixed_image_standardization\\\\n-    control_array = np.ones_like(labels_array) * control_value\\\\n-    sess.run(enqueue_op, {image_paths_placeholder: image_paths_array, labels_placeholder: labels_array, control_placeholder: control_array})\\\\n-\\\\n-    # Training loop\\\\n-    train_time = 0\\\\n-    while batch_number < args.epoch_size:\\\\n-        start_time = time.time()\\\\n-        feed_dict = {learning_rate_placeholder: lr, phase_train_placeholder:True, batch_size_placeholder:args.batch_size}\\\\n-        tensor_list = [loss, train_op, step, reg_losses, prelogits, cross_entropy_mean, learning_rate, prelogits_norm, accuracy, prelogits_center_loss]\\\\n-        if batch_number % 100 == 0:\\\\n-            loss_, _, step_, reg_losses_, prelogits_, cross_entropy_mean_, lr_, prelogits_norm_, accuracy_, center_loss_, summary_str = sess.run(tensor_list + [summary_op], feed_dict=feed_dict)\\\\n-            summary_writer.add_summary(summary_str, global_step=step_)\\\\n-        else:\\\\n-            loss_, _, step_, reg_losses_, prelogits_, cross_entropy_mean_, lr_, prelogits_norm_, accuracy_, center_loss_ = sess.run(tensor_list, feed_dict=feed_dict)\\\\n-         \\\\n-        duration = time.time() - start_time\\\\n-        stat[\\\\\\\'loss\\\\\\\'][step_-1] = loss_\\\\n-        stat[\\\\\\\'center_loss\\\\\\\'][step_-1] = center_loss_\\\\n-        stat[\\\\\\\'reg_loss\\\\\\\'][step_-1] = np.sum(reg_losses_)\\\\n-        stat[\\\\\\\'xent_loss\\\\\\\'][step_-1] = cross_entropy_mean_\\\\n-        stat[\\\\\\\'prelogits_norm\\\\\\\'][step_-1] = prelogits_norm_\\\\n-        stat[\\\\\\\'learning_rate\\\\\\\'][epoch-1] = lr_\\\\n-        stat[\\\\\\\'accuracy\\\\\\\'][step_-1] = accuracy_\\\\n-        stat[\\\\\\\'prelogits_hist\\\\\\\'][epoch-1,:] += np.histogram(np.minimum(np.abs(prelogits_), prelogits_hist_max), bins=1000, range=(0.0, prelogits_hist_max))[0]\\\\n-        \\\\n-        duration = time.time() - start_time\\\\n-        print(\\\\\\\'Epoch: [%d][%d/%d]\\\\\\\\tTime %.3f\\\\\\\\tLoss %2.3f\\\\\\\\tXent %2.3f\\\\\\\\tRegLoss %2.3f\\\\\\\\tAccuracy %2.3f\\\\\\\\tLr %2.5f\\\\\\\\tCl %2.3f\\\\\\\' %\\\\n-              (epoch, batch_number+1, args.epoch_size, duration, loss_, cross_entropy_mean_, np.sum(reg_losses_), accuracy_, lr_, center_loss_))\\\\n-        batch_number += 1\\\\n-        train_time += duration\\\\n-    # Add validation loss and accuracy to summary\\\\n-    summary = tf.Summary()\\\\n-    #pylint: disable=maybe-no-member\\\\n-    summary.value.add(tag=\\\\\\\'time/total\\\\\\\', simple_value=train_time)\\\\n-    summary_writer.add_summary(summary, global_step=step_)\\\\n-    return True\\\\n-\\\\n-def validate(args, sess, epoch, image_list, label_list, enqueue_op, image_paths_placeholder, labels_placeholder, control_placeholder,\\\\n-             phase_train_placeholder, batch_size_placeholder, \\\\n-             stat, loss, regularization_losses, cross_entropy_mean, accuracy, validate_every_n_epochs, use_fixed_image_standardization):\\\\n-  \\\\n-    print(\\\\\\\'Running forward pass on validation set\\\\\\\')\\\\n-\\\\n-    nrof_batches = len(label_list) // args.lfw_batch_size\\\\n-    nrof_images = nrof_batches * args.lfw_batch_size\\\\n-    \\\\n-    # Enqueue one epoch of image paths and labels\\\\n-    labels_array = np.expand_dims(np.array(label_list[:nrof_images]),1)\\\\n-    image_paths_array = np.expand_dims(np.array(image_list[:nrof_images]),1)\\\\n-    control_array = np.ones_like(labels_array, np.int32)*facenet.FIXED_STANDARDIZATION * use_fixed_image_standardization\\\\n-    sess.run(enqueue_op, {image_paths_placeholder: image_paths_array, labels_placeholder: labels_array, control_placeholder: control_array})\\\\n-\\\\n-    loss_array = np.zeros((nrof_batches,), np.float32)\\\\n-    xent_array = np.zeros((nrof_batches,), np.float32)\\\\n-    accuracy_array = np.zeros((nrof_batches,), np.float32)\\\\n-\\\\n-    # Training loop\\\\n-    start_time = time.time()\\\\n-    for i in range(nrof_batches):\\\\n-        feed_dict = {phase_train_placeholder:False, batch_size_placeholder:args.lfw_batch_size}\\\\n-        loss_, cross_entropy_mean_, accuracy_ = sess.run([loss, cross_entropy_mean, accuracy], feed_dict=feed_dict)\\\\n-        loss_array[i], xent_array[i], accuracy_array[i] = (loss_, cross_entropy_mean_, accuracy_)\\\\n-        if i % 10 == 9:\\\\n-            print(\\\\\\\'.\\\\\\\', end=\\\\\\\'\\\\\\\')\\\\n-            sys.stdout.flush()\\\\n-    print(\\\\\\\'\\\\\\\')\\\\n-\\\\n-    duration = time.time() - start_time\\\\n-\\\\n-    val_index = (epoch-1)//validate_every_n_epochs\\\\n-    stat[\\\\\\\'val_loss\\\\\\\'][val_index] = np.mean(loss_array)\\\\n-    stat[\\\\\\\'val_xent_loss\\\\\\\'][val_index] = np.mean(xent_array)\\\\n-    stat[\\\\\\\'val_accuracy\\\\\\\'][val_index] = np.mean(accuracy_array)\\\\n-\\\\n-    print(\\\\\\\'Validation Epoch: %d\\\\\\\\tTime %.3f\\\\\\\\tLoss %2.3f\\\\\\\\tXent %2.3f\\\\\\\\tAccuracy %2.3f\\\\\\\' %\\\\n-          (epoch, duration, np.mean(loss_array), np.mean(xent_array), np.mean(accuracy_array)))\\\\n-\\\\n-\\\\n-def evaluate(sess, enqueue_op, image_paths_placeholder, labels_placeholder, phase_train_placeholder, batch_size_placeholder, control_placeholder, \\\\n-        embeddings, labels, image_paths, actual_issame, batch_size, nrof_folds, log_dir, step, summary_writer, stat, epoch, distance_metric, subtract_mean, use_flipped_images, use_fixed_image_standardization):\\\\n-    start_time = time.time()\\\\n-    # Run forward pass to calculate embeddings\\\\n-    print(\\\\\\\'Runnning forward pass on LFW images\\\\\\\')\\\\n-    \\\\n-    # Enqueue one epoch of image paths and labels\\\\n-    nrof_embeddings = len(actual_issame)*2  # nrof_pairs * nrof_images_per_pair\\\\n-    nrof_flips = 2 if use_flipped_images else 1\\\\n-    nrof_images = nrof_embeddings * nrof_flips\\\\n-    labels_array = np.expand_dims(np.arange(0,nrof_images),1)\\\\n-    image_paths_array = np.expand_dims(np.repeat(np.array(image_paths),nrof_flips),1)\\\\n-    control_array = np.zeros_like(labels_array, np.int32)\\\\n-    if use_fixed_image_standardization:\\\\n-        control_array += np.ones_like(labels_array)*facenet.FIXED_STANDARDIZATION\\\\n-    if use_flipped_images:\\\\n-        # Flip every second image\\\\n-        control_array += (labels_array % 2)*facenet.FLIP\\\\n-    sess.run(enqueue_op, {image_paths_placeholder: image_paths_array, labels_placeholder: labels_array, control_placeholder: control_array})\\\\n-    \\\\n-    embedding_size = int(embeddings.get_shape()[1])\\\\n-    assert nrof_images % batch_size == 0, \\\\\\\'The number of LFW images must be an integer multiple of the LFW batch size\\\\\\\'\\\\n-    nrof_batches = nrof_images // batch_size\\\\n-    emb_array = np.zeros((nrof_images, embedding_size))\\\\n-    lab_array = np.zeros((nrof_images,))\\\\n-    for i in range(nrof_batches):\\\\n-        feed_dict = {phase_train_placeholder:False, batch_size_placeholder:batch_size}\\\\n-        emb, lab = sess.run([embeddings, labels], feed_dict=feed_dict)\\\\n-        lab_array[lab] = lab\\\\n-        emb_array[lab, :] = emb\\\\n-        if i % 10 == 9:\\\\n-            print(\\\\\\\'.\\\\\\\', end=\\\\\\\'\\\\\\\')\\\\n-            sys.stdout.flush()\\\\n-    print(\\\\\\\'\\\\\\\')\\\\n-    embeddings = np.zeros((nrof_embeddings, embedding_size*nrof_flips))\\\\n-    if use_flipped_images:\\\\n-        # Concatenate embeddings for flipped and non flipped version of the images\\\\n-        embeddings[:,:embedding_size] = emb_array[0::2,:]\\\\n-        embeddings[:,embedding_size:] = emb_array[1::2,:]\\\\n-    else:\\\\n-        embeddings = emb_array\\\\n-\\\\n-    assert np.array_equal(lab_array, np.arange(nrof_images))==True, \\\\\\\'Wrong labels used for evaluation, possibly caused by training examples left in the input pipeline\\\\\\\'\\\\n-    _, _, accuracy, val, val_std, far = lfw.evaluate(embeddings, actual_issame, nrof_folds=nrof_folds, distance_metric=distance_metric, subtract_mean=subtract_mean)\\\\n-    \\\\n-    print(\\\\\\\'Accuracy: %2.5f+-%2.5f\\\\\\\' % (np.mean(accuracy), np.std(accuracy)))\\\\n-    print(\\\\\\\'Validation rate: %2.5f+-%2.5f @ FAR=%2.5f\\\\\\\' % (val, val_std, far))\\\\n-    lfw_time = time.time() - start_time\\\\n-    # Add validation loss and accuracy to summary\\\\n-    summary = tf.Summary()\\\\n-    #pylint: disable=maybe-no-member\\\\n-    summary.value.add(tag=\\\\\\\'lfw/accuracy\\\\\\\', simple_value=np.mean(accuracy))\\\\n-    summary.value.add(tag=\\\\\\\'lfw/val_rate\\\\\\\', simple_value=val)\\\\n-    summary.value.add(tag=\\\\\\\'time/lfw\\\\\\\', simple_value=lfw_time)\\\\n-    summary_writer.add_summary(summary, step)\\\\n-    with open(os.path.join(log_dir,\\\\\\\'lfw_result.txt\\\\\\\'),\\\\\\\'at\\\\\\\') as f:\\\\n-        f.write(\\\\\\\'%d\\\\\\\\t%.5f\\\\\\\\t%.5f\\\\\\\\n\\\\\\\' % (step, np.mean(accuracy), val))\\\\n-    stat[\\\\\\\'lfw_accuracy\\\\\\\'][epoch-1] = np.mean(accuracy)\\\\n-    stat[\\\\\\\'lfw_valrate\\\\\\\'][epoch-1] = val\\\\n-\\\\n-def save_variables_and_metagraph(sess, saver, summary_writer, model_dir, model_name, step):\\\\n-    # Save the model checkpoint\\\\n-    print(\\\\\\\'Saving variables\\\\\\\')\\\\n-    start_time = time.time()\\\\n-    checkpoint_path = os.path.join(model_dir, \\\\\\\'model-%s.ckpt\\\\\\\' % model_name)\\\\n-    saver.save(sess, checkpoint_path, global_step=step, write_meta_graph=False)\\\\n-    save_time_variables = time.time() - start_time\\\\n-    print(\\\\\\\'Variables saved in %.2f seconds\\\\\\\' % save_time_variables)\\\\n-    metagraph_filename = os.path.join(model_dir, \\\\\\\'model-%s.meta\\\\\\\' % model_name)\\\\n-    save_time_metagraph = 0  \\\\n-    if not os.path.exists(metagraph_filename):\\\\n-        print(\\\\\\\'Saving metagraph\\\\\\\')\\\\n-        start_time = time.time()\\\\n-        saver.export_meta_graph(metagraph_filename)\\\\n-        save_time_metagraph = time.time() - start_time\\\\n-        print(\\\\\\\'Metagraph saved in %.2f seconds\\\\\\\' % save_time_metagraph)\\\\n-    summary = tf.Summary()\\\\n-    #pylint: disable=maybe-no-member\\\\n-    summary.value.add(tag=\\\\\\\'time/save_variables\\\\\\\', simple_value=save_time_variables)\\\\n-    summary.value.add(tag=\\\\\\\'time/save_metagraph\\\\\\\', simple_value=save_time_metagraph)\\\\n-    summary_writer.add_summary(summary, step)\\\\n-  \\\\n-\\\\n-def parse_arguments(argv):\\\\n-    parser = argparse.ArgumentParser()\\\\n-    \\\\n-    parser.add_argument(\\\\\\\'--logs_base_dir\\\\\\\', type=str, \\\\n-        help=\\\\\\\'Directory where to write event logs.\\\\\\\', default=\\\\\\\'~/logs/facenet\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--models_base_dir\\\\\\\', type=str,\\\\n-        help=\\\\\\\'Directory where to write trained models and checkpoints.\\\\\\\', default=\\\\\\\'~/models/facenet\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--gpu_memory_fraction\\\\\\\', type=float,\\\\n-        help=\\\\\\\'Upper bound on the amount of GPU memory that will be used by the process.\\\\\\\', default=1.0)\\\\n-    parser.add_argument(\\\\\\\'--pretrained_model\\\\\\\', type=str,\\\\n-        help=\\\\\\\'Load a pretrained model before training starts.\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--data_dir\\\\\\\', type=str,\\\\n-        help=\\\\\\\'Path to the data directory containing aligned face patches.\\\\\\\',\\\\n-        default=\\\\\\\'~/datasets/casia/casia_maxpy_mtcnnalign_182_160\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--model_def\\\\\\\', type=str,\\\\n-        help=\\\\\\\'Model definition. Points to a module containing the definition of the inference graph.\\\\\\\', default=\\\\\\\'models.inception_resnet_v1\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--max_nrof_epochs\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Number of epochs to run.\\\\\\\', default=500)\\\\n-    parser.add_argument(\\\\\\\'--batch_size\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Number of images to process in a batch.\\\\\\\', default=90)\\\\n-    parser.add_argument(\\\\\\\'--image_size\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Image size (height, width) in pixels.\\\\\\\', default=160)\\\\n-    parser.add_argument(\\\\\\\'--epoch_size\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Number of batches per epoch.\\\\\\\', default=1000)\\\\n-    parser.add_argument(\\\\\\\'--embedding_size\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Dimensionality of the embedding.\\\\\\\', default=128)\\\\n-    parser.add_argument(\\\\\\\'--random_crop\\\\\\\', \\\\n-        help=\\\\\\\'Performs random cropping of training images. If false, the center image_size pixels from the training images are used. \\\\\\\' +\\\\n-         \\\\\\\'If the size of the images in the data directory is equal to image_size no cropping is performed\\\\\\\', action=\\\\\\\'store_true\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--random_flip\\\\\\\', \\\\n-        help=\\\\\\\'Performs random horizontal flipping of training images.\\\\\\\', action=\\\\\\\'store_true\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--random_rotate\\\\\\\', \\\\n-        help=\\\\\\\'Performs random rotations of training images.\\\\\\\', action=\\\\\\\'store_true\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--use_fixed_image_standardization\\\\\\\', \\\\n-        help=\\\\\\\'Performs fixed standardization of images.\\\\\\\', action=\\\\\\\'store_true\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--keep_probability\\\\\\\', type=float,\\\\n-        help=\\\\\\\'Keep probability of dropout for the fully connected layer(s).\\\\\\\', default=1.0)\\\\n-    parser.add_argument(\\\\\\\'--weight_decay\\\\\\\', type=float,\\\\n-        help=\\\\\\\'L2 weight regularization.\\\\\\\', default=0.0)\\\\n-    parser.add_argument(\\\\\\\'--center_loss_factor\\\\\\\', type=float,\\\\n-        help=\\\\\\\'Center loss factor.\\\\\\\', default=0.0)\\\\n-    parser.add_argument(\\\\\\\'--center_loss_alfa\\\\\\\', type=float,\\\\n-        help=\\\\\\\'Center update rate for center loss.\\\\\\\', default=0.95)\\\\n-    parser.add_argument(\\\\\\\'--prelogits_norm_loss_factor\\\\\\\', type=float,\\\\n-        help=\\\\\\\'Loss based on the norm of the activations in the prelogits layer.\\\\\\\', default=0.0)\\\\n-    parser.add_argument(\\\\\\\'--prelogits_norm_p\\\\\\\', type=float,\\\\n-        help=\\\\\\\'Norm to use for prelogits norm loss.\\\\\\\', default=1.0)\\\\n-    parser.add_argument(\\\\\\\'--prelogits_hist_max\\\\\\\', type=float,\\\\n-        help=\\\\\\\'The max value for the prelogits histogram.\\\\\\\', default=10.0)\\\\n-    parser.add_argument(\\\\\\\'--optimizer\\\\\\\', type=str, choices=[\\\\\\\'ADAGRAD\\\\\\\', \\\\\\\'ADADELTA\\\\\\\', \\\\\\\'ADAM\\\\\\\', \\\\\\\'RMSPROP\\\\\\\', \\\\\\\'MOM\\\\\\\'],\\\\n-        help=\\\\\\\'The optimization algorithm to use\\\\\\\', default=\\\\\\\'ADAGRAD\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--learning_rate\\\\\\\', type=float,\\\\n-        help=\\\\\\\'Initial learning rate. If set to a negative value a learning rate \\\\\\\' +\\\\n-        \\\\\\\'schedule can be specified in the file "learning_rate_schedule.txt"\\\\\\\', default=0.1)\\\\n-    parser.add_argument(\\\\\\\'--learning_rate_decay_epochs\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Number of epochs between learning rate decay.\\\\\\\', default=100)\\\\n-    parser.add_argument(\\\\\\\'--learning_rate_decay_factor\\\\\\\', type=float,\\\\n-        help=\\\\\\\'Learning rate decay factor.\\\\\\\', default=1.0)\\\\n-    parser.add_argument(\\\\\\\'--moving_average_decay\\\\\\\', type=float,\\\\n-        help=\\\\\\\'Exponential decay for tracking of training parameters.\\\\\\\', default=0.9999)\\\\n-    parser.add_argument(\\\\\\\'--seed\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Random seed.\\\\\\\', default=666)\\\\n-    parser.add_argument(\\\\\\\'--nrof_preprocess_threads\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Number of preprocessing (data loading and augmentation) threads.\\\\\\\', default=4)\\\\n-    parser.add_argument(\\\\\\\'--log_histograms\\\\\\\', \\\\n-        help=\\\\\\\'Enables logging of weight/bias histograms in tensorboard.\\\\\\\', action=\\\\\\\'store_true\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--learning_rate_schedule_file\\\\\\\', type=str,\\\\n-        help=\\\\\\\'File containing the learning rate schedule that is used when learning_rate is set to to -1.\\\\\\\', default=\\\\\\\'data/learning_rate_schedule.txt\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--filter_filename\\\\\\\', type=str,\\\\n-        help=\\\\\\\'File containing image data used for dataset filtering\\\\\\\', default=\\\\\\\'\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--filter_percentile\\\\\\\', type=float,\\\\n-        help=\\\\\\\'Keep only the percentile images closed to its class center\\\\\\\', default=100.0)\\\\n-    parser.add_argument(\\\\\\\'--filter_min_nrof_images_per_class\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Keep only the classes with this number of examples or more\\\\\\\', default=0)\\\\n-    parser.add_argument(\\\\\\\'--validate_every_n_epochs\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Number of epoch between validation\\\\\\\', default=5)\\\\n-    parser.add_argument(\\\\\\\'--validation_set_split_ratio\\\\\\\', type=float,\\\\n-        help=\\\\\\\'The ratio of the total dataset to use for validation\\\\\\\', default=0.0)\\\\n-    parser.add_argument(\\\\\\\'--min_nrof_val_images_per_class\\\\\\\', type=float,\\\\n-        help=\\\\\\\'Classes with fewer images will be removed from the validation set\\\\\\\', default=0)\\\\n- \\\\n-    # Parameters for validation on LFW\\\\n-    parser.add_argument(\\\\\\\'--lfw_pairs\\\\\\\', type=str,\\\\n-        help=\\\\\\\'The file containing the pairs to use for validation.\\\\\\\', default=\\\\\\\'data/pairs.txt\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--lfw_dir\\\\\\\', type=str,\\\\n-        help=\\\\\\\'Path to the data directory containing aligned face patches.\\\\\\\', default=\\\\\\\'\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--lfw_batch_size\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Number of images to process in a batch in the LFW test set.\\\\\\\', default=100)\\\\n-    parser.add_argument(\\\\\\\'--lfw_nrof_folds\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Number of folds to use for cross validation. Mainly used for testing.\\\\\\\', default=10)\\\\n-    parser.add_argument(\\\\\\\'--lfw_distance_metric\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Type of distance metric to use. 0: Euclidian, 1:Cosine similarity distance.\\\\\\\', default=0)\\\\n-    parser.add_argument(\\\\\\\'--lfw_use_flipped_images\\\\\\\', \\\\n-        help=\\\\\\\'Concatenates embeddings for the image and its horizontally flipped counterpart.\\\\\\\', action=\\\\\\\'store_true\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--lfw_subtract_mean\\\\\\\', \\\\n-        help=\\\\\\\'Subtract feature mean before calculating distance.\\\\\\\', action=\\\\\\\'store_true\\\\\\\')\\\\n-    return parser.parse_args(argv)\\\\n-  \\\\n-\\\\n-if __name__ == \\\\\\\'__main__\\\\\\\':\\\\n-    main(parse_arguments(sys.argv[1:]))\\\\ndiff --git a/src/train_tripletloss.py b/src/train_tripletloss.py\\\\ndeleted file mode 100644\\\\nindex d6df19a..0000000\\\\n--- a/src/train_tripletloss.py\\\\n+++ /dev/null\\\\n@@ -1,486 +0,0 @@\\\\n-"""Training a face recognizer with TensorFlow based on the FaceNet paper\\\\n-FaceNet: A Unified Embedding for Face Recognition and Clustering: http://arxiv.org/abs/1503.03832\\\\n-"""\\\\n-# MIT License\\\\n-# \\\\n-# Copyright (c) 2016 David Sandberg\\\\n-# \\\\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\n-# of this software and associated documentation files (the "Software"), to deal\\\\n-# in the Software without restriction, including without limitation the rights\\\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\n-# copies of the Software, and to permit persons to whom the Software is\\\\n-# furnished to do so, subject to the following conditions:\\\\n-# \\\\n-# The above copyright notice and this permission notice shall be included in all\\\\n-# copies or substantial portions of the Software.\\\\n-# \\\\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\n-# SOFTWARE.\\\\n-\\\\n-from __future__ import absolute_import\\\\n-from __future__ import division\\\\n-from __future__ import print_function\\\\n-\\\\n-from datetime import datetime\\\\n-import os.path\\\\n-import time\\\\n-import sys\\\\n-import tensorflow as tf\\\\n-import numpy as np\\\\n-import importlib\\\\n-import itertools\\\\n-import argparse\\\\n-import facenet\\\\n-import lfw\\\\n-\\\\n-from tensorflow.python.ops import data_flow_ops\\\\n-\\\\n-from six.moves import xrange  # @UnresolvedImport\\\\n-\\\\n-def main(args):\\\\n-  \\\\n-    network = importlib.import_module(args.model_def)\\\\n-\\\\n-    subdir = datetime.strftime(datetime.now(), \\\\\\\'%Y%m%d-%H%M%S\\\\\\\')\\\\n-    log_dir = os.path.join(os.path.expanduser(args.logs_base_dir), subdir)\\\\n-    if not os.path.isdir(log_dir):  # Create the log directory if it doesn\\\\\\\'t exist\\\\n-        os.makedirs(log_dir)\\\\n-    model_dir = os.path.join(os.path.expanduser(args.models_base_dir), subdir)\\\\n-    if not os.path.isdir(model_dir):  # Create the model directory if it doesn\\\\\\\'t exist\\\\n-        os.makedirs(model_dir)\\\\n-\\\\n-    # Write arguments to a text file\\\\n-    facenet.write_arguments_to_file(args, os.path.join(log_dir, \\\\\\\'arguments.txt\\\\\\\'))\\\\n-        \\\\n-    # Store some git revision info in a text file in the log directory\\\\n-    src_path,_ = os.path.split(os.path.realpath(__file__))\\\\n-    facenet.store_revision_info(src_path, log_dir, \\\\\\\' \\\\\\\'.join(sys.argv))\\\\n-\\\\n-    np.random.seed(seed=args.seed)\\\\n-    train_set = facenet.get_dataset(args.data_dir)\\\\n-    \\\\n-    print(\\\\\\\'Model directory: %s\\\\\\\' % model_dir)\\\\n-    print(\\\\\\\'Log directory: %s\\\\\\\' % log_dir)\\\\n-    if args.pretrained_model:\\\\n-        print(\\\\\\\'Pre-trained model: %s\\\\\\\' % os.path.expanduser(args.pretrained_model))\\\\n-    \\\\n-    if args.lfw_dir:\\\\n-        print(\\\\\\\'LFW directory: %s\\\\\\\' % args.lfw_dir)\\\\n-        # Read the file containing the pairs used for testing\\\\n-        pairs = lfw.read_pairs(os.path.expanduser(args.lfw_pairs))\\\\n-        # Get the paths for the corresponding images\\\\n-        lfw_paths, actual_issame = lfw.get_paths(os.path.expanduser(args.lfw_dir), pairs)\\\\n-        \\\\n-    \\\\n-    with tf.Graph().as_default():\\\\n-        tf.set_random_seed(args.seed)\\\\n-        global_step = tf.Variable(0, trainable=False)\\\\n-\\\\n-        # Placeholder for the learning rate\\\\n-        learning_rate_placeholder = tf.placeholder(tf.float32, name=\\\\\\\'learning_rate\\\\\\\')\\\\n-        \\\\n-        batch_size_placeholder = tf.placeholder(tf.int32, name=\\\\\\\'batch_size\\\\\\\')\\\\n-        \\\\n-        phase_train_placeholder = tf.placeholder(tf.bool, name=\\\\\\\'phase_train\\\\\\\')\\\\n-        \\\\n-        image_paths_placeholder = tf.placeholder(tf.string, shape=(None,3), name=\\\\\\\'image_paths\\\\\\\')\\\\n-        labels_placeholder = tf.placeholder(tf.int64, shape=(None,3), name=\\\\\\\'labels\\\\\\\')\\\\n-        \\\\n-        input_queue = data_flow_ops.FIFOQueue(capacity=100000,\\\\n-                                    dtypes=[tf.string, tf.int64],\\\\n-                                    shapes=[(3,), (3,)],\\\\n-                                    shared_name=None, name=None)\\\\n-        enqueue_op = input_queue.enqueue_many([image_paths_placeholder, labels_placeholder])\\\\n-        \\\\n-        nrof_preprocess_threads = 4\\\\n-        images_and_labels = []\\\\n-        for _ in range(nrof_preprocess_threads):\\\\n-            filenames, label = input_queue.dequeue()\\\\n-            images = []\\\\n-            for filename in tf.unstack(filenames):\\\\n-                file_contents = tf.read_file(filename)\\\\n-                image = tf.image.decode_image(file_contents, channels=3)\\\\n-                \\\\n-                if args.random_crop:\\\\n-                    image = tf.random_crop(image, [args.image_size, args.image_size, 3])\\\\n-                else:\\\\n-                    image = tf.image.resize_image_with_crop_or_pad(image, args.image_size, args.image_size)\\\\n-                if args.random_flip:\\\\n-                    image = tf.image.random_flip_left_right(image)\\\\n-    \\\\n-                #pylint: disable=no-member\\\\n-                image.set_shape((args.image_size, args.image_size, 3))\\\\n-                images.append(tf.image.per_image_standardization(image))\\\\n-            images_and_labels.append([images, label])\\\\n-    \\\\n-        image_batch, labels_batch = tf.train.batch_join(\\\\n-            images_and_labels, batch_size=batch_size_placeholder, \\\\n-            shapes=[(args.image_size, args.image_size, 3), ()], enqueue_many=True,\\\\n-            capacity=4 * nrof_preprocess_threads * args.batch_size,\\\\n-            allow_smaller_final_batch=True)\\\\n-        image_batch = tf.identity(image_batch, \\\\\\\'image_batch\\\\\\\')\\\\n-        image_batch = tf.identity(image_batch, \\\\\\\'input\\\\\\\')\\\\n-        labels_batch = tf.identity(labels_batch, \\\\\\\'label_batch\\\\\\\')\\\\n-\\\\n-        # Build the inference graph\\\\n-        prelogits, _ = network.inference(image_batch, args.keep_probability, \\\\n-            phase_train=phase_train_placeholder, bottleneck_layer_size=args.embedding_size,\\\\n-            weight_decay=args.weight_decay)\\\\n-        \\\\n-        embeddings = tf.nn.l2_normalize(prelogits, 1, 1e-10, name=\\\\\\\'embeddings\\\\\\\')\\\\n-        # Split embeddings into anchor, positive and negative and calculate triplet loss\\\\n-        anchor, positive, negative = tf.unstack(tf.reshape(embeddings, [-1,3,args.embedding_size]), 3, 1)\\\\n-        triplet_loss = facenet.triplet_loss(anchor, positive, negative, args.alpha)\\\\n-        \\\\n-        learning_rate = tf.train.exponential_decay(learning_rate_placeholder, global_step,\\\\n-            args.learning_rate_decay_epochs*args.epoch_size, args.learning_rate_decay_factor, staircase=True)\\\\n-        tf.summary.scalar(\\\\\\\'learning_rate\\\\\\\', learning_rate)\\\\n-\\\\n-        # Calculate the total losses\\\\n-        regularization_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\\\\n-        total_loss = tf.add_n([triplet_loss] + regularization_losses, name=\\\\\\\'total_loss\\\\\\\')\\\\n-\\\\n-        # Build a Graph that trains the model with one batch of examples and updates the model parameters\\\\n-        train_op = facenet.train(total_loss, global_step, args.optimizer, \\\\n-            learning_rate, args.moving_average_decay, tf.global_variables())\\\\n-        \\\\n-        # Create a saver\\\\n-        saver = tf.train.Saver(tf.trainable_variables(), max_to_keep=3)\\\\n-\\\\n-        # Build the summary operation based on the TF collection of Summaries.\\\\n-        summary_op = tf.summary.merge_all()\\\\n-\\\\n-        # Start running operations on the Graph.\\\\n-        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\\\\n-        sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))        \\\\n-\\\\n-        # Initialize variables\\\\n-        sess.run(tf.global_variables_initializer(), feed_dict={phase_train_placeholder:True})\\\\n-        sess.run(tf.local_variables_initializer(), feed_dict={phase_train_placeholder:True})\\\\n-\\\\n-        summary_writer = tf.summary.FileWriter(log_dir, sess.graph)\\\\n-        coord = tf.train.Coordinator()\\\\n-        tf.train.start_queue_runners(coord=coord, sess=sess)\\\\n-\\\\n-        with sess.as_default():\\\\n-\\\\n-            if args.pretrained_model:\\\\n-                print(\\\\\\\'Restoring pretrained model: %s\\\\\\\' % args.pretrained_model)\\\\n-                saver.restore(sess, os.path.expanduser(args.pretrained_model))\\\\n-\\\\n-            # Training and validation loop\\\\n-            epoch = 0\\\\n-            while epoch < args.max_nrof_epochs:\\\\n-                step = sess.run(global_step, feed_dict=None)\\\\n-                epoch = step // args.epoch_size\\\\n-                # Train for one epoch\\\\n-                train(args, sess, train_set, epoch, image_paths_placeholder, labels_placeholder, labels_batch,\\\\n-                    batch_size_placeholder, learning_rate_placeholder, phase_train_placeholder, enqueue_op, input_queue, global_step, \\\\n-                    embeddings, total_loss, train_op, summary_op, summary_writer, args.learning_rate_schedule_file,\\\\n-                    args.embedding_size, anchor, positive, negative, triplet_loss)\\\\n-\\\\n-                # Save variables and the metagraph if it doesn\\\\\\\'t exist already\\\\n-                save_variables_and_metagraph(sess, saver, summary_writer, model_dir, subdir, step)\\\\n-\\\\n-                # Evaluate on LFW\\\\n-                if args.lfw_dir:\\\\n-                    evaluate(sess, lfw_paths, embeddings, labels_batch, image_paths_placeholder, labels_placeholder, \\\\n-                            batch_size_placeholder, learning_rate_placeholder, phase_train_placeholder, enqueue_op, actual_issame, args.batch_size, \\\\n-                            args.lfw_nrof_folds, log_dir, step, summary_writer, args.embedding_size)\\\\n-\\\\n-    return model_dir\\\\n-\\\\n-\\\\n-def train(args, sess, dataset, epoch, image_paths_placeholder, labels_placeholder, labels_batch,\\\\n-          batch_size_placeholder, learning_rate_placeholder, phase_train_placeholder, enqueue_op, input_queue, global_step, \\\\n-          embeddings, loss, train_op, summary_op, summary_writer, learning_rate_schedule_file,\\\\n-          embedding_size, anchor, positive, negative, triplet_loss):\\\\n-    batch_number = 0\\\\n-    \\\\n-    if args.learning_rate>0.0:\\\\n-        lr = args.learning_rate\\\\n-    else:\\\\n-        lr = facenet.get_learning_rate_from_file(learning_rate_schedule_file, epoch)\\\\n-    while batch_number < args.epoch_size:\\\\n-        # Sample people randomly from the dataset\\\\n-        image_paths, num_per_class = sample_people(dataset, args.people_per_batch, args.images_per_person)\\\\n-        \\\\n-        print(\\\\\\\'Running forward pass on sampled images: \\\\\\\', end=\\\\\\\'\\\\\\\')\\\\n-        start_time = time.time()\\\\n-        nrof_examples = args.people_per_batch * args.images_per_person\\\\n-        labels_array = np.reshape(np.arange(nrof_examples),(-1,3))\\\\n-        image_paths_array = np.reshape(np.expand_dims(np.array(image_paths),1), (-1,3))\\\\n-        sess.run(enqueue_op, {image_paths_placeholder: image_paths_array, labels_placeholder: labels_array})\\\\n-        emb_array = np.zeros((nrof_examples, embedding_size))\\\\n-        nrof_batches = int(np.ceil(nrof_examples / args.batch_size))\\\\n-        for i in range(nrof_batches):\\\\n-            batch_size = min(nrof_examples-i*args.batch_size, args.batch_size)\\\\n-            emb, lab = sess.run([embeddings, labels_batch], feed_dict={batch_size_placeholder: batch_size, \\\\n-                learning_rate_placeholder: lr, phase_train_placeholder: True})\\\\n-            emb_array[lab,:] = emb\\\\n-        print(\\\\\\\'%.3f\\\\\\\' % (time.time()-start_time))\\\\n-\\\\n-        # Select triplets based on the embeddings\\\\n-        print(\\\\\\\'Selecting suitable triplets for training\\\\\\\')\\\\n-        triplets, nrof_random_negs, nrof_triplets = select_triplets(emb_array, num_per_class, \\\\n-            image_paths, args.people_per_batch, args.alpha)\\\\n-        selection_time = time.time() - start_time\\\\n-        print(\\\\\\\'(nrof_random_negs, nrof_triplets) = (%d, %d): time=%.3f seconds\\\\\\\' % \\\\n-            (nrof_random_negs, nrof_triplets, selection_time))\\\\n-\\\\n-        # Perform training on the selected triplets\\\\n-        nrof_batches = int(np.ceil(nrof_triplets*3/args.batch_size))\\\\n-        triplet_paths = list(itertools.chain(*triplets))\\\\n-        labels_array = np.reshape(np.arange(len(triplet_paths)),(-1,3))\\\\n-        triplet_paths_array = np.reshape(np.expand_dims(np.array(triplet_paths),1), (-1,3))\\\\n-        sess.run(enqueue_op, {image_paths_placeholder: triplet_paths_array, labels_placeholder: labels_array})\\\\n-        nrof_examples = len(triplet_paths)\\\\n-        train_time = 0\\\\n-        i = 0\\\\n-        emb_array = np.zeros((nrof_examples, embedding_size))\\\\n-        loss_array = np.zeros((nrof_triplets,))\\\\n-        summary = tf.Summary()\\\\n-        step = 0\\\\n-        while i < nrof_batches:\\\\n-            start_time = time.time()\\\\n-            batch_size = min(nrof_examples-i*args.batch_size, args.batch_size)\\\\n-            feed_dict = {batch_size_placeholder: batch_size, learning_rate_placeholder: lr, phase_train_placeholder: True}\\\\n-            err, _, step, emb, lab = sess.run([loss, train_op, global_step, embeddings, labels_batch], feed_dict=feed_dict)\\\\n-            emb_array[lab,:] = emb\\\\n-            loss_array[i] = err\\\\n-            duration = time.time() - start_time\\\\n-            print(\\\\\\\'Epoch: [%d][%d/%d]\\\\\\\\tTime %.3f\\\\\\\\tLoss %2.3f\\\\\\\' %\\\\n-                  (epoch, batch_number+1, args.epoch_size, duration, err))\\\\n-            batch_number += 1\\\\n-            i += 1\\\\n-            train_time += duration\\\\n-            summary.value.add(tag=\\\\\\\'loss\\\\\\\', simple_value=err)\\\\n-            \\\\n-        # Add validation loss and accuracy to summary\\\\n-        #pylint: disable=maybe-no-member\\\\n-        summary.value.add(tag=\\\\\\\'time/selection\\\\\\\', simple_value=selection_time)\\\\n-        summary_writer.add_summary(summary, step)\\\\n-    return step\\\\n-  \\\\n-def select_triplets(embeddings, nrof_images_per_class, image_paths, people_per_batch, alpha):\\\\n-    """ Select the triplets for training\\\\n-    """\\\\n-    trip_idx = 0\\\\n-    emb_start_idx = 0\\\\n-    num_trips = 0\\\\n-    triplets = []\\\\n-    \\\\n-    # VGG Face: Choosing good triplets is crucial and should strike a balance between\\\\n-    #  selecting informative (i.e. challenging) examples and swamping training with examples that\\\\n-    #  are too hard. This is achieve by extending each pair (a, p) to a triplet (a, p, n) by sampling\\\\n-    #  the image n at random, but only between the ones that violate the triplet loss margin. The\\\\n-    #  latter is a form of hard-negative mining, but it is not as aggressive (and much cheaper) than\\\\n-    #  choosing the maximally violating example, as often done in structured output learning.\\\\n-\\\\n-    for i in xrange(people_per_batch):\\\\n-        nrof_images = int(nrof_images_per_class[i])\\\\n-        for j in xrange(1,nrof_images):\\\\n-            a_idx = emb_start_idx + j - 1\\\\n-            neg_dists_sqr = np.sum(np.square(embeddings[a_idx] - embeddings), 1)\\\\n-            for pair in xrange(j, nrof_images): # For every possible positive pair.\\\\n-                p_idx = emb_start_idx + pair\\\\n-                pos_dist_sqr = np.sum(np.square(embeddings[a_idx]-embeddings[p_idx]))\\\\n-                neg_dists_sqr[emb_start_idx:emb_start_idx+nrof_images] = np.NaN\\\\n-                #all_neg = np.where(np.logical_and(neg_dists_sqr-pos_dist_sqr<alpha, pos_dist_sqr<neg_dists_sqr))[0]  # FaceNet selection\\\\n-                all_neg = np.where(neg_dists_sqr-pos_dist_sqr<alpha)[0] # VGG Face selecction\\\\n-                nrof_random_negs = all_neg.shape[0]\\\\n-                if nrof_random_negs>0:\\\\n-                    rnd_idx = np.random.randint(nrof_random_negs)\\\\n-                    n_idx = all_neg[rnd_idx]\\\\n-                    triplets.append((image_paths[a_idx], image_paths[p_idx], image_paths[n_idx]))\\\\n-                    #print(\\\\\\\'Triplet %d: (%d, %d, %d), pos_dist=%2.6f, neg_dist=%2.6f (%d, %d, %d, %d, %d)\\\\\\\' % \\\\n-                    #    (trip_idx, a_idx, p_idx, n_idx, pos_dist_sqr, neg_dists_sqr[n_idx], nrof_random_negs, rnd_idx, i, j, emb_start_idx))\\\\n-                    trip_idx += 1\\\\n-\\\\n-                num_trips += 1\\\\n-\\\\n-        emb_start_idx += nrof_images\\\\n-\\\\n-    np.random.shuffle(triplets)\\\\n-    return triplets, num_trips, len(triplets)\\\\n-\\\\n-def sample_people(dataset, people_per_batch, images_per_person):\\\\n-    nrof_images = people_per_batch * images_per_person\\\\n-  \\\\n-    # Sample classes from the dataset\\\\n-    nrof_classes = len(dataset)\\\\n-    class_indices = np.arange(nrof_classes)\\\\n-    np.random.shuffle(class_indices)\\\\n-    \\\\n-    i = 0\\\\n-    image_paths = []\\\\n-    num_per_class = []\\\\n-    sampled_class_indices = []\\\\n-    # Sample images from these classes until we have enough\\\\n-    while len(image_paths)<nrof_images:\\\\n-        class_index = class_indices[i]\\\\n-        nrof_images_in_class = len(dataset[class_index])\\\\n-        image_indices = np.arange(nrof_images_in_class)\\\\n-        np.random.shuffle(image_indices)\\\\n-        nrof_images_from_class = min(nrof_images_in_class, images_per_person, nrof_images-len(image_paths))\\\\n-        idx = image_indices[0:nrof_images_from_class]\\\\n-        image_paths_for_class = [dataset[class_index].image_paths[j] for j in idx]\\\\n-        sampled_class_indices += [class_index]*nrof_images_from_class\\\\n-        image_paths += image_paths_for_class\\\\n-        num_per_class.append(nrof_images_from_class)\\\\n-        i+=1\\\\n-  \\\\n-    return image_paths, num_per_class\\\\n-\\\\n-def evaluate(sess, image_paths, embeddings, labels_batch, image_paths_placeholder, labels_placeholder, \\\\n-        batch_size_placeholder, learning_rate_placeholder, phase_train_placeholder, enqueue_op, actual_issame, batch_size, \\\\n-        nrof_folds, log_dir, step, summary_writer, embedding_size):\\\\n-    start_time = time.time()\\\\n-    # Run forward pass to calculate embeddings\\\\n-    print(\\\\\\\'Running forward pass on LFW images: \\\\\\\', end=\\\\\\\'\\\\\\\')\\\\n-    \\\\n-    nrof_images = len(actual_issame)*2\\\\n-    assert(len(image_paths)==nrof_images)\\\\n-    labels_array = np.reshape(np.arange(nrof_images),(-1,3))\\\\n-    image_paths_array = np.reshape(np.expand_dims(np.array(image_paths),1), (-1,3))\\\\n-    sess.run(enqueue_op, {image_paths_placeholder: image_paths_array, labels_placeholder: labels_array})\\\\n-    emb_array = np.zeros((nrof_images, embedding_size))\\\\n-    nrof_batches = int(np.ceil(nrof_images / batch_size))\\\\n-    label_check_array = np.zeros((nrof_images,))\\\\n-    for i in xrange(nrof_batches):\\\\n-        batch_size = min(nrof_images-i*batch_size, batch_size)\\\\n-        emb, lab = sess.run([embeddings, labels_batch], feed_dict={batch_size_placeholder: batch_size,\\\\n-            learning_rate_placeholder: 0.0, phase_train_placeholder: False})\\\\n-        emb_array[lab,:] = emb\\\\n-        label_check_array[lab] = 1\\\\n-    print(\\\\\\\'%.3f\\\\\\\' % (time.time()-start_time))\\\\n-    \\\\n-    assert(np.all(label_check_array==1))\\\\n-    \\\\n-    _, _, accuracy, val, val_std, far = lfw.evaluate(emb_array, actual_issame, nrof_folds=nrof_folds)\\\\n-    \\\\n-    print(\\\\\\\'Accuracy: %1.3f+-%1.3f\\\\\\\' % (np.mean(accuracy), np.std(accuracy)))\\\\n-    print(\\\\\\\'Validation rate: %2.5f+-%2.5f @ FAR=%2.5f\\\\\\\' % (val, val_std, far))\\\\n-    lfw_time = time.time() - start_time\\\\n-    # Add validation loss and accuracy to summary\\\\n-    summary = tf.Summary()\\\\n-    #pylint: disable=maybe-no-member\\\\n-    summary.value.add(tag=\\\\\\\'lfw/accuracy\\\\\\\', simple_value=np.mean(accuracy))\\\\n-    summary.value.add(tag=\\\\\\\'lfw/val_rate\\\\\\\', simple_value=val)\\\\n-    summary.value.add(tag=\\\\\\\'time/lfw\\\\\\\', simple_value=lfw_time)\\\\n-    summary_writer.add_summary(summary, step)\\\\n-    with open(os.path.join(log_dir,\\\\\\\'lfw_result.txt\\\\\\\'),\\\\\\\'at\\\\\\\') as f:\\\\n-        f.write(\\\\\\\'%d\\\\\\\\t%.5f\\\\\\\\t%.5f\\\\\\\\n\\\\\\\' % (step, np.mean(accuracy), val))\\\\n-\\\\n-def save_variables_and_metagraph(sess, saver, summary_writer, model_dir, model_name, step):\\\\n-    # Save the model checkpoint\\\\n-    print(\\\\\\\'Saving variables\\\\\\\')\\\\n-    start_time = time.time()\\\\n-    checkpoint_path = os.path.join(model_dir, \\\\\\\'model-%s.ckpt\\\\\\\' % model_name)\\\\n-    saver.save(sess, checkpoint_path, global_step=step, write_meta_graph=False)\\\\n-    save_time_variables = time.time() - start_time\\\\n-    print(\\\\\\\'Variables saved in %.2f seconds\\\\\\\' % save_time_variables)\\\\n-    metagraph_filename = os.path.join(model_dir, \\\\\\\'model-%s.meta\\\\\\\' % model_name)\\\\n-    save_time_metagraph = 0  \\\\n-    if not os.path.exists(metagraph_filename):\\\\n-        print(\\\\\\\'Saving metagraph\\\\\\\')\\\\n-        start_time = time.time()\\\\n-        saver.export_meta_graph(metagraph_filename)\\\\n-        save_time_metagraph = time.time() - start_time\\\\n-        print(\\\\\\\'Metagraph saved in %.2f seconds\\\\\\\' % save_time_metagraph)\\\\n-    summary = tf.Summary()\\\\n-    #pylint: disable=maybe-no-member\\\\n-    summary.value.add(tag=\\\\\\\'time/save_variables\\\\\\\', simple_value=save_time_variables)\\\\n-    summary.value.add(tag=\\\\\\\'time/save_metagraph\\\\\\\', simple_value=save_time_metagraph)\\\\n-    summary_writer.add_summary(summary, step)\\\\n-  \\\\n-  \\\\n-def get_learning_rate_from_file(filename, epoch):\\\\n-    with open(filename, \\\\\\\'r\\\\\\\') as f:\\\\n-        for line in f.readlines():\\\\n-            line = line.split(\\\\\\\'#\\\\\\\', 1)[0]\\\\n-            if line:\\\\n-                par = line.strip().split(\\\\\\\':\\\\\\\')\\\\n-                e = int(par[0])\\\\n-                lr = float(par[1])\\\\n-                if e <= epoch:\\\\n-                    learning_rate = lr\\\\n-                else:\\\\n-                    return learning_rate\\\\n-    \\\\n-\\\\n-def parse_arguments(argv):\\\\n-    parser = argparse.ArgumentParser()\\\\n-    \\\\n-    parser.add_argument(\\\\\\\'--logs_base_dir\\\\\\\', type=str, \\\\n-        help=\\\\\\\'Directory where to write event logs.\\\\\\\', default=\\\\\\\'~/logs/facenet\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--models_base_dir\\\\\\\', type=str,\\\\n-        help=\\\\\\\'Directory where to write trained models and checkpoints.\\\\\\\', default=\\\\\\\'~/models/facenet\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--gpu_memory_fraction\\\\\\\', type=float,\\\\n-        help=\\\\\\\'Upper bound on the amount of GPU memory that will be used by the process.\\\\\\\', default=1.0)\\\\n-    parser.add_argument(\\\\\\\'--pretrained_model\\\\\\\', type=str,\\\\n-        help=\\\\\\\'Load a pretrained model before training starts.\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--data_dir\\\\\\\', type=str,\\\\n-        help=\\\\\\\'Path to the data directory containing aligned face patches.\\\\\\\',\\\\n-        default=\\\\\\\'~/datasets/casia/casia_maxpy_mtcnnalign_182_160\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--model_def\\\\\\\', type=str,\\\\n-        help=\\\\\\\'Model definition. Points to a module containing the definition of the inference graph.\\\\\\\', default=\\\\\\\'models.inception_resnet_v1\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--max_nrof_epochs\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Number of epochs to run.\\\\\\\', default=500)\\\\n-    parser.add_argument(\\\\\\\'--batch_size\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Number of images to process in a batch.\\\\\\\', default=90)\\\\n-    parser.add_argument(\\\\\\\'--image_size\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Image size (height, width) in pixels.\\\\\\\', default=160)\\\\n-    parser.add_argument(\\\\\\\'--people_per_batch\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Number of people per batch.\\\\\\\', default=45)\\\\n-    parser.add_argument(\\\\\\\'--images_per_person\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Number of images per person.\\\\\\\', default=40)\\\\n-    parser.add_argument(\\\\\\\'--epoch_size\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Number of batches per epoch.\\\\\\\', default=1000)\\\\n-    parser.add_argument(\\\\\\\'--alpha\\\\\\\', type=float,\\\\n-        help=\\\\\\\'Positive to negative triplet distance margin.\\\\\\\', default=0.2)\\\\n-    parser.add_argument(\\\\\\\'--embedding_size\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Dimensionality of the embedding.\\\\\\\', default=128)\\\\n-    parser.add_argument(\\\\\\\'--random_crop\\\\\\\', \\\\n-        help=\\\\\\\'Performs random cropping of training images. If false, the center image_size pixels from the training images are used. \\\\\\\' +\\\\n-         \\\\\\\'If the size of the images in the data directory is equal to image_size no cropping is performed\\\\\\\', action=\\\\\\\'store_true\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--random_flip\\\\\\\', \\\\n-        help=\\\\\\\'Performs random horizontal flipping of training images.\\\\\\\', action=\\\\\\\'store_true\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--keep_probability\\\\\\\', type=float,\\\\n-        help=\\\\\\\'Keep probability of dropout for the fully connected layer(s).\\\\\\\', default=1.0)\\\\n-    parser.add_argument(\\\\\\\'--weight_decay\\\\\\\', type=float,\\\\n-        help=\\\\\\\'L2 weight regularization.\\\\\\\', default=0.0)\\\\n-    parser.add_argument(\\\\\\\'--optimizer\\\\\\\', type=str, choices=[\\\\\\\'ADAGRAD\\\\\\\', \\\\\\\'ADADELTA\\\\\\\', \\\\\\\'ADAM\\\\\\\', \\\\\\\'RMSPROP\\\\\\\', \\\\\\\'MOM\\\\\\\'],\\\\n-        help=\\\\\\\'The optimization algorithm to use\\\\\\\', default=\\\\\\\'ADAGRAD\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--learning_rate\\\\\\\', type=float,\\\\n-        help=\\\\\\\'Initial learning rate. If set to a negative value a learning rate \\\\\\\' +\\\\n-        \\\\\\\'schedule can be specified in the file "learning_rate_schedule.txt"\\\\\\\', default=0.1)\\\\n-    parser.add_argument(\\\\\\\'--learning_rate_decay_epochs\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Number of epochs between learning rate decay.\\\\\\\', default=100)\\\\n-    parser.add_argument(\\\\\\\'--learning_rate_decay_factor\\\\\\\', type=float,\\\\n-        help=\\\\\\\'Learning rate decay factor.\\\\\\\', default=1.0)\\\\n-    parser.add_argument(\\\\\\\'--moving_average_decay\\\\\\\', type=float,\\\\n-        help=\\\\\\\'Exponential decay for tracking of training parameters.\\\\\\\', default=0.9999)\\\\n-    parser.add_argument(\\\\\\\'--seed\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Random seed.\\\\\\\', default=666)\\\\n-    parser.add_argument(\\\\\\\'--learning_rate_schedule_file\\\\\\\', type=str,\\\\n-        help=\\\\\\\'File containing the learning rate schedule that is used when learning_rate is set to to -1.\\\\\\\', default=\\\\\\\'data/learning_rate_schedule.txt\\\\\\\')\\\\n-\\\\n-    # Parameters for validation on LFW\\\\n-    parser.add_argument(\\\\\\\'--lfw_pairs\\\\\\\', type=str,\\\\n-        help=\\\\\\\'The file containing the pairs to use for validation.\\\\\\\', default=\\\\\\\'data/pairs.txt\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--lfw_dir\\\\\\\', type=str,\\\\n-        help=\\\\\\\'Path to the data directory containing aligned face patches.\\\\\\\', default=\\\\\\\'\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--lfw_nrof_folds\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Number of folds to use for cross validation. Mainly used for testing.\\\\\\\', default=10)\\\\n-    return parser.parse_args(argv)\\\\n-  \\\\n-\\\\n-if __name__ == \\\\\\\'__main__\\\\\\\':\\\\n-    main(parse_arguments(sys.argv[1:]))\\\\ndiff --git a/src/validate_on_lfw.py b/src/validate_on_lfw.py\\\\ndeleted file mode 100644\\\\nindex ac456c5..0000000\\\\n--- a/src/validate_on_lfw.py\\\\n+++ /dev/null\\\\n@@ -1,164 +0,0 @@\\\\n-"""Validate a face recognizer on the "Labeled Faces in the Wild" dataset (http://vis-www.cs.umass.edu/lfw/).\\\\n-Embeddings are calculated using the pairs from http://vis-www.cs.umass.edu/lfw/pairs.txt and the ROC curve\\\\n-is calculated and plotted. Both the model metagraph and the model parameters need to exist\\\\n-in the same directory, and the metagraph should have the extension \\\\\\\'.meta\\\\\\\'.\\\\n-"""\\\\n-# MIT License\\\\n-# \\\\n-# Copyright (c) 2016 David Sandberg\\\\n-# \\\\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\n-# of this software and associated documentation files (the "Software"), to deal\\\\n-# in the Software without restriction, including without limitation the rights\\\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\n-# copies of the Software, and to permit persons to whom the Software is\\\\n-# furnished to do so, subject to the following conditions:\\\\n-# \\\\n-# The above copyright notice and this permission notice shall be included in all\\\\n-# copies or substantial portions of the Software.\\\\n-# \\\\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\n-# SOFTWARE.\\\\n-\\\\n-from __future__ import absolute_import\\\\n-from __future__ import division\\\\n-from __future__ import print_function\\\\n-\\\\n-import tensorflow as tf\\\\n-import numpy as np\\\\n-import argparse\\\\n-import facenet\\\\n-import lfw\\\\n-import os\\\\n-import sys\\\\n-from tensorflow.python.ops import data_flow_ops\\\\n-from sklearn import metrics\\\\n-from scipy.optimize import brentq\\\\n-from scipy import interpolate\\\\n-\\\\n-def main(args):\\\\n-  \\\\n-    with tf.Graph().as_default():\\\\n-      \\\\n-        with tf.Session() as sess:\\\\n-            \\\\n-            # Read the file containing the pairs used for testing\\\\n-            pairs = lfw.read_pairs(os.path.expanduser(args.lfw_pairs))\\\\n-\\\\n-            # Get the paths for the corresponding images\\\\n-            paths, actual_issame = lfw.get_paths(os.path.expanduser(args.lfw_dir), pairs)\\\\n-            \\\\n-            image_paths_placeholder = tf.placeholder(tf.string, shape=(None,1), name=\\\\\\\'image_paths\\\\\\\')\\\\n-            labels_placeholder = tf.placeholder(tf.int32, shape=(None,1), name=\\\\\\\'labels\\\\\\\')\\\\n-            batch_size_placeholder = tf.placeholder(tf.int32, name=\\\\\\\'batch_size\\\\\\\')\\\\n-            control_placeholder = tf.placeholder(tf.int32, shape=(None,1), name=\\\\\\\'control\\\\\\\')\\\\n-            phase_train_placeholder = tf.placeholder(tf.bool, name=\\\\\\\'phase_train\\\\\\\')\\\\n- \\\\n-            nrof_preprocess_threads = 4\\\\n-            image_size = (args.image_size, args.image_size)\\\\n-            eval_input_queue = data_flow_ops.FIFOQueue(capacity=2000000,\\\\n-                                        dtypes=[tf.string, tf.int32, tf.int32],\\\\n-                                        shapes=[(1,), (1,), (1,)],\\\\n-                                        shared_name=None, name=None)\\\\n-            eval_enqueue_op = eval_input_queue.enqueue_many([image_paths_placeholder, labels_placeholder, control_placeholder], name=\\\\\\\'eval_enqueue_op\\\\\\\')\\\\n-            image_batch, label_batch = facenet.create_input_pipeline(eval_input_queue, image_size, nrof_preprocess_threads, batch_size_placeholder)\\\\n-     \\\\n-            # Load the model\\\\n-            input_map = {\\\\\\\'image_batch\\\\\\\': image_batch, \\\\\\\'label_batch\\\\\\\': label_batch, \\\\\\\'phase_train\\\\\\\': phase_train_placeholder}\\\\n-            facenet.load_model(args.model, input_map=input_map)\\\\n-\\\\n-            # Get output tensor\\\\n-            embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")\\\\n-#              \\\\n-            coord = tf.train.Coordinator()\\\\n-            tf.train.start_queue_runners(coord=coord, sess=sess)\\\\n-\\\\n-            evaluate(sess, eval_enqueue_op, image_paths_placeholder, labels_placeholder, phase_train_placeholder, batch_size_placeholder, control_placeholder,\\\\n-                embeddings, label_batch, paths, actual_issame, args.lfw_batch_size, args.lfw_nrof_folds, args.distance_metric, args.subtract_mean,\\\\n-                args.use_flipped_images, args.use_fixed_image_standardization)\\\\n-\\\\n-              \\\\n-def evaluate(sess, enqueue_op, image_paths_placeholder, labels_placeholder, phase_train_placeholder, batch_size_placeholder, control_placeholder,\\\\n-        embeddings, labels, image_paths, actual_issame, batch_size, nrof_folds, distance_metric, subtract_mean, use_flipped_images, use_fixed_image_standardization):\\\\n-    # Run forward pass to calculate embeddings\\\\n-    print(\\\\\\\'Runnning forward pass on LFW images\\\\\\\')\\\\n-    \\\\n-    # Enqueue one epoch of image paths and labels\\\\n-    nrof_embeddings = len(actual_issame)*2  # nrof_pairs * nrof_images_per_pair\\\\n-    nrof_flips = 2 if use_flipped_images else 1\\\\n-    nrof_images = nrof_embeddings * nrof_flips\\\\n-    labels_array = np.expand_dims(np.arange(0,nrof_images),1)\\\\n-    image_paths_array = np.expand_dims(np.repeat(np.array(image_paths),nrof_flips),1)\\\\n-    control_array = np.zeros_like(labels_array, np.int32)\\\\n-    if use_fixed_image_standardization:\\\\n-        control_array += np.ones_like(labels_array)*facenet.FIXED_STANDARDIZATION\\\\n-    if use_flipped_images:\\\\n-        # Flip every second image\\\\n-        control_array += (labels_array % 2)*facenet.FLIP\\\\n-    sess.run(enqueue_op, {image_paths_placeholder: image_paths_array, labels_placeholder: labels_array, control_placeholder: control_array})\\\\n-    \\\\n-    embedding_size = int(embeddings.get_shape()[1])\\\\n-    assert nrof_images % batch_size == 0, \\\\\\\'The number of LFW images must be an integer multiple of the LFW batch size\\\\\\\'\\\\n-    nrof_batches = nrof_images // batch_size\\\\n-    emb_array = np.zeros((nrof_images, embedding_size))\\\\n-    lab_array = np.zeros((nrof_images,))\\\\n-    for i in range(nrof_batches):\\\\n-        feed_dict = {phase_train_placeholder:False, batch_size_placeholder:batch_size}\\\\n-        emb, lab = sess.run([embeddings, labels], feed_dict=feed_dict)\\\\n-        lab_array[lab] = lab\\\\n-        emb_array[lab, :] = emb\\\\n-        if i % 10 == 9:\\\\n-            print(\\\\\\\'.\\\\\\\', end=\\\\\\\'\\\\\\\')\\\\n-            sys.stdout.flush()\\\\n-    print(\\\\\\\'\\\\\\\')\\\\n-    embeddings = np.zeros((nrof_embeddings, embedding_size*nrof_flips))\\\\n-    if use_flipped_images:\\\\n-        # Concatenate embeddings for flipped and non flipped version of the images\\\\n-        embeddings[:,:embedding_size] = emb_array[0::2,:]\\\\n-        embeddings[:,embedding_size:] = emb_array[1::2,:]\\\\n-    else:\\\\n-        embeddings = emb_array\\\\n-\\\\n-    assert np.array_equal(lab_array, np.arange(nrof_images))==True, \\\\\\\'Wrong labels used for evaluation, possibly caused by training examples left in the input pipeline\\\\\\\'\\\\n-    tpr, fpr, accuracy, val, val_std, far = lfw.evaluate(embeddings, actual_issame, nrof_folds=nrof_folds, distance_metric=distance_metric, subtract_mean=subtract_mean)\\\\n-    \\\\n-    print(\\\\\\\'Accuracy: %2.5f+-%2.5f\\\\\\\' % (np.mean(accuracy), np.std(accuracy)))\\\\n-    print(\\\\\\\'Validation rate: %2.5f+-%2.5f @ FAR=%2.5f\\\\\\\' % (val, val_std, far))\\\\n-    \\\\n-    auc = metrics.auc(fpr, tpr)\\\\n-    print(\\\\\\\'Area Under Curve (AUC): %1.3f\\\\\\\' % auc)\\\\n-    eer = brentq(lambda x: 1. - x - interpolate.interp1d(fpr, tpr)(x), 0., 1.)\\\\n-    print(\\\\\\\'Equal Error Rate (EER): %1.3f\\\\\\\' % eer)\\\\n-    \\\\n-def parse_arguments(argv):\\\\n-    parser = argparse.ArgumentParser()\\\\n-    \\\\n-    parser.add_argument(\\\\\\\'lfw_dir\\\\\\\', type=str,\\\\n-        help=\\\\\\\'Path to the data directory containing aligned LFW face patches.\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--lfw_batch_size\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Number of images to process in a batch in the LFW test set.\\\\\\\', default=100)\\\\n-    parser.add_argument(\\\\\\\'model\\\\\\\', type=str, \\\\n-        help=\\\\\\\'Could be either a directory containing the meta_file and ckpt_file or a model protobuf (.pb) file\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--image_size\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Image size (height, width) in pixels.\\\\\\\', default=160)\\\\n-    parser.add_argument(\\\\\\\'--lfw_pairs\\\\\\\', type=str,\\\\n-        help=\\\\\\\'The file containing the pairs to use for validation.\\\\\\\', default=\\\\\\\'data/pairs.txt\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--lfw_nrof_folds\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Number of folds to use for cross validation. Mainly used for testing.\\\\\\\', default=10)\\\\n-    parser.add_argument(\\\\\\\'--distance_metric\\\\\\\', type=int,\\\\n-        help=\\\\\\\'Distance metric  0:euclidian, 1:cosine similarity.\\\\\\\', default=0)\\\\n-    parser.add_argument(\\\\\\\'--use_flipped_images\\\\\\\', \\\\n-        help=\\\\\\\'Concatenates embeddings for the image and its horizontally flipped counterpart.\\\\\\\', action=\\\\\\\'store_true\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--subtract_mean\\\\\\\', \\\\n-        help=\\\\\\\'Subtract feature mean before calculating distance.\\\\\\\', action=\\\\\\\'store_true\\\\\\\')\\\\n-    parser.add_argument(\\\\\\\'--use_fixed_image_standardization\\\\\\\', \\\\n-        help=\\\\\\\'Performs fixed standardization of images.\\\\\\\', action=\\\\\\\'store_true\\\\\\\')\\\\n-    return parser.parse_args(argv)\\\\n-\\\\n-if __name__ == \\\\\\\'__main__\\\\\\\':\\\\n-    main(parse_arguments(sys.argv[1:]))\\\\ndiff --git a/test/a b/test/a\\\\ndeleted file mode 100644\\\\nindex 8b13789..0000000\\\\n--- a/test/a\\\\n+++ /dev/null\\\\n@@ -1 +0,0 @@\\\\n-\\\\ndiff --git a/test/batch_norm_test.py b/test/batch_norm_test.py\\\\ndeleted file mode 100644\\\\nindex 48cfd55..0000000\\\\n--- a/test/batch_norm_test.py\\\\n+++ /dev/null\\\\n@@ -1,66 +0,0 @@\\\\n-# MIT License\\\\n-# \\\\n-# Copyright (c) 2016 David Sandberg\\\\n-# \\\\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\n-# of this software and associated documentation files (the "Software"), to deal\\\\n-# in the Software without restriction, including without limitation the rights\\\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\n-# copies of the Software, and to permit persons to whom the Software is\\\\n-# furnished to do so, subject to the following conditions:\\\\n-# \\\\n-# The above copyright notice and this permission notice shall be included in all\\\\n-# copies or substantial portions of the Software.\\\\n-# \\\\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\n-# SOFTWARE.\\\\n-\\\\n-import unittest\\\\n-import tensorflow as tf\\\\n-import models\\\\n-import numpy as np\\\\n-import numpy.testing as testing\\\\n-\\\\n-class BatchNormTest(unittest.TestCase):\\\\n-\\\\n-\\\\n-    @unittest.skip("Skip batch norm test case")\\\\n-    def testBatchNorm(self):\\\\n-      \\\\n-        tf.set_random_seed(123)\\\\n-  \\\\n-        x = tf.placeholder(tf.float32, [None, 20, 20, 10], name=\\\\\\\'input\\\\\\\')\\\\n-        phase_train = tf.placeholder(tf.bool, name=\\\\\\\'phase_train\\\\\\\')\\\\n-        \\\\n-        # generate random noise to pass into batch norm\\\\n-        #x_gen = tf.random_normal([50,20,20,10])\\\\n-        \\\\n-        bn = models.network.batch_norm(x, phase_train)\\\\n-        \\\\n-        init = tf.global_variables_initializer()\\\\n-        sess = tf.Session(config=tf.ConfigProto())\\\\n-        sess.run(init)\\\\n-  \\\\n-        with sess.as_default():\\\\n-        \\\\n-            #generate a constant variable to pass into batch norm\\\\n-            y = np.random.normal(0, 1, size=(50,20,20,10))\\\\n-            \\\\n-            feed_dict = {x: y, phase_train: True}\\\\n-            sess.run(bn, feed_dict=feed_dict)\\\\n-            \\\\n-            feed_dict = {x: y, phase_train: False}\\\\n-            y1 = sess.run(bn, feed_dict=feed_dict)\\\\n-            y2 = sess.run(bn, feed_dict=feed_dict)\\\\n-            \\\\n-            testing.assert_almost_equal(y1, y2, 10, \\\\\\\'Output from two forward passes with phase_train==false should be equal\\\\\\\')\\\\n-\\\\n-\\\\n-if __name__ == "__main__":\\\\n-    unittest.main()\\\\n-    \\\\n\\\\\\\\ No newline at end of file\\\\ndiff --git a/test/center_loss_test.py b/test/center_loss_test.py\\\\ndeleted file mode 100644\\\\nindex 196cd11..0000000\\\\n--- a/test/center_loss_test.py\\\\n+++ /dev/null\\\\n@@ -1,87 +0,0 @@\\\\n-# MIT License\\\\n-# \\\\n-# Copyright (c) 2016 David Sandberg\\\\n-# \\\\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\n-# of this software and associated documentation files (the "Software"), to deal\\\\n-# in the Software without restriction, including without limitation the rights\\\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\n-# copies of the Software, and to permit persons to whom the Software is\\\\n-# furnished to do so, subject to the following conditions:\\\\n-# \\\\n-# The above copyright notice and this permission notice shall be included in all\\\\n-# copies or substantial portions of the Software.\\\\n-# \\\\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\n-# SOFTWARE.\\\\n-\\\\n-import unittest\\\\n-import tensorflow as tf\\\\n-import numpy as np\\\\n-import facenet\\\\n-\\\\n-class CenterLossTest(unittest.TestCase):\\\\n-  \\\\n-\\\\n-\\\\n-    def testCenterLoss(self):\\\\n-        batch_size = 16\\\\n-        nrof_features = 2\\\\n-        nrof_classes = 16\\\\n-        alfa = 0.5\\\\n-        \\\\n-        with tf.Graph().as_default():\\\\n-        \\\\n-            features = tf.placeholder(tf.float32, shape=(batch_size, nrof_features), name=\\\\\\\'features\\\\\\\')\\\\n-            labels = tf.placeholder(tf.int32, shape=(batch_size,), name=\\\\\\\'labels\\\\\\\')\\\\n-\\\\n-            # Define center loss\\\\n-            center_loss, centers = facenet.center_loss(features, labels, alfa, nrof_classes)\\\\n-            \\\\n-            label_to_center = np.array( [ \\\\n-                 [-3,-3],  [-3,-1],  [-3,1],  [-3,3],\\\\n-                 [-1,-3],  [-1,-1],  [-1,1],  [-1,3],\\\\n-                 [ 1,-3],  [ 1,-1],  [ 1,1],  [ 1,3],\\\\n-                 [ 3,-3],  [ 3,-1],  [ 3,1],  [ 3,3] \\\\n-                 ])\\\\n-                \\\\n-            sess = tf.Session()\\\\n-            with sess.as_default():\\\\n-                sess.run(tf.global_variables_initializer())\\\\n-                np.random.seed(seed=666)\\\\n-                \\\\n-                for _ in range(0,100):\\\\n-                    # Create array of random labels\\\\n-                    lbls = np.random.randint(low=0, high=nrof_classes, size=(batch_size,))\\\\n-                    feats = create_features(label_to_center, batch_size, nrof_features, lbls)\\\\n-\\\\n-                    center_loss_, centers_ = sess.run([center_loss, centers], feed_dict={features:feats, labels:lbls})\\\\n-                    \\\\n-                # After a large number of updates the estimated centers should be close to the true ones\\\\n-                np.testing.assert_almost_equal(centers_, label_to_center, decimal=5, err_msg=\\\\\\\'Incorrect estimated centers\\\\\\\')\\\\n-                np.testing.assert_almost_equal(center_loss_, 0.0, decimal=5, err_msg=\\\\\\\'Incorrect center loss\\\\\\\')\\\\n-                \\\\n-\\\\n-def create_features(label_to_center, batch_size, nrof_features, labels):\\\\n-    # Map label to center\\\\n-#     label_to_center_dict = { \\\\n-#          0:(-3,-3),  1:(-3,-1),  2:(-3,1),  3:(-3,3),\\\\n-#          4:(-1,-3),  5:(-1,-1),  6:(-1,1),  7:(-1,3),\\\\n-#          8:( 1,-3),  9:( 1,-1), 10:( 1,1), 11:( 1,3),\\\\n-#         12:( 3,-3), 13:( 3,-1), 14:( 3,1), 15:( 3,3),\\\\n-#         }\\\\n-    # Create array of features corresponding to the labels\\\\n-    feats = np.zeros((batch_size, nrof_features))\\\\n-    for i in range(batch_size):\\\\n-        cntr =  label_to_center[labels[i]]\\\\n-        for j in range(nrof_features):\\\\n-            feats[i,j] = cntr[j]\\\\n-    return feats\\\\n-                      \\\\n-if __name__ == "__main__":\\\\n-    unittest.main()\\\\ndiff --git a/test/restore_test.py b/test/restore_test.py\\\\ndeleted file mode 100644\\\\nindex befb04d..0000000\\\\n--- a/test/restore_test.py\\\\n+++ /dev/null\\\\n@@ -1,181 +0,0 @@\\\\n-# MIT License\\\\n-# \\\\n-# Copyright (c) 2016 David Sandberg\\\\n-# \\\\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\n-# of this software and associated documentation files (the "Software"), to deal\\\\n-# in the Software without restriction, including without limitation the rights\\\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\n-# copies of the Software, and to permit persons to whom the Software is\\\\n-# furnished to do so, subject to the following conditions:\\\\n-# \\\\n-# The above copyright notice and this permission notice shall be included in all\\\\n-# copies or substantial portions of the Software.\\\\n-# \\\\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\n-# SOFTWARE.\\\\n-\\\\n-import unittest\\\\n-import tempfile\\\\n-import os\\\\n-import shutil\\\\n-import tensorflow as tf\\\\n-import numpy as np\\\\n-\\\\n-class TrainTest(unittest.TestCase):\\\\n-  \\\\n-    @classmethod\\\\n-    def setUpClass(self):\\\\n-        self.tmp_dir = tempfile.mkdtemp()\\\\n-        \\\\n-    @classmethod\\\\n-    def tearDownClass(self):\\\\n-        # Recursively remove the temporary directory\\\\n-        shutil.rmtree(self.tmp_dir)\\\\n-\\\\n-    def test_restore_noema(self):\\\\n-        \\\\n-        # Create 100 phony x, y data points in NumPy, y = x * 0.1 + 0.3\\\\n-        x_data = np.random.rand(100).astype(np.float32)\\\\n-        y_data = x_data * 0.1 + 0.3\\\\n-        \\\\n-        # Try to find values for W and b that compute y_data = W * x_data + b\\\\n-        # (We know that W should be 0.1 and b 0.3, but TensorFlow will\\\\n-        # figure that out for us.)\\\\n-        W = tf.Variable(tf.random_uniform([1], -1.0, 1.0), name=\\\\\\\'W\\\\\\\')\\\\n-        b = tf.Variable(tf.zeros([1]), name=\\\\\\\'b\\\\\\\')\\\\n-        y = W * x_data + b\\\\n-        \\\\n-        # Minimize the mean squared errors.\\\\n-        loss = tf.reduce_mean(tf.square(y - y_data))\\\\n-        optimizer = tf.train.GradientDescentOptimizer(0.5)\\\\n-        train = optimizer.minimize(loss)\\\\n-        \\\\n-        # Before starting, initialize the variables.  We will \\\\\\\'run\\\\\\\' this first.\\\\n-        init = tf.global_variables_initializer()\\\\n-\\\\n-        saver = tf.train.Saver(tf.trainable_variables())\\\\n-        \\\\n-        # Launch the graph.\\\\n-        sess = tf.Session()\\\\n-        sess.run(init)\\\\n-        \\\\n-        # Fit the line.\\\\n-        for _ in range(201):\\\\n-            sess.run(train)\\\\n-        \\\\n-        w_reference = sess.run(\\\\\\\'W:0\\\\\\\')\\\\n-        b_reference = sess.run(\\\\\\\'b:0\\\\\\\')\\\\n-        \\\\n-        saver.save(sess, os.path.join(self.tmp_dir, "model_ex1"))\\\\n-        \\\\n-        tf.reset_default_graph()\\\\n-\\\\n-        saver = tf.train.import_meta_graph(os.path.join(self.tmp_dir, "model_ex1.meta"))\\\\n-        sess = tf.Session()\\\\n-        saver.restore(sess, os.path.join(self.tmp_dir, "model_ex1"))\\\\n-        \\\\n-        w_restored = sess.run(\\\\\\\'W:0\\\\\\\')\\\\n-        b_restored = sess.run(\\\\\\\'b:0\\\\\\\')\\\\n-        \\\\n-        self.assertAlmostEqual(w_reference, w_restored, \\\\\\\'Restored model use different weight than the original model\\\\\\\')\\\\n-        self.assertAlmostEqual(b_reference, b_restored, \\\\\\\'Restored model use different weight than the original model\\\\\\\')\\\\n-\\\\n-\\\\n-    @unittest.skip("Skip restore EMA test case for now")\\\\n-    def test_restore_ema(self):\\\\n-        \\\\n-        # Create 100 phony x, y data points in NumPy, y = x * 0.1 + 0.3\\\\n-        x_data = np.random.rand(100).astype(np.float32)\\\\n-        y_data = x_data * 0.1 + 0.3\\\\n-        \\\\n-        # Try to find values for W and b that compute y_data = W * x_data + b\\\\n-        # (We know that W should be 0.1 and b 0.3, but TensorFlow will\\\\n-        # figure that out for us.)\\\\n-        W = tf.Variable(tf.random_uniform([1], -1.0, 1.0), name=\\\\\\\'W\\\\\\\')\\\\n-        b = tf.Variable(tf.zeros([1]), name=\\\\\\\'b\\\\\\\')\\\\n-        y = W * x_data + b\\\\n-        \\\\n-        # Minimize the mean squared errors.\\\\n-        loss = tf.reduce_mean(tf.square(y - y_data))\\\\n-        optimizer = tf.train.GradientDescentOptimizer(0.5)\\\\n-        opt_op = optimizer.minimize(loss)\\\\n-\\\\n-        # Track the moving averages of all trainable variables.\\\\n-        ema = tf.train.ExponentialMovingAverage(decay=0.9999)\\\\n-        averages_op = ema.apply(tf.trainable_variables())\\\\n-        with tf.control_dependencies([opt_op]):\\\\n-            train_op = tf.group(averages_op)\\\\n-  \\\\n-        # Before starting, initialize the variables.  We will \\\\\\\'run\\\\\\\' this first.\\\\n-        init = tf.global_variables_initializer()\\\\n-\\\\n-        saver = tf.train.Saver(tf.trainable_variables())\\\\n-        \\\\n-        # Launch the graph.\\\\n-        sess = tf.Session()\\\\n-        sess.run(init)\\\\n-        \\\\n-        # Fit the line.\\\\n-        for _ in range(201):\\\\n-            sess.run(train_op)\\\\n-        \\\\n-        w_reference = sess.run(\\\\\\\'W/ExponentialMovingAverage:0\\\\\\\')\\\\n-        b_reference = sess.run(\\\\\\\'b/ExponentialMovingAverage:0\\\\\\\')\\\\n-        \\\\n-        saver.save(sess, os.path.join(self.tmp_dir, "model_ex1"))\\\\n-                \\\\n-        tf.reset_default_graph()\\\\n-\\\\n-        tf.train.import_meta_graph(os.path.join(self.tmp_dir, "model_ex1.meta"))\\\\n-        sess = tf.Session()\\\\n-        \\\\n-        print(\\\\\\\'------------------------------------------------------\\\\\\\')\\\\n-        for var in tf.global_variables():\\\\n-            print(\\\\\\\'all variables: \\\\\\\' + var.op.name)\\\\n-        for var in tf.trainable_variables():\\\\n-            print(\\\\\\\'normal variable: \\\\\\\' + var.op.name)\\\\n-        for var in tf.moving_average_variables():\\\\n-            print(\\\\\\\'ema variable: \\\\\\\' + var.op.name)\\\\n-        print(\\\\\\\'------------------------------------------------------\\\\\\\')\\\\n-\\\\n-        mode = 1\\\\n-        restore_vars = {}\\\\n-        if mode == 0:\\\\n-            ema = tf.train.ExponentialMovingAverage(1.0)\\\\n-            for var in tf.trainable_variables():\\\\n-                print(\\\\\\\'%s: %s\\\\\\\' % (ema.average_name(var), var.op.name))\\\\n-                restore_vars[ema.average_name(var)] = var\\\\n-        elif mode == 1:\\\\n-            for var in tf.trainable_variables():\\\\n-                ema_name = var.op.name + \\\\\\\'/ExponentialMovingAverage\\\\\\\'\\\\n-                print(\\\\\\\'%s: %s\\\\\\\' % (ema_name, var.op.name))\\\\n-                restore_vars[ema_name] = var\\\\n-            \\\\n-        saver = tf.train.Saver(restore_vars, name=\\\\\\\'ema_restore\\\\\\\')\\\\n-        \\\\n-        saver.restore(sess, os.path.join(self.tmp_dir, "model_ex1"))\\\\n-        \\\\n-        w_restored = sess.run(\\\\\\\'W:0\\\\\\\')\\\\n-        b_restored = sess.run(\\\\\\\'b:0\\\\\\\')\\\\n-        \\\\n-        self.assertAlmostEqual(w_reference, w_restored, \\\\\\\'Restored model modes not use the EMA filtered weight\\\\\\\')\\\\n-        self.assertAlmostEqual(b_reference, b_restored, \\\\\\\'Restored model modes not use the EMA filtered bias\\\\\\\')\\\\n-\\\\n-        \\\\n-# Create a checkpoint file pointing to the model\\\\n-def create_checkpoint_file(model_dir, model_file):\\\\n-    checkpoint_filename = os.path.join(model_dir, \\\\\\\'checkpoint\\\\\\\')\\\\n-    full_model_filename = os.path.join(model_dir, model_file)\\\\n-    with open(checkpoint_filename, \\\\\\\'w\\\\\\\') as f:\\\\n-        f.write(\\\\\\\'model_checkpoint_path: "%s"\\\\\\\\n\\\\\\\' % full_model_filename)\\\\n-        f.write(\\\\\\\'all_model_checkpoint_paths: "%s"\\\\\\\\n\\\\\\\' % full_model_filename)\\\\n-        \\\\n-if __name__ == "__main__":\\\\n-    unittest.main()\\\\n-    \\\\n\\\\\\\\ No newline at end of file\\\\ndiff --git a/test/train_test.py b/test/train_test.py\\\\ndeleted file mode 100644\\\\nindex 12cd663..0000000\\\\n--- a/test/train_test.py\\\\n+++ /dev/null\\\\n@@ -1,246 +0,0 @@\\\\n-# MIT License\\\\n-# \\\\n-# Copyright (c) 2016 David Sandberg\\\\n-# \\\\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\n-# of this software and associated documentation files (the "Software"), to deal\\\\n-# in the Software without restriction, including without limitation the rights\\\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\n-# copies of the Software, and to permit persons to whom the Software is\\\\n-# furnished to do so, subject to the following conditions:\\\\n-# \\\\n-# The above copyright notice and this permission notice shall be included in all\\\\n-# copies or substantial portions of the Software.\\\\n-# \\\\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\n-# SOFTWARE.\\\\n-\\\\n-import unittest\\\\n-import tempfile\\\\n-import numpy as np\\\\n-import cv2\\\\n-import os\\\\n-import shutil\\\\n-import download_and_extract  # @UnresolvedImport\\\\n-import subprocess\\\\n-\\\\n-def memory_usage_psutil():\\\\n-    # return the memory usage in MB\\\\n-    import psutil\\\\n-    process = psutil.Process(os.getpid())\\\\n-    mem = process.memory_info()[0] / float(2 ** 20)\\\\n-    return mem\\\\n-\\\\n-def align_dataset_if_needed(self):\\\\n-    if not os.path.exists(\\\\\\\'data/lfw_aligned\\\\\\\'):\\\\n-        argv = [\\\\\\\'python\\\\\\\',\\\\n-                \\\\\\\'src/align/align_dataset_mtcnn.py\\\\\\\',\\\\n-                \\\\\\\'data/lfw\\\\\\\',\\\\n-                \\\\\\\'data/lfw_aligned\\\\\\\',\\\\n-                \\\\\\\'--image_size\\\\\\\', \\\\\\\'160\\\\\\\',\\\\n-                \\\\\\\'--margin\\\\\\\', \\\\\\\'32\\\\\\\' ]\\\\n-        subprocess.call(argv)\\\\n-        \\\\n-        \\\\n-class TrainTest(unittest.TestCase):\\\\n-  \\\\n-    @classmethod\\\\n-    def setUpClass(self):\\\\n-        self.tmp_dir = tempfile.mkdtemp()\\\\n-        self.dataset_dir = os.path.join(self.tmp_dir, \\\\\\\'dataset\\\\\\\')\\\\n-        create_mock_dataset(self.dataset_dir, 160)\\\\n-        self.lfw_pairs_file = create_mock_lfw_pairs(self.tmp_dir)\\\\n-        print(self.lfw_pairs_file)\\\\n-        self.pretrained_model_name = \\\\\\\'20180402-114759\\\\\\\'\\\\n-        download_and_extract.download_and_extract_file(self.pretrained_model_name, \\\\\\\'data/\\\\\\\')\\\\n-        download_and_extract.download_and_extract_file(\\\\\\\'lfw-subset\\\\\\\', \\\\\\\'data/\\\\\\\')\\\\n-        self.model_file = os.path.join(\\\\\\\'data\\\\\\\', self.pretrained_model_name, \\\\\\\'model-%s.ckpt-275\\\\\\\' % self.pretrained_model_name)\\\\n-        self.pretrained_model = os.path.join(\\\\\\\'data\\\\\\\', self.pretrained_model_name)\\\\n-        self.frozen_graph_filename = os.path.join(\\\\\\\'data\\\\\\\', self.pretrained_model_name+\\\\\\\'.pb\\\\\\\')\\\\n-        print(\\\\\\\'Memory utilization (SetUpClass): %.3f MB\\\\\\\' % memory_usage_psutil())\\\\n-\\\\n-    @classmethod\\\\n-    def tearDownClass(self):\\\\n-        # Recursively remove the temporary directory\\\\n-        shutil.rmtree(self.tmp_dir)\\\\n-\\\\n-    def tearDown(self):\\\\n-        print(\\\\\\\'Memory utilization (TearDown): %.3f MB\\\\\\\' % memory_usage_psutil())\\\\n-\\\\n-    def test_training_classifier_inception_resnet_v1(self):\\\\n-        print(\\\\\\\'test_training_classifier_inception_resnet_v1\\\\\\\')\\\\n-        argv = [\\\\\\\'python\\\\\\\',\\\\n-                \\\\\\\'src/train_softmax.py\\\\\\\',\\\\n-                \\\\\\\'--logs_base_dir\\\\\\\', self.tmp_dir,\\\\n-                \\\\\\\'--models_base_dir\\\\\\\', self.tmp_dir,\\\\n-                \\\\\\\'--data_dir\\\\\\\', self.dataset_dir,\\\\n-                \\\\\\\'--model_def\\\\\\\', \\\\\\\'models.inception_resnet_v1\\\\\\\',\\\\n-                \\\\\\\'--epoch_size\\\\\\\', \\\\\\\'1\\\\\\\',\\\\n-                \\\\\\\'--max_nrof_epochs\\\\\\\', \\\\\\\'1\\\\\\\',\\\\n-                \\\\\\\'--batch_size\\\\\\\', \\\\\\\'1\\\\\\\',\\\\n-                \\\\\\\'--lfw_pairs\\\\\\\', self.lfw_pairs_file,\\\\n-                \\\\\\\'--lfw_dir\\\\\\\', self.dataset_dir,\\\\n-                \\\\\\\'--lfw_nrof_folds\\\\\\\', \\\\\\\'2\\\\\\\',\\\\n-                \\\\\\\'--lfw_batch_size\\\\\\\', \\\\\\\'1\\\\\\\',\\\\n-                \\\\\\\'--nrof_preprocess_threads\\\\\\\', \\\\\\\'1\\\\\\\' ]\\\\n-        subprocess.call(argv)\\\\n-\\\\n-    def test_training_classifier_inception_resnet_v2(self):\\\\n-        print(\\\\\\\'test_training_classifier_inception_resnet_v2\\\\\\\')\\\\n-        argv = [\\\\\\\'python\\\\\\\',\\\\n-                \\\\\\\'src/train_softmax.py\\\\\\\',\\\\n-                \\\\\\\'--logs_base_dir\\\\\\\', self.tmp_dir,\\\\n-                \\\\\\\'--models_base_dir\\\\\\\', self.tmp_dir,\\\\n-                \\\\\\\'--data_dir\\\\\\\', self.dataset_dir,\\\\n-                \\\\\\\'--model_def\\\\\\\', \\\\\\\'models.inception_resnet_v2\\\\\\\',\\\\n-                \\\\\\\'--epoch_size\\\\\\\', \\\\\\\'1\\\\\\\',\\\\n-                \\\\\\\'--max_nrof_epochs\\\\\\\', \\\\\\\'1\\\\\\\',\\\\n-                \\\\\\\'--batch_size\\\\\\\', \\\\\\\'1\\\\\\\',\\\\n-                \\\\\\\'--lfw_pairs\\\\\\\', self.lfw_pairs_file,\\\\n-                \\\\\\\'--lfw_dir\\\\\\\', self.dataset_dir,\\\\n-                \\\\\\\'--lfw_nrof_folds\\\\\\\', \\\\\\\'2\\\\\\\',\\\\n-                \\\\\\\'--lfw_batch_size\\\\\\\', \\\\\\\'1\\\\\\\' ]\\\\n-        subprocess.call(argv)\\\\n-  \\\\n-    def test_training_classifier_squeezenet(self):\\\\n-        print(\\\\\\\'test_training_classifier_squeezenet\\\\\\\')\\\\n-        argv = [\\\\\\\'python\\\\\\\',\\\\n-                \\\\\\\'src/train_softmax.py\\\\\\\',\\\\n-                \\\\\\\'--logs_base_dir\\\\\\\', self.tmp_dir,\\\\n-                \\\\\\\'--models_base_dir\\\\\\\', self.tmp_dir,\\\\n-                \\\\\\\'--data_dir\\\\\\\', self.dataset_dir,\\\\n-                \\\\\\\'--model_def\\\\\\\', \\\\\\\'models.squeezenet\\\\\\\',\\\\n-                \\\\\\\'--epoch_size\\\\\\\', \\\\\\\'1\\\\\\\',\\\\n-                \\\\\\\'--max_nrof_epochs\\\\\\\', \\\\\\\'1\\\\\\\',\\\\n-                \\\\\\\'--batch_size\\\\\\\', \\\\\\\'1\\\\\\\',\\\\n-                \\\\\\\'--lfw_pairs\\\\\\\', self.lfw_pairs_file,\\\\n-                \\\\\\\'--lfw_dir\\\\\\\', self.dataset_dir,\\\\n-                \\\\\\\'--lfw_nrof_folds\\\\\\\', \\\\\\\'2\\\\\\\',\\\\n-                \\\\\\\'--lfw_batch_size\\\\\\\', \\\\\\\'1\\\\\\\',\\\\n-                \\\\\\\'--nrof_preprocess_threads\\\\\\\', \\\\\\\'1\\\\\\\' ]\\\\n-        subprocess.call(argv)\\\\n- \\\\n-    def test_train_tripletloss_inception_resnet_v1(self):\\\\n-        print(\\\\\\\'test_train_tripletloss_inception_resnet_v1\\\\\\\')\\\\n-        argv = [\\\\\\\'python\\\\\\\',\\\\n-                \\\\\\\'src/train_tripletloss.py\\\\\\\',\\\\n-                \\\\\\\'--logs_base_dir\\\\\\\', self.tmp_dir,\\\\n-                \\\\\\\'--models_base_dir\\\\\\\', self.tmp_dir,\\\\n-                \\\\\\\'--data_dir\\\\\\\', self.dataset_dir,\\\\n-                \\\\\\\'--model_def\\\\\\\', \\\\\\\'models.inception_resnet_v1\\\\\\\',\\\\n-                \\\\\\\'--epoch_size\\\\\\\', \\\\\\\'1\\\\\\\',\\\\n-                \\\\\\\'--max_nrof_epochs\\\\\\\', \\\\\\\'1\\\\\\\',\\\\n-                \\\\\\\'--batch_size\\\\\\\', \\\\\\\'6\\\\\\\',\\\\n-                \\\\\\\'--people_per_batch\\\\\\\', \\\\\\\'2\\\\\\\',\\\\n-                \\\\\\\'--images_per_person\\\\\\\', \\\\\\\'3\\\\\\\',\\\\n-                \\\\\\\'--lfw_pairs\\\\\\\', self.lfw_pairs_file,\\\\n-                \\\\\\\'--lfw_dir\\\\\\\', self.dataset_dir,\\\\n-                \\\\\\\'--lfw_nrof_folds\\\\\\\', \\\\\\\'2\\\\\\\' ]\\\\n-        subprocess.call(argv)\\\\n-  \\\\n-    def test_finetune_tripletloss_inception_resnet_v1(self):\\\\n-        print(\\\\\\\'test_finetune_tripletloss_inception_resnet_v1\\\\\\\')\\\\n-        argv = [\\\\\\\'python\\\\\\\',\\\\n-                \\\\\\\'src/train_tripletloss.py\\\\\\\',\\\\n-                \\\\\\\'--logs_base_dir\\\\\\\', self.tmp_dir,\\\\n-                \\\\\\\'--models_base_dir\\\\\\\', self.tmp_dir,\\\\n-                \\\\\\\'--data_dir\\\\\\\', self.dataset_dir,\\\\n-                \\\\\\\'--model_def\\\\\\\', \\\\\\\'models.inception_resnet_v1\\\\\\\',\\\\n-                \\\\\\\'--pretrained_model\\\\\\\', self.model_file,\\\\n-                \\\\\\\'--embedding_size\\\\\\\', \\\\\\\'512\\\\\\\',\\\\n-                \\\\\\\'--epoch_size\\\\\\\', \\\\\\\'1\\\\\\\',\\\\n-                \\\\\\\'--max_nrof_epochs\\\\\\\', \\\\\\\'1\\\\\\\',\\\\n-                \\\\\\\'--batch_size\\\\\\\', \\\\\\\'6\\\\\\\',\\\\n-                \\\\\\\'--people_per_batch\\\\\\\', \\\\\\\'2\\\\\\\',\\\\n-                \\\\\\\'--images_per_person\\\\\\\', \\\\\\\'3\\\\\\\',\\\\n-                \\\\\\\'--lfw_pairs\\\\\\\', self.lfw_pairs_file,\\\\n-                \\\\\\\'--lfw_dir\\\\\\\', self.dataset_dir,\\\\n-                \\\\\\\'--lfw_nrof_folds\\\\\\\', \\\\\\\'2\\\\\\\' ]\\\\n-        subprocess.call(argv)\\\\n-  \\\\n-    def test_compare(self):\\\\n-        print(\\\\\\\'test_compare\\\\\\\')\\\\n-        argv = [\\\\\\\'python\\\\\\\',\\\\n-                \\\\\\\'src/compare.py\\\\\\\',\\\\n-                os.path.join(\\\\\\\'data/\\\\\\\', self.pretrained_model_name),\\\\n-                \\\\\\\'data/images/Anthony_Hopkins_0001.jpg\\\\\\\',\\\\n-                \\\\\\\'data/images/Anthony_Hopkins_0002.jpg\\\\\\\' ]\\\\n-        subprocess.call(argv)\\\\n-         \\\\n-    def test_validate_on_lfw(self):\\\\n-        print(\\\\\\\'test_validate_on_lfw\\\\\\\')\\\\n-        align_dataset_if_needed(self)\\\\n-        argv = [\\\\\\\'python\\\\\\\',\\\\n-                \\\\\\\'src/validate_on_lfw.py\\\\\\\', \\\\n-                \\\\\\\'data/lfw_aligned\\\\\\\',\\\\n-                self.pretrained_model,\\\\n-                \\\\\\\'--lfw_pairs\\\\\\\', \\\\\\\'data/lfw/pairs_small.txt\\\\\\\',\\\\n-                \\\\\\\'--lfw_nrof_folds\\\\\\\', \\\\\\\'2\\\\\\\',\\\\n-                \\\\\\\'--lfw_batch_size\\\\\\\', \\\\\\\'6\\\\\\\']\\\\n-        subprocess.call(argv)\\\\n- \\\\n-    def test_validate_on_lfw_frozen_graph(self):\\\\n-        print(\\\\\\\'test_validate_on_lfw_frozen_graph\\\\\\\')\\\\n-        self.pretrained_model = os.path.join(\\\\\\\'data\\\\\\\', self.pretrained_model_name)\\\\n-        frozen_model = os.path.join(self.pretrained_model, self.pretrained_model_name+\\\\\\\'.pb\\\\\\\')\\\\n-        argv = [\\\\\\\'python\\\\\\\',\\\\n-                \\\\\\\'src/validate_on_lfw.py\\\\\\\',\\\\n-                self.dataset_dir,\\\\n-                frozen_model,\\\\n-                \\\\\\\'--lfw_pairs\\\\\\\', self.lfw_pairs_file,\\\\n-                \\\\\\\'--lfw_nrof_folds\\\\\\\', \\\\\\\'2\\\\\\\',\\\\n-                \\\\\\\'--lfw_batch_size\\\\\\\', \\\\\\\'6\\\\\\\']\\\\n-        subprocess.call(argv)\\\\n- \\\\n-    def test_freeze_graph(self):\\\\n-        print(\\\\\\\'test_freeze_graph\\\\\\\')\\\\n-        argv = [\\\\\\\'python\\\\\\\',\\\\n-                \\\\\\\'src/freeze_graph.py\\\\\\\',\\\\n-                self.pretrained_model,\\\\n-                self.frozen_graph_filename ]\\\\n-        subprocess.call(argv)\\\\n-\\\\n-# Create a mock dataset with random pixel images\\\\n-def create_mock_dataset(dataset_dir, image_size):\\\\n-   \\\\n-    nrof_persons = 3\\\\n-    nrof_images_per_person = 2\\\\n-    np.random.seed(seed=666)\\\\n-    os.mkdir(dataset_dir)\\\\n-    for i in range(nrof_persons):\\\\n-        class_name = \\\\\\\'%04d\\\\\\\' % (i+1)\\\\n-        class_dir = os.path.join(dataset_dir, class_name)\\\\n-        os.mkdir(class_dir)\\\\n-        for j in range(nrof_images_per_person):\\\\n-            img_name = \\\\\\\'%04d\\\\\\\' % (j+1)\\\\n-            img_path = os.path.join(class_dir, class_name+\\\\\\\'_\\\\\\\'+img_name + \\\\\\\'.png\\\\\\\')\\\\n-            img = np.random.uniform(low=0.0, high=255.0, size=(image_size,image_size,3))\\\\n-            cv2.imwrite(img_path, img) #@UndefinedVariable\\\\n-\\\\n-# Create a mock LFW pairs file\\\\n-def create_mock_lfw_pairs(tmp_dir):\\\\n-    pairs_filename = os.path.join(tmp_dir, \\\\\\\'pairs_mock.txt\\\\\\\')\\\\n-    with open(pairs_filename, \\\\\\\'w\\\\\\\') as f:\\\\n-        f.write(\\\\\\\'10 300\\\\\\\\n\\\\\\\')\\\\n-        f.write(\\\\\\\'0001 1 2\\\\\\\\n\\\\\\\')\\\\n-        f.write(\\\\\\\'0001 1 0002 1\\\\\\\\n\\\\\\\')\\\\n-        f.write(\\\\\\\'0002 1 0003 1\\\\\\\\n\\\\\\\')\\\\n-        f.write(\\\\\\\'0001 1 0003 1\\\\\\\\n\\\\\\\')\\\\n-        f.write(\\\\\\\'0002 1 2\\\\\\\\n\\\\\\\')\\\\n-        f.write(\\\\\\\'0001 2 0002 2\\\\\\\\n\\\\\\\')\\\\n-        f.write(\\\\\\\'0002 2 0003 2\\\\\\\\n\\\\\\\')\\\\n-        f.write(\\\\\\\'0001 2 0003 2\\\\\\\\n\\\\\\\')\\\\n-        f.write(\\\\\\\'0003 1 2\\\\\\\\n\\\\\\\')\\\\n-        f.write(\\\\\\\'0001 1 0002 2\\\\\\\\n\\\\\\\')\\\\n-        f.write(\\\\\\\'0002 1 0003 2\\\\\\\\n\\\\\\\')\\\\n-        f.write(\\\\\\\'0001 1 0003 2\\\\\\\\n\\\\\\\')\\\\n-    return pairs_filename\\\\n-\\\\n-if __name__ == "__main__":\\\\n-    unittest.main()\\\\n-    \\\\n\\\\\\\\ No newline at end of file\\\\ndiff --git a/test/triplet_loss_test.py b/test/triplet_loss_test.py\\\\ndeleted file mode 100644\\\\nindex 2648b30..0000000\\\\n--- a/test/triplet_loss_test.py\\\\n+++ /dev/null\\\\n@@ -1,54 +0,0 @@\\\\n-# MIT License\\\\n-# \\\\n-# Copyright (c) 2016 David Sandberg\\\\n-# \\\\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\\\n-# of this software and associated documentation files (the "Software"), to deal\\\\n-# in the Software without restriction, including without limitation the rights\\\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\\\n-# copies of the Software, and to permit persons to whom the Software is\\\\n-# furnished to do so, subject to the following conditions:\\\\n-# \\\\n-# The above copyright notice and this permission notice shall be included in all\\\\n-# copies or substantial portions of the Software.\\\\n-# \\\\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\\\n-# SOFTWARE.\\\\n-\\\\n-import unittest\\\\n-import tensorflow as tf\\\\n-import numpy as np\\\\n-import facenet\\\\n-\\\\n-class DemuxEmbeddingsTest(unittest.TestCase):\\\\n-  \\\\n-    def testDemuxEmbeddings(self):\\\\n-        batch_size = 3*12\\\\n-        embedding_size = 16\\\\n-        alpha = 0.2\\\\n-        \\\\n-        with tf.Graph().as_default():\\\\n-        \\\\n-            embeddings = tf.placeholder(tf.float64, shape=(batch_size, embedding_size), name=\\\\\\\'embeddings\\\\\\\')\\\\n-            anchor, positive, negative = tf.unstack(tf.reshape(embeddings, [-1,3,embedding_size]), 3, 1)\\\\n-            triplet_loss = facenet.triplet_loss(anchor, positive, negative, alpha)\\\\n-                \\\\n-            sess = tf.Session()\\\\n-            with sess.as_default():\\\\n-                np.random.seed(seed=666)\\\\n-                emb = np.random.uniform(size=(batch_size, embedding_size))\\\\n-                tf_triplet_loss = sess.run(triplet_loss, feed_dict={embeddings:emb})\\\\n-\\\\n-                pos_dist_sqr = np.sum(np.square(emb[0::3,:]-emb[1::3,:]),1)\\\\n-                neg_dist_sqr = np.sum(np.square(emb[0::3,:]-emb[2::3,:]),1)\\\\n-                np_triplet_loss = np.mean(np.maximum(0.0, pos_dist_sqr - neg_dist_sqr + alpha))\\\\n-                \\\\n-                np.testing.assert_almost_equal(tf_triplet_loss, np_triplet_loss, decimal=5, err_msg=\\\\\\\'Triplet loss is incorrect\\\\\\\')\\\\n-                      \\\\n-if __name__ == "__main__":\\\\n-    unittest.main()\\\\ndiff --git a/video/a b/video/a\\\\ndeleted file mode 100644\\\\nindex 8b13789..0000000\\\\n--- a/video/a\\\\n+++ /dev/null\\\\n@@ -1 +0,0 @@\\\\n-\\\\ndiff --git a/video/camtest.mp4 b/video/camtest.mp4\\\\ndeleted file mode 100644\\\\nindex a503c89..0000000\\\\nBinary files a/video/camtest.mp4 and /dev/null differ\\\'\\n\\\\ No newline at end of file\\ndiff --git a/Dataset/FaceData/processed/thaongo/419652962_741170244266451_4914393583094088361_n.png b/Dataset/FaceData/processed/thaongo/419652962_741170244266451_4914393583094088361_n.png\\ndeleted file mode 100644\\nindex 59b8881..0000000\\nBinary files a/Dataset/FaceData/processed/thaongo/419652962_741170244266451_4914393583094088361_n.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/thaongo/thao1.png b/Dataset/FaceData/processed/thaongo/thao1.png\\ndeleted file mode 100644\\nindex 19e7768..0000000\\nBinary files a/Dataset/FaceData/processed/thaongo/thao1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/thaongo/thao10.png b/Dataset/FaceData/processed/thaongo/thao10.png\\ndeleted file mode 100644\\nindex 0722617..0000000\\nBinary files a/Dataset/FaceData/processed/thaongo/thao10.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/thaongo/thao2.png b/Dataset/FaceData/processed/thaongo/thao2.png\\ndeleted file mode 100644\\nindex 0af1725..0000000\\nBinary files a/Dataset/FaceData/processed/thaongo/thao2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/thaongo/thao21.png b/Dataset/FaceData/processed/thaongo/thao21.png\\ndeleted file mode 100644\\nindex 1bbfe45..0000000\\nBinary files a/Dataset/FaceData/processed/thaongo/thao21.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/thaongo/thao24.png b/Dataset/FaceData/processed/thaongo/thao24.png\\ndeleted file mode 100644\\nindex 56fa63e..0000000\\nBinary files a/Dataset/FaceData/processed/thaongo/thao24.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/thaongo/thao25.png b/Dataset/FaceData/processed/thaongo/thao25.png\\ndeleted file mode 100644\\nindex c07933d..0000000\\nBinary files a/Dataset/FaceData/processed/thaongo/thao25.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/thaongo/thao26.png b/Dataset/FaceData/processed/thaongo/thao26.png\\ndeleted file mode 100644\\nindex 581b89c..0000000\\nBinary files a/Dataset/FaceData/processed/thaongo/thao26.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/thaongo/thao29.png b/Dataset/FaceData/processed/thaongo/thao29.png\\ndeleted file mode 100644\\nindex 57cb062..0000000\\nBinary files a/Dataset/FaceData/processed/thaongo/thao29.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/thaongo/thao3.png b/Dataset/FaceData/processed/thaongo/thao3.png\\ndeleted file mode 100644\\nindex bdf5429..0000000\\nBinary files a/Dataset/FaceData/processed/thaongo/thao3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/thaongo/thao31.png b/Dataset/FaceData/processed/thaongo/thao31.png\\ndeleted file mode 100644\\nindex a7a1a21..0000000\\nBinary files a/Dataset/FaceData/processed/thaongo/thao31.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/thaongo/thao32.png b/Dataset/FaceData/processed/thaongo/thao32.png\\ndeleted file mode 100644\\nindex 542d066..0000000\\nBinary files a/Dataset/FaceData/processed/thaongo/thao32.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/thaongo/thao33.png b/Dataset/FaceData/processed/thaongo/thao33.png\\ndeleted file mode 100644\\nindex 20f0836..0000000\\nBinary files a/Dataset/FaceData/processed/thaongo/thao33.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/thaongo/thao34.png b/Dataset/FaceData/processed/thaongo/thao34.png\\ndeleted file mode 100644\\nindex a464345..0000000\\nBinary files a/Dataset/FaceData/processed/thaongo/thao34.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/thaongo/thao35.png b/Dataset/FaceData/processed/thaongo/thao35.png\\ndeleted file mode 100644\\nindex b93506a..0000000\\nBinary files a/Dataset/FaceData/processed/thaongo/thao35.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/thaongo/thao4.png b/Dataset/FaceData/processed/thaongo/thao4.png\\ndeleted file mode 100644\\nindex 2f5c293..0000000\\nBinary files a/Dataset/FaceData/processed/thaongo/thao4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/thaongo/thao5.png b/Dataset/FaceData/processed/thaongo/thao5.png\\ndeleted file mode 100644\\nindex 971fbf0..0000000\\nBinary files a/Dataset/FaceData/processed/thaongo/thao5.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/thaongo/thao6.png b/Dataset/FaceData/processed/thaongo/thao6.png\\ndeleted file mode 100644\\nindex bc1dfb4..0000000\\nBinary files a/Dataset/FaceData/processed/thaongo/thao6.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/tran nhat truong/truong1.png b/Dataset/FaceData/processed/tran nhat truong/truong1.png\\ndeleted file mode 100644\\nindex 73ad783..0000000\\nBinary files a/Dataset/FaceData/processed/tran nhat truong/truong1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/truong giang/0630_truonggiang_1.png b/Dataset/FaceData/processed/truong giang/0630_truonggiang_1.png\\ndeleted file mode 100644\\nindex aef3c00..0000000\\nBinary files a/Dataset/FaceData/processed/truong giang/0630_truonggiang_1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/truong giang/0632_truonggiang_2.png b/Dataset/FaceData/processed/truong giang/0632_truonggiang_2.png\\ndeleted file mode 100644\\nindex 04f9496..0000000\\nBinary files a/Dataset/FaceData/processed/truong giang/0632_truonggiang_2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/truong giang/1545311811-862-truong-giang-bat-ngo-dan-dau-de-cu-nam-dien-vien-dien-anh-duoc-yeu-thich-nhat-truonggiang-1545278076-width660height990.png b/Dataset/FaceData/processed/truong giang/1545311811-862-truong-giang-bat-ngo-dan-dau-de-cu-nam-dien-vien-dien-anh-duoc-yeu-thich-nhat-truonggiang-1545278076-width660height990.png\\ndeleted file mode 100644\\nindex 4726517..0000000\\nBinary files a/Dataset/FaceData/processed/truong giang/1545311811-862-truong-giang-bat-ngo-dan-dau-de-cu-nam-dien-vien-dien-anh-duoc-yeu-thich-nhat-truonggiang-1545278076-width660height990.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/truong giang/A27U7778.png b/Dataset/FaceData/processed/truong giang/A27U7778.png\\ndeleted file mode 100644\\nindex d438893..0000000\\nBinary files a/Dataset/FaceData/processed/truong giang/A27U7778.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/truong giang/fb_img_1704768289216-1704768712-408-width720height960.png b/Dataset/FaceData/processed/truong giang/fb_img_1704768289216-1704768712-408-width720height960.png\\ndeleted file mode 100644\\nindex 6690a8e..0000000\\nBinary files a/Dataset/FaceData/processed/truong giang/fb_img_1704768289216-1704768712-408-width720height960.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/truong giang/fb_img_1704768450012-1704768746-24-width720height1079.png b/Dataset/FaceData/processed/truong giang/fb_img_1704768450012-1704768746-24-width720height1079.png\\ndeleted file mode 100644\\nindex 03aa0c1..0000000\\nBinary files a/Dataset/FaceData/processed/truong giang/fb_img_1704768450012-1704768746-24-width720height1079.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/truong giang/giang1.png b/Dataset/FaceData/processed/truong giang/giang1.png\\ndeleted file mode 100644\\nindex 07370ba..0000000\\nBinary files a/Dataset/FaceData/processed/truong giang/giang1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/truong giang/giang2.png b/Dataset/FaceData/processed/truong giang/giang2.png\\ndeleted file mode 100644\\nindex 2fd1bbe..0000000\\nBinary files a/Dataset/FaceData/processed/truong giang/giang2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/truong giang/giang3.png b/Dataset/FaceData/processed/truong giang/giang3.png\\ndeleted file mode 100644\\nindex 3f46dea..0000000\\nBinary files a/Dataset/FaceData/processed/truong giang/giang3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/truong giang/giang4.png b/Dataset/FaceData/processed/truong giang/giang4.png\\ndeleted file mode 100644\\nindex 07a3048..0000000\\nBinary files a/Dataset/FaceData/processed/truong giang/giang4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/truong giang/mc-truong-giang-1229339.png b/Dataset/FaceData/processed/truong giang/mc-truong-giang-1229339.png\\ndeleted file mode 100644\\nindex daaa4d2..0000000\\nBinary files a/Dataset/FaceData/processed/truong giang/mc-truong-giang-1229339.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/truong giang/mc-truong-giang-918712.png b/Dataset/FaceData/processed/truong giang/mc-truong-giang-918712.png\\ndeleted file mode 100644\\nindex c40374e..0000000\\nBinary files a/Dataset/FaceData/processed/truong giang/mc-truong-giang-918712.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/truong giang/trg1.png b/Dataset/FaceData/processed/truong giang/trg1.png\\ndeleted file mode 100644\\nindex 09e142f..0000000\\nBinary files a/Dataset/FaceData/processed/truong giang/trg1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/truong giang/vtr-4472.png b/Dataset/FaceData/processed/truong giang/vtr-4472.png\\ndeleted file mode 100644\\nindex e49cb79..0000000\\nBinary files a/Dataset/FaceData/processed/truong giang/vtr-4472.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/processed/truong giang/vtr-4475.png b/Dataset/FaceData/processed/truong giang/vtr-4475.png\\ndeleted file mode 100644\\nindex 44fa858..0000000\\nBinary files a/Dataset/FaceData/processed/truong giang/vtr-4475.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/0.png b/Dataset/FaceData/raw/Bui Anh Tuan/0.png\\ndeleted file mode 100644\\nindex 2cb8312..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/0.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/1.png b/Dataset/FaceData/raw/Bui Anh Tuan/1.png\\ndeleted file mode 100644\\nindex d25b764..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/10.png b/Dataset/FaceData/raw/Bui Anh Tuan/10.png\\ndeleted file mode 100644\\nindex 9091f86..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/10.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/11.png b/Dataset/FaceData/raw/Bui Anh Tuan/11.png\\ndeleted file mode 100644\\nindex 609a368..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/11.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/12.png b/Dataset/FaceData/raw/Bui Anh Tuan/12.png\\ndeleted file mode 100644\\nindex c0a0b51..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/12.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/13.png b/Dataset/FaceData/raw/Bui Anh Tuan/13.png\\ndeleted file mode 100644\\nindex b879393..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/13.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/14.png b/Dataset/FaceData/raw/Bui Anh Tuan/14.png\\ndeleted file mode 100644\\nindex 7a1c32f..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/14.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/15.png b/Dataset/FaceData/raw/Bui Anh Tuan/15.png\\ndeleted file mode 100644\\nindex 4d1bf9f..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/15.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/16.png b/Dataset/FaceData/raw/Bui Anh Tuan/16.png\\ndeleted file mode 100644\\nindex 5b7634d..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/16.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/17.png b/Dataset/FaceData/raw/Bui Anh Tuan/17.png\\ndeleted file mode 100644\\nindex 416e14a..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/17.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/18.png b/Dataset/FaceData/raw/Bui Anh Tuan/18.png\\ndeleted file mode 100644\\nindex b047070..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/18.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/19.png b/Dataset/FaceData/raw/Bui Anh Tuan/19.png\\ndeleted file mode 100644\\nindex b74565a..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/19.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/2.png b/Dataset/FaceData/raw/Bui Anh Tuan/2.png\\ndeleted file mode 100644\\nindex c9fdb41..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/20.png b/Dataset/FaceData/raw/Bui Anh Tuan/20.png\\ndeleted file mode 100644\\nindex 8ab6eb1..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/20.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/21.png b/Dataset/FaceData/raw/Bui Anh Tuan/21.png\\ndeleted file mode 100644\\nindex 5d4660b..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/21.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/22.png b/Dataset/FaceData/raw/Bui Anh Tuan/22.png\\ndeleted file mode 100644\\nindex 476cbce..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/22.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/23.png b/Dataset/FaceData/raw/Bui Anh Tuan/23.png\\ndeleted file mode 100644\\nindex f516e12..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/23.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/24.png b/Dataset/FaceData/raw/Bui Anh Tuan/24.png\\ndeleted file mode 100644\\nindex ce9d477..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/24.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/25.png b/Dataset/FaceData/raw/Bui Anh Tuan/25.png\\ndeleted file mode 100644\\nindex b9db1d8..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/25.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/26.png b/Dataset/FaceData/raw/Bui Anh Tuan/26.png\\ndeleted file mode 100644\\nindex e856821..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/26.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/27.png b/Dataset/FaceData/raw/Bui Anh Tuan/27.png\\ndeleted file mode 100644\\nindex a2eacab..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/27.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/28.png b/Dataset/FaceData/raw/Bui Anh Tuan/28.png\\ndeleted file mode 100644\\nindex 2258040..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/28.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/29.png b/Dataset/FaceData/raw/Bui Anh Tuan/29.png\\ndeleted file mode 100644\\nindex 9705bce..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/29.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/3.png b/Dataset/FaceData/raw/Bui Anh Tuan/3.png\\ndeleted file mode 100644\\nindex d4c8ae1..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/30.png b/Dataset/FaceData/raw/Bui Anh Tuan/30.png\\ndeleted file mode 100644\\nindex 4a8790f..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/30.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/31.png b/Dataset/FaceData/raw/Bui Anh Tuan/31.png\\ndeleted file mode 100644\\nindex 653e476..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/31.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/32.png b/Dataset/FaceData/raw/Bui Anh Tuan/32.png\\ndeleted file mode 100644\\nindex bea3acc..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/32.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/33.png b/Dataset/FaceData/raw/Bui Anh Tuan/33.png\\ndeleted file mode 100644\\nindex 953bc33..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/33.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/34.png b/Dataset/FaceData/raw/Bui Anh Tuan/34.png\\ndeleted file mode 100644\\nindex d81177c..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/34.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/35.png b/Dataset/FaceData/raw/Bui Anh Tuan/35.png\\ndeleted file mode 100644\\nindex c816d00..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/35.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/36.png b/Dataset/FaceData/raw/Bui Anh Tuan/36.png\\ndeleted file mode 100644\\nindex 4bbb2ed..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/36.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/37.png b/Dataset/FaceData/raw/Bui Anh Tuan/37.png\\ndeleted file mode 100644\\nindex 1a4ec24..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/37.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/38.png b/Dataset/FaceData/raw/Bui Anh Tuan/38.png\\ndeleted file mode 100644\\nindex 2625e91..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/38.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/39.png b/Dataset/FaceData/raw/Bui Anh Tuan/39.png\\ndeleted file mode 100644\\nindex 8a98074..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/39.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/4.png b/Dataset/FaceData/raw/Bui Anh Tuan/4.png\\ndeleted file mode 100644\\nindex d2b5dce..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/40.png b/Dataset/FaceData/raw/Bui Anh Tuan/40.png\\ndeleted file mode 100644\\nindex fd5075d..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/40.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/41.png b/Dataset/FaceData/raw/Bui Anh Tuan/41.png\\ndeleted file mode 100644\\nindex 5abc475..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/41.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/42.png b/Dataset/FaceData/raw/Bui Anh Tuan/42.png\\ndeleted file mode 100644\\nindex 33c24a1..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/42.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/43.png b/Dataset/FaceData/raw/Bui Anh Tuan/43.png\\ndeleted file mode 100644\\nindex dc1090f..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/43.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/44.png b/Dataset/FaceData/raw/Bui Anh Tuan/44.png\\ndeleted file mode 100644\\nindex 0129185..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/44.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/45.png b/Dataset/FaceData/raw/Bui Anh Tuan/45.png\\ndeleted file mode 100644\\nindex 405533b..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/45.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/46.png b/Dataset/FaceData/raw/Bui Anh Tuan/46.png\\ndeleted file mode 100644\\nindex 6dec77e..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/46.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/47.png b/Dataset/FaceData/raw/Bui Anh Tuan/47.png\\ndeleted file mode 100644\\nindex b1f2372..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/47.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/5.png b/Dataset/FaceData/raw/Bui Anh Tuan/5.png\\ndeleted file mode 100644\\nindex b02a6a0..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/5.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/6.png b/Dataset/FaceData/raw/Bui Anh Tuan/6.png\\ndeleted file mode 100644\\nindex 452eb92..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/6.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/7.png b/Dataset/FaceData/raw/Bui Anh Tuan/7.png\\ndeleted file mode 100644\\nindex 8a43135..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/7.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/8.png b/Dataset/FaceData/raw/Bui Anh Tuan/8.png\\ndeleted file mode 100644\\nindex aa1a44c..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/8.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Bui Anh Tuan/9.png b/Dataset/FaceData/raw/Bui Anh Tuan/9.png\\ndeleted file mode 100644\\nindex c4d6bae..0000000\\nBinary files a/Dataset/FaceData/raw/Bui Anh Tuan/9.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/0.png b/Dataset/FaceData/raw/Dam vinh hung/0.png\\ndeleted file mode 100644\\nindex 4d7e181..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/0.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/1.png b/Dataset/FaceData/raw/Dam vinh hung/1.png\\ndeleted file mode 100644\\nindex 062f015..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/10.png b/Dataset/FaceData/raw/Dam vinh hung/10.png\\ndeleted file mode 100644\\nindex ca6b9d4..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/10.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/11.png b/Dataset/FaceData/raw/Dam vinh hung/11.png\\ndeleted file mode 100644\\nindex 887b100..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/11.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/12.png b/Dataset/FaceData/raw/Dam vinh hung/12.png\\ndeleted file mode 100644\\nindex 62b4d1c..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/12.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/13.png b/Dataset/FaceData/raw/Dam vinh hung/13.png\\ndeleted file mode 100644\\nindex eeac293..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/13.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/14.png b/Dataset/FaceData/raw/Dam vinh hung/14.png\\ndeleted file mode 100644\\nindex e65e57c..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/14.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/15.png b/Dataset/FaceData/raw/Dam vinh hung/15.png\\ndeleted file mode 100644\\nindex 8d6cbae..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/15.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/16.png b/Dataset/FaceData/raw/Dam vinh hung/16.png\\ndeleted file mode 100644\\nindex 4794f95..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/16.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/17.png b/Dataset/FaceData/raw/Dam vinh hung/17.png\\ndeleted file mode 100644\\nindex ea1819b..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/17.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/18.png b/Dataset/FaceData/raw/Dam vinh hung/18.png\\ndeleted file mode 100644\\nindex 0169adb..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/18.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/19.png b/Dataset/FaceData/raw/Dam vinh hung/19.png\\ndeleted file mode 100644\\nindex 158e214..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/19.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/2.png b/Dataset/FaceData/raw/Dam vinh hung/2.png\\ndeleted file mode 100644\\nindex 4f1873b..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/20.png b/Dataset/FaceData/raw/Dam vinh hung/20.png\\ndeleted file mode 100644\\nindex 9c20142..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/20.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/21.png b/Dataset/FaceData/raw/Dam vinh hung/21.png\\ndeleted file mode 100644\\nindex 70a723a..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/21.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/22.png b/Dataset/FaceData/raw/Dam vinh hung/22.png\\ndeleted file mode 100644\\nindex 08e99de..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/22.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/23.png b/Dataset/FaceData/raw/Dam vinh hung/23.png\\ndeleted file mode 100644\\nindex adc1f0c..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/23.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/24.png b/Dataset/FaceData/raw/Dam vinh hung/24.png\\ndeleted file mode 100644\\nindex 059b567..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/24.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/25.png b/Dataset/FaceData/raw/Dam vinh hung/25.png\\ndeleted file mode 100644\\nindex a681a71..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/25.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/26.png b/Dataset/FaceData/raw/Dam vinh hung/26.png\\ndeleted file mode 100644\\nindex 2db3388..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/26.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/27.png b/Dataset/FaceData/raw/Dam vinh hung/27.png\\ndeleted file mode 100644\\nindex a770776..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/27.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/28.png b/Dataset/FaceData/raw/Dam vinh hung/28.png\\ndeleted file mode 100644\\nindex 2497c4b..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/28.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/29.png b/Dataset/FaceData/raw/Dam vinh hung/29.png\\ndeleted file mode 100644\\nindex 36e29b5..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/29.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/3.png b/Dataset/FaceData/raw/Dam vinh hung/3.png\\ndeleted file mode 100644\\nindex 203e0da..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/30.png b/Dataset/FaceData/raw/Dam vinh hung/30.png\\ndeleted file mode 100644\\nindex 316fbb1..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/30.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/31.png b/Dataset/FaceData/raw/Dam vinh hung/31.png\\ndeleted file mode 100644\\nindex 8d37322..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/31.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/32.png b/Dataset/FaceData/raw/Dam vinh hung/32.png\\ndeleted file mode 100644\\nindex 70e5757..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/32.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/33.png b/Dataset/FaceData/raw/Dam vinh hung/33.png\\ndeleted file mode 100644\\nindex f295300..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/33.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/34.png b/Dataset/FaceData/raw/Dam vinh hung/34.png\\ndeleted file mode 100644\\nindex f8385fa..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/34.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/35.png b/Dataset/FaceData/raw/Dam vinh hung/35.png\\ndeleted file mode 100644\\nindex fc43193..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/35.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/36.png b/Dataset/FaceData/raw/Dam vinh hung/36.png\\ndeleted file mode 100644\\nindex 16abb5b..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/36.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/37.png b/Dataset/FaceData/raw/Dam vinh hung/37.png\\ndeleted file mode 100644\\nindex 38dc60b..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/37.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/38.png b/Dataset/FaceData/raw/Dam vinh hung/38.png\\ndeleted file mode 100644\\nindex a322289..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/38.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/39.png b/Dataset/FaceData/raw/Dam vinh hung/39.png\\ndeleted file mode 100644\\nindex 6f1fb3f..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/39.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/4.png b/Dataset/FaceData/raw/Dam vinh hung/4.png\\ndeleted file mode 100644\\nindex 69c5e54..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/40.png b/Dataset/FaceData/raw/Dam vinh hung/40.png\\ndeleted file mode 100644\\nindex 3bdf602..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/40.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/41.png b/Dataset/FaceData/raw/Dam vinh hung/41.png\\ndeleted file mode 100644\\nindex accfc7f..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/41.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/42.png b/Dataset/FaceData/raw/Dam vinh hung/42.png\\ndeleted file mode 100644\\nindex fe90db5..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/42.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/43.png b/Dataset/FaceData/raw/Dam vinh hung/43.png\\ndeleted file mode 100644\\nindex eee917d..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/43.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/5.png b/Dataset/FaceData/raw/Dam vinh hung/5.png\\ndeleted file mode 100644\\nindex 34889d6..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/5.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/6.png b/Dataset/FaceData/raw/Dam vinh hung/6.png\\ndeleted file mode 100644\\nindex c033cdb..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/6.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/7.png b/Dataset/FaceData/raw/Dam vinh hung/7.png\\ndeleted file mode 100644\\nindex eeacdc5..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/7.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/8.png b/Dataset/FaceData/raw/Dam vinh hung/8.png\\ndeleted file mode 100644\\nindex 5d66d18..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/8.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Dam vinh hung/9.png b/Dataset/FaceData/raw/Dam vinh hung/9.png\\ndeleted file mode 100644\\nindex 119af1c..0000000\\nBinary files a/Dataset/FaceData/raw/Dam vinh hung/9.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/0.png b/Dataset/FaceData/raw/Den Vau/0.png\\ndeleted file mode 100644\\nindex 0114b01..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/0.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/1.png b/Dataset/FaceData/raw/Den Vau/1.png\\ndeleted file mode 100644\\nindex e8ab59a..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/10.png b/Dataset/FaceData/raw/Den Vau/10.png\\ndeleted file mode 100644\\nindex 5c90a66..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/10.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/11.png b/Dataset/FaceData/raw/Den Vau/11.png\\ndeleted file mode 100644\\nindex 1db538f..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/11.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/12.png b/Dataset/FaceData/raw/Den Vau/12.png\\ndeleted file mode 100644\\nindex 17b1d14..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/12.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/13.png b/Dataset/FaceData/raw/Den Vau/13.png\\ndeleted file mode 100644\\nindex 38f674a..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/13.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/14.png b/Dataset/FaceData/raw/Den Vau/14.png\\ndeleted file mode 100644\\nindex 7057040..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/14.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/15.png b/Dataset/FaceData/raw/Den Vau/15.png\\ndeleted file mode 100644\\nindex 118ea82..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/15.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/16.png b/Dataset/FaceData/raw/Den Vau/16.png\\ndeleted file mode 100644\\nindex b413e22..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/16.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/17.png b/Dataset/FaceData/raw/Den Vau/17.png\\ndeleted file mode 100644\\nindex def8d32..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/17.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/18.png b/Dataset/FaceData/raw/Den Vau/18.png\\ndeleted file mode 100644\\nindex 040d762..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/18.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/19.png b/Dataset/FaceData/raw/Den Vau/19.png\\ndeleted file mode 100644\\nindex 75aa5bc..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/19.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/2.png b/Dataset/FaceData/raw/Den Vau/2.png\\ndeleted file mode 100644\\nindex ef6ff8c..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/20.png b/Dataset/FaceData/raw/Den Vau/20.png\\ndeleted file mode 100644\\nindex f86a682..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/20.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/21.png b/Dataset/FaceData/raw/Den Vau/21.png\\ndeleted file mode 100644\\nindex b7bf0d2..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/21.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/22.png b/Dataset/FaceData/raw/Den Vau/22.png\\ndeleted file mode 100644\\nindex 06a476c..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/22.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/23.png b/Dataset/FaceData/raw/Den Vau/23.png\\ndeleted file mode 100644\\nindex 2caedcb..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/23.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/24.png b/Dataset/FaceData/raw/Den Vau/24.png\\ndeleted file mode 100644\\nindex 34ece7c..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/24.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/25.png b/Dataset/FaceData/raw/Den Vau/25.png\\ndeleted file mode 100644\\nindex e8d5bfe..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/25.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/26.png b/Dataset/FaceData/raw/Den Vau/26.png\\ndeleted file mode 100644\\nindex 9a96eb0..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/26.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/27.png b/Dataset/FaceData/raw/Den Vau/27.png\\ndeleted file mode 100644\\nindex 4d693c7..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/27.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/28.png b/Dataset/FaceData/raw/Den Vau/28.png\\ndeleted file mode 100644\\nindex eef0f8c..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/28.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/29.png b/Dataset/FaceData/raw/Den Vau/29.png\\ndeleted file mode 100644\\nindex e0cd4f6..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/29.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/3.png b/Dataset/FaceData/raw/Den Vau/3.png\\ndeleted file mode 100644\\nindex cf48ff8..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/30.png b/Dataset/FaceData/raw/Den Vau/30.png\\ndeleted file mode 100644\\nindex cb38643..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/30.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/31.png b/Dataset/FaceData/raw/Den Vau/31.png\\ndeleted file mode 100644\\nindex d965265..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/31.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/32.png b/Dataset/FaceData/raw/Den Vau/32.png\\ndeleted file mode 100644\\nindex 1a9c23f..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/32.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/33.png b/Dataset/FaceData/raw/Den Vau/33.png\\ndeleted file mode 100644\\nindex 346c03e..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/33.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/34.png b/Dataset/FaceData/raw/Den Vau/34.png\\ndeleted file mode 100644\\nindex 14cffcb..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/34.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/35.png b/Dataset/FaceData/raw/Den Vau/35.png\\ndeleted file mode 100644\\nindex f514a14..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/35.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/36.png b/Dataset/FaceData/raw/Den Vau/36.png\\ndeleted file mode 100644\\nindex 7a0b6d1..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/36.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/37.png b/Dataset/FaceData/raw/Den Vau/37.png\\ndeleted file mode 100644\\nindex 09566ef..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/37.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/38.png b/Dataset/FaceData/raw/Den Vau/38.png\\ndeleted file mode 100644\\nindex f37308a..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/38.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/39.png b/Dataset/FaceData/raw/Den Vau/39.png\\ndeleted file mode 100644\\nindex d4819e0..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/39.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/4.png b/Dataset/FaceData/raw/Den Vau/4.png\\ndeleted file mode 100644\\nindex c6ba8c2..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/40.png b/Dataset/FaceData/raw/Den Vau/40.png\\ndeleted file mode 100644\\nindex 81a305d..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/40.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/41.png b/Dataset/FaceData/raw/Den Vau/41.png\\ndeleted file mode 100644\\nindex 1e66e4b..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/41.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/42.png b/Dataset/FaceData/raw/Den Vau/42.png\\ndeleted file mode 100644\\nindex 50b8df8..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/42.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/43.png b/Dataset/FaceData/raw/Den Vau/43.png\\ndeleted file mode 100644\\nindex 17afae5..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/43.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/44.png b/Dataset/FaceData/raw/Den Vau/44.png\\ndeleted file mode 100644\\nindex 31008d5..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/44.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/45.png b/Dataset/FaceData/raw/Den Vau/45.png\\ndeleted file mode 100644\\nindex 8f2dfc6..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/45.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/46.png b/Dataset/FaceData/raw/Den Vau/46.png\\ndeleted file mode 100644\\nindex 901c19a..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/46.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/47.png b/Dataset/FaceData/raw/Den Vau/47.png\\ndeleted file mode 100644\\nindex c2df1b8..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/47.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/48.png b/Dataset/FaceData/raw/Den Vau/48.png\\ndeleted file mode 100644\\nindex 68f99e6..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/48.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/49.png b/Dataset/FaceData/raw/Den Vau/49.png\\ndeleted file mode 100644\\nindex 8df3ee8..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/49.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/5.png b/Dataset/FaceData/raw/Den Vau/5.png\\ndeleted file mode 100644\\nindex adaa574..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/5.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/50.png b/Dataset/FaceData/raw/Den Vau/50.png\\ndeleted file mode 100644\\nindex 21efeb1..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/50.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/51.png b/Dataset/FaceData/raw/Den Vau/51.png\\ndeleted file mode 100644\\nindex 6bc6d41..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/51.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/52.png b/Dataset/FaceData/raw/Den Vau/52.png\\ndeleted file mode 100644\\nindex 4573091..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/52.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/53.png b/Dataset/FaceData/raw/Den Vau/53.png\\ndeleted file mode 100644\\nindex aed3079..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/53.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/54.png b/Dataset/FaceData/raw/Den Vau/54.png\\ndeleted file mode 100644\\nindex b2d1440..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/54.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/55.png b/Dataset/FaceData/raw/Den Vau/55.png\\ndeleted file mode 100644\\nindex 4b0449c..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/55.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/56.png b/Dataset/FaceData/raw/Den Vau/56.png\\ndeleted file mode 100644\\nindex 97c9f94..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/56.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/57.png b/Dataset/FaceData/raw/Den Vau/57.png\\ndeleted file mode 100644\\nindex 9851533..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/57.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/58.png b/Dataset/FaceData/raw/Den Vau/58.png\\ndeleted file mode 100644\\nindex b1095ff..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/58.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/59.png b/Dataset/FaceData/raw/Den Vau/59.png\\ndeleted file mode 100644\\nindex 9a55468..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/59.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/6.png b/Dataset/FaceData/raw/Den Vau/6.png\\ndeleted file mode 100644\\nindex ae41f77..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/6.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/60.png b/Dataset/FaceData/raw/Den Vau/60.png\\ndeleted file mode 100644\\nindex 81363b8..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/60.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/61.png b/Dataset/FaceData/raw/Den Vau/61.png\\ndeleted file mode 100644\\nindex d3ed57f..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/61.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/62.png b/Dataset/FaceData/raw/Den Vau/62.png\\ndeleted file mode 100644\\nindex 60b8e7d..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/62.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/63.png b/Dataset/FaceData/raw/Den Vau/63.png\\ndeleted file mode 100644\\nindex ac379eb..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/63.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/64.png b/Dataset/FaceData/raw/Den Vau/64.png\\ndeleted file mode 100644\\nindex 37a776b..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/64.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/65.png b/Dataset/FaceData/raw/Den Vau/65.png\\ndeleted file mode 100644\\nindex 7c36149..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/65.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/66.png b/Dataset/FaceData/raw/Den Vau/66.png\\ndeleted file mode 100644\\nindex 1b5e22f..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/66.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/67.png b/Dataset/FaceData/raw/Den Vau/67.png\\ndeleted file mode 100644\\nindex b690225..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/67.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/68.png b/Dataset/FaceData/raw/Den Vau/68.png\\ndeleted file mode 100644\\nindex 193893d..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/68.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/69.png b/Dataset/FaceData/raw/Den Vau/69.png\\ndeleted file mode 100644\\nindex e0a6453..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/69.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/7.png b/Dataset/FaceData/raw/Den Vau/7.png\\ndeleted file mode 100644\\nindex 41cde9a..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/7.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/70.png b/Dataset/FaceData/raw/Den Vau/70.png\\ndeleted file mode 100644\\nindex a0ba207..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/70.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/71.png b/Dataset/FaceData/raw/Den Vau/71.png\\ndeleted file mode 100644\\nindex a3bd450..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/71.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/72.png b/Dataset/FaceData/raw/Den Vau/72.png\\ndeleted file mode 100644\\nindex 151b2c7..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/72.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/73.png b/Dataset/FaceData/raw/Den Vau/73.png\\ndeleted file mode 100644\\nindex e3eb70a..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/73.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/8.png b/Dataset/FaceData/raw/Den Vau/8.png\\ndeleted file mode 100644\\nindex 40f87e5..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/8.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Den Vau/9.png b/Dataset/FaceData/raw/Den Vau/9.png\\ndeleted file mode 100644\\nindex caf1dca..0000000\\nBinary files a/Dataset/FaceData/raw/Den Vau/9.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/0.png b/Dataset/FaceData/raw/Ha Anh Tuan/0.png\\ndeleted file mode 100644\\nindex cf30085..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/0.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/1.png b/Dataset/FaceData/raw/Ha Anh Tuan/1.png\\ndeleted file mode 100644\\nindex 8f38ca0..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/10.png b/Dataset/FaceData/raw/Ha Anh Tuan/10.png\\ndeleted file mode 100644\\nindex b57778e..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/10.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/11.png b/Dataset/FaceData/raw/Ha Anh Tuan/11.png\\ndeleted file mode 100644\\nindex 3d6ccab..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/11.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/12.png b/Dataset/FaceData/raw/Ha Anh Tuan/12.png\\ndeleted file mode 100644\\nindex 283089f..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/12.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/13.png b/Dataset/FaceData/raw/Ha Anh Tuan/13.png\\ndeleted file mode 100644\\nindex 68afaf5..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/13.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/14.png b/Dataset/FaceData/raw/Ha Anh Tuan/14.png\\ndeleted file mode 100644\\nindex b8f40af..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/14.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/15.png b/Dataset/FaceData/raw/Ha Anh Tuan/15.png\\ndeleted file mode 100644\\nindex b380e16..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/15.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/16.png b/Dataset/FaceData/raw/Ha Anh Tuan/16.png\\ndeleted file mode 100644\\nindex 7eb5056..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/16.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/17.png b/Dataset/FaceData/raw/Ha Anh Tuan/17.png\\ndeleted file mode 100644\\nindex a5c4df5..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/17.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/18.png b/Dataset/FaceData/raw/Ha Anh Tuan/18.png\\ndeleted file mode 100644\\nindex 9c7e5a5..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/18.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/19.png b/Dataset/FaceData/raw/Ha Anh Tuan/19.png\\ndeleted file mode 100644\\nindex f105930..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/19.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/2.png b/Dataset/FaceData/raw/Ha Anh Tuan/2.png\\ndeleted file mode 100644\\nindex b5c0018..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/20.png b/Dataset/FaceData/raw/Ha Anh Tuan/20.png\\ndeleted file mode 100644\\nindex 4528610..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/20.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/21.png b/Dataset/FaceData/raw/Ha Anh Tuan/21.png\\ndeleted file mode 100644\\nindex fe37d3e..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/21.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/22.png b/Dataset/FaceData/raw/Ha Anh Tuan/22.png\\ndeleted file mode 100644\\nindex 7ea4956..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/22.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/23.png b/Dataset/FaceData/raw/Ha Anh Tuan/23.png\\ndeleted file mode 100644\\nindex a773732..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/23.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/24.png b/Dataset/FaceData/raw/Ha Anh Tuan/24.png\\ndeleted file mode 100644\\nindex 24bbbde..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/24.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/25.png b/Dataset/FaceData/raw/Ha Anh Tuan/25.png\\ndeleted file mode 100644\\nindex 4696e1b..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/25.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/26.png b/Dataset/FaceData/raw/Ha Anh Tuan/26.png\\ndeleted file mode 100644\\nindex 60f0485..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/26.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/27.png b/Dataset/FaceData/raw/Ha Anh Tuan/27.png\\ndeleted file mode 100644\\nindex 325f875..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/27.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/28.png b/Dataset/FaceData/raw/Ha Anh Tuan/28.png\\ndeleted file mode 100644\\nindex 94bc98b..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/28.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/29.png b/Dataset/FaceData/raw/Ha Anh Tuan/29.png\\ndeleted file mode 100644\\nindex e20504d..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/29.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/3.png b/Dataset/FaceData/raw/Ha Anh Tuan/3.png\\ndeleted file mode 100644\\nindex c09961f..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/30.png b/Dataset/FaceData/raw/Ha Anh Tuan/30.png\\ndeleted file mode 100644\\nindex 10fc0be..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/30.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/31.png b/Dataset/FaceData/raw/Ha Anh Tuan/31.png\\ndeleted file mode 100644\\nindex 64c3dea..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/31.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/32.png b/Dataset/FaceData/raw/Ha Anh Tuan/32.png\\ndeleted file mode 100644\\nindex c0265fc..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/32.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/33.png b/Dataset/FaceData/raw/Ha Anh Tuan/33.png\\ndeleted file mode 100644\\nindex a8244d8..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/33.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/34.png b/Dataset/FaceData/raw/Ha Anh Tuan/34.png\\ndeleted file mode 100644\\nindex cfd24c4..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/34.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/35.png b/Dataset/FaceData/raw/Ha Anh Tuan/35.png\\ndeleted file mode 100644\\nindex 62ebba1..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/35.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/36.png b/Dataset/FaceData/raw/Ha Anh Tuan/36.png\\ndeleted file mode 100644\\nindex c4db4a1..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/36.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/37.png b/Dataset/FaceData/raw/Ha Anh Tuan/37.png\\ndeleted file mode 100644\\nindex 51d329b..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/37.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/38.png b/Dataset/FaceData/raw/Ha Anh Tuan/38.png\\ndeleted file mode 100644\\nindex 0540fa5..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/38.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/39.png b/Dataset/FaceData/raw/Ha Anh Tuan/39.png\\ndeleted file mode 100644\\nindex 537a614..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/39.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/4.png b/Dataset/FaceData/raw/Ha Anh Tuan/4.png\\ndeleted file mode 100644\\nindex 3ec1bc2..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/40.png b/Dataset/FaceData/raw/Ha Anh Tuan/40.png\\ndeleted file mode 100644\\nindex 43274ea..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/40.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/5.png b/Dataset/FaceData/raw/Ha Anh Tuan/5.png\\ndeleted file mode 100644\\nindex 2537196..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/5.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/6.png b/Dataset/FaceData/raw/Ha Anh Tuan/6.png\\ndeleted file mode 100644\\nindex c8e0d16..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/6.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/7.png b/Dataset/FaceData/raw/Ha Anh Tuan/7.png\\ndeleted file mode 100644\\nindex c5aa103..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/7.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/8.png b/Dataset/FaceData/raw/Ha Anh Tuan/8.png\\ndeleted file mode 100644\\nindex c8e8a1d..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/8.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Ha Anh Tuan/9.png b/Dataset/FaceData/raw/Ha Anh Tuan/9.png\\ndeleted file mode 100644\\nindex 0b22929..0000000\\nBinary files a/Dataset/FaceData/raw/Ha Anh Tuan/9.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/0.png b/Dataset/FaceData/raw/Hoai linh/0.png\\ndeleted file mode 100644\\nindex d077b17..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/0.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/1.png b/Dataset/FaceData/raw/Hoai linh/1.png\\ndeleted file mode 100644\\nindex ae4106b..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/10.png b/Dataset/FaceData/raw/Hoai linh/10.png\\ndeleted file mode 100644\\nindex e4354f1..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/10.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/11.png b/Dataset/FaceData/raw/Hoai linh/11.png\\ndeleted file mode 100644\\nindex 1d3a991..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/11.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/12.png b/Dataset/FaceData/raw/Hoai linh/12.png\\ndeleted file mode 100644\\nindex 291524d..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/12.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/13.png b/Dataset/FaceData/raw/Hoai linh/13.png\\ndeleted file mode 100644\\nindex 7820f07..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/13.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/14.png b/Dataset/FaceData/raw/Hoai linh/14.png\\ndeleted file mode 100644\\nindex 8913da4..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/14.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/15.png b/Dataset/FaceData/raw/Hoai linh/15.png\\ndeleted file mode 100644\\nindex bafeefa..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/15.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/16.png b/Dataset/FaceData/raw/Hoai linh/16.png\\ndeleted file mode 100644\\nindex 505732e..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/16.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/17.png b/Dataset/FaceData/raw/Hoai linh/17.png\\ndeleted file mode 100644\\nindex d36a3aa..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/17.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/18.png b/Dataset/FaceData/raw/Hoai linh/18.png\\ndeleted file mode 100644\\nindex 18f8fdb..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/18.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/19.png b/Dataset/FaceData/raw/Hoai linh/19.png\\ndeleted file mode 100644\\nindex 0da507e..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/19.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/2.png b/Dataset/FaceData/raw/Hoai linh/2.png\\ndeleted file mode 100644\\nindex 713c77b..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/20.png b/Dataset/FaceData/raw/Hoai linh/20.png\\ndeleted file mode 100644\\nindex f1a3723..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/20.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/21.png b/Dataset/FaceData/raw/Hoai linh/21.png\\ndeleted file mode 100644\\nindex f790491..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/21.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/22.png b/Dataset/FaceData/raw/Hoai linh/22.png\\ndeleted file mode 100644\\nindex cdee5ce..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/22.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/23.png b/Dataset/FaceData/raw/Hoai linh/23.png\\ndeleted file mode 100644\\nindex 1735d82..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/23.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/24.png b/Dataset/FaceData/raw/Hoai linh/24.png\\ndeleted file mode 100644\\nindex 881f275..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/24.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/25.png b/Dataset/FaceData/raw/Hoai linh/25.png\\ndeleted file mode 100644\\nindex 6c29037..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/25.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/26.png b/Dataset/FaceData/raw/Hoai linh/26.png\\ndeleted file mode 100644\\nindex 5b24dda..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/26.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/27.png b/Dataset/FaceData/raw/Hoai linh/27.png\\ndeleted file mode 100644\\nindex 7933e70..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/27.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/28.png b/Dataset/FaceData/raw/Hoai linh/28.png\\ndeleted file mode 100644\\nindex a6a63b9..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/28.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/29.png b/Dataset/FaceData/raw/Hoai linh/29.png\\ndeleted file mode 100644\\nindex aa67cb7..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/29.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/3.png b/Dataset/FaceData/raw/Hoai linh/3.png\\ndeleted file mode 100644\\nindex 2edc3f7..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/30.png b/Dataset/FaceData/raw/Hoai linh/30.png\\ndeleted file mode 100644\\nindex a26bd61..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/30.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/31.png b/Dataset/FaceData/raw/Hoai linh/31.png\\ndeleted file mode 100644\\nindex 85624a5..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/31.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/32.png b/Dataset/FaceData/raw/Hoai linh/32.png\\ndeleted file mode 100644\\nindex 627567e..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/32.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/33.png b/Dataset/FaceData/raw/Hoai linh/33.png\\ndeleted file mode 100644\\nindex 31b7f68..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/33.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/34.png b/Dataset/FaceData/raw/Hoai linh/34.png\\ndeleted file mode 100644\\nindex a1cfe01..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/34.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/35.png b/Dataset/FaceData/raw/Hoai linh/35.png\\ndeleted file mode 100644\\nindex b739ab9..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/35.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/36.png b/Dataset/FaceData/raw/Hoai linh/36.png\\ndeleted file mode 100644\\nindex 85728d1..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/36.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/37.png b/Dataset/FaceData/raw/Hoai linh/37.png\\ndeleted file mode 100644\\nindex 37dcc83..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/37.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/38.png b/Dataset/FaceData/raw/Hoai linh/38.png\\ndeleted file mode 100644\\nindex 52de9a1..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/38.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/39.png b/Dataset/FaceData/raw/Hoai linh/39.png\\ndeleted file mode 100644\\nindex 432d400..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/39.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/4.png b/Dataset/FaceData/raw/Hoai linh/4.png\\ndeleted file mode 100644\\nindex 708dde0..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/40.png b/Dataset/FaceData/raw/Hoai linh/40.png\\ndeleted file mode 100644\\nindex cd8ceaf..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/40.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/5.png b/Dataset/FaceData/raw/Hoai linh/5.png\\ndeleted file mode 100644\\nindex 9a32b7f..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/5.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/6.png b/Dataset/FaceData/raw/Hoai linh/6.png\\ndeleted file mode 100644\\nindex 57e240a..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/6.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/7.png b/Dataset/FaceData/raw/Hoai linh/7.png\\ndeleted file mode 100644\\nindex 89b2bd1..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/7.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/8.png b/Dataset/FaceData/raw/Hoai linh/8.png\\ndeleted file mode 100644\\nindex 07e1261..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/8.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Hoai linh/9.png b/Dataset/FaceData/raw/Hoai linh/9.png\\ndeleted file mode 100644\\nindex 6cbbe61..0000000\\nBinary files a/Dataset/FaceData/raw/Hoai linh/9.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/chunghoang/386429669_867969661603917_3228776363804735267_n.jpg b/Dataset/FaceData/raw/K205480106002/386429669_867969661603917_3228776363804735267_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/chunghoang/386429669_867969661603917_3228776363804735267_n.jpg\\nrename to Dataset/FaceData/raw/K205480106002/386429669_867969661603917_3228776363804735267_n.jpg\\ndiff --git a/Dataset/FaceData/raw/chunghoang/422737427_390399053474445_3140718471568843261_n.jpg b/Dataset/FaceData/raw/K205480106002/422737427_390399053474445_3140718471568843261_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/chunghoang/422737427_390399053474445_3140718471568843261_n.jpg\\nrename to Dataset/FaceData/raw/K205480106002/422737427_390399053474445_3140718471568843261_n.jpg\\ndiff --git a/Dataset/FaceData/raw/chunghoang/chung1.jpg b/Dataset/FaceData/raw/K205480106002/chung1.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/chunghoang/chung1.jpg\\nrename to Dataset/FaceData/raw/K205480106002/chung1.jpg\\ndiff --git a/Dataset/FaceData/raw/chunghoang/chung2.jpg b/Dataset/FaceData/raw/K205480106002/chung2.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/chunghoang/chung2.jpg\\nrename to Dataset/FaceData/raw/K205480106002/chung2.jpg\\ndiff --git a/Dataset/FaceData/raw/chunghoang/chung3.jpg b/Dataset/FaceData/raw/K205480106002/chung3.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/chunghoang/chung3.jpg\\nrename to Dataset/FaceData/raw/K205480106002/chung3.jpg\\ndiff --git a/Dataset/FaceData/raw/chunghoang/chung4.jpg b/Dataset/FaceData/raw/K205480106002/chung4.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/chunghoang/chung4.jpg\\nrename to Dataset/FaceData/raw/K205480106002/chung4.jpg\\ndiff --git a/Dataset/FaceData/raw/chunghoang/chung6.jpg b/Dataset/FaceData/raw/K205480106002/chung6.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/chunghoang/chung6.jpg\\nrename to Dataset/FaceData/raw/K205480106002/chung6.jpg\\ndiff --git a/Dataset/FaceData/raw/chunghoang/img.png b/Dataset/FaceData/raw/K205480106002/img.png\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/chunghoang/img.png\\nrename to Dataset/FaceData/raw/K205480106002/img.png\\ndiff --git a/Dataset/FaceData/raw/chunghoang/img_1.png b/Dataset/FaceData/raw/K205480106002/img_1.png\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/chunghoang/img_1.png\\nrename to Dataset/FaceData/raw/K205480106002/img_1.png\\ndiff --git a/Dataset/FaceData/raw/hoang tran phau/img.png b/Dataset/FaceData/raw/K205480106003/img.png\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/hoang tran phau/img.png\\nrename to Dataset/FaceData/raw/K205480106003/img.png\\ndiff --git a/Dataset/FaceData/raw/hoang tran phau/img_1.png b/Dataset/FaceData/raw/K205480106003/img_1.png\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/hoang tran phau/img_1.png\\nrename to Dataset/FaceData/raw/K205480106003/img_1.png\\ndiff --git a/Dataset/FaceData/raw/hoang tran phau/phau.jpg b/Dataset/FaceData/raw/K205480106003/phau.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/hoang tran phau/phau.jpg\\nrename to Dataset/FaceData/raw/K205480106003/phau.jpg\\ndiff --git a/Dataset/FaceData/raw/hoang tran phau/phau1.jpg b/Dataset/FaceData/raw/K205480106003/phau1.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/hoang tran phau/phau1.jpg\\nrename to Dataset/FaceData/raw/K205480106003/phau1.jpg\\ndiff --git a/Dataset/FaceData/raw/hoang tran phau/phau2.jpg b/Dataset/FaceData/raw/K205480106003/phau2.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/hoang tran phau/phau2.jpg\\nrename to Dataset/FaceData/raw/K205480106003/phau2.jpg\\ndiff --git a/Dataset/FaceData/raw/hoang tran phau/phau3.jpg b/Dataset/FaceData/raw/K205480106003/phau3.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/hoang tran phau/phau3.jpg\\nrename to Dataset/FaceData/raw/K205480106003/phau3.jpg\\ndiff --git a/Dataset/FaceData/raw/Minh hoa/116428895_656623338282021_8457872234875945077_n.jpg b/Dataset/FaceData/raw/K205480106006/116428895_656623338282021_8457872234875945077_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Minh hoa/116428895_656623338282021_8457872234875945077_n.jpg\\nrename to Dataset/FaceData/raw/K205480106006/116428895_656623338282021_8457872234875945077_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Minh hoa/133049557_769265223684498_4689118252074034370_n.jpg b/Dataset/FaceData/raw/K205480106006/133049557_769265223684498_4689118252074034370_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Minh hoa/133049557_769265223684498_4689118252074034370_n.jpg\\nrename to Dataset/FaceData/raw/K205480106006/133049557_769265223684498_4689118252074034370_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Minh hoa/258158616_974113876532964_9067509414358086927_n.jpg b/Dataset/FaceData/raw/K205480106006/258158616_974113876532964_9067509414358086927_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Minh hoa/258158616_974113876532964_9067509414358086927_n.jpg\\nrename to Dataset/FaceData/raw/K205480106006/258158616_974113876532964_9067509414358086927_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Minh hoa/277588798_1056746241603060_3376911805269669778_n.jpg b/Dataset/FaceData/raw/K205480106006/277588798_1056746241603060_3376911805269669778_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Minh hoa/277588798_1056746241603060_3376911805269669778_n.jpg\\nrename to Dataset/FaceData/raw/K205480106006/277588798_1056746241603060_3376911805269669778_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Minh hoa/45761069_299092524035106_5787233926145638400_n.jpg b/Dataset/FaceData/raw/K205480106006/45761069_299092524035106_5787233926145638400_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Minh hoa/45761069_299092524035106_5787233926145638400_n.jpg\\nrename to Dataset/FaceData/raw/K205480106006/45761069_299092524035106_5787233926145638400_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Minh hoa/51367653_335164410427917_2686636884146257920_n.jpg b/Dataset/FaceData/raw/K205480106006/51367653_335164410427917_2686636884146257920_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Minh hoa/51367653_335164410427917_2686636884146257920_n.jpg\\nrename to Dataset/FaceData/raw/K205480106006/51367653_335164410427917_2686636884146257920_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Minh hoa/72597481_459453121332378_4444718657989246976_n.jpg b/Dataset/FaceData/raw/K205480106006/72597481_459453121332378_4444718657989246976_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Minh hoa/72597481_459453121332378_4444718657989246976_n.jpg\\nrename to Dataset/FaceData/raw/K205480106006/72597481_459453121332378_4444718657989246976_n.jpg\\ndiff --git a/Dataset/FaceData/raw/My Duyen/240594338_608022267035848_559750156049629888_n.jpg b/Dataset/FaceData/raw/K205480106007/240594338_608022267035848_559750156049629888_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/My Duyen/240594338_608022267035848_559750156049629888_n.jpg\\nrename to Dataset/FaceData/raw/K205480106007/240594338_608022267035848_559750156049629888_n.jpg\\ndiff --git a/Dataset/FaceData/raw/My Duyen/271565569_687653065739434_6695347522364803324_n.jpg b/Dataset/FaceData/raw/K205480106007/271565569_687653065739434_6695347522364803324_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/My Duyen/271565569_687653065739434_6695347522364803324_n.jpg\\nrename to Dataset/FaceData/raw/K205480106007/271565569_687653065739434_6695347522364803324_n.jpg\\ndiff --git a/Dataset/FaceData/raw/My Duyen/276281855_728896961615044_4850973774883281965_n.jpg b/Dataset/FaceData/raw/K205480106007/276281855_728896961615044_4850973774883281965_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/My Duyen/276281855_728896961615044_4850973774883281965_n.jpg\\nrename to Dataset/FaceData/raw/K205480106007/276281855_728896961615044_4850973774883281965_n.jpg\\ndiff --git a/Dataset/FaceData/raw/My Duyen/375727668_1053445732493497_6855315188334578963_n.jpg b/Dataset/FaceData/raw/K205480106007/375727668_1053445732493497_6855315188334578963_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/My Duyen/375727668_1053445732493497_6855315188334578963_n.jpg\\nrename to Dataset/FaceData/raw/K205480106007/375727668_1053445732493497_6855315188334578963_n.jpg\\ndiff --git a/Dataset/FaceData/raw/My Duyen/377915813_1055517365619667_3022176625716036504_n.jpg b/Dataset/FaceData/raw/K205480106007/377915813_1055517365619667_3022176625716036504_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/My Duyen/377915813_1055517365619667_3022176625716036504_n.jpg\\nrename to Dataset/FaceData/raw/K205480106007/377915813_1055517365619667_3022176625716036504_n.jpg\\ndiff --git a/Dataset/FaceData/raw/My Duyen/383221108_1063489451489125_7303325553687006067_n.jpg b/Dataset/FaceData/raw/K205480106007/383221108_1063489451489125_7303325553687006067_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/My Duyen/383221108_1063489451489125_7303325553687006067_n.jpg\\nrename to Dataset/FaceData/raw/K205480106007/383221108_1063489451489125_7303325553687006067_n.jpg\\ndiff --git a/Dataset/FaceData/raw/My Duyen/399161466_1085274189310651_5389319938695371438_n.jpg b/Dataset/FaceData/raw/K205480106007/399161466_1085274189310651_5389319938695371438_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/My Duyen/399161466_1085274189310651_5389319938695371438_n.jpg\\nrename to Dataset/FaceData/raw/K205480106007/399161466_1085274189310651_5389319938695371438_n.jpg\\ndiff --git a/Dataset/FaceData/raw/My Duyen/425727875_1136306777540725_7475412167375191065_n.jpg b/Dataset/FaceData/raw/K205480106007/425727875_1136306777540725_7475412167375191065_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/My Duyen/425727875_1136306777540725_7475412167375191065_n.jpg\\nrename to Dataset/FaceData/raw/K205480106007/425727875_1136306777540725_7475412167375191065_n.jpg\\ndiff --git a/Dataset/FaceData/raw/My Duyen/71477803_179402706564475_6524185163780325376_n.jpg b/Dataset/FaceData/raw/K205480106007/71477803_179402706564475_6524185163780325376_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/My Duyen/71477803_179402706564475_6524185163780325376_n.jpg\\nrename to Dataset/FaceData/raw/K205480106007/71477803_179402706564475_6524185163780325376_n.jpg\\ndiff --git a/Dataset/FaceData/raw/My Duyen/Screenshot 2024-02-08 200137.png b/Dataset/FaceData/raw/K205480106007/Screenshot 2024-02-08 200137.png\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/My Duyen/Screenshot 2024-02-08 200137.png\\nrename to Dataset/FaceData/raw/K205480106007/Screenshot 2024-02-08 200137.png\\ndiff --git a/Dataset/FaceData/raw/nguyen phuong tram/337142073_1253839052216597_199657983855233980_n.jpg b/Dataset/FaceData/raw/K205480106009/337142073_1253839052216597_199657983855233980_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/nguyen phuong tram/337142073_1253839052216597_199657983855233980_n.jpg\\nrename to Dataset/FaceData/raw/K205480106009/337142073_1253839052216597_199657983855233980_n.jpg\\ndiff --git a/Dataset/FaceData/raw/nguyen phuong tram/339263904_1264665414159651_8733650862788543327_n.jpg b/Dataset/FaceData/raw/K205480106009/339263904_1264665414159651_8733650862788543327_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/nguyen phuong tram/339263904_1264665414159651_8733650862788543327_n.jpg\\nrename to Dataset/FaceData/raw/K205480106009/339263904_1264665414159651_8733650862788543327_n.jpg\\ndiff --git a/Dataset/FaceData/raw/nguyen phuong tram/339266601_894783791775673_734864429475267886_n.jpg b/Dataset/FaceData/raw/K205480106009/339266601_894783791775673_734864429475267886_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/nguyen phuong tram/339266601_894783791775673_734864429475267886_n.jpg\\nrename to Dataset/FaceData/raw/K205480106009/339266601_894783791775673_734864429475267886_n.jpg\\ndiff --git a/Dataset/FaceData/raw/nguyen phuong tram/339408406_1209323986622559_1237855961637611483_n.jpg b/Dataset/FaceData/raw/K205480106009/339408406_1209323986622559_1237855961637611483_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/nguyen phuong tram/339408406_1209323986622559_1237855961637611483_n.jpg\\nrename to Dataset/FaceData/raw/K205480106009/339408406_1209323986622559_1237855961637611483_n.jpg\\ndiff --git a/Dataset/FaceData/raw/nguyen phuong tram/anh1.jpg b/Dataset/FaceData/raw/K205480106009/anh1.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/nguyen phuong tram/anh1.jpg\\nrename to Dataset/FaceData/raw/K205480106009/anh1.jpg\\ndiff --git a/Dataset/FaceData/raw/nguyen phuong tram/anh2.jpg b/Dataset/FaceData/raw/K205480106009/anh2.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/nguyen phuong tram/anh2.jpg\\nrename to Dataset/FaceData/raw/K205480106009/anh2.jpg\\ndiff --git a/Dataset/FaceData/raw/nguyen phuong tram/anh3.jpg b/Dataset/FaceData/raw/K205480106009/anh3.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/nguyen phuong tram/anh3.jpg\\nrename to Dataset/FaceData/raw/K205480106009/anh3.jpg\\ndiff --git a/Dataset/FaceData/raw/nguyen phuong tram/anh4.jpg b/Dataset/FaceData/raw/K205480106009/anh4.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/nguyen phuong tram/anh4.jpg\\nrename to Dataset/FaceData/raw/K205480106009/anh4.jpg\\ndiff --git a/Dataset/FaceData/raw/nguyen phuong tram/anh5.jpg b/Dataset/FaceData/raw/K205480106009/anh5.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/nguyen phuong tram/anh5.jpg\\nrename to Dataset/FaceData/raw/K205480106009/anh5.jpg\\ndiff --git a/Dataset/FaceData/raw/nguyen phuong tram/anh7.jpg b/Dataset/FaceData/raw/K205480106009/anh7.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/nguyen phuong tram/anh7.jpg\\nrename to Dataset/FaceData/raw/K205480106009/anh7.jpg\\ndiff --git a/Dataset/FaceData/raw/nguyen phuong tram/anh8.jpg b/Dataset/FaceData/raw/K205480106009/anh8.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/nguyen phuong tram/anh8.jpg\\nrename to Dataset/FaceData/raw/K205480106009/anh8.jpg\\ndiff --git a/Dataset/FaceData/raw/thaongo/419652962_741170244266451_4914393583094088361_n.jpg b/Dataset/FaceData/raw/K205480106011/419652962_741170244266451_4914393583094088361_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/thaongo/419652962_741170244266451_4914393583094088361_n.jpg\\nrename to Dataset/FaceData/raw/K205480106011/419652962_741170244266451_4914393583094088361_n.jpg\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao1.jpg b/Dataset/FaceData/raw/K205480106011/thao1.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/thaongo/thao1.jpg\\nrename to Dataset/FaceData/raw/K205480106011/thao1.jpg\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao10.jpg b/Dataset/FaceData/raw/K205480106011/thao10.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/thaongo/thao10.jpg\\nrename to Dataset/FaceData/raw/K205480106011/thao10.jpg\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao19.jpg b/Dataset/FaceData/raw/K205480106011/thao19.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/thaongo/thao19.jpg\\nrename to Dataset/FaceData/raw/K205480106011/thao19.jpg\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao2.jpg b/Dataset/FaceData/raw/K205480106011/thao2.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/thaongo/thao2.jpg\\nrename to Dataset/FaceData/raw/K205480106011/thao2.jpg\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao21.jpg b/Dataset/FaceData/raw/K205480106011/thao21.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/thaongo/thao21.jpg\\nrename to Dataset/FaceData/raw/K205480106011/thao21.jpg\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao24.jpg b/Dataset/FaceData/raw/K205480106011/thao24.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/thaongo/thao24.jpg\\nrename to Dataset/FaceData/raw/K205480106011/thao24.jpg\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao25.jpg b/Dataset/FaceData/raw/K205480106011/thao25.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/thaongo/thao25.jpg\\nrename to Dataset/FaceData/raw/K205480106011/thao25.jpg\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao26.jpg b/Dataset/FaceData/raw/K205480106011/thao26.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/thaongo/thao26.jpg\\nrename to Dataset/FaceData/raw/K205480106011/thao26.jpg\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao29.jpg b/Dataset/FaceData/raw/K205480106011/thao29.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/thaongo/thao29.jpg\\nrename to Dataset/FaceData/raw/K205480106011/thao29.jpg\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao3.jpg b/Dataset/FaceData/raw/K205480106011/thao3.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/thaongo/thao3.jpg\\nrename to Dataset/FaceData/raw/K205480106011/thao3.jpg\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao31.jpg b/Dataset/FaceData/raw/K205480106011/thao31.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/thaongo/thao31.jpg\\nrename to Dataset/FaceData/raw/K205480106011/thao31.jpg\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao32.jpg b/Dataset/FaceData/raw/K205480106011/thao32.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/thaongo/thao32.jpg\\nrename to Dataset/FaceData/raw/K205480106011/thao32.jpg\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao33.jpg b/Dataset/FaceData/raw/K205480106011/thao33.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/thaongo/thao33.jpg\\nrename to Dataset/FaceData/raw/K205480106011/thao33.jpg\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao34.jpg b/Dataset/FaceData/raw/K205480106011/thao34.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/thaongo/thao34.jpg\\nrename to Dataset/FaceData/raw/K205480106011/thao34.jpg\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao35.jpg b/Dataset/FaceData/raw/K205480106011/thao35.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/thaongo/thao35.jpg\\nrename to Dataset/FaceData/raw/K205480106011/thao35.jpg\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao4.jpg b/Dataset/FaceData/raw/K205480106011/thao4.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/thaongo/thao4.jpg\\nrename to Dataset/FaceData/raw/K205480106011/thao4.jpg\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao5.jpg b/Dataset/FaceData/raw/K205480106011/thao5.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/thaongo/thao5.jpg\\nrename to Dataset/FaceData/raw/K205480106011/thao5.jpg\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao6.jpg b/Dataset/FaceData/raw/K205480106011/thao6.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/thaongo/thao6.jpg\\nrename to Dataset/FaceData/raw/K205480106011/thao6.jpg\\ndiff --git a/Dataset/FaceData/raw/thaongo/thao7.jpg b/Dataset/FaceData/raw/K205480106011/thao7.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/thaongo/thao7.jpg\\nrename to Dataset/FaceData/raw/K205480106011/thao7.jpg\\ndiff --git a/Dataset/FaceData/raw/Do hieu/176064931_2957139457942069_3035200184642124074_n.jpg b/Dataset/FaceData/raw/K205480106012/176064931_2957139457942069_3035200184642124074_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Do hieu/176064931_2957139457942069_3035200184642124074_n.jpg\\nrename to Dataset/FaceData/raw/K205480106012/176064931_2957139457942069_3035200184642124074_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Do hieu/177907728_2957139527942062_5622464185056568311_n.jpg b/Dataset/FaceData/raw/K205480106012/177907728_2957139527942062_5622464185056568311_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Do hieu/177907728_2957139527942062_5622464185056568311_n.jpg\\nrename to Dataset/FaceData/raw/K205480106012/177907728_2957139527942062_5622464185056568311_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Do hieu/177993461_2957139491275399_3222091836626291316_n.jpg b/Dataset/FaceData/raw/K205480106012/177993461_2957139491275399_3222091836626291316_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Do hieu/177993461_2957139491275399_3222091836626291316_n.jpg\\nrename to Dataset/FaceData/raw/K205480106012/177993461_2957139491275399_3222091836626291316_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Do hieu/178929889_2957139244608757_1991887332909086037_n (1).jpg b/Dataset/FaceData/raw/K205480106012/178929889_2957139244608757_1991887332909086037_n (1).jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Do hieu/178929889_2957139244608757_1991887332909086037_n (1).jpg\\nrename to Dataset/FaceData/raw/K205480106012/178929889_2957139244608757_1991887332909086037_n (1).jpg\\ndiff --git a/Dataset/FaceData/raw/Do hieu/178929889_2957139244608757_1991887332909086037_n.jpg b/Dataset/FaceData/raw/K205480106012/178929889_2957139244608757_1991887332909086037_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Do hieu/178929889_2957139244608757_1991887332909086037_n.jpg\\nrename to Dataset/FaceData/raw/K205480106012/178929889_2957139244608757_1991887332909086037_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Do hieu/314736967_3413393448983332_3470974153489929662_n.jpg b/Dataset/FaceData/raw/K205480106012/314736967_3413393448983332_3470974153489929662_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Do hieu/314736967_3413393448983332_3470974153489929662_n.jpg\\nrename to Dataset/FaceData/raw/K205480106012/314736967_3413393448983332_3470974153489929662_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Do hieu/408729291_122109331016134044_5530016628103795106_n.jpg b/Dataset/FaceData/raw/K205480106012/408729291_122109331016134044_5530016628103795106_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Do hieu/408729291_122109331016134044_5530016628103795106_n.jpg\\nrename to Dataset/FaceData/raw/K205480106012/408729291_122109331016134044_5530016628103795106_n.jpg\\ndiff --git a/Dataset/FaceData/raw/nguyen ngoc thai/284851180_1033334854278874_6949309560983343387_n.jpg b/Dataset/FaceData/raw/K205480106014/284851180_1033334854278874_6949309560983343387_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/nguyen ngoc thai/284851180_1033334854278874_6949309560983343387_n.jpg\\nrename to Dataset/FaceData/raw/K205480106014/284851180_1033334854278874_6949309560983343387_n.jpg\\ndiff --git a/Dataset/FaceData/raw/nguyen ngoc thai/thai1.jpg b/Dataset/FaceData/raw/K205480106014/thai1.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/nguyen ngoc thai/thai1.jpg\\nrename to Dataset/FaceData/raw/K205480106014/thai1.jpg\\ndiff --git a/Dataset/FaceData/raw/nguyen ngoc thai/thai2.jpg b/Dataset/FaceData/raw/K205480106014/thai2.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/nguyen ngoc thai/thai2.jpg\\nrename to Dataset/FaceData/raw/K205480106014/thai2.jpg\\ndiff --git a/Dataset/FaceData/raw/nguyen ngoc thai/thai3.jpg b/Dataset/FaceData/raw/K205480106014/thai3.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/nguyen ngoc thai/thai3.jpg\\nrename to Dataset/FaceData/raw/K205480106014/thai3.jpg\\ndiff --git a/Dataset/FaceData/raw/nguyen ngoc thai/thai4.jpg b/Dataset/FaceData/raw/K205480106014/thai4.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/nguyen ngoc thai/thai4.jpg\\nrename to Dataset/FaceData/raw/K205480106014/thai4.jpg\\ndiff --git a/Dataset/FaceData/raw/nguyen ngoc thai/thai5.jpg b/Dataset/FaceData/raw/K205480106014/thai5.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/nguyen ngoc thai/thai5.jpg\\nrename to Dataset/FaceData/raw/K205480106014/thai5.jpg\\ndiff --git a/Dataset/FaceData/raw/nguyen ngoc thai/thaidemo.jpg b/Dataset/FaceData/raw/K205480106014/thaidemo.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/nguyen ngoc thai/thaidemo.jpg\\nrename to Dataset/FaceData/raw/K205480106014/thaidemo.jpg\\ndiff --git a/Dataset/FaceData/raw/nguyen ngoc thai/thaidemo2.jpg b/Dataset/FaceData/raw/K205480106014/thaidemo2.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/nguyen ngoc thai/thaidemo2.jpg\\nrename to Dataset/FaceData/raw/K205480106014/thaidemo2.jpg\\ndiff --git a/Dataset/FaceData/raw/Duc viet/152373366_899599367523323_8039073461193180489_n.jpg b/Dataset/FaceData/raw/K205480106015/152373366_899599367523323_8039073461193180489_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Duc viet/152373366_899599367523323_8039073461193180489_n.jpg\\nrename to Dataset/FaceData/raw/K205480106015/152373366_899599367523323_8039073461193180489_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Duc viet/152709553_899599430856650_818805157951754296_n.jpg b/Dataset/FaceData/raw/K205480106015/152709553_899599430856650_818805157951754296_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Duc viet/152709553_899599430856650_818805157951754296_n.jpg\\nrename to Dataset/FaceData/raw/K205480106015/152709553_899599430856650_818805157951754296_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Duc viet/154070237_435134567707863_6078333129900068002_n.jpg b/Dataset/FaceData/raw/K205480106015/154070237_435134567707863_6078333129900068002_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Duc viet/154070237_435134567707863_6078333129900068002_n.jpg\\nrename to Dataset/FaceData/raw/K205480106015/154070237_435134567707863_6078333129900068002_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Duc viet/61506698_348134895895603_7272087717616287744_n.jpg b/Dataset/FaceData/raw/K205480106015/61506698_348134895895603_7272087717616287744_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Duc viet/61506698_348134895895603_7272087717616287744_n.jpg\\nrename to Dataset/FaceData/raw/K205480106015/61506698_348134895895603_7272087717616287744_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Duc viet/61560706_348134092562350_1539501885898096640_n.jpg b/Dataset/FaceData/raw/K205480106015/61560706_348134092562350_1539501885898096640_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Duc viet/61560706_348134092562350_1539501885898096640_n.jpg\\nrename to Dataset/FaceData/raw/K205480106015/61560706_348134092562350_1539501885898096640_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Duc viet/61584844_348135582562201_7506169027295707136_n.jpg b/Dataset/FaceData/raw/K205480106015/61584844_348135582562201_7506169027295707136_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Duc viet/61584844_348135582562201_7506169027295707136_n.jpg\\nrename to Dataset/FaceData/raw/K205480106015/61584844_348135582562201_7506169027295707136_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Duc viet/61820425_348134402562319_3380097574999425024_n.jpg b/Dataset/FaceData/raw/K205480106015/61820425_348134402562319_3380097574999425024_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Duc viet/61820425_348134402562319_3380097574999425024_n.jpg\\nrename to Dataset/FaceData/raw/K205480106015/61820425_348134402562319_3380097574999425024_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Duc viet/61848774_348135615895531_3014436068146544640_n.jpg b/Dataset/FaceData/raw/K205480106015/61848774_348135615895531_3014436068146544640_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Duc viet/61848774_348135615895531_3014436068146544640_n.jpg\\nrename to Dataset/FaceData/raw/K205480106015/61848774_348135615895531_3014436068146544640_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Duc viet/61967926_348135315895561_496212973459603456_n.jpg b/Dataset/FaceData/raw/K205480106015/61967926_348135315895561_496212973459603456_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Duc viet/61967926_348135315895561_496212973459603456_n.jpg\\nrename to Dataset/FaceData/raw/K205480106015/61967926_348135315895561_496212973459603456_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Duc viet/62021360_348135282562231_7688022791626424320_n.jpg b/Dataset/FaceData/raw/K205480106015/62021360_348135282562231_7688022791626424320_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Duc viet/62021360_348135282562231_7688022791626424320_n.jpg\\nrename to Dataset/FaceData/raw/K205480106015/62021360_348135282562231_7688022791626424320_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Duc viet/62035132_348134362562323_2007170459463843840_n.jpg b/Dataset/FaceData/raw/K205480106015/62035132_348134362562323_2007170459463843840_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Duc viet/62035132_348134362562323_2007170459463843840_n.jpg\\nrename to Dataset/FaceData/raw/K205480106015/62035132_348134362562323_2007170459463843840_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Duc viet/64869534_359570548085371_8201502723321888768_n.jpg b/Dataset/FaceData/raw/K205480106015/64869534_359570548085371_8201502723321888768_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Duc viet/64869534_359570548085371_8201502723321888768_n.jpg\\nrename to Dataset/FaceData/raw/K205480106015/64869534_359570548085371_8201502723321888768_n.jpg\\ndiff --git a/Dataset/FaceData/raw/tran nhat truong/truong1.jpg b/Dataset/FaceData/raw/K205480106020/truong1.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/tran nhat truong/truong1.jpg\\nrename to Dataset/FaceData/raw/K205480106020/truong1.jpg\\ndiff --git a/Dataset/FaceData/raw/duong thi bich nguyet/anh1.jpg b/Dataset/FaceData/raw/K205480106021/anh1.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/duong thi bich nguyet/anh1.jpg\\nrename to Dataset/FaceData/raw/K205480106021/anh1.jpg\\ndiff --git a/Dataset/FaceData/raw/duong thi bich nguyet/nguyet2.jpg b/Dataset/FaceData/raw/K205480106021/nguyet2.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/duong thi bich nguyet/nguyet2.jpg\\nrename to Dataset/FaceData/raw/K205480106021/nguyet2.jpg\\ndiff --git a/Dataset/FaceData/raw/duong thi bich nguyet/nguyet3.jpg b/Dataset/FaceData/raw/K205480106021/nguyet3.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/duong thi bich nguyet/nguyet3.jpg\\nrename to Dataset/FaceData/raw/K205480106021/nguyet3.jpg\\ndiff --git a/Dataset/FaceData/raw/duong thi bich nguyet/nguyet4.jpg b/Dataset/FaceData/raw/K205480106021/nguyet4.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/duong thi bich nguyet/nguyet4.jpg\\nrename to Dataset/FaceData/raw/K205480106021/nguyet4.jpg\\ndiff --git a/Dataset/FaceData/raw/duong thi bich nguyet/nguyet6.jpg b/Dataset/FaceData/raw/K205480106021/nguyet6.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/duong thi bich nguyet/nguyet6.jpg\\nrename to Dataset/FaceData/raw/K205480106021/nguyet6.jpg\\ndiff --git a/Dataset/FaceData/raw/Tran Hoc/107223180_1197468397263141_6372187421696273098_n.jpg b/Dataset/FaceData/raw/K205480106030/107223180_1197468397263141_6372187421696273098_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Tran Hoc/107223180_1197468397263141_6372187421696273098_n.jpg\\nrename to Dataset/FaceData/raw/K205480106030/107223180_1197468397263141_6372187421696273098_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Tran Hoc/120220333_1261416600868320_4101096592656067221_n.jpg b/Dataset/FaceData/raw/K205480106030/120220333_1261416600868320_4101096592656067221_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Tran Hoc/120220333_1261416600868320_4101096592656067221_n.jpg\\nrename to Dataset/FaceData/raw/K205480106030/120220333_1261416600868320_4101096592656067221_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Tran Hoc/235810118_1494231920920119_422367748034160663_n.jpg b/Dataset/FaceData/raw/K205480106030/235810118_1494231920920119_422367748034160663_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Tran Hoc/235810118_1494231920920119_422367748034160663_n.jpg\\nrename to Dataset/FaceData/raw/K205480106030/235810118_1494231920920119_422367748034160663_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Tran Hoc/90066892_1096495004027148_8085701175137009664_n.jpg b/Dataset/FaceData/raw/K205480106030/90066892_1096495004027148_8085701175137009664_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Tran Hoc/90066892_1096495004027148_8085701175137009664_n.jpg\\nrename to Dataset/FaceData/raw/K205480106030/90066892_1096495004027148_8085701175137009664_n.jpg\\ndiff --git a/Dataset/FaceData/raw/Ma bach duy/duy1.jpg b/Dataset/FaceData/raw/K205480106034/duy1.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Ma bach duy/duy1.jpg\\nrename to Dataset/FaceData/raw/K205480106034/duy1.jpg\\ndiff --git a/Dataset/FaceData/raw/Ma bach duy/duy2.jpg b/Dataset/FaceData/raw/K205480106034/duy2.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Ma bach duy/duy2.jpg\\nrename to Dataset/FaceData/raw/K205480106034/duy2.jpg\\ndiff --git a/Dataset/FaceData/raw/Ma bach duy/duy3.jpg b/Dataset/FaceData/raw/K205480106034/duy3.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Ma bach duy/duy3.jpg\\nrename to Dataset/FaceData/raw/K205480106034/duy3.jpg\\ndiff --git a/Dataset/FaceData/raw/Ma bach duy/duy4.jpg b/Dataset/FaceData/raw/K205480106034/duy4.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/Ma bach duy/duy4.jpg\\nrename to Dataset/FaceData/raw/K205480106034/duy4.jpg\\ndiff --git a/Dataset/FaceData/raw/dang thi ha/385534676_267391239125906_3185308814281359599_n.jpg b/Dataset/FaceData/raw/K205480106040/385534676_267391239125906_3185308814281359599_n.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/dang thi ha/385534676_267391239125906_3185308814281359599_n.jpg\\nrename to Dataset/FaceData/raw/K205480106040/385534676_267391239125906_3185308814281359599_n.jpg\\ndiff --git a/Dataset/FaceData/raw/dang thi ha/anh1.jpg b/Dataset/FaceData/raw/K205480106040/anh1.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/dang thi ha/anh1.jpg\\nrename to Dataset/FaceData/raw/K205480106040/anh1.jpg\\ndiff --git a/Dataset/FaceData/raw/dang thi ha/anh2.jpg b/Dataset/FaceData/raw/K205480106040/anh2.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/dang thi ha/anh2.jpg\\nrename to Dataset/FaceData/raw/K205480106040/anh2.jpg\\ndiff --git a/Dataset/FaceData/raw/dang thi ha/anh3.jpg b/Dataset/FaceData/raw/K205480106040/anh3.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/dang thi ha/anh3.jpg\\nrename to Dataset/FaceData/raw/K205480106040/anh3.jpg\\ndiff --git a/Dataset/FaceData/raw/dang thi ha/anh4.jpg b/Dataset/FaceData/raw/K205480106040/anh4.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/dang thi ha/anh4.jpg\\nrename to Dataset/FaceData/raw/K205480106040/anh4.jpg\\ndiff --git a/Dataset/FaceData/raw/dang thi ha/demo.jpg b/Dataset/FaceData/raw/K205480106040/demo.jpg\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/dang thi ha/demo.jpg\\nrename to Dataset/FaceData/raw/K205480106040/demo.jpg\\ndiff --git a/Dataset/FaceData/raw/dang thi ha/img.png b/Dataset/FaceData/raw/K205480106040/img.png\\nsimilarity index 100%\\nrename from Dataset/FaceData/raw/dang thi ha/img.png\\nrename to Dataset/FaceData/raw/K205480106040/img.png\\ndiff --git a/Dataset/FaceData/raw/Nam Em/0.png b/Dataset/FaceData/raw/Nam Em/0.png\\ndeleted file mode 100644\\nindex 3f85836..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/0.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/1.png b/Dataset/FaceData/raw/Nam Em/1.png\\ndeleted file mode 100644\\nindex b368d4c..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/10.png b/Dataset/FaceData/raw/Nam Em/10.png\\ndeleted file mode 100644\\nindex 7d82425..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/10.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/11.png b/Dataset/FaceData/raw/Nam Em/11.png\\ndeleted file mode 100644\\nindex 83d23f9..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/11.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/12.png b/Dataset/FaceData/raw/Nam Em/12.png\\ndeleted file mode 100644\\nindex c2e1b32..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/12.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/13.png b/Dataset/FaceData/raw/Nam Em/13.png\\ndeleted file mode 100644\\nindex 93a8ce8..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/13.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/14.png b/Dataset/FaceData/raw/Nam Em/14.png\\ndeleted file mode 100644\\nindex c8ba086..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/14.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/15.png b/Dataset/FaceData/raw/Nam Em/15.png\\ndeleted file mode 100644\\nindex db0ea3d..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/15.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/16.png b/Dataset/FaceData/raw/Nam Em/16.png\\ndeleted file mode 100644\\nindex d1fa253..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/16.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/17.png b/Dataset/FaceData/raw/Nam Em/17.png\\ndeleted file mode 100644\\nindex 9376f01..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/17.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/18.png b/Dataset/FaceData/raw/Nam Em/18.png\\ndeleted file mode 100644\\nindex d958f8f..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/18.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/19.png b/Dataset/FaceData/raw/Nam Em/19.png\\ndeleted file mode 100644\\nindex 5f70694..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/19.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/2.png b/Dataset/FaceData/raw/Nam Em/2.png\\ndeleted file mode 100644\\nindex 5aa9812..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/20.png b/Dataset/FaceData/raw/Nam Em/20.png\\ndeleted file mode 100644\\nindex 8e4c692..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/20.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/21.png b/Dataset/FaceData/raw/Nam Em/21.png\\ndeleted file mode 100644\\nindex e9e68d2..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/21.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/22.png b/Dataset/FaceData/raw/Nam Em/22.png\\ndeleted file mode 100644\\nindex 1dbfba4..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/22.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/23.png b/Dataset/FaceData/raw/Nam Em/23.png\\ndeleted file mode 100644\\nindex d204f07..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/23.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/24.png b/Dataset/FaceData/raw/Nam Em/24.png\\ndeleted file mode 100644\\nindex 44c88e8..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/24.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/25.png b/Dataset/FaceData/raw/Nam Em/25.png\\ndeleted file mode 100644\\nindex 56e76a5..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/25.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/26.png b/Dataset/FaceData/raw/Nam Em/26.png\\ndeleted file mode 100644\\nindex fb4f36c..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/26.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/27.png b/Dataset/FaceData/raw/Nam Em/27.png\\ndeleted file mode 100644\\nindex 4898fd1..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/27.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/28.png b/Dataset/FaceData/raw/Nam Em/28.png\\ndeleted file mode 100644\\nindex eb29914..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/28.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/29.png b/Dataset/FaceData/raw/Nam Em/29.png\\ndeleted file mode 100644\\nindex fbed1bd..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/29.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/3.png b/Dataset/FaceData/raw/Nam Em/3.png\\ndeleted file mode 100644\\nindex 915e775..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/30.png b/Dataset/FaceData/raw/Nam Em/30.png\\ndeleted file mode 100644\\nindex 075d317..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/30.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/31.png b/Dataset/FaceData/raw/Nam Em/31.png\\ndeleted file mode 100644\\nindex b8cc242..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/31.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/32.png b/Dataset/FaceData/raw/Nam Em/32.png\\ndeleted file mode 100644\\nindex 1d17733..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/32.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/33.png b/Dataset/FaceData/raw/Nam Em/33.png\\ndeleted file mode 100644\\nindex a7ff820..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/33.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/34.png b/Dataset/FaceData/raw/Nam Em/34.png\\ndeleted file mode 100644\\nindex ee5f107..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/34.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/35.png b/Dataset/FaceData/raw/Nam Em/35.png\\ndeleted file mode 100644\\nindex ac81719..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/35.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/36.png b/Dataset/FaceData/raw/Nam Em/36.png\\ndeleted file mode 100644\\nindex a05d3d5..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/36.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/37.png b/Dataset/FaceData/raw/Nam Em/37.png\\ndeleted file mode 100644\\nindex 92d4f2e..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/37.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/38.png b/Dataset/FaceData/raw/Nam Em/38.png\\ndeleted file mode 100644\\nindex 7cbc9b0..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/38.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/39.png b/Dataset/FaceData/raw/Nam Em/39.png\\ndeleted file mode 100644\\nindex a20014c..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/39.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/4.png b/Dataset/FaceData/raw/Nam Em/4.png\\ndeleted file mode 100644\\nindex 0fb452e..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/40.png b/Dataset/FaceData/raw/Nam Em/40.png\\ndeleted file mode 100644\\nindex 080826c..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/40.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/41.png b/Dataset/FaceData/raw/Nam Em/41.png\\ndeleted file mode 100644\\nindex a6faa48..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/41.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/5.png b/Dataset/FaceData/raw/Nam Em/5.png\\ndeleted file mode 100644\\nindex 5bf3168..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/5.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/6.png b/Dataset/FaceData/raw/Nam Em/6.png\\ndeleted file mode 100644\\nindex 00c0655..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/6.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/7.png b/Dataset/FaceData/raw/Nam Em/7.png\\ndeleted file mode 100644\\nindex 8d5892d..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/7.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/8.png b/Dataset/FaceData/raw/Nam Em/8.png\\ndeleted file mode 100644\\nindex 29b4f2d..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/8.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nam Em/9.png b/Dataset/FaceData/raw/Nam Em/9.png\\ndeleted file mode 100644\\nindex bdcb671..0000000\\nBinary files a/Dataset/FaceData/raw/Nam Em/9.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/0.png b/Dataset/FaceData/raw/Nguyen phu trong/0.png\\ndeleted file mode 100644\\nindex 976e984..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/0.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/1.png b/Dataset/FaceData/raw/Nguyen phu trong/1.png\\ndeleted file mode 100644\\nindex 4f79532..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/10.png b/Dataset/FaceData/raw/Nguyen phu trong/10.png\\ndeleted file mode 100644\\nindex e9ea96c..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/10.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/11.png b/Dataset/FaceData/raw/Nguyen phu trong/11.png\\ndeleted file mode 100644\\nindex 8444d05..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/11.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/12.png b/Dataset/FaceData/raw/Nguyen phu trong/12.png\\ndeleted file mode 100644\\nindex bba1419..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/12.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/13.png b/Dataset/FaceData/raw/Nguyen phu trong/13.png\\ndeleted file mode 100644\\nindex 97b46a3..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/13.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/14.png b/Dataset/FaceData/raw/Nguyen phu trong/14.png\\ndeleted file mode 100644\\nindex aa70e6a..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/14.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/15.png b/Dataset/FaceData/raw/Nguyen phu trong/15.png\\ndeleted file mode 100644\\nindex f6b4932..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/15.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/16.png b/Dataset/FaceData/raw/Nguyen phu trong/16.png\\ndeleted file mode 100644\\nindex a8bbb6d..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/16.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/17.png b/Dataset/FaceData/raw/Nguyen phu trong/17.png\\ndeleted file mode 100644\\nindex a0a99be..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/17.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/18.png b/Dataset/FaceData/raw/Nguyen phu trong/18.png\\ndeleted file mode 100644\\nindex f46d72c..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/18.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/19.png b/Dataset/FaceData/raw/Nguyen phu trong/19.png\\ndeleted file mode 100644\\nindex ccc12c7..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/19.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/2.png b/Dataset/FaceData/raw/Nguyen phu trong/2.png\\ndeleted file mode 100644\\nindex 0ba9303..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/20.png b/Dataset/FaceData/raw/Nguyen phu trong/20.png\\ndeleted file mode 100644\\nindex 0a81161..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/20.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/21.png b/Dataset/FaceData/raw/Nguyen phu trong/21.png\\ndeleted file mode 100644\\nindex c8a7165..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/21.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/22.png b/Dataset/FaceData/raw/Nguyen phu trong/22.png\\ndeleted file mode 100644\\nindex 4eeec1d..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/22.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/23.png b/Dataset/FaceData/raw/Nguyen phu trong/23.png\\ndeleted file mode 100644\\nindex 58220d7..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/23.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/24.png b/Dataset/FaceData/raw/Nguyen phu trong/24.png\\ndeleted file mode 100644\\nindex 8f46da4..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/24.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/25.png b/Dataset/FaceData/raw/Nguyen phu trong/25.png\\ndeleted file mode 100644\\nindex e4c119e..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/25.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/26.png b/Dataset/FaceData/raw/Nguyen phu trong/26.png\\ndeleted file mode 100644\\nindex b4f5ef2..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/26.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/27.png b/Dataset/FaceData/raw/Nguyen phu trong/27.png\\ndeleted file mode 100644\\nindex fb0431a..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/27.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/28.png b/Dataset/FaceData/raw/Nguyen phu trong/28.png\\ndeleted file mode 100644\\nindex 5755fa1..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/28.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/29.png b/Dataset/FaceData/raw/Nguyen phu trong/29.png\\ndeleted file mode 100644\\nindex c048cdd..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/29.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/3.png b/Dataset/FaceData/raw/Nguyen phu trong/3.png\\ndeleted file mode 100644\\nindex 6df31c4..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/30.png b/Dataset/FaceData/raw/Nguyen phu trong/30.png\\ndeleted file mode 100644\\nindex 14d0da8..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/30.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/31.png b/Dataset/FaceData/raw/Nguyen phu trong/31.png\\ndeleted file mode 100644\\nindex 5f42334..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/31.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/32.png b/Dataset/FaceData/raw/Nguyen phu trong/32.png\\ndeleted file mode 100644\\nindex 6db206e..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/32.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/33.png b/Dataset/FaceData/raw/Nguyen phu trong/33.png\\ndeleted file mode 100644\\nindex 2cc421b..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/33.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/34.png b/Dataset/FaceData/raw/Nguyen phu trong/34.png\\ndeleted file mode 100644\\nindex 24425b9..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/34.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/35.png b/Dataset/FaceData/raw/Nguyen phu trong/35.png\\ndeleted file mode 100644\\nindex 6443185..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/35.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/36.png b/Dataset/FaceData/raw/Nguyen phu trong/36.png\\ndeleted file mode 100644\\nindex 479c39c..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/36.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/37.png b/Dataset/FaceData/raw/Nguyen phu trong/37.png\\ndeleted file mode 100644\\nindex ac32025..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/37.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/38.png b/Dataset/FaceData/raw/Nguyen phu trong/38.png\\ndeleted file mode 100644\\nindex 0f4a752..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/38.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/39.png b/Dataset/FaceData/raw/Nguyen phu trong/39.png\\ndeleted file mode 100644\\nindex 5f670ae..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/39.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/4.png b/Dataset/FaceData/raw/Nguyen phu trong/4.png\\ndeleted file mode 100644\\nindex 89cf6b5..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/40.png b/Dataset/FaceData/raw/Nguyen phu trong/40.png\\ndeleted file mode 100644\\nindex d8192e2..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/40.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/41.png b/Dataset/FaceData/raw/Nguyen phu trong/41.png\\ndeleted file mode 100644\\nindex f47c1f9..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/41.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/42.png b/Dataset/FaceData/raw/Nguyen phu trong/42.png\\ndeleted file mode 100644\\nindex 12c8d9b..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/42.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/43.png b/Dataset/FaceData/raw/Nguyen phu trong/43.png\\ndeleted file mode 100644\\nindex b7c5b7b..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/43.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/44.png b/Dataset/FaceData/raw/Nguyen phu trong/44.png\\ndeleted file mode 100644\\nindex 493053e..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/44.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/45.png b/Dataset/FaceData/raw/Nguyen phu trong/45.png\\ndeleted file mode 100644\\nindex 7248c04..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/45.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/46.png b/Dataset/FaceData/raw/Nguyen phu trong/46.png\\ndeleted file mode 100644\\nindex 048a5b2..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/46.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/47.png b/Dataset/FaceData/raw/Nguyen phu trong/47.png\\ndeleted file mode 100644\\nindex 5c4b6e6..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/47.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/5.png b/Dataset/FaceData/raw/Nguyen phu trong/5.png\\ndeleted file mode 100644\\nindex 446d6b7..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/5.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/6.png b/Dataset/FaceData/raw/Nguyen phu trong/6.png\\ndeleted file mode 100644\\nindex 990ec82..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/6.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/7.png b/Dataset/FaceData/raw/Nguyen phu trong/7.png\\ndeleted file mode 100644\\nindex 71af50e..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/7.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/8.png b/Dataset/FaceData/raw/Nguyen phu trong/8.png\\ndeleted file mode 100644\\nindex 787185b..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/8.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Nguyen phu trong/9.png b/Dataset/FaceData/raw/Nguyen phu trong/9.png\\ndeleted file mode 100644\\nindex 33ee782..0000000\\nBinary files a/Dataset/FaceData/raw/Nguyen phu trong/9.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/0.png b/Dataset/FaceData/raw/Quang Hai/0.png\\ndeleted file mode 100644\\nindex a6d2f9b..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/0.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/1.png b/Dataset/FaceData/raw/Quang Hai/1.png\\ndeleted file mode 100644\\nindex 577a6c8..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/10.png b/Dataset/FaceData/raw/Quang Hai/10.png\\ndeleted file mode 100644\\nindex 02996f7..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/10.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/11.png b/Dataset/FaceData/raw/Quang Hai/11.png\\ndeleted file mode 100644\\nindex 4aabdc7..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/11.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/12.png b/Dataset/FaceData/raw/Quang Hai/12.png\\ndeleted file mode 100644\\nindex d9fe5a2..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/12.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/13.png b/Dataset/FaceData/raw/Quang Hai/13.png\\ndeleted file mode 100644\\nindex 4d666d1..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/13.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/14.png b/Dataset/FaceData/raw/Quang Hai/14.png\\ndeleted file mode 100644\\nindex 75f6024..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/14.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/15.png b/Dataset/FaceData/raw/Quang Hai/15.png\\ndeleted file mode 100644\\nindex 6024976..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/15.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/16.png b/Dataset/FaceData/raw/Quang Hai/16.png\\ndeleted file mode 100644\\nindex 2e004d0..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/16.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/17.png b/Dataset/FaceData/raw/Quang Hai/17.png\\ndeleted file mode 100644\\nindex 6821caf..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/17.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/18.png b/Dataset/FaceData/raw/Quang Hai/18.png\\ndeleted file mode 100644\\nindex afa82bd..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/18.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/19.png b/Dataset/FaceData/raw/Quang Hai/19.png\\ndeleted file mode 100644\\nindex 7f85c49..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/19.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/2.png b/Dataset/FaceData/raw/Quang Hai/2.png\\ndeleted file mode 100644\\nindex 07aae1b..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/20.png b/Dataset/FaceData/raw/Quang Hai/20.png\\ndeleted file mode 100644\\nindex 180098e..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/20.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/21.png b/Dataset/FaceData/raw/Quang Hai/21.png\\ndeleted file mode 100644\\nindex 95da114..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/21.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/22.png b/Dataset/FaceData/raw/Quang Hai/22.png\\ndeleted file mode 100644\\nindex 2970246..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/22.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/23.png b/Dataset/FaceData/raw/Quang Hai/23.png\\ndeleted file mode 100644\\nindex 1ad6b85..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/23.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/24.png b/Dataset/FaceData/raw/Quang Hai/24.png\\ndeleted file mode 100644\\nindex 983a361..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/24.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/25.png b/Dataset/FaceData/raw/Quang Hai/25.png\\ndeleted file mode 100644\\nindex 6d557f1..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/25.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/26.png b/Dataset/FaceData/raw/Quang Hai/26.png\\ndeleted file mode 100644\\nindex e34d23f..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/26.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/27.png b/Dataset/FaceData/raw/Quang Hai/27.png\\ndeleted file mode 100644\\nindex 342077c..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/27.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/28.png b/Dataset/FaceData/raw/Quang Hai/28.png\\ndeleted file mode 100644\\nindex 6fb2afc..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/28.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/29.png b/Dataset/FaceData/raw/Quang Hai/29.png\\ndeleted file mode 100644\\nindex caed707..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/29.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/3.png b/Dataset/FaceData/raw/Quang Hai/3.png\\ndeleted file mode 100644\\nindex a0de1f4..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/4.png b/Dataset/FaceData/raw/Quang Hai/4.png\\ndeleted file mode 100644\\nindex aa00799..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/5.png b/Dataset/FaceData/raw/Quang Hai/5.png\\ndeleted file mode 100644\\nindex 2618781..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/5.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/6.png b/Dataset/FaceData/raw/Quang Hai/6.png\\ndeleted file mode 100644\\nindex 37f4a9d..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/6.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/7.png b/Dataset/FaceData/raw/Quang Hai/7.png\\ndeleted file mode 100644\\nindex 8476564..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/7.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/8.png b/Dataset/FaceData/raw/Quang Hai/8.png\\ndeleted file mode 100644\\nindex 1f1a863..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/8.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Quang Hai/9.png b/Dataset/FaceData/raw/Quang Hai/9.png\\ndeleted file mode 100644\\nindex ff757a4..0000000\\nBinary files a/Dataset/FaceData/raw/Quang Hai/9.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/0.png b/Dataset/FaceData/raw/Van Dung/0.png\\ndeleted file mode 100644\\nindex fb573d8..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/0.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/1.png b/Dataset/FaceData/raw/Van Dung/1.png\\ndeleted file mode 100644\\nindex afebc3c..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/10.png b/Dataset/FaceData/raw/Van Dung/10.png\\ndeleted file mode 100644\\nindex 91653e1..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/10.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/11.png b/Dataset/FaceData/raw/Van Dung/11.png\\ndeleted file mode 100644\\nindex 3b1117b..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/11.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/12.png b/Dataset/FaceData/raw/Van Dung/12.png\\ndeleted file mode 100644\\nindex f6fc72b..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/12.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/13.png b/Dataset/FaceData/raw/Van Dung/13.png\\ndeleted file mode 100644\\nindex dd98255..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/13.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/14.png b/Dataset/FaceData/raw/Van Dung/14.png\\ndeleted file mode 100644\\nindex 052a8b7..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/14.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/15.png b/Dataset/FaceData/raw/Van Dung/15.png\\ndeleted file mode 100644\\nindex 2fd5f14..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/15.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/16.png b/Dataset/FaceData/raw/Van Dung/16.png\\ndeleted file mode 100644\\nindex ad10e4f..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/16.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/17.png b/Dataset/FaceData/raw/Van Dung/17.png\\ndeleted file mode 100644\\nindex 726b38e..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/17.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/18.png b/Dataset/FaceData/raw/Van Dung/18.png\\ndeleted file mode 100644\\nindex 72f8314..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/18.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/19.png b/Dataset/FaceData/raw/Van Dung/19.png\\ndeleted file mode 100644\\nindex 935b936..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/19.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/2.png b/Dataset/FaceData/raw/Van Dung/2.png\\ndeleted file mode 100644\\nindex 13ff3ad..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/20.png b/Dataset/FaceData/raw/Van Dung/20.png\\ndeleted file mode 100644\\nindex 789c33e..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/20.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/21.png b/Dataset/FaceData/raw/Van Dung/21.png\\ndeleted file mode 100644\\nindex 7595297..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/21.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/22.png b/Dataset/FaceData/raw/Van Dung/22.png\\ndeleted file mode 100644\\nindex 2111edf..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/22.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/23.png b/Dataset/FaceData/raw/Van Dung/23.png\\ndeleted file mode 100644\\nindex 305a232..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/23.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/24.png b/Dataset/FaceData/raw/Van Dung/24.png\\ndeleted file mode 100644\\nindex 8e91ae6..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/24.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/25.png b/Dataset/FaceData/raw/Van Dung/25.png\\ndeleted file mode 100644\\nindex efb1a4b..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/25.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/26.png b/Dataset/FaceData/raw/Van Dung/26.png\\ndeleted file mode 100644\\nindex bb677de..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/26.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/27.png b/Dataset/FaceData/raw/Van Dung/27.png\\ndeleted file mode 100644\\nindex 3ea1790..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/27.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/28.png b/Dataset/FaceData/raw/Van Dung/28.png\\ndeleted file mode 100644\\nindex eec7817..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/28.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/29.png b/Dataset/FaceData/raw/Van Dung/29.png\\ndeleted file mode 100644\\nindex c967c22..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/29.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/3.png b/Dataset/FaceData/raw/Van Dung/3.png\\ndeleted file mode 100644\\nindex 8cdccba..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/30.png b/Dataset/FaceData/raw/Van Dung/30.png\\ndeleted file mode 100644\\nindex 9e8e926..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/30.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/31.png b/Dataset/FaceData/raw/Van Dung/31.png\\ndeleted file mode 100644\\nindex ba76211..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/31.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/32.png b/Dataset/FaceData/raw/Van Dung/32.png\\ndeleted file mode 100644\\nindex 5f0c082..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/32.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/33.png b/Dataset/FaceData/raw/Van Dung/33.png\\ndeleted file mode 100644\\nindex d010b1b..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/33.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/34.png b/Dataset/FaceData/raw/Van Dung/34.png\\ndeleted file mode 100644\\nindex 2fc326e..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/34.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/35.png b/Dataset/FaceData/raw/Van Dung/35.png\\ndeleted file mode 100644\\nindex 14a1d9b..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/35.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/36.png b/Dataset/FaceData/raw/Van Dung/36.png\\ndeleted file mode 100644\\nindex 5bceec7..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/36.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/37.png b/Dataset/FaceData/raw/Van Dung/37.png\\ndeleted file mode 100644\\nindex 8627b2c..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/37.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/38.png b/Dataset/FaceData/raw/Van Dung/38.png\\ndeleted file mode 100644\\nindex 3d69fd3..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/38.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/39.png b/Dataset/FaceData/raw/Van Dung/39.png\\ndeleted file mode 100644\\nindex 7c52a65..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/39.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/4.png b/Dataset/FaceData/raw/Van Dung/4.png\\ndeleted file mode 100644\\nindex bd5ec4b..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/40.png b/Dataset/FaceData/raw/Van Dung/40.png\\ndeleted file mode 100644\\nindex 037c910..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/40.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/41.png b/Dataset/FaceData/raw/Van Dung/41.png\\ndeleted file mode 100644\\nindex 7f3ed0d..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/41.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/42.png b/Dataset/FaceData/raw/Van Dung/42.png\\ndeleted file mode 100644\\nindex 8f38805..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/42.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/43.png b/Dataset/FaceData/raw/Van Dung/43.png\\ndeleted file mode 100644\\nindex b3f87d0..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/43.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/44.png b/Dataset/FaceData/raw/Van Dung/44.png\\ndeleted file mode 100644\\nindex 7da54c7..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/44.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/45.png b/Dataset/FaceData/raw/Van Dung/45.png\\ndeleted file mode 100644\\nindex 54af81a..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/45.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/46.png b/Dataset/FaceData/raw/Van Dung/46.png\\ndeleted file mode 100644\\nindex b9bf46a..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/46.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/47.png b/Dataset/FaceData/raw/Van Dung/47.png\\ndeleted file mode 100644\\nindex 40c7d56..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/47.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/48.png b/Dataset/FaceData/raw/Van Dung/48.png\\ndeleted file mode 100644\\nindex 3b12754..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/48.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/49.png b/Dataset/FaceData/raw/Van Dung/49.png\\ndeleted file mode 100644\\nindex de7a734..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/49.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/5.png b/Dataset/FaceData/raw/Van Dung/5.png\\ndeleted file mode 100644\\nindex 441750d..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/5.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/50.png b/Dataset/FaceData/raw/Van Dung/50.png\\ndeleted file mode 100644\\nindex 29aa6db..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/50.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/51.png b/Dataset/FaceData/raw/Van Dung/51.png\\ndeleted file mode 100644\\nindex c242452..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/51.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/52.png b/Dataset/FaceData/raw/Van Dung/52.png\\ndeleted file mode 100644\\nindex 33b91c1..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/52.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/53.png b/Dataset/FaceData/raw/Van Dung/53.png\\ndeleted file mode 100644\\nindex 857c2ed..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/53.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/54.png b/Dataset/FaceData/raw/Van Dung/54.png\\ndeleted file mode 100644\\nindex 9d6bd7a..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/54.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/55.png b/Dataset/FaceData/raw/Van Dung/55.png\\ndeleted file mode 100644\\nindex c2e3edf..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/55.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/56.png b/Dataset/FaceData/raw/Van Dung/56.png\\ndeleted file mode 100644\\nindex 3377934..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/56.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/57.png b/Dataset/FaceData/raw/Van Dung/57.png\\ndeleted file mode 100644\\nindex e918362..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/57.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/58.png b/Dataset/FaceData/raw/Van Dung/58.png\\ndeleted file mode 100644\\nindex bf4207d..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/58.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/59.png b/Dataset/FaceData/raw/Van Dung/59.png\\ndeleted file mode 100644\\nindex 5dfed2c..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/59.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/6.png b/Dataset/FaceData/raw/Van Dung/6.png\\ndeleted file mode 100644\\nindex 8d43cdd..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/6.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/60.png b/Dataset/FaceData/raw/Van Dung/60.png\\ndeleted file mode 100644\\nindex aa63e20..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/60.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/61.png b/Dataset/FaceData/raw/Van Dung/61.png\\ndeleted file mode 100644\\nindex ecc2328..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/61.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/62.png b/Dataset/FaceData/raw/Van Dung/62.png\\ndeleted file mode 100644\\nindex fd3a0c9..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/62.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/63.png b/Dataset/FaceData/raw/Van Dung/63.png\\ndeleted file mode 100644\\nindex 482a0ef..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/63.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/64.png b/Dataset/FaceData/raw/Van Dung/64.png\\ndeleted file mode 100644\\nindex 3a05341..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/64.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/65.png b/Dataset/FaceData/raw/Van Dung/65.png\\ndeleted file mode 100644\\nindex 50bb2d8..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/65.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/66.png b/Dataset/FaceData/raw/Van Dung/66.png\\ndeleted file mode 100644\\nindex ad5b14b..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/66.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/67.png b/Dataset/FaceData/raw/Van Dung/67.png\\ndeleted file mode 100644\\nindex 5b40e28..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/67.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/68.png b/Dataset/FaceData/raw/Van Dung/68.png\\ndeleted file mode 100644\\nindex 98b3c29..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/68.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/69.png b/Dataset/FaceData/raw/Van Dung/69.png\\ndeleted file mode 100644\\nindex 89b487c..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/69.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/7.png b/Dataset/FaceData/raw/Van Dung/7.png\\ndeleted file mode 100644\\nindex 43abdc9..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/7.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/70.png b/Dataset/FaceData/raw/Van Dung/70.png\\ndeleted file mode 100644\\nindex a9c08a6..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/70.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/71.png b/Dataset/FaceData/raw/Van Dung/71.png\\ndeleted file mode 100644\\nindex a3e80b3..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/71.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/72.png b/Dataset/FaceData/raw/Van Dung/72.png\\ndeleted file mode 100644\\nindex 1d6af0b..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/72.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/73.png b/Dataset/FaceData/raw/Van Dung/73.png\\ndeleted file mode 100644\\nindex e0e48ad..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/73.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/74.png b/Dataset/FaceData/raw/Van Dung/74.png\\ndeleted file mode 100644\\nindex 2e3b0e3..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/74.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/75.png b/Dataset/FaceData/raw/Van Dung/75.png\\ndeleted file mode 100644\\nindex 9f9bdab..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/75.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/76.png b/Dataset/FaceData/raw/Van Dung/76.png\\ndeleted file mode 100644\\nindex 6fb8eef..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/76.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/77.png b/Dataset/FaceData/raw/Van Dung/77.png\\ndeleted file mode 100644\\nindex b1bb266..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/77.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/78.png b/Dataset/FaceData/raw/Van Dung/78.png\\ndeleted file mode 100644\\nindex 0c93be7..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/78.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/79.png b/Dataset/FaceData/raw/Van Dung/79.png\\ndeleted file mode 100644\\nindex 3f6c196..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/79.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/8.png b/Dataset/FaceData/raw/Van Dung/8.png\\ndeleted file mode 100644\\nindex 358f044..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/8.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/80.png b/Dataset/FaceData/raw/Van Dung/80.png\\ndeleted file mode 100644\\nindex a15fbed..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/80.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/81.png b/Dataset/FaceData/raw/Van Dung/81.png\\ndeleted file mode 100644\\nindex 68c2d89..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/81.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/82.png b/Dataset/FaceData/raw/Van Dung/82.png\\ndeleted file mode 100644\\nindex 5ce98d2..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/82.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/83.png b/Dataset/FaceData/raw/Van Dung/83.png\\ndeleted file mode 100644\\nindex 97eee8f..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/83.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/84.png b/Dataset/FaceData/raw/Van Dung/84.png\\ndeleted file mode 100644\\nindex 54d6b3a..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/84.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/85.png b/Dataset/FaceData/raw/Van Dung/85.png\\ndeleted file mode 100644\\nindex 89c8cbc..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/85.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/86.png b/Dataset/FaceData/raw/Van Dung/86.png\\ndeleted file mode 100644\\nindex 7719d4f..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/86.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/87.png b/Dataset/FaceData/raw/Van Dung/87.png\\ndeleted file mode 100644\\nindex cfcbba9..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/87.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/88.png b/Dataset/FaceData/raw/Van Dung/88.png\\ndeleted file mode 100644\\nindex ea92fa7..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/88.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Van Dung/9.png b/Dataset/FaceData/raw/Van Dung/9.png\\ndeleted file mode 100644\\nindex eb7946c..0000000\\nBinary files a/Dataset/FaceData/raw/Van Dung/9.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/0.png b/Dataset/FaceData/raw/Xuan Hinh/0.png\\ndeleted file mode 100644\\nindex 688659b..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/0.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/1.png b/Dataset/FaceData/raw/Xuan Hinh/1.png\\ndeleted file mode 100644\\nindex 7c4d3ba..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/1.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/10.png b/Dataset/FaceData/raw/Xuan Hinh/10.png\\ndeleted file mode 100644\\nindex ffc6cc4..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/10.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/11.png b/Dataset/FaceData/raw/Xuan Hinh/11.png\\ndeleted file mode 100644\\nindex 9eefb5d..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/11.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/12.png b/Dataset/FaceData/raw/Xuan Hinh/12.png\\ndeleted file mode 100644\\nindex d658bcd..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/12.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/13.png b/Dataset/FaceData/raw/Xuan Hinh/13.png\\ndeleted file mode 100644\\nindex 436bc30..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/13.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/14.png b/Dataset/FaceData/raw/Xuan Hinh/14.png\\ndeleted file mode 100644\\nindex 2300065..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/14.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/15.png b/Dataset/FaceData/raw/Xuan Hinh/15.png\\ndeleted file mode 100644\\nindex e891a1f..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/15.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/16.png b/Dataset/FaceData/raw/Xuan Hinh/16.png\\ndeleted file mode 100644\\nindex 19e9d74..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/16.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/17.png b/Dataset/FaceData/raw/Xuan Hinh/17.png\\ndeleted file mode 100644\\nindex 80ce171..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/17.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/18.png b/Dataset/FaceData/raw/Xuan Hinh/18.png\\ndeleted file mode 100644\\nindex d73ba47..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/18.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/19.png b/Dataset/FaceData/raw/Xuan Hinh/19.png\\ndeleted file mode 100644\\nindex 279c9d1..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/19.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/2.png b/Dataset/FaceData/raw/Xuan Hinh/2.png\\ndeleted file mode 100644\\nindex 517fba9..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/2.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/20.png b/Dataset/FaceData/raw/Xuan Hinh/20.png\\ndeleted file mode 100644\\nindex 266b493..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/20.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/21.png b/Dataset/FaceData/raw/Xuan Hinh/21.png\\ndeleted file mode 100644\\nindex f37666b..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/21.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/22.png b/Dataset/FaceData/raw/Xuan Hinh/22.png\\ndeleted file mode 100644\\nindex a35741d..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/22.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/23.png b/Dataset/FaceData/raw/Xuan Hinh/23.png\\ndeleted file mode 100644\\nindex 968cb20..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/23.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/24.png b/Dataset/FaceData/raw/Xuan Hinh/24.png\\ndeleted file mode 100644\\nindex 40b3ff9..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/24.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/25.png b/Dataset/FaceData/raw/Xuan Hinh/25.png\\ndeleted file mode 100644\\nindex bd445d8..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/25.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/26.png b/Dataset/FaceData/raw/Xuan Hinh/26.png\\ndeleted file mode 100644\\nindex 17a720f..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/26.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/27.png b/Dataset/FaceData/raw/Xuan Hinh/27.png\\ndeleted file mode 100644\\nindex 4933cf1..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/27.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/28.png b/Dataset/FaceData/raw/Xuan Hinh/28.png\\ndeleted file mode 100644\\nindex d9049b4..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/28.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/29.png b/Dataset/FaceData/raw/Xuan Hinh/29.png\\ndeleted file mode 100644\\nindex 58fd1f0..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/29.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/3.png b/Dataset/FaceData/raw/Xuan Hinh/3.png\\ndeleted file mode 100644\\nindex 991c986..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/3.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/30.png b/Dataset/FaceData/raw/Xuan Hinh/30.png\\ndeleted file mode 100644\\nindex 7fb03a8..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/30.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/31.png b/Dataset/FaceData/raw/Xuan Hinh/31.png\\ndeleted file mode 100644\\nindex 0c4727d..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/31.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/32.png b/Dataset/FaceData/raw/Xuan Hinh/32.png\\ndeleted file mode 100644\\nindex dfe6ed6..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/32.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/33.png b/Dataset/FaceData/raw/Xuan Hinh/33.png\\ndeleted file mode 100644\\nindex 297ac7e..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/33.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/34.png b/Dataset/FaceData/raw/Xuan Hinh/34.png\\ndeleted file mode 100644\\nindex 7f60484..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/34.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/35.png b/Dataset/FaceData/raw/Xuan Hinh/35.png\\ndeleted file mode 100644\\nindex 4cb7b00..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/35.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/36.png b/Dataset/FaceData/raw/Xuan Hinh/36.png\\ndeleted file mode 100644\\nindex 6a32e5d..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/36.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/37.png b/Dataset/FaceData/raw/Xuan Hinh/37.png\\ndeleted file mode 100644\\nindex a90334a..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/37.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/38.png b/Dataset/FaceData/raw/Xuan Hinh/38.png\\ndeleted file mode 100644\\nindex 4080070..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/38.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/39.png b/Dataset/FaceData/raw/Xuan Hinh/39.png\\ndeleted file mode 100644\\nindex 746a244..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/39.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/4.png b/Dataset/FaceData/raw/Xuan Hinh/4.png\\ndeleted file mode 100644\\nindex d33c18c..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/4.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/40.png b/Dataset/FaceData/raw/Xuan Hinh/40.png\\ndeleted file mode 100644\\nindex 58ec201..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/40.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/41.png b/Dataset/FaceData/raw/Xuan Hinh/41.png\\ndeleted file mode 100644\\nindex 32fcb66..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/41.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/42.png b/Dataset/FaceData/raw/Xuan Hinh/42.png\\ndeleted file mode 100644\\nindex 464f602..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/42.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/5.png b/Dataset/FaceData/raw/Xuan Hinh/5.png\\ndeleted file mode 100644\\nindex 35a7ca6..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/5.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/6.png b/Dataset/FaceData/raw/Xuan Hinh/6.png\\ndeleted file mode 100644\\nindex 1694a98..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/6.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/7.png b/Dataset/FaceData/raw/Xuan Hinh/7.png\\ndeleted file mode 100644\\nindex 978e648..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/7.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/8.png b/Dataset/FaceData/raw/Xuan Hinh/8.png\\ndeleted file mode 100644\\nindex 5091129..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/8.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/Xuan Hinh/9.png b/Dataset/FaceData/raw/Xuan Hinh/9.png\\ndeleted file mode 100644\\nindex 7c21026..0000000\\nBinary files a/Dataset/FaceData/raw/Xuan Hinh/9.png and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/truong giang/0630_truonggiang_1.jpg b/Dataset/FaceData/raw/truong giang/0630_truonggiang_1.jpg\\ndeleted file mode 100644\\nindex df05ae9..0000000\\nBinary files a/Dataset/FaceData/raw/truong giang/0630_truonggiang_1.jpg and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/truong giang/0632_truonggiang_2.jpg b/Dataset/FaceData/raw/truong giang/0632_truonggiang_2.jpg\\ndeleted file mode 100644\\nindex d847b59..0000000\\nBinary files a/Dataset/FaceData/raw/truong giang/0632_truonggiang_2.jpg and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/truong giang/1545311811-862-truong-giang-bat-ngo-dan-dau-de-cu-nam-dien-vien-dien-anh-duoc-yeu-thich-nhat-truonggiang-1545278076-width660height990.jpg b/Dataset/FaceData/raw/truong giang/1545311811-862-truong-giang-bat-ngo-dan-dau-de-cu-nam-dien-vien-dien-anh-duoc-yeu-thich-nhat-truonggiang-1545278076-width660height990.jpg\\ndeleted file mode 100644\\nindex bfe5872..0000000\\nBinary files a/Dataset/FaceData/raw/truong giang/1545311811-862-truong-giang-bat-ngo-dan-dau-de-cu-nam-dien-vien-dien-anh-duoc-yeu-thich-nhat-truonggiang-1545278076-width660height990.jpg and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/truong giang/A27U7778.jpg b/Dataset/FaceData/raw/truong giang/A27U7778.jpg\\ndeleted file mode 100644\\nindex e8d102c..0000000\\nBinary files a/Dataset/FaceData/raw/truong giang/A27U7778.jpg and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/truong giang/fb_img_1704768289216-1704768712-408-width720height960.jpg b/Dataset/FaceData/raw/truong giang/fb_img_1704768289216-1704768712-408-width720height960.jpg\\ndeleted file mode 100644\\nindex b55736d..0000000\\nBinary files a/Dataset/FaceData/raw/truong giang/fb_img_1704768289216-1704768712-408-width720height960.jpg and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/truong giang/fb_img_1704768450012-1704768746-24-width720height1079.jpg b/Dataset/FaceData/raw/truong giang/fb_img_1704768450012-1704768746-24-width720height1079.jpg\\ndeleted file mode 100644\\nindex 3253faa..0000000\\nBinary files a/Dataset/FaceData/raw/truong giang/fb_img_1704768450012-1704768746-24-width720height1079.jpg and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/truong giang/giang1.jpg b/Dataset/FaceData/raw/truong giang/giang1.jpg\\ndeleted file mode 100644\\nindex db2b7ad..0000000\\nBinary files a/Dataset/FaceData/raw/truong giang/giang1.jpg and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/truong giang/giang2.jpg b/Dataset/FaceData/raw/truong giang/giang2.jpg\\ndeleted file mode 100644\\nindex 770e8f8..0000000\\nBinary files a/Dataset/FaceData/raw/truong giang/giang2.jpg and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/truong giang/giang3.jpg b/Dataset/FaceData/raw/truong giang/giang3.jpg\\ndeleted file mode 100644\\nindex f4f0b5f..0000000\\nBinary files a/Dataset/FaceData/raw/truong giang/giang3.jpg and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/truong giang/giang4.jpg b/Dataset/FaceData/raw/truong giang/giang4.jpg\\ndeleted file mode 100644\\nindex 1b86637..0000000\\nBinary files a/Dataset/FaceData/raw/truong giang/giang4.jpg and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/truong giang/mc-truong-giang-1229339.jpg b/Dataset/FaceData/raw/truong giang/mc-truong-giang-1229339.jpg\\ndeleted file mode 100644\\nindex 5f90889..0000000\\nBinary files a/Dataset/FaceData/raw/truong giang/mc-truong-giang-1229339.jpg and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/truong giang/mc-truong-giang-918712.jpg b/Dataset/FaceData/raw/truong giang/mc-truong-giang-918712.jpg\\ndeleted file mode 100644\\nindex 04b7d09..0000000\\nBinary files a/Dataset/FaceData/raw/truong giang/mc-truong-giang-918712.jpg and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/truong giang/trg1 b/Dataset/FaceData/raw/truong giang/trg1\\ndeleted file mode 100644\\nindex ac83601..0000000\\nBinary files a/Dataset/FaceData/raw/truong giang/trg1 and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/truong giang/vtr-4472.jpg b/Dataset/FaceData/raw/truong giang/vtr-4472.jpg\\ndeleted file mode 100644\\nindex d6dba0c..0000000\\nBinary files a/Dataset/FaceData/raw/truong giang/vtr-4472.jpg and /dev/null differ\\ndiff --git a/Dataset/FaceData/raw/truong giang/vtr-4475.jpg b/Dataset/FaceData/raw/truong giang/vtr-4475.jpg\\ndeleted file mode 100644\\nindex 804a3f7..0000000\\nBinary files a/Dataset/FaceData/raw/truong giang/vtr-4475.jpg and /dev/null differ\\ndiff --git a/Models/facemodel.pkl b/Models/facemodel.pkl\\ndeleted file mode 100644\\nindex bf72afc..0000000\\nBinary files a/Models/facemodel.pkl and /dev/null differ\\ndiff --git a/requirements.txt b/requirements.txt\\ndeleted file mode 100644\\nindex aa078a0..0000000\\n--- a/requirements.txt\\n+++ /dev/null\\n@@ -1,10 +0,0 @@\\n-tensorflow\\n-keras\\n-scikit-learn\\n-opencv-python\\n-h5py\\n-matplotlib\\n-Pillow\\n-requests\\n-psutil\\n-imageio\\n\\\\ No newline at end of file\\ndiff --git a/src/Danhgia.py b/src/Danhgia.py\\nnew file mode 100644\\nindex 0000000..a775d91\\n--- /dev/null\\n+++ b/src/Danhgia.py\\n@@ -0,0 +1,95 @@\\n+import cv2\\n+import numpy as np\\n+import os\\n+import tensorflow as tf\\n+import facenet\\n+import align.detect_face\\n+import pickle\\n+from tkinter import *\\n+from tkinter import filedialog\\n+from PIL import Image, ImageTk\\n+import tkinter as tk\\n+from sklearn.svm import SVC\\n+from sklearn.metrics import accuracy_score\\n+import matplotlib.pyplot as plt\\n+\\n+class FaceRecognitionApp:\\n+    def __init__(self, root):\\n+        # ... (ph\\xe1\\xba\\xa7n kh\\xe1\\xbb\\x9fi t\\xe1\\xba\\xa1o gi\\xe1\\xbb\\xaf nguy\\xc3\\xaan)\\n+\\n+        # Th\\xc3\\xaam m\\xe1\\xbb\\x99t n\\xc3\\xbat \\xc4\\x91\\xe1\\xbb\\x83 b\\xe1\\xba\\xaft \\xc4\\x91\\xe1\\xba\\xa7u qu\\xc3\\xa1 tr\\xc3\\xacnh \\xc4\\x91\\xc3\\xa1nh gi\\xc3\\xa1 m\\xc3\\xb4 h\\xc3\\xacnh\\n+        self.results_label = Text(root, width=40, height=10)\\n+        self.results_label.pack(pady=5, anchor=NE)\\n+\\n+        self.evaluate_model_button = Button(root, text="\\xc4\\x90\\xc3\\xa1nh gi\\xc3\\xa1 m\\xc3\\xb4 h\\xc3\\xacnh", command=self.evaluate_model)\\n+        self.evaluate_model_button.pack(pady=5, anchor=NE)\\n+\\n+    def evaluate_model(self):\\n+        # Load paths to classifier and FaceNet model\\n+        CLASSIFIER_PATH = r\\\'../Models/facemodel.pkl\\\'  # \\xc4\\x90\\xc6\\xb0\\xe1\\xbb\\x9dng d\\xe1\\xba\\xabn \\xc4\\x91\\xe1\\xba\\xbfn file classifier\\n+        FACENET_MODEL_PATH = \\\'../Models/20180402-114759.pb\\\'  # \\xc4\\x90\\xc6\\xb0\\xe1\\xbb\\x9dng d\\xe1\\xba\\xabn \\xc4\\x91\\xe1\\xba\\xbfn file FaceNet model\\n+\\n+        # Load classifier model\\n+        with open(CLASSIFIER_PATH, \\\'rb\\\') as file:\\n+            model, class_names = pickle.load(file)\\n+\\n+        # Load FaceNet model\\n+        with tf.Graph().as_default():\\n+            sess = tf.compat.v1.Session()\\n+            facenet.load_model(FACENET_MODEL_PATH)\\n+            images_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("input:0")\\n+            embeddings = tf.compat.v1.get_default_graph().get_tensor_by_name("embeddings:0")\\n+            phase_train_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("phase_train:0")\\n+            embedding_size = embeddings.get_shape()[1]\\n+\\n+        # Load paths and labels for the test dataset\\n+        dataset = facenet.get_dataset("../Dataset/FaceData/processed")\\n+        paths, labels = facenet.get_image_paths_and_labels(dataset)\\n+\\n+        # Calculate embeddings for the test dataset\\n+        emb_array = np.zeros((len(paths), embedding_size))\\n+        for i in range(len(paths)):\\n+            img = cv2.imread(paths[i])\\n+            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\\n+            scaled = cv2.resize(img, (160, 160), interpolation=cv2.INTER_CUBIC)\\n+            scaled = facenet.prewhiten(scaled)\\n+            scaled_reshape = scaled.reshape(-1, 160, 160, 3)\\n+            feed_dict = {images_placeholder: scaled_reshape, phase_train_placeholder: False}\\n+            emb_array[i, :] = sess.run(embeddings, feed_dict=feed_dict)\\n+\\n+        # Predict labels for the test dataset\\n+        predictions = model.predict(emb_array)\\n+        accuracy = accuracy_score(labels, predictions)\\n+\\n+        # Display accuracy in the results label\\n+        if hasattr(self, \\\'results_label\\\') and isinstance(self.results_label, Text):\\n+            self.results_label.delete(\\\'1.0\\\', END)\\n+            self.results_label.insert(END, f"\\xc4\\x90\\xe1\\xbb\\x99 ch\\xc3\\xadnh x\\xc3\\xa1c tr\\xc3\\xaan t\\xe1\\xba\\xadp ki\\xe1\\xbb\\x83m tra: {accuracy:.2%}")\\n+\\n+        # V\\xe1\\xba\\xbd bi\\xe1\\xbb\\x83u \\xc4\\x91\\xe1\\xbb\\x93\\n+        self.plot_accuracy_curve(model, emb_array, labels, class_names)\\n+\\n+    def plot_accuracy_curve(self, model, emb_array, labels, class_names):\\n+        # V\\xe1\\xba\\xbd bi\\xe1\\xbb\\x83u \\xc4\\x91\\xe1\\xbb\\x93 \\xc4\\x91\\xe1\\xbb\\x99 ch\\xc3\\xadnh x\\xc3\\xa1c\\n+        predictions = model.predict_proba(emb_array)\\n+        best_class_indices = np.argmax(predictions, axis=1)\\n+        best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\\n+\\n+        plt.figure(figsize=(10, 6))\\n+        plt.plot(range(len(best_class_indices)), best_class_probabilities, marker=\\\'o\\\', linestyle=\\\'-\\\')\\n+        plt.xticks(range(len(best_class_indices)), [class_names[i] for i in best_class_indices], rotation=\\\'vertical\\\')\\n+        plt.xlabel(\\\'L\\xe1\\xbb\\x9bp\\\')\\n+        plt.ylabel(\\\'\\xc4\\x90\\xe1\\xbb\\x99 ch\\xc3\\xadnh x\\xc3\\xa1c\\\')\\n+        plt.title(\\\'\\xc4\\x90\\xe1\\xbb\\x99 ch\\xc3\\xadnh x\\xc3\\xa1c c\\xe1\\xbb\\xa7a m\\xc3\\xb4 h\\xc3\\xacnh tr\\xc3\\xaan t\\xe1\\xba\\xadp ki\\xe1\\xbb\\x83m tra\\\')\\n+        plt.grid(True)\\n+        plt.tight_layout()\\n+        plt.show()\\n+\\n+\\n+def main():\\n+    root = Tk()\\n+    app = FaceRecognitionApp(root)\\n+    root.mainloop()\\n+\\n+if __name__ == "__main__":\\n+    main()\\ndiff --git a/src/__pycache__/face_cam.cpython-39.pyc b/src/__pycache__/face_cam.cpython-39.pyc\\ndeleted file mode 100644\\nindex 73fe178..0000000\\nBinary files a/src/__pycache__/face_cam.cpython-39.pyc and /dev/null differ\\ndiff --git a/src/__pycache__/facenet.cpython-37.pyc b/src/__pycache__/facenet.cpython-37.pyc\\ndeleted file mode 100644\\nindex 3b10b34..0000000\\nBinary files a/src/__pycache__/facenet.cpython-37.pyc and /dev/null differ\\ndiff --git a/src/__pycache__/facenet.cpython-39.pyc b/src/__pycache__/facenet.cpython-39.pyc\\nindex f88119d..b84cfd7 100644\\nBinary files a/src/__pycache__/facenet.cpython-39.pyc and b/src/__pycache__/facenet.cpython-39.pyc differ\\ndiff --git a/src/align_dataset_mtcnn.py b/src/align_dataset_mtcnn.py\\nindex 27d460b..f4b27aa 100644\\n--- a/src/align_dataset_mtcnn.py\\n+++ b/src/align_dataset_mtcnn.py\\n@@ -1,25 +1,3 @@\\n-"""Performs face alignment and stores face thumbnails in the output directory."""\\n-# MIT License\\n-# \\n-# Copyright (c) 2016 David Sandberg\\n-# \\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\n-# of this software and associated documentation files (the "Software"), to deal\\n-# in the Software without restriction, including without limitation the rights\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\n-# copies of the Software, and to permit persons to whom the Software is\\n-# furnished to do so, subject to the following conditions:\\n-# \\n-# The above copyright notice and this permission notice shall be included in all\\n-# copies or substantial portions of the Software.\\n-# \\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\n-# SOFTWARE.\\n \\n from __future__ import absolute_import\\n from __future__ import division\\ndiff --git a/src/classifier.py b/src/classifier.py\\nindex be144fe..780726f 100644\\n--- a/src/classifier.py\\n+++ b/src/classifier.py\\n@@ -1,31 +1,6 @@\\n-"""An example of how to use your own dataset to train a classifier that recognizes people.\\n-"""\\n-# MIT License\\n-# \\n-# Copyright (c) 2016 David Sandberg\\n-# \\n-# Permission is hereby granted, free of charge, to any person obtaining a copy\\n-# of this software and associated documentation files (the "Software"), to deal\\n-# in the Software without restriction, including without limitation the rights\\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\\n-# copies of the Software, and to permit persons to whom the Software is\\n-# furnished to do so, subject to the following conditions:\\n-# \\n-# The above copyright notice and this permission notice shall be included in all\\n-# copies or substantial portions of the Software.\\n-# \\n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\\n-# SOFTWARE.\\n-\\n from __future__ import absolute_import\\n from __future__ import division\\n from __future__ import print_function\\n-\\n import tensorflow as tf\\n import numpy as np\\n import argparse\\n@@ -36,75 +11,74 @@ import math\\n import pickle\\n from sklearn.svm import SVC\\n \\n+\\n def main(args):\\n-  \\n     with tf.Graph().as_default():\\n-      \\n+\\n         with tf.compat.v1.Session() as sess:\\n-            \\n+\\n             np.random.seed(seed=args.seed)\\n-            \\n+\\n             if args.use_split_dataset:\\n                 dataset_tmp = facenet.get_dataset(args.data_dir)\\n-                train_set, test_set = split_dataset(dataset_tmp, args.min_nrof_images_per_class, args.nrof_train_images_per_class)\\n-                if (args.mode==\\\'TRAIN\\\'):\\n+                train_set, test_set = split_dataset(dataset_tmp, args.min_nrof_images_per_class,\\n+                                                    args.nrof_train_images_per_class)\\n+                if (args.mode == \\\'TRAIN\\\'):\\n                     dataset = train_set\\n-                elif (args.mode==\\\'CLASSIFY\\\'):\\n+                elif (args.mode == \\\'CLASSIFY\\\'):\\n                     dataset = test_set\\n             else:\\n                 dataset = facenet.get_dataset(args.data_dir)\\n \\n             # Check that there are at least one training image per class\\n             for cls in dataset:\\n-                assert(len(cls.image_paths)>0, \\\'There must be at least one image for each class in the dataset\\\')\\n+                assert (len(cls.image_paths) > 0, \\\'There must be at least one image for each class in the dataset\\\')\\n \\n-                 \\n             paths, labels = facenet.get_image_paths_and_labels(dataset)\\n-            \\n+\\n             print(\\\'Number of classes: %d\\\' % len(dataset))\\n             print(\\\'Number of images: %d\\\' % len(paths))\\n-            \\n+\\n             # Load the Models\\n             print(\\\'Loading feature extraction Models\\\')\\n             facenet.load_model(args.Models)\\n \\n-            \\n             # Get input and output tensors\\n             images_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("input:0")\\n             embeddings = tf.compat.v1.get_default_graph().get_tensor_by_name("embeddings:0")\\n             phase_train_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("phase_train:0")\\n             embedding_size = embeddings.get_shape()[1]\\n-            \\n+\\n             # Run forward pass to calculate embeddings\\n             print(\\\'Calculating features for images\\\')\\n             nrof_images = len(paths)\\n-            nrof_batches_per_epoch = int(math.ceil(1.0*nrof_images / args.batch_size))\\n+            nrof_batches_per_epoch = int(math.ceil(1.0 * nrof_images / args.batch_size))\\n             emb_array = np.zeros((nrof_images, embedding_size))\\n             for i in range(nrof_batches_per_epoch):\\n-                start_index = i*args.batch_size\\n-                end_index = min((i+1)*args.batch_size, nrof_images)\\n+                start_index = i * args.batch_size\\n+                end_index = min((i + 1) * args.batch_size, nrof_images)\\n                 paths_batch = paths[start_index:end_index]\\n                 images = facenet.load_data(paths_batch, False, False, args.image_size)\\n-                feed_dict = { images_placeholder:images, phase_train_placeholder:False }\\n-                emb_array[start_index:end_index,:] = sess.run(embeddings, feed_dict=feed_dict)\\n-            \\n+                feed_dict = {images_placeholder: images, phase_train_placeholder: False}\\n+                emb_array[start_index:end_index, :] = sess.run(embeddings, feed_dict=feed_dict)\\n+\\n             classifier_filename_exp = os.path.expanduser(args.classifier_filename)\\n \\n-            if (args.mode==\\\'TRAIN\\\'):\\n+            if (args.mode == \\\'TRAIN\\\'):\\n                 # Train classifier\\n                 print(\\\'Training classifier\\\')\\n                 model = SVC(kernel=\\\'linear\\\', probability=True)\\n                 model.fit(emb_array, labels)\\n-            \\n+\\n                 # Create a list of class names\\n-                class_names = [ cls.name.replace(\\\'_\\\', \\\' \\\') for cls in dataset]\\n+                class_names = [cls.name.replace(\\\'_\\\', \\\' \\\') for cls in dataset]\\n \\n                 # Saving classifier Models\\n                 with open(classifier_filename_exp, \\\'wb\\\') as outfile:\\n                     pickle.dump((model, class_names), outfile)\\n                 print(\\\'Saved classifier Models to file "%s"\\\' % classifier_filename_exp)\\n-                \\n-            elif (args.mode==\\\'CLASSIFY\\\'):\\n+\\n+            elif (args.mode == \\\'CLASSIFY\\\'):\\n                 # Classify images\\n                 print(\\\'Testing classifier\\\')\\n                 with open(classifier_filename_exp, \\\'rb\\\') as infile:\\n@@ -115,57 +89,60 @@ def main(args):\\n                 predictions = model.predict_proba(emb_array)\\n                 best_class_indices = np.argmax(predictions, axis=1)\\n                 best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\\n-                \\n+\\n                 for i in range(len(best_class_indices)):\\n                     print(\\\'%4d  %s: %.3f\\\' % (i, class_names[best_class_indices[i]], best_class_probabilities[i]))\\n-                    \\n+\\n                 accuracy = np.mean(np.equal(best_class_indices, labels))\\n                 print(\\\'Accuracy: %.3f\\\' % accuracy)\\n-                \\n-            \\n+\\n+\\n def split_dataset(dataset, min_nrof_images_per_class, nrof_train_images_per_class):\\n     train_set = []\\n     test_set = []\\n     for cls in dataset:\\n         paths = cls.image_paths\\n         # Remove classes with less than min_nrof_images_per_class\\n-        if len(paths)>=min_nrof_images_per_class:\\n+        if len(paths) >= min_nrof_images_per_class:\\n             np.random.shuffle(paths)\\n             train_set.append(facenet.ImageClass(cls.name, paths[:nrof_train_images_per_class]))\\n             test_set.append(facenet.ImageClass(cls.name, paths[nrof_train_images_per_class:]))\\n     return train_set, test_set\\n \\n-            \\n+\\n def parse_arguments(argv):\\n     parser = argparse.ArgumentParser()\\n-    \\n+\\n     parser.add_argument(\\\'mode\\\', type=str, choices=[\\\'TRAIN\\\', \\\'CLASSIFY\\\'],\\n-        help=\\\'Indicates if a new classifier should be trained or a classification \\\' + \\n-        \\\'Models should be used for classification\\\', default=\\\'CLASSIFY\\\')\\n+                        help=\\\'Indicates if a new classifier should be trained or a classification \\\' +\\n+                             \\\'Models should be used for classification\\\', default=\\\'CLASSIFY\\\')\\n     parser.add_argument(\\\'data_dir\\\', type=str,\\n-        help=\\\'Path to the data directory containing aligned LFW face patches.\\\')\\n+                        help=\\\'Path to the data directory containing aligned LFW face patches.\\\')\\n     parser.add_argument(\\\'Models\\\', type=str,\\n-        help=\\\'Could be either a directory containing the meta_file and ckpt_file or a Models protobuf (.pb) file\\\')\\n-    parser.add_argument(\\\'classifier_filename\\\', \\n-        help=\\\'Classifier Models file name as a pickle (.pkl) file. \\\' +\\n-        \\\'For training this is the output and for classification this is an input.\\\')\\n-    parser.add_argument(\\\'--use_split_dataset\\\', \\n-        help=\\\'Indicates that the dataset specified by data_dir should be split into a training and test set. \\\' +  \\n-        \\\'Otherwise a separate test set can be specified using the test_data_dir option.\\\', action=\\\'store_true\\\')\\n+                        help=\\\'Could be either a directory containing the meta_file and ckpt_file or a Models protobuf (.pb) file\\\')\\n+    parser.add_argument(\\\'classifier_filename\\\',\\n+                        help=\\\'Classifier Models file name as a pickle (.pkl) file. \\\' +\\n+                             \\\'For training this is the output and for classification this is an input.\\\')\\n+    parser.add_argument(\\\'--use_split_dataset\\\',\\n+                        help=\\\'Indicates that the dataset specified by data_dir should be split into a training and test set. \\\' +\\n+                             \\\'Otherwise a separate test set can be specified using the test_data_dir option.\\\',\\n+                        action=\\\'store_true\\\')\\n     parser.add_argument(\\\'--test_data_dir\\\', type=str,\\n-        help=\\\'Path to the test data directory containing aligned images used for testing.\\\')\\n+                        help=\\\'Path to the test data directory containing aligned images used for testing.\\\')\\n     parser.add_argument(\\\'--batch_size\\\', type=int,\\n-        help=\\\'Number of images to process in a batch.\\\', default=90)\\n+                        help=\\\'Number of images to process in a batch.\\\', default=90)\\n     parser.add_argument(\\\'--image_size\\\', type=int,\\n-        help=\\\'Image size (height, width) in pixels.\\\', default=160)\\n+                        help=\\\'Image size (height, width) in pixels.\\\', default=160)\\n     parser.add_argument(\\\'--seed\\\', type=int,\\n-        help=\\\'Random seed.\\\', default=666)\\n+                        help=\\\'Random seed.\\\', default=666)\\n     parser.add_argument(\\\'--min_nrof_images_per_class\\\', type=int,\\n-        help=\\\'Only include classes with at least this number of images in the dataset\\\', default=20)\\n+                        help=\\\'Only include classes with at least this number of images in the dataset\\\', default=20)\\n     parser.add_argument(\\\'--nrof_train_images_per_class\\\', type=int,\\n-        help=\\\'Use this number of images from each class for training and the rest for testing\\\', default=10)\\n-    \\n+                        help=\\\'Use this number of images from each class for training and the rest for testing\\\',\\n+                        default=10)\\n+\\n     return parser.parse_args(argv)\\n \\n+\\n if __name__ == \\\'__main__\\\':\\n     main(parse_arguments(sys.argv[1:]))\\ndiff --git a/src/face_cam.py b/src/face_cam.py\\ndeleted file mode 100644\\nindex 91daf5d..0000000\\n--- a/src/face_cam.py\\n+++ /dev/null\\n@@ -1,135 +0,0 @@\\n-from __future__ import absolute_import\\n-from __future__ import division\\n-from __future__ import print_function\\n-\\n-import tensorflow as tf\\n-from imutils.video import VideoStream\\n-\\n-\\n-import argparse\\n-import facenet\\n-import imutils\\n-import os\\n-import sys\\n-import math\\n-import pickle\\n-import align.detect_face\\n-import numpy as np\\n-import cv2\\n-import collections\\n-from sklearn.svm import SVC\\n-\\n-\\n-def main():\\n-    parser = argparse.ArgumentParser()\\n-    parser.add_argument(\\\'--path\\\', help=\\\'Path of the video you want to test on.\\\', default=0)\\n-    args = parser.parse_args()\\n-\\n-    MINSIZE = 20\\n-    THRESHOLD = [0.6, 0.7, 0.7]\\n-    FACTOR = 0.709\\n-    IMAGE_SIZE = 182\\n-    INPUT_IMAGE_SIZE = 160\\n-    CLASSIFIER_PATH = \\\'Models/facemodel.pkl\\\'\\n-    VIDEO_PATH = args.path\\n-    FACENET_MODEL_PATH = \\\'Models/20180402-114759.pb\\\'\\n-\\n-    # Load The Custom Classifier\\n-    with open(CLASSIFIER_PATH, \\\'rb\\\') as file:\\n-        model, class_names = pickle.load(file)\\n-    print("Custom Classifier, Successfully loaded")\\n-\\n-    with tf.Graph().as_default():\\n-\\n-        # Cai dat GPU neu co\\n-        gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.6)\\n-        sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\\n-\\n-        with sess.as_default():\\n-\\n-            # Load the Models\\n-            print(\\\'Loading feature extraction Models\\\')\\n-            facenet.load_model(FACENET_MODEL_PATH)\\n-\\n-            # Get input and output tensors\\n-            images_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("input:0")\\n-            embeddings = tf.compat.v1.get_default_graph().get_tensor_by_name("embeddings:0")\\n-            phase_train_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("phase_train:0")\\n-            embedding_size = embeddings.get_shape()[1]\\n-\\n-            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, "src/align")\\n-\\n-            people_detected = set()\\n-            person_detected = collections.Counter()\\n-\\n-            cap  = VideoStream(src=0).start()\\n-\\n-            while (True):\\n-                frame = cap.read()\\n-                frame = imutils.resize(frame, width=600)\\n-                frame = cv2.flip(frame, 1)\\n-\\n-                bounding_boxes, _ = align.detect_face.detect_face(frame, MINSIZE, pnet, rnet, onet, THRESHOLD, FACTOR)\\n-\\n-                faces_found = bounding_boxes.shape[0]\\n-                try:\\n-                    if faces_found > 1:\\n-                        cv2.putText(frame, "Only one face", (0, 100), cv2.FONT_HERSHEY_COMPLEX_SMALL,\\n-                                    1, (255, 255, 255), thickness=1, lineType=2)\\n-                    elif faces_found > 0:\\n-                        det = bounding_boxes[:, 0:4]\\n-                        bb = np.zeros((faces_found, 4), dtype=np.int32)\\n-                        for i in range(faces_found):\\n-                            bb[i][0] = det[i][0]\\n-                            bb[i][1] = det[i][1]\\n-                            bb[i][2] = det[i][2]\\n-                            bb[i][3] = det[i][3]\\n-                            print(bb[i][3]-bb[i][1])\\n-                            print(frame.shape[0])\\n-                            print((bb[i][3]-bb[i][1])/frame.shape[0])\\n-                            if (bb[i][3]-bb[i][1])/frame.shape[0]>0.25:\\n-                                cropped = frame[bb[i][1]:bb[i][3], bb[i][0]:bb[i][2], :]\\n-                                scaled = cv2.resize(cropped, (INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE),\\n-                                                    interpolation=cv2.INTER_CUBIC)\\n-                                scaled = facenet.prewhiten(scaled)\\n-                                scaled_reshape = scaled.reshape(-1, INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE, 3)\\n-                                feed_dict = {images_placeholder: scaled_reshape, phase_train_placeholder: False}\\n-                                emb_array = sess.run(embeddings, feed_dict=feed_dict)\\n-\\n-                                predictions = model.predict_proba(emb_array)\\n-                                best_class_indices = np.argmax(predictions, axis=1)\\n-                                best_class_probabilities = predictions[\\n-                                    np.arange(len(best_class_indices)), best_class_indices]\\n-                                best_name = class_names[best_class_indices[0]]\\n-                                print("Name: {}, Probability: {}".format(best_name, best_class_probabilities))\\n-\\n-\\n-\\n-                                if best_class_probabilities > 0.8:\\n-                                    cv2.rectangle(frame, (bb[i][0], bb[i][1]), (bb[i][2], bb[i][3]), (0, 255, 0), 2)\\n-                                    text_x = bb[i][0]\\n-                                    text_y = bb[i][3] + 20\\n-\\n-                                    name = class_names[best_class_indices[0]]\\n-                                    cv2.putText(frame, name, (text_x, text_y), cv2.FONT_HERSHEY_COMPLEX_SMALL,\\n-                                                1, (255, 255, 255), thickness=1, lineType=2)\\n-                                    cv2.putText(frame, str(round(best_class_probabilities[0], 3)), (text_x, text_y + 17),\\n-                                                cv2.FONT_HERSHEY_COMPLEX_SMALL,\\n-                                                1, (255, 255, 255), thickness=1, lineType=2)\\n-                                    person_detected[best_name] += 1\\n-                                else:\\n-                                    name = "Unknown"\\n-\\n-                except:\\n-                    pass\\n-\\n-                cv2.imshow(\\\'Face Recognition\\\', frame)\\n-                if cv2.waitKey(1) & 0xFF == ord(\\\'q\\\'):\\n-                    break\\n-\\n-            cap.release()\\n-            cv2.destroyAllWindows()\\n-\\n-main()\\n-\\n-\\ndiff --git a/src/main.py b/src/main.py\\nindex 0f039ca..da5871c 100644\\n--- a/src/main.py\\n+++ b/src/main.py\\n@@ -1,90 +1,19 @@\\n import cv2\\n import numpy as np\\n-import os\\n import tensorflow as tf\\n import facenet\\n import align.detect_face\\n import pickle\\n-from tkinter import *\\n-from tkinter import filedialog\\n-from PIL import Image, ImageTk\\n-import tkinter as tk\\n-from deepface import DeepFace\\n-\\n-## code cat anh khuon mat tu anh goc :\\n-#python src/align_dataset_mtcnn.py  Dataset/FaceData/raw Dataset/FaceData/processed --image_size 160 --margin 32  --random_order --gpu_memory_fraction 0.25\\n-## code tao model :\\n-#python src/classifier.py TRAIN Dataset/FaceData/processed Models/20180402-114759.pb Models/facemodel.pkl --batch_size 1000\\n-class FaceRecognitionApp:\\n-    def __init__(self, root):\\n-        self.root = root\\n-        self.root.title("Nh\\xe1\\xba\\xadn di\\xe1\\xbb\\x87n khu\\xc3\\xb4n m\\xe1\\xba\\xb7t")\\n-\\n-        # Load background image\\n-        background_image = Image.open(r"D:\\\\ma\\\\back.jpg")  # \\xc4\\x90\\xc6\\xb0\\xe1\\xbb\\x9dng d\\xe1\\xba\\xabn \\xc4\\x91\\xe1\\xba\\xbfn h\\xc3\\xacnh n\\xe1\\xbb\\x81n\\n-        bg_width, bg_height = background_image.size\\n-\\n-        # Set screen width and height\\n-        screen_width = 700\\n-        screen_height = 400\\n-\\n-        # Calculate scale factor for the background image\\n-        width_scale = screen_width / bg_width\\n-        height_scale = screen_height / bg_height\\n-        scale_factor = max(width_scale, height_scale)\\n-\\n-        # Resize background image to fit the screen\\n-        new_width = int(bg_width * scale_factor)\\n-        new_height = int(bg_height * scale_factor)\\n-        background_image = background_image.resize((new_width, new_height), Image.LANCZOS)\\n-\\n-        # Convert background image to PhotoImage\\n-        background_photo = ImageTk.PhotoImage(background_image)\\n-\\n-        # Create a label for the background image\\n-        background_label = Label(root, image=background_photo)\\n-        background_label.image = background_photo\\n-        background_label.place(x=0, y=0, relwidth=1, relheight=1)  # Fill the entire window\\n-\\n-        # Fix the size of the window\\n-        self.root.geometry(f"{screen_width}x{screen_height}+0+0")\\n-\\n-        # Load the face recognition model\\n-        self.load_model()\\n-\\n-        # Initialize image label\\n-        self.image_label = Label(root)\\n-        self.image_label.place(x=10, y=10)\\n-\\n-        # Initialize buttons\\n-        self.choose_image_button = Button(root, text="T\\xe1\\xba\\xa3i \\xe1\\xba\\xa3nh l\\xc3\\xaan", command=self.choose_image)\\n-        self.choose_image_button.pack(pady=5, anchor=NE)\\n-\\n-        self.detect_image_button = Button(root, text="Ki\\xe1\\xbb\\x83m tra h\\xc3\\xacnh \\xe1\\xba\\xa3nh", command=self.detect_faces_image)\\n-        self.detect_image_button.pack(pady=5, anchor=NE)\\n-\\n-        # Initialize buttons for camera and video\\n-        self.open_camera_button = Button(root, text="M\\xe1\\xbb\\x9f camera", command=self.open_camera)\\n-        self.open_camera_button.pack(pady=5, anchor=NE)\\n-        self.camera_opened = False\\n-\\n-        self.load_video_button = Button(root, text="T\\xe1\\xba\\xa3i video", command=self.load_video)\\n-        self.load_video_button.pack(pady=5, anchor=NE)\\n-        self.video_opened = False\\n-\\n-        # Initialize results label as a Text widget\\n-        self.results_label = Text(root, width=40, height=10)\\n-        self.results_label.pack(pady=5, anchor=NE)\\n-\\n-    def load_model(self):\\n+\\n+class FaceRecognitionCamera:\\n+    def __init__(self):\\n         # Load paths to classifier and FaceNet model\\n-        self.CLASSIFIER_PATH = \\\'../Models/facemodel.pkl\\\'  # \\xc4\\x90\\xc6\\xb0\\xe1\\xbb\\x9dng d\\xe1\\xba\\xabn \\xc4\\x91\\xe1\\xba\\xbfn file classifier\\n-        self.FACENET_MODEL_PATH = \\\'../Models/20180402-114759.pb\\\'  # \\xc4\\x90\\xc6\\xb0\\xe1\\xbb\\x9dng d\\xe1\\xba\\xabn \\xc4\\x91\\xe1\\xba\\xbfn file FaceNet model\\n+        self.CLASSIFIER_PATH = r\\\'D:\\\\AI_PROJECT\\\\Face_Pro\\\\Models\\\\facemodel.pkl\\\'\\n+        self.FACENET_MODEL_PATH = r\\\'D:\\\\AI_PROJECT\\\\Face_Pro\\\\Models\\\\20180402-114759.pb\\\'\\n \\n         # Load classifier model\\n         with open(self.CLASSIFIER_PATH, \\\'rb\\\') as file:\\n             self.model, self.class_names = pickle.load(file)\\n-        print("Loaded face recognition model")\\n \\n         # Load FaceNet model\\n         with tf.Graph().as_default():\\n@@ -95,28 +24,26 @@ class FaceRecognitionApp:\\n             self.phase_train_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("phase_train:0")\\n             self.mtcnn_pnet, self.mtcnn_rnet, self.mtcnn_onet = align.detect_face.create_mtcnn(self.sess, None)\\n \\n-    def choose_image(self):\\n-        self.image_path = filedialog.askopenfilename()\\n-        if self.image_path:\\n-            image_pil = Image.open(self.image_path)\\n-            resized_image = image_pil.resize((300, 300), Image.LANCZOS)\\n-            image = ImageTk.PhotoImage(resized_image)\\n-            self.image_label.configure(image=image)\\n-            self.image_label.image = image\\n-            self.results_label.delete(\\\'1.0\\\', END)  # Clear the results label\\n-\\n-    def detect_faces_image(self):\\n-        if hasattr(self, \\\'image_path\\\'):\\n-            image = cv2.imread(self.image_path)\\n-            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\\n-            self.detect_faces(image)\\n+    def detect_faces_camera(self):\\n+        cap = cv2.VideoCapture(0)\\n \\n-    def detect_faces(self, image):\\n-        # Clear the detected names list before detecting new faces\\n-        self.detected_names = []\\n-        self.face_info_list = []\\n-        self.counter = 1  # Initialize counter for face numbering\\n+        while cap.isOpened():\\n+            ret, frame = cap.read()\\n+            if ret:\\n+                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\\n+                self.detect_faces(frame)\\n+                # Hi\\xe1\\xbb\\x83n th\\xe1\\xbb\\x8b video v\\xe1\\xbb\\x9bi k\\xe1\\xba\\xbft qu\\xe1\\xba\\xa3 nh\\xe1\\xba\\xadn di\\xe1\\xbb\\x87n khu\\xc3\\xb4n m\\xe1\\xba\\xb7t\\n+                cv2.imshow(\\\'Face Recognition\\\', cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\\n \\n+                if cv2.waitKey(1) & 0xFF == ord(\\\'q\\\'):\\n+                    break\\n+            else:\\n+                break\\n+\\n+        cap.release()\\n+        cv2.destroyAllWindows()\\n+\\n+    def detect_faces(self, image):\\n         bounding_boxes, _ = align.detect_face.detect_face(image, 20, self.mtcnn_pnet, self.mtcnn_rnet, self.mtcnn_onet,\\n                                                           [0.6, 0.7, 0.7], 0.709)\\n         faces_found = bounding_boxes.shape[0]\\n@@ -141,95 +68,23 @@ class FaceRecognitionApp:\\n                 best_class_indices = np.argmax(predictions, axis=1)\\n                 best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\\n \\n-                # Check if the best class probability is above a certain threshold\\n-                if best_class_probabilities >= 0.2:\\n+                if best_class_probabilities >= 0.8:\\n                     best_name = self.class_names[best_class_indices[0]]\\n-                else:\\n-                    best_name = "Ch\\xc6\\xb0a x\\xc3\\xa1c \\xc4\\x91\\xe1\\xbb\\x8bnh"\\n-\\n-                cv2.rectangle(image, (bb[0], bb[1]), (bb[2], bb[3]), (0, 255, 0), 2)\\n-\\n-                # Draw number on the image\\n-                if self.counter >= 1:\\n-                    cv2.putText(image, str(self.counter), (bb[0], bb[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255),\\n-                                2, cv2.LINE_AA)\\n-\\n-                # Add the detected face names to the list\\n-                if self.counter >= 1:\\n-                    self.detected_names.append(f"  {self.counter}: {best_name}")\\n-                else:\\n-                    self.detected_names.append(best_name)\\n-\\n-                self.counter += 1  # Increment the counter\\n-\\n-            image = Image.fromarray(image)\\n-            image = ImageTk.PhotoImage(image.resize((300, 300), Image.LANCZOS))\\n-            self.image_label.configure(image=image)\\n-            self.image_label.image = image\\n-            self.results_label.delete(\\\'1.0\\\', END)  # Clear the results label\\n-            self.results_label.insert(END, "T\\xc3\\xaan khu\\xc3\\xb4n m\\xe1\\xba\\xb7t \\xc4\\x91\\xc6\\xb0\\xe1\\xbb\\xa3c nh\\xe1\\xba\\xadn d\\xe1\\xba\\xa1ng:\\\\n" + "\\\\n".join(self.detected_names))\\n-        else:\\n-            self.results_label.delete(\\\'1.0\\\', END)\\n-            self.results_label.insert(END, "Kh\\xc3\\xb4ng c\\xc3\\xb3 khu\\xc3\\xb4n m\\xe1\\xba\\xb7t \\xc4\\x91\\xc6\\xb0\\xe1\\xbb\\xa3c ph\\xc3\\xa1t hi\\xe1\\xbb\\x87n.")\\n-\\n-    def open_camera(self):\\n-        if not self.camera_opened:\\n-            self.cap = cv2.VideoCapture(0)\\n-            self.camera_opened = True\\n-            self.open_camera_button.config(text="T\\xe1\\xba\\xaft Camera")\\n-            self.detect_faces_camera(self.cap)\\n-        else:\\n-            self.camera_opened = False\\n-            self.cap.release()\\n-            cv2.destroyAllWindows()\\n-            self.open_camera_button.config(text="M\\xe1\\xbb\\x9f Camera")\\n-\\n-    def load_video(self):\\n-        if not self.video_opened:\\n-            video_path = filedialog.askopenfilename()\\n-            if video_path:\\n-                self.cap = cv2.VideoCapture(video_path)\\n-                self.video_opened = True\\n-                self.load_video_button.config(text="D\\xe1\\xbb\\xabng video")\\n-                self.detect_faces_camera(self.cap)\\n-        else:\\n-            self.video_opened = False\\n-            self.cap.release()\\n-            self.load_video_button.config(text="T\\xe1\\xba\\xa3i video ")\\n+                    # Hi\\xe1\\xbb\\x83n th\\xe1\\xbb\\x8b k\\xe1\\xba\\xbft qu\\xe1\\xba\\xa3 nh\\xe1\\xba\\xadn di\\xe1\\xbb\\x87n tr\\xc3\\xaan video\\n+                    self.show_detection_result(image, bb, best_name)\\n \\n-    def detect_faces_camera(self, cap):\\n-        self.camera_window = tk.Toplevel(self.root)  # S\\xe1\\xbb\\xad d\\xe1\\xbb\\xa5ng self.root thay v\\xc3\\xac self.master\\n-        self.camera_window.title("Cam v\\xc3\\xa0 xem video ")\\n-\\n-        self.image_label = tk.Label(self.camera_window)\\n-        self.image_label.pack()\\n-\\n-        while cap.isOpened():\\n-            ret, frame = cap.read()\\n-            if ret:\\n-                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\\n-                self.detect_faces(frame)\\n-\\n-                frame = Image.fromarray(frame)\\n-                frame = ImageTk.PhotoImage(frame.resize((300, 300), Image.LANCZOS))\\n-                self.image_label.configure(image=frame)\\n-                self.image_label.image = frame\\n-\\n-                self.camera_window.update()\\n-\\n-                if cv2.waitKey(1) & 0xFF == ord(\\\'q\\\'):\\n-                    break\\n-            else:\\n-                break\\n-\\n-        cap.release()\\n-        cv2.destroyAllWindows()\\n+        else:\\n+            # Hi\\xe1\\xbb\\x83n th\\xe1\\xbb\\x8b "Kh\\xc3\\xb4ng c\\xc3\\xb3 khu\\xc3\\xb4n m\\xe1\\xba\\xb7t \\xc4\\x91\\xc6\\xb0\\xe1\\xbb\\xa3c ph\\xc3\\xa1t hi\\xe1\\xbb\\x87n" n\\xe1\\xba\\xbfu kh\\xc3\\xb4ng c\\xc3\\xb3 khu\\xc3\\xb4n m\\xe1\\xba\\xb7t n\\xc3\\xa0o trong khung h\\xc3\\xacnh\\n+            cv2.putText(image, "Khong co khuon mat duoc phat hien", (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\\n \\n+    def show_detection_result(self, image, bb, name):\\n+        # Hi\\xe1\\xbb\\x83n th\\xe1\\xbb\\x8b khu\\xc3\\xb4n m\\xe1\\xba\\xb7t v\\xc3\\xa0 t\\xc3\\xaan c\\xe1\\xbb\\xa7a ng\\xc6\\xb0\\xe1\\xbb\\x9di \\xc4\\x91\\xc6\\xb0\\xe1\\xbb\\xa3c nh\\xe1\\xba\\xadn di\\xe1\\xbb\\x87n\\n+        cv2.rectangle(image, (bb[0], bb[1]), (bb[2], bb[3]), (0, 255, 0), 2)\\n+        cv2.putText(image, name, (bb[0], bb[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\\n \\n def main():\\n-    root = Tk()\\n-    app = FaceRecognitionApp(root)\\n-    root.mainloop()\\n+    face_recognition = FaceRecognitionCamera()\\n+    face_recognition.detect_faces_camera()\\n \\n if __name__ == "__main__":\\n     main()\'\n\\ No newline at end of file\ndiff --git a/BackEnd/Face_AI/src/__pycache__/facenet.cpython-39.pyc b/BackEnd/Face_AI/src/__pycache__/facenet.cpython-39.pyc\ndeleted file mode 100644\nindex b84cfd7..0000000\nBinary files a/BackEnd/Face_AI/src/__pycache__/facenet.cpython-39.pyc and /dev/null differ\ndiff --git a/BackEnd/Face_AI/src/align/__pycache__/detect_face.cpython-37.pyc b/BackEnd/Face_AI/src/align/__pycache__/detect_face.cpython-37.pyc\ndeleted file mode 100644\nindex 4692c43..0000000\nBinary files a/BackEnd/Face_AI/src/align/__pycache__/detect_face.cpython-37.pyc and /dev/null differ\ndiff --git a/BackEnd/Face_AI/src/align/__pycache__/detect_face.cpython-39.pyc b/BackEnd/Face_AI/src/align/__pycache__/detect_face.cpython-39.pyc\ndeleted file mode 100644\nindex 09bd2f2..0000000\nBinary files a/BackEnd/Face_AI/src/align/__pycache__/detect_face.cpython-39.pyc and /dev/null differ\ndiff --git a/BackEnd/Face_AI/src/align/a b/BackEnd/Face_AI/src/align/a\ndeleted file mode 100644\nindex 8b13789..0000000\n--- a/BackEnd/Face_AI/src/align/a\n+++ /dev/null\n@@ -1 +0,0 @@\n-\ndiff --git a/BackEnd/Face_AI/src/align/det1.npy b/BackEnd/Face_AI/src/align/det1.npy\ndeleted file mode 100644\nindex 7c05a2c..0000000\nBinary files a/BackEnd/Face_AI/src/align/det1.npy and /dev/null differ\ndiff --git a/BackEnd/Face_AI/src/align/det2.npy b/BackEnd/Face_AI/src/align/det2.npy\ndeleted file mode 100644\nindex 85d5bf0..0000000\nBinary files a/BackEnd/Face_AI/src/align/det2.npy and /dev/null differ\ndiff --git a/BackEnd/Face_AI/src/align/det3.npy b/BackEnd/Face_AI/src/align/det3.npy\ndeleted file mode 100644\nindex 90d5ba9..0000000\nBinary files a/BackEnd/Face_AI/src/align/det3.npy and /dev/null differ\ndiff --git a/BackEnd/Face_AI/src/align/detect_face.py b/BackEnd/Face_AI/src/align/detect_face.py\ndeleted file mode 100644\nindex 2300ff3..0000000\n--- a/BackEnd/Face_AI/src/align/detect_face.py\n+++ /dev/null\n@@ -1,781 +0,0 @@\n-""" Tensorflow implementation of the face detection / alignment algorithm found at\n-https://github.com/kpzhang93/MTCNN_face_detection_alignment\n-"""\n-# MIT License\n-# \n-# Copyright (c) 2016 David Sandberg\n-# \n-# Permission is hereby granted, free of charge, to any person obtaining a copy\n-# of this software and associated documentation files (the "Software"), to deal\n-# in the Software without restriction, including without limitation the rights\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n-# copies of the Software, and to permit persons to whom the Software is\n-# furnished to do so, subject to the following conditions:\n-# \n-# The above copyright notice and this permission notice shall be included in all\n-# copies or substantial portions of the Software.\n-# \n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n-# SOFTWARE.\n-\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-from six import string_types, iteritems\n-\n-import numpy as np\n-import tensorflow as tf\n-#from math import floor\n-import cv2\n-import os\n-\n-def layer(op):\n-    """Decorator for composable network layers."""\n-\n-    def layer_decorated(self, *args, **kwargs):\n-        # Automatically set a name if not provided.\n-        name = kwargs.setdefault(\'name\', self.get_unique_name(op.__name__))\n-        # Figure out the layer inputs.\n-        if len(self.terminals) == 0:\n-            raise RuntimeError(\'No input variables found for layer %s.\' % name)\n-        elif len(self.terminals) == 1:\n-            layer_input = self.terminals[0]\n-        else:\n-            layer_input = list(self.terminals)\n-        # Perform the operation and get the output.\n-        layer_output = op(self, layer_input, *args, **kwargs)\n-        # Add to layer LUT.\n-        self.layers[name] = layer_output\n-        # This output is now the input for the next layer.\n-        self.feed(layer_output)\n-        # Return self for chained calls.\n-        return self\n-\n-    return layer_decorated\n-\n-class Network(object):\n-\n-    def __init__(self, inputs, trainable=True):\n-        # The input nodes for this network\n-        self.inputs = inputs\n-        # The current list of terminal nodes\n-        self.terminals = []\n-        # Mapping from layer names to layers\n-        self.layers = dict(inputs)\n-        # If true, the resulting variables are set as trainable\n-        self.trainable = trainable\n-\n-        self.setup()\n-\n-    def setup(self):\n-        """Construct the network. """\n-        raise NotImplementedError(\'Must be implemented by the subclass.\')\n-\n-    def load(self, data_path, session, ignore_missing=False):\n-        """Load network weights.\n-        data_path: The path to the numpy-serialized network weights\n-        session: The current TensorFlow session\n-        ignore_missing: If true, serialized weights for missing layers are ignored.\n-        """\n-        data_dict = np.load(data_path, encoding=\'latin1\',allow_pickle=True).item() #pylint: disable=no-member\n-\n-        for op_name in data_dict:\n-            with tf.compat.v1.variable_scope(op_name, reuse=True):\n-                for param_name, data in iteritems(data_dict[op_name]):\n-                    try:\n-                        var = tf.compat.v1.get_variable(param_name)\n-                        session.run(var.assign(data))\n-                    except ValueError:\n-                        if not ignore_missing:\n-                            raise\n-\n-    def feed(self, *args):\n-        """Set the input(s) for the next operation by replacing the terminal nodes.\n-        The arguments can be either layer names or the actual layers.\n-        """\n-        assert len(args) != 0\n-        self.terminals = []\n-        for fed_layer in args:\n-            if isinstance(fed_layer, string_types):\n-                try:\n-                    fed_layer = self.layers[fed_layer]\n-                except KeyError:\n-                    raise KeyError(\'Unknown layer name fed: %s\' % fed_layer)\n-            self.terminals.append(fed_layer)\n-        return self\n-\n-    def get_output(self):\n-        """Returns the current network output."""\n-        return self.terminals[-1]\n-\n-    def get_unique_name(self, prefix):\n-        """Returns an index-suffixed unique name for the given prefix.\n-        This is used for auto-generating layer names based on the type-prefix.\n-        """\n-        ident = sum(t.startswith(prefix) for t, _ in self.layers.items()) + 1\n-        return \'%s_%d\' % (prefix, ident)\n-\n-    def make_var(self, name, shape):\n-        """Creates a new TensorFlow variable."""\n-        return tf.compat.v1.get_variable(name, shape, trainable=self.trainable)\n-\n-    def validate_padding(self, padding):\n-        """Verifies that the padding is one of the supported ones."""\n-        assert padding in (\'SAME\', \'VALID\')\n-\n-    @layer\n-    def conv(self,\n-             inp,\n-             k_h,\n-             k_w,\n-             c_o,\n-             s_h,\n-             s_w,\n-             name,\n-             relu=True,\n-             padding=\'SAME\',\n-             group=1,\n-             biased=True):\n-        # Verify that the padding is acceptable\n-        self.validate_padding(padding)\n-        # Get the number of channels in the input\n-        c_i = int(inp.get_shape()[-1])\n-        # Verify that the grouping parameter is valid\n-        assert c_i % group == 0\n-        assert c_o % group == 0\n-        # Convolution for a given input and kernel\n-        convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\n-        with tf.compat.v1.variable_scope(name) as scope:\n-            kernel = self.make_var(\'weights\', shape=[k_h, k_w, c_i // group, c_o])\n-            # This is the common-case. Convolve the input without any further complications.\n-            output = convolve(inp, kernel)\n-            # Add the biases\n-            if biased:\n-                biases = self.make_var(\'biases\', [c_o])\n-                output = tf.nn.bias_add(output, biases)\n-            if relu:\n-                # ReLU non-linearity\n-                output = tf.nn.relu(output, name=scope.name)\n-            return output\n-\n-    @layer\n-    def prelu(self, inp, name):\n-        with tf.compat.v1.variable_scope(name):\n-            i = int(inp.get_shape()[-1])\n-            alpha = self.make_var(\'alpha\', shape=(i,))\n-            output = tf.nn.relu(inp) + tf.multiply(alpha, -tf.nn.relu(-inp))\n-        return output\n-\n-    @layer\n-    def max_pool(self, inp, k_h, k_w, s_h, s_w, name, padding=\'SAME\'):\n-        self.validate_padding(padding)\n-        return tf.nn.max_pool(inp,\n-                              ksize=[1, k_h, k_w, 1],\n-                              strides=[1, s_h, s_w, 1],\n-                              padding=padding,\n-                              name=name)\n-\n-    @layer\n-    def fc(self, inp, num_out, name, relu=True):\n-        with tf.compat.v1.variable_scope(name):\n-            input_shape = inp.get_shape()\n-            if input_shape.ndims == 4:\n-                # The input is spatial. Vectorize it first.\n-                dim = 1\n-                for d in input_shape[1:].as_list():\n-                    dim *= int(d)\n-                feed_in = tf.reshape(inp, [-1, dim])\n-            else:\n-                feed_in, dim = (inp, input_shape[-1])\n-            weights = self.make_var(\'weights\', shape=[dim, num_out])\n-            biases = self.make_var(\'biases\', [num_out])\n-            op = tf.compat.v1.nn.relu_layer if relu else tf.compat.v1.nn.xw_plus_b\n-            fc = op(feed_in, weights, biases, name=name)\n-            return fc\n-\n-\n-    """\n-    Multi dimensional softmax,\n-    refer to https://github.com/tensorflow/tensorflow/issues/210\n-    compute softmax along the dimension of target\n-    the native softmax only supports batch_size x dimension\n-    """\n-    @layer\n-    def softmax(self, target, axis, name=None):\n-        max_axis = tf.reduce_max(target, axis, keepdims=True)\n-        target_exp = tf.exp(target-max_axis)\n-        normalize = tf.reduce_sum(target_exp, axis, keepdims=True)\n-        softmax = tf.compat.v1.div(target_exp, normalize, name)\n-        return softmax\n-    \n-class PNet(Network):\n-    def setup(self):\n-        (self.feed(\'data\') #pylint: disable=no-value-for-parameter, no-member\n-             .conv(3, 3, 10, 1, 1, padding=\'VALID\', relu=False, name=\'conv1\')\n-             .prelu(name=\'PReLU1\')\n-             .max_pool(2, 2, 2, 2, name=\'pool1\')\n-             .conv(3, 3, 16, 1, 1, padding=\'VALID\', relu=False, name=\'conv2\')\n-             .prelu(name=\'PReLU2\')\n-             .conv(3, 3, 32, 1, 1, padding=\'VALID\', relu=False, name=\'conv3\')\n-             .prelu(name=\'PReLU3\')\n-             .conv(1, 1, 2, 1, 1, relu=False, name=\'conv4-1\')\n-             .softmax(3,name=\'prob1\'))\n-\n-        (self.feed(\'PReLU3\') #pylint: disable=no-value-for-parameter\n-             .conv(1, 1, 4, 1, 1, relu=False, name=\'conv4-2\'))\n-        \n-class RNet(Network):\n-    def setup(self):\n-        (self.feed(\'data\') #pylint: disable=no-value-for-parameter, no-member\n-             .conv(3, 3, 28, 1, 1, padding=\'VALID\', relu=False, name=\'conv1\')\n-             .prelu(name=\'prelu1\')\n-             .max_pool(3, 3, 2, 2, name=\'pool1\')\n-             .conv(3, 3, 48, 1, 1, padding=\'VALID\', relu=False, name=\'conv2\')\n-             .prelu(name=\'prelu2\')\n-             .max_pool(3, 3, 2, 2, padding=\'VALID\', name=\'pool2\')\n-             .conv(2, 2, 64, 1, 1, padding=\'VALID\', relu=False, name=\'conv3\')\n-             .prelu(name=\'prelu3\')\n-             .fc(128, relu=False, name=\'conv4\')\n-             .prelu(name=\'prelu4\')\n-             .fc(2, relu=False, name=\'conv5-1\')\n-             .softmax(1,name=\'prob1\'))\n-\n-        (self.feed(\'prelu4\') #pylint: disable=no-value-for-parameter\n-             .fc(4, relu=False, name=\'conv5-2\'))\n-\n-class ONet(Network):\n-    def setup(self):\n-        (self.feed(\'data\') #pylint: disable=no-value-for-parameter, no-member\n-             .conv(3, 3, 32, 1, 1, padding=\'VALID\', relu=False, name=\'conv1\')\n-             .prelu(name=\'prelu1\')\n-             .max_pool(3, 3, 2, 2, name=\'pool1\')\n-             .conv(3, 3, 64, 1, 1, padding=\'VALID\', relu=False, name=\'conv2\')\n-             .prelu(name=\'prelu2\')\n-             .max_pool(3, 3, 2, 2, padding=\'VALID\', name=\'pool2\')\n-             .conv(3, 3, 64, 1, 1, padding=\'VALID\', relu=False, name=\'conv3\')\n-             .prelu(name=\'prelu3\')\n-             .max_pool(2, 2, 2, 2, name=\'pool3\')\n-             .conv(2, 2, 128, 1, 1, padding=\'VALID\', relu=False, name=\'conv4\')\n-             .prelu(name=\'prelu4\')\n-             .fc(256, relu=False, name=\'conv5\')\n-             .prelu(name=\'prelu5\')\n-             .fc(2, relu=False, name=\'conv6-1\')\n-             .softmax(1, name=\'prob1\'))\n-\n-        (self.feed(\'prelu5\') #pylint: disable=no-value-for-parameter\n-             .fc(4, relu=False, name=\'conv6-2\'))\n-\n-        (self.feed(\'prelu5\') #pylint: disable=no-value-for-parameter\n-             .fc(10, relu=False, name=\'conv6-3\'))\n-\n-def create_mtcnn(sess, model_path):\n-    if not model_path:\n-        model_path,_ = os.path.split(os.path.realpath(__file__))\n-\n-    with tf.compat.v1.variable_scope(\'pnet\'):\n-        data = tf.compat.v1.placeholder(tf.float32, (None,None,None,3), \'input\')\n-        pnet = PNet({\'data\':data})\n-        pnet.load(os.path.join(model_path, \'det1.npy\'), sess)\n-    with tf.compat.v1.variable_scope(\'rnet\'):\n-        data = tf.compat.v1.placeholder(tf.float32, (None,24,24,3), \'input\')\n-        rnet = RNet({\'data\':data})\n-        rnet.load(os.path.join(model_path, \'det2.npy\'), sess)\n-    with tf.compat.v1.variable_scope(\'onet\'):\n-        data = tf.compat.v1.placeholder(tf.float32, (None,48,48,3), \'input\')\n-        onet = ONet({\'data\':data})\n-        onet.load(os.path.join(model_path, \'det3.npy\'), sess)\n-        \n-    pnet_fun = lambda img : sess.run((\'pnet/conv4-2/BiasAdd:0\', \'pnet/prob1:0\'), feed_dict={\'pnet/input:0\':img})\n-    rnet_fun = lambda img : sess.run((\'rnet/conv5-2/conv5-2:0\', \'rnet/prob1:0\'), feed_dict={\'rnet/input:0\':img})\n-    onet_fun = lambda img : sess.run((\'onet/conv6-2/conv6-2:0\', \'onet/conv6-3/conv6-3:0\', \'onet/prob1:0\'), feed_dict={\'onet/input:0\':img})\n-    return pnet_fun, rnet_fun, onet_fun\n-\n-def detect_face(img, minsize, pnet, rnet, onet, threshold, factor):\n-    """Detects faces in an image, and returns bounding boxes and points for them.\n-    img: input image\n-    minsize: minimum faces\' size\n-    pnet, rnet, onet: caffemodel\n-    threshold: threshold=[th1, th2, th3], th1-3 are three steps\'s threshold\n-    factor: the factor used to create a scaling pyramid of face sizes to detect in the image.\n-    """\n-    factor_count=0\n-    total_boxes=np.empty((0,9))\n-    points=np.empty(0)\n-    h=img.shape[0]\n-    w=img.shape[1]\n-    minl=np.amin([h, w])\n-    m=12.0/minsize\n-    minl=minl*m\n-    # create scale pyramid\n-    scales=[]\n-    while minl>=12:\n-        scales += [m*np.power(factor, factor_count)]\n-        minl = minl*factor\n-        factor_count += 1\n-\n-    # first stage\n-    for scale in scales:\n-        hs=int(np.ceil(h*scale))\n-        ws=int(np.ceil(w*scale))\n-        im_data = imresample(img, (hs, ws))\n-        im_data = (im_data-127.5)*0.0078125\n-        img_x = np.expand_dims(im_data, 0)\n-        img_y = np.transpose(img_x, (0,2,1,3))\n-        out = pnet(img_y)\n-        out0 = np.transpose(out[0], (0,2,1,3))\n-        out1 = np.transpose(out[1], (0,2,1,3))\n-        \n-        boxes, _ = generateBoundingBox(out1[0,:,:,1].copy(), out0[0,:,:,:].copy(), scale, threshold[0])\n-        \n-        # inter-scale nms\n-        pick = nms(boxes.copy(), 0.5, \'Union\')\n-        if boxes.size>0 and pick.size>0:\n-            boxes = boxes[pick,:]\n-            total_boxes = np.append(total_boxes, boxes, axis=0)\n-\n-    numbox = total_boxes.shape[0]\n-    if numbox>0:\n-        pick = nms(total_boxes.copy(), 0.7, \'Union\')\n-        total_boxes = total_boxes[pick,:]\n-        regw = total_boxes[:,2]-total_boxes[:,0]\n-        regh = total_boxes[:,3]-total_boxes[:,1]\n-        qq1 = total_boxes[:,0]+total_boxes[:,5]*regw\n-        qq2 = total_boxes[:,1]+total_boxes[:,6]*regh\n-        qq3 = total_boxes[:,2]+total_boxes[:,7]*regw\n-        qq4 = total_boxes[:,3]+total_boxes[:,8]*regh\n-        total_boxes = np.transpose(np.vstack([qq1, qq2, qq3, qq4, total_boxes[:,4]]))\n-        total_boxes = rerec(total_boxes.copy())\n-        total_boxes[:,0:4] = np.fix(total_boxes[:,0:4]).astype(np.int32)\n-        dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph = pad(total_boxes.copy(), w, h)\n-\n-    numbox = total_boxes.shape[0]\n-    if numbox>0:\n-        # second stage\n-        tempimg = np.zeros((24,24,3,numbox))\n-        for k in range(0,numbox):\n-            tmp = np.zeros((int(tmph[k]),int(tmpw[k]),3))\n-            tmp[dy[k]-1:edy[k],dx[k]-1:edx[k],:] = img[y[k]-1:ey[k],x[k]-1:ex[k],:]\n-            if tmp.shape[0]>0 and tmp.shape[1]>0 or tmp.shape[0]==0 and tmp.shape[1]==0:\n-                tempimg[:,:,:,k] = imresample(tmp, (24, 24))\n-            else:\n-                return np.empty()\n-        tempimg = (tempimg-127.5)*0.0078125\n-        tempimg1 = np.transpose(tempimg, (3,1,0,2))\n-        out = rnet(tempimg1)\n-        out0 = np.transpose(out[0])\n-        out1 = np.transpose(out[1])\n-        score = out1[1,:]\n-        ipass = np.where(score>threshold[1])\n-        total_boxes = np.hstack([total_boxes[ipass[0],0:4].copy(), np.expand_dims(score[ipass].copy(),1)])\n-        mv = out0[:,ipass[0]]\n-        if total_boxes.shape[0]>0:\n-            pick = nms(total_boxes, 0.7, \'Union\')\n-            total_boxes = total_boxes[pick,:]\n-            total_boxes = bbreg(total_boxes.copy(), np.transpose(mv[:,pick]))\n-            total_boxes = rerec(total_boxes.copy())\n-\n-    numbox = total_boxes.shape[0]\n-    if numbox>0:\n-        # third stage\n-        total_boxes = np.fix(total_boxes).astype(np.int32)\n-        dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph = pad(total_boxes.copy(), w, h)\n-        tempimg = np.zeros((48,48,3,numbox))\n-        for k in range(0,numbox):\n-            tmp = np.zeros((int(tmph[k]),int(tmpw[k]),3))\n-            tmp[dy[k]-1:edy[k],dx[k]-1:edx[k],:] = img[y[k]-1:ey[k],x[k]-1:ex[k],:]\n-            if tmp.shape[0]>0 and tmp.shape[1]>0 or tmp.shape[0]==0 and tmp.shape[1]==0:\n-                tempimg[:,:,:,k] = imresample(tmp, (48, 48))\n-            else:\n-                return np.empty()\n-        tempimg = (tempimg-127.5)*0.0078125\n-        tempimg1 = np.transpose(tempimg, (3,1,0,2))\n-        out = onet(tempimg1)\n-        out0 = np.transpose(out[0])\n-        out1 = np.transpose(out[1])\n-        out2 = np.transpose(out[2])\n-        score = out2[1,:]\n-        points = out1\n-        ipass = np.where(score>threshold[2])\n-        points = points[:,ipass[0]]\n-        total_boxes = np.hstack([total_boxes[ipass[0],0:4].copy(), np.expand_dims(score[ipass].copy(),1)])\n-        mv = out0[:,ipass[0]]\n-\n-        w = total_boxes[:,2]-total_boxes[:,0]+1\n-        h = total_boxes[:,3]-total_boxes[:,1]+1\n-        points[0:5,:] = np.tile(w,(5, 1))*points[0:5,:] + np.tile(total_boxes[:,0],(5, 1))-1\n-        points[5:10,:] = np.tile(h,(5, 1))*points[5:10,:] + np.tile(total_boxes[:,1],(5, 1))-1\n-        if total_boxes.shape[0]>0:\n-            total_boxes = bbreg(total_boxes.copy(), np.transpose(mv))\n-            pick = nms(total_boxes.copy(), 0.7, \'Min\')\n-            total_boxes = total_boxes[pick,:]\n-            points = points[:,pick]\n-                \n-    return total_boxes, points\n-\n-\n-def bulk_detect_face(images, detection_window_size_ratio, pnet, rnet, onet, threshold, factor):\n-    """Detects faces in a list of images\n-    images: list containing input images\n-    detection_window_size_ratio: ratio of minimum face size to smallest image dimension\n-    pnet, rnet, onet: caffemodel\n-    threshold: threshold=[th1 th2 th3], th1-3 are three steps\'s threshold [0-1]\n-    factor: the factor used to create a scaling pyramid of face sizes to detect in the image.\n-    """\n-    all_scales = [None] * len(images)\n-    images_with_boxes = [None] * len(images)\n-\n-    for i in range(len(images)):\n-        images_with_boxes[i] = {\'total_boxes\': np.empty((0, 9))}\n-\n-    # create scale pyramid\n-    for index, img in enumerate(images):\n-        all_scales[index] = []\n-        h = img.shape[0]\n-        w = img.shape[1]\n-        minsize = int(detection_window_size_ratio * np.minimum(w, h))\n-        factor_count = 0\n-        minl = np.amin([h, w])\n-        if minsize <= 12:\n-            minsize = 12\n-\n-        m = 12.0 / minsize\n-        minl = minl * m\n-        while minl >= 12:\n-            all_scales[index].append(m * np.power(factor, factor_count))\n-            minl = minl * factor\n-            factor_count += 1\n-\n-    # # # # # # # # # # # # #\n-    # first stage - fast proposal network (pnet) to obtain face candidates\n-    # # # # # # # # # # # # #\n-\n-    images_obj_per_resolution = {}\n-\n-    # TODO: use some type of rounding to number module 8 to increase probability that pyramid images will have the same resolution across input images\n-\n-    for index, scales in enumerate(all_scales):\n-        h = images[index].shape[0]\n-        w = images[index].shape[1]\n-\n-        for scale in scales:\n-            hs = int(np.ceil(h * scale))\n-            ws = int(np.ceil(w * scale))\n-\n-            if (ws, hs) not in images_obj_per_resolution:\n-                images_obj_per_resolution[(ws, hs)] = []\n-\n-            im_data = imresample(images[index], (hs, ws))\n-            im_data = (im_data - 127.5) * 0.0078125\n-            img_y = np.transpose(im_data, (1, 0, 2))  # caffe uses different dimensions ordering\n-            images_obj_per_resolution[(ws, hs)].append({\'scale\': scale, \'image\': img_y, \'index\': index})\n-\n-    for resolution in images_obj_per_resolution:\n-        images_per_resolution = [i[\'image\'] for i in images_obj_per_resolution[resolution]]\n-        outs = pnet(images_per_resolution)\n-\n-        for index in range(len(outs[0])):\n-            scale = images_obj_per_resolution[resolution][index][\'scale\']\n-            image_index = images_obj_per_resolution[resolution][index][\'index\']\n-            out0 = np.transpose(outs[0][index], (1, 0, 2))\n-            out1 = np.transpose(outs[1][index], (1, 0, 2))\n-\n-            boxes, _ = generateBoundingBox(out1[:, :, 1].copy(), out0[:, :, :].copy(), scale, threshold[0])\n-\n-            # inter-scale nms\n-            pick = nms(boxes.copy(), 0.5, \'Union\')\n-            if boxes.size > 0 and pick.size > 0:\n-                boxes = boxes[pick, :]\n-                images_with_boxes[image_index][\'total_boxes\'] = np.append(images_with_boxes[image_index][\'total_boxes\'],\n-                                                                          boxes,\n-                                                                          axis=0)\n-\n-    for index, image_obj in enumerate(images_with_boxes):\n-        numbox = image_obj[\'total_boxes\'].shape[0]\n-        if numbox > 0:\n-            h = images[index].shape[0]\n-            w = images[index].shape[1]\n-            pick = nms(image_obj[\'total_boxes\'].copy(), 0.7, \'Union\')\n-            image_obj[\'total_boxes\'] = image_obj[\'total_boxes\'][pick, :]\n-            regw = image_obj[\'total_boxes\'][:, 2] - image_obj[\'total_boxes\'][:, 0]\n-            regh = image_obj[\'total_boxes\'][:, 3] - image_obj[\'total_boxes\'][:, 1]\n-            qq1 = image_obj[\'total_boxes\'][:, 0] + image_obj[\'total_boxes\'][:, 5] * regw\n-            qq2 = image_obj[\'total_boxes\'][:, 1] + image_obj[\'total_boxes\'][:, 6] * regh\n-            qq3 = image_obj[\'total_boxes\'][:, 2] + image_obj[\'total_boxes\'][:, 7] * regw\n-            qq4 = image_obj[\'total_boxes\'][:, 3] + image_obj[\'total_boxes\'][:, 8] * regh\n-            image_obj[\'total_boxes\'] = np.transpose(np.vstack([qq1, qq2, qq3, qq4, image_obj[\'total_boxes\'][:, 4]]))\n-            image_obj[\'total_boxes\'] = rerec(image_obj[\'total_boxes\'].copy())\n-            image_obj[\'total_boxes\'][:, 0:4] = np.fix(image_obj[\'total_boxes\'][:, 0:4]).astype(np.int32)\n-            dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph = pad(image_obj[\'total_boxes\'].copy(), w, h)\n-\n-            numbox = image_obj[\'total_boxes\'].shape[0]\n-            tempimg = np.zeros((24, 24, 3, numbox))\n-\n-            if numbox > 0:\n-                for k in range(0, numbox):\n-                    tmp = np.zeros((int(tmph[k]), int(tmpw[k]), 3))\n-                    tmp[dy[k] - 1:edy[k], dx[k] - 1:edx[k], :] = images[index][y[k] - 1:ey[k], x[k] - 1:ex[k], :]\n-                    if tmp.shape[0] > 0 and tmp.shape[1] > 0 or tmp.shape[0] == 0 and tmp.shape[1] == 0:\n-                        tempimg[:, :, :, k] = imresample(tmp, (24, 24))\n-                    else:\n-                        return np.empty()\n-\n-                tempimg = (tempimg - 127.5) * 0.0078125\n-                image_obj[\'rnet_input\'] = np.transpose(tempimg, (3, 1, 0, 2))\n-\n-    # # # # # # # # # # # # #\n-    # second stage - refinement of face candidates with rnet\n-    # # # # # # # # # # # # #\n-\n-    bulk_rnet_input = np.empty((0, 24, 24, 3))\n-    for index, image_obj in enumerate(images_with_boxes):\n-        if \'rnet_input\' in image_obj:\n-            bulk_rnet_input = np.append(bulk_rnet_input, image_obj[\'rnet_input\'], axis=0)\n-\n-    out = rnet(bulk_rnet_input)\n-    out0 = np.transpose(out[0])\n-    out1 = np.transpose(out[1])\n-    score = out1[1, :]\n-\n-    i = 0\n-    for index, image_obj in enumerate(images_with_boxes):\n-        if \'rnet_input\' not in image_obj:\n-            continue\n-\n-        rnet_input_count = image_obj[\'rnet_input\'].shape[0]\n-        score_per_image = score[i:i + rnet_input_count]\n-        out0_per_image = out0[:, i:i + rnet_input_count]\n-\n-        ipass = np.where(score_per_image > threshold[1])\n-        image_obj[\'total_boxes\'] = np.hstack([image_obj[\'total_boxes\'][ipass[0], 0:4].copy(),\n-                                              np.expand_dims(score_per_image[ipass].copy(), 1)])\n-\n-        mv = out0_per_image[:, ipass[0]]\n-\n-        if image_obj[\'total_boxes\'].shape[0] > 0:\n-            h = images[index].shape[0]\n-            w = images[index].shape[1]\n-            pick = nms(image_obj[\'total_boxes\'], 0.7, \'Union\')\n-            image_obj[\'total_boxes\'] = image_obj[\'total_boxes\'][pick, :]\n-            image_obj[\'total_boxes\'] = bbreg(image_obj[\'total_boxes\'].copy(), np.transpose(mv[:, pick]))\n-            image_obj[\'total_boxes\'] = rerec(image_obj[\'total_boxes\'].copy())\n-\n-            numbox = image_obj[\'total_boxes\'].shape[0]\n-\n-            if numbox > 0:\n-                tempimg = np.zeros((48, 48, 3, numbox))\n-                image_obj[\'total_boxes\'] = np.fix(image_obj[\'total_boxes\']).astype(np.int32)\n-                dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph = pad(image_obj[\'total_boxes\'].copy(), w, h)\n-\n-                for k in range(0, numbox):\n-                    tmp = np.zeros((int(tmph[k]), int(tmpw[k]), 3))\n-                    tmp[dy[k] - 1:edy[k], dx[k] - 1:edx[k], :] = images[index][y[k] - 1:ey[k], x[k] - 1:ex[k], :]\n-                    if tmp.shape[0] > 0 and tmp.shape[1] > 0 or tmp.shape[0] == 0 and tmp.shape[1] == 0:\n-                        tempimg[:, :, :, k] = imresample(tmp, (48, 48))\n-                    else:\n-                        return np.empty()\n-                tempimg = (tempimg - 127.5) * 0.0078125\n-                image_obj[\'onet_input\'] = np.transpose(tempimg, (3, 1, 0, 2))\n-\n-        i += rnet_input_count\n-\n-    # # # # # # # # # # # # #\n-    # third stage - further refinement and facial landmarks positions with onet\n-    # # # # # # # # # # # # #\n-\n-    bulk_onet_input = np.empty((0, 48, 48, 3))\n-    for index, image_obj in enumerate(images_with_boxes):\n-        if \'onet_input\' in image_obj:\n-            bulk_onet_input = np.append(bulk_onet_input, image_obj[\'onet_input\'], axis=0)\n-\n-    out = onet(bulk_onet_input)\n-\n-    out0 = np.transpose(out[0])\n-    out1 = np.transpose(out[1])\n-    out2 = np.transpose(out[2])\n-    score = out2[1, :]\n-    points = out1\n-\n-    i = 0\n-    ret = []\n-    for index, image_obj in enumerate(images_with_boxes):\n-        if \'onet_input\' not in image_obj:\n-            ret.append(None)\n-            continue\n-\n-        onet_input_count = image_obj[\'onet_input\'].shape[0]\n-\n-        out0_per_image = out0[:, i:i + onet_input_count]\n-        score_per_image = score[i:i + onet_input_count]\n-        points_per_image = points[:, i:i + onet_input_count]\n-\n-        ipass = np.where(score_per_image > threshold[2])\n-        points_per_image = points_per_image[:, ipass[0]]\n-\n-        image_obj[\'total_boxes\'] = np.hstack([image_obj[\'total_boxes\'][ipass[0], 0:4].copy(),\n-                                              np.expand_dims(score_per_image[ipass].copy(), 1)])\n-        mv = out0_per_image[:, ipass[0]]\n-\n-        w = image_obj[\'total_boxes\'][:, 2] - image_obj[\'total_boxes\'][:, 0] + 1\n-        h = image_obj[\'total_boxes\'][:, 3] - image_obj[\'total_boxes\'][:, 1] + 1\n-        points_per_image[0:5, :] = np.tile(w, (5, 1)) * points_per_image[0:5, :] + np.tile(\n-            image_obj[\'total_boxes\'][:, 0], (5, 1)) - 1\n-        points_per_image[5:10, :] = np.tile(h, (5, 1)) * points_per_image[5:10, :] + np.tile(\n-            image_obj[\'total_boxes\'][:, 1], (5, 1)) - 1\n-\n-        if image_obj[\'total_boxes\'].shape[0] > 0:\n-            image_obj[\'total_boxes\'] = bbreg(image_obj[\'total_boxes\'].copy(), np.transpose(mv))\n-            pick = nms(image_obj[\'total_boxes\'].copy(), 0.7, \'Min\')\n-            image_obj[\'total_boxes\'] = image_obj[\'total_boxes\'][pick, :]\n-            points_per_image = points_per_image[:, pick]\n-\n-            ret.append((image_obj[\'total_boxes\'], points_per_image))\n-        else:\n-            ret.append(None)\n-\n-        i += onet_input_count\n-\n-    return ret\n-\n-\n-# function [boundingbox] = bbreg(boundingbox,reg)\n-def bbreg(boundingbox,reg):\n-    """Calibrate bounding boxes"""\n-    if reg.shape[1]==1:\n-        reg = np.reshape(reg, (reg.shape[2], reg.shape[3]))\n-\n-    w = boundingbox[:,2]-boundingbox[:,0]+1\n-    h = boundingbox[:,3]-boundingbox[:,1]+1\n-    b1 = boundingbox[:,0]+reg[:,0]*w\n-    b2 = boundingbox[:,1]+reg[:,1]*h\n-    b3 = boundingbox[:,2]+reg[:,2]*w\n-    b4 = boundingbox[:,3]+reg[:,3]*h\n-    boundingbox[:,0:4] = np.transpose(np.vstack([b1, b2, b3, b4 ]))\n-    return boundingbox\n- \n-def generateBoundingBox(imap, reg, scale, t):\n-    """Use heatmap to generate bounding boxes"""\n-    stride=2\n-    cellsize=12\n-\n-    imap = np.transpose(imap)\n-    dx1 = np.transpose(reg[:,:,0])\n-    dy1 = np.transpose(reg[:,:,1])\n-    dx2 = np.transpose(reg[:,:,2])\n-    dy2 = np.transpose(reg[:,:,3])\n-    y, x = np.where(imap >= t)\n-    if y.shape[0]==1:\n-        dx1 = np.flipud(dx1)\n-        dy1 = np.flipud(dy1)\n-        dx2 = np.flipud(dx2)\n-        dy2 = np.flipud(dy2)\n-    score = imap[(y,x)]\n-    reg = np.transpose(np.vstack([ dx1[(y,x)], dy1[(y,x)], dx2[(y,x)], dy2[(y,x)] ]))\n-    if reg.size==0:\n-        reg = np.empty((0,3))\n-    bb = np.transpose(np.vstack([y,x]))\n-    q1 = np.fix((stride*bb+1)/scale)\n-    q2 = np.fix((stride*bb+cellsize-1+1)/scale)\n-    boundingbox = np.hstack([q1, q2, np.expand_dims(score,1), reg])\n-    return boundingbox, reg\n- \n-# function pick = nms(boxes,threshold,type)\n-def nms(boxes, threshold, method):\n-    if boxes.size==0:\n-        return np.empty((0,3))\n-    x1 = boxes[:,0]\n-    y1 = boxes[:,1]\n-    x2 = boxes[:,2]\n-    y2 = boxes[:,3]\n-    s = boxes[:,4]\n-    area = (x2-x1+1) * (y2-y1+1)\n-    I = np.argsort(s)\n-    pick = np.zeros_like(s, dtype=np.int16)\n-    counter = 0\n-    while I.size>0:\n-        i = I[-1]\n-        pick[counter] = i\n-        counter += 1\n-        idx = I[0:-1]\n-        xx1 = np.maximum(x1[i], x1[idx])\n-        yy1 = np.maximum(y1[i], y1[idx])\n-        xx2 = np.minimum(x2[i], x2[idx])\n-        yy2 = np.minimum(y2[i], y2[idx])\n-        w = np.maximum(0.0, xx2-xx1+1)\n-        h = np.maximum(0.0, yy2-yy1+1)\n-        inter = w * h\n-        if method is \'Min\':\n-            o = inter / np.minimum(area[i], area[idx])\n-        else:\n-            o = inter / (area[i] + area[idx] - inter)\n-        I = I[np.where(o<=threshold)]\n-    pick = pick[0:counter]\n-    return pick\n-\n-# function [dy edy dx edx y ey x ex tmpw tmph] = pad(total_boxes,w,h)\n-def pad(total_boxes, w, h):\n-    """Compute the padding coordinates (pad the bounding boxes to square)"""\n-    tmpw = (total_boxes[:,2]-total_boxes[:,0]+1).astype(np.int32)\n-    tmph = (total_boxes[:,3]-total_boxes[:,1]+1).astype(np.int32)\n-    numbox = total_boxes.shape[0]\n-\n-    dx = np.ones((numbox), dtype=np.int32)\n-    dy = np.ones((numbox), dtype=np.int32)\n-    edx = tmpw.copy().astype(np.int32)\n-    edy = tmph.copy().astype(np.int32)\n-\n-    x = total_boxes[:,0].copy().astype(np.int32)\n-    y = total_boxes[:,1].copy().astype(np.int32)\n-    ex = total_boxes[:,2].copy().astype(np.int32)\n-    ey = total_boxes[:,3].copy().astype(np.int32)\n-\n-    tmp = np.where(ex>w)\n-    edx.flat[tmp] = np.expand_dims(-ex[tmp]+w+tmpw[tmp],1)\n-    ex[tmp] = w\n-    \n-    tmp = np.where(ey>h)\n-    edy.flat[tmp] = np.expand_dims(-ey[tmp]+h+tmph[tmp],1)\n-    ey[tmp] = h\n-\n-    tmp = np.where(x<1)\n-    dx.flat[tmp] = np.expand_dims(2-x[tmp],1)\n-    x[tmp] = 1\n-\n-    tmp = np.where(y<1)\n-    dy.flat[tmp] = np.expand_dims(2-y[tmp],1)\n-    y[tmp] = 1\n-    \n-    return dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph\n-\n-# function [bboxA] = rerec(bboxA)\n-def rerec(bboxA):\n-    """Convert bboxA to square."""\n-    h = bboxA[:,3]-bboxA[:,1]\n-    w = bboxA[:,2]-bboxA[:,0]\n-    l = np.maximum(w, h)\n-    bboxA[:,0] = bboxA[:,0]+w*0.5-l*0.5\n-    bboxA[:,1] = bboxA[:,1]+h*0.5-l*0.5\n-    bboxA[:,2:4] = bboxA[:,0:2] + np.transpose(np.tile(l,(2,1)))\n-    return bboxA\n-\n-def imresample(img, sz):\n-    im_data = cv2.resize(img, (sz[1], sz[0]), interpolation=cv2.INTER_AREA) #@UndefinedVariable\n-    return im_data\n-\n-    # This method is kept for debugging purpose\n-#     h=img.shape[0]\n-#     w=img.shape[1]\n-#     hs, ws = sz\n-#     dx = float(w) / ws\n-#     dy = float(h) / hs\n-#     im_data = np.zeros((hs,ws,3))\n-#     for a1 in range(0,hs):\n-#         for a2 in range(0,ws):\n-#             for a3 in range(0,3):\n-#                 im_data[a1,a2,a3] = img[int(floor(a1*dy)),int(floor(a2*dx)),a3]\n-#     return im_data\n-\ndiff --git a/BackEnd/Face_AI/src/align_dataset_mtcnn.py b/BackEnd/Face_AI/src/align_dataset_mtcnn.py\ndeleted file mode 100644\nindex f4b27aa..0000000\n--- a/BackEnd/Face_AI/src/align_dataset_mtcnn.py\n+++ /dev/null\n@@ -1,140 +0,0 @@\n-\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-from scipy import misc\n-import sys\n-import os\n-import argparse\n-import tensorflow as tf\n-import numpy as np\n-import facenet\n-import align.detect_face\n-import random\n-from time import sleep\n-\n-def main(args):\n-    sleep(random.random())\n-    output_dir = os.path.expanduser(args.output_dir)\n-    if not os.path.exists(output_dir):\n-        os.makedirs(output_dir)\n-    # Store some git revision info in a text file in the log directory\n-    src_path,_ = os.path.split(os.path.realpath(__file__))\n-    facenet.store_revision_info(src_path, output_dir, \' \'.join(sys.argv))\n-    dataset = facenet.get_dataset(args.input_dir)\n-    \n-    print(\'Creating networks and loading parameters\')\n-    \n-    with tf.Graph().as_default():\n-        #gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.gpu_memory_fraction)\n-        sess = tf.compat.v1.Session()#config=tf.ConfigProto())#gpu_options=gpu_options, log_device_placement=False))\n-        with sess.as_default():\n-            pnet, rnet, onet = align.detect_face.create_mtcnn(sess, None)\n-    \n-    minsize = 20 # minimum size of face\n-    threshold = [ 0.6, 0.7, 0.7 ]  # three steps\'s threshold\n-    factor = 0.709 # scale factor\n-\n-    # Add a random key to the filename to allow alignment using multiple processes\n-    random_key = np.random.randint(0, high=99999)\n-    bounding_boxes_filename = os.path.join(output_dir, \'bounding_boxes_%05d.txt\' % random_key)\n-    \n-    with open(bounding_boxes_filename, "w") as text_file:\n-        nrof_images_total = 0\n-        nrof_successfully_aligned = 0\n-        if args.random_order:\n-            random.shuffle(dataset)\n-        for cls in dataset:\n-            output_class_dir = os.path.join(output_dir, cls.name)\n-            if not os.path.exists(output_class_dir):\n-                os.makedirs(output_class_dir)\n-                if args.random_order:\n-                    random.shuffle(cls.image_paths)\n-            for image_path in cls.image_paths:\n-                nrof_images_total += 1\n-                filename = os.path.splitext(os.path.split(image_path)[1])[0]\n-                output_filename = os.path.join(output_class_dir, filename+\'.png\')\n-                print(image_path)\n-                if not os.path.exists(output_filename):\n-                    try:\n-                        import imageio\n-                        img = imageio.imread(image_path)\n-                    except (IOError, ValueError, IndexError) as e:\n-                        errorMessage = \'{}: {}\'.format(image_path, e)\n-                        print(errorMessage)\n-                    else:\n-                        if img.ndim<2:\n-                            print(\'Unable to align "%s"\' % image_path)\n-                            text_file.write(\'%s\\n\' % (output_filename))\n-                            continue\n-                        if img.ndim == 2:\n-                            img = facenet.to_rgb(img)\n-                        img = img[:,:,0:3]\n-    \n-                        bounding_boxes, _ = align.detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)\n-                        nrof_faces = bounding_boxes.shape[0]\n-                        if nrof_faces>0:\n-                            det = bounding_boxes[:,0:4]\n-                            det_arr = []\n-                            img_size = np.asarray(img.shape)[0:2]\n-                            if nrof_faces>1:\n-                                if args.detect_multiple_faces:\n-                                    for i in range(nrof_faces):\n-                                        det_arr.append(np.squeeze(det[i]))\n-                                else:\n-                                    bounding_box_size = (det[:,2]-det[:,0])*(det[:,3]-det[:,1])\n-                                    img_center = img_size / 2\n-                                    offsets = np.vstack([ (det[:,0]+det[:,2])/2-img_center[1], (det[:,1]+det[:,3])/2-img_center[0] ])\n-                                    offset_dist_squared = np.sum(np.power(offsets,2.0),0)\n-                                    index = np.argmax(bounding_box_size-offset_dist_squared*2.0) # some extra weight on the centering\n-                                    det_arr.append(det[index,:])\n-                            else:\n-                                det_arr.append(np.squeeze(det))\n-\n-                            for i, det in enumerate(det_arr):\n-                                det = np.squeeze(det)\n-                                bb = np.zeros(4, dtype=np.int32)\n-                                bb[0] = np.maximum(det[0]-args.margin/2, 0)\n-                                bb[1] = np.maximum(det[1]-args.margin/2, 0)\n-                                bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\n-                                bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\n-                                cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n-                                from PIL import Image\n-                                cropped = Image.fromarray(cropped)\n-                                scaled = cropped.resize((args.image_size, args.image_size), Image.BILINEAR)\n-                                nrof_successfully_aligned += 1\n-                                filename_base, file_extension = os.path.splitext(output_filename)\n-                                if args.detect_multiple_faces:\n-                                    output_filename_n = "{}_{}{}".format(filename_base, i, file_extension)\n-                                else:\n-                                    output_filename_n = "{}{}".format(filename_base, file_extension)\n-                                imageio.imwrite(output_filename_n, scaled)\n-                                text_file.write(\'%s %d %d %d %d\\n\' % (output_filename_n, bb[0], bb[1], bb[2], bb[3]))\n-                        else:\n-                            print(\'Unable to align "%s"\' % image_path)\n-                            text_file.write(\'%s\\n\' % (output_filename))\n-                            \n-    print(\'Total number of images: %d\' % nrof_images_total)\n-    print(\'Number of successfully aligned images: %d\' % nrof_successfully_aligned)\n-            \n-\n-def parse_arguments(argv):\n-    parser = argparse.ArgumentParser()\n-    \n-    parser.add_argument(\'input_dir\', type=str, help=\'Directory with unaligned images.\')\n-    parser.add_argument(\'output_dir\', type=str, help=\'Directory with aligned face thumbnails.\')\n-    parser.add_argument(\'--image_size\', type=int,\n-        help=\'Image size (height, width) in pixels.\', default=182)\n-    parser.add_argument(\'--margin\', type=int,\n-        help=\'Margin for the crop around the bounding box (height, width) in pixels.\', default=44)\n-    parser.add_argument(\'--random_order\', \n-        help=\'Shuffles the order of images to enable alignment using multiple processes.\', action=\'store_true\')\n-    parser.add_argument(\'--gpu_memory_fraction\', type=float,\n-        help=\'Upper bound on the amount of GPU memory that will be used by the process.\', default=1.0)\n-    parser.add_argument(\'--detect_multiple_faces\', type=bool,\n-                        help=\'Detect and align multiple faces per image.\', default=False)\n-    return parser.parse_args(argv)\n-\n-if __name__ == \'__main__\':\n-    main(parse_arguments(sys.argv[1:]))\ndiff --git a/BackEnd/Face_AI/src/classifier.py b/BackEnd/Face_AI/src/classifier.py\ndeleted file mode 100644\nindex 780726f..0000000\n--- a/BackEnd/Face_AI/src/classifier.py\n+++ /dev/null\n@@ -1,148 +0,0 @@\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-import tensorflow as tf\n-import numpy as np\n-import argparse\n-import facenet\n-import os\n-import sys\n-import math\n-import pickle\n-from sklearn.svm import SVC\n-\n-\n-def main(args):\n-    with tf.Graph().as_default():\n-\n-        with tf.compat.v1.Session() as sess:\n-\n-            np.random.seed(seed=args.seed)\n-\n-            if args.use_split_dataset:\n-                dataset_tmp = facenet.get_dataset(args.data_dir)\n-                train_set, test_set = split_dataset(dataset_tmp, args.min_nrof_images_per_class,\n-                                                    args.nrof_train_images_per_class)\n-                if (args.mode == \'TRAIN\'):\n-                    dataset = train_set\n-                elif (args.mode == \'CLASSIFY\'):\n-                    dataset = test_set\n-            else:\n-                dataset = facenet.get_dataset(args.data_dir)\n-\n-            # Check that there are at least one training image per class\n-            for cls in dataset:\n-                assert (len(cls.image_paths) > 0, \'There must be at least one image for each class in the dataset\')\n-\n-            paths, labels = facenet.get_image_paths_and_labels(dataset)\n-\n-            print(\'Number of classes: %d\' % len(dataset))\n-            print(\'Number of images: %d\' % len(paths))\n-\n-            # Load the Models\n-            print(\'Loading feature extraction Models\')\n-            facenet.load_model(args.Models)\n-\n-            # Get input and output tensors\n-            images_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("input:0")\n-            embeddings = tf.compat.v1.get_default_graph().get_tensor_by_name("embeddings:0")\n-            phase_train_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("phase_train:0")\n-            embedding_size = embeddings.get_shape()[1]\n-\n-            # Run forward pass to calculate embeddings\n-            print(\'Calculating features for images\')\n-            nrof_images = len(paths)\n-            nrof_batches_per_epoch = int(math.ceil(1.0 * nrof_images / args.batch_size))\n-            emb_array = np.zeros((nrof_images, embedding_size))\n-            for i in range(nrof_batches_per_epoch):\n-                start_index = i * args.batch_size\n-                end_index = min((i + 1) * args.batch_size, nrof_images)\n-                paths_batch = paths[start_index:end_index]\n-                images = facenet.load_data(paths_batch, False, False, args.image_size)\n-                feed_dict = {images_placeholder: images, phase_train_placeholder: False}\n-                emb_array[start_index:end_index, :] = sess.run(embeddings, feed_dict=feed_dict)\n-\n-            classifier_filename_exp = os.path.expanduser(args.classifier_filename)\n-\n-            if (args.mode == \'TRAIN\'):\n-                # Train classifier\n-                print(\'Training classifier\')\n-                model = SVC(kernel=\'linear\', probability=True)\n-                model.fit(emb_array, labels)\n-\n-                # Create a list of class names\n-                class_names = [cls.name.replace(\'_\', \' \') for cls in dataset]\n-\n-                # Saving classifier Models\n-                with open(classifier_filename_exp, \'wb\') as outfile:\n-                    pickle.dump((model, class_names), outfile)\n-                print(\'Saved classifier Models to file "%s"\' % classifier_filename_exp)\n-\n-            elif (args.mode == \'CLASSIFY\'):\n-                # Classify images\n-                print(\'Testing classifier\')\n-                with open(classifier_filename_exp, \'rb\') as infile:\n-                    (model, class_names) = pickle.load(infile)\n-\n-                print(\'Loaded classifier Models from file "%s"\' % classifier_filename_exp)\n-\n-                predictions = model.predict_proba(emb_array)\n-                best_class_indices = np.argmax(predictions, axis=1)\n-                best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\n-\n-                for i in range(len(best_class_indices)):\n-                    print(\'%4d  %s: %.3f\' % (i, class_names[best_class_indices[i]], best_class_probabilities[i]))\n-\n-                accuracy = np.mean(np.equal(best_class_indices, labels))\n-                print(\'Accuracy: %.3f\' % accuracy)\n-\n-\n-def split_dataset(dataset, min_nrof_images_per_class, nrof_train_images_per_class):\n-    train_set = []\n-    test_set = []\n-    for cls in dataset:\n-        paths = cls.image_paths\n-        # Remove classes with less than min_nrof_images_per_class\n-        if len(paths) >= min_nrof_images_per_class:\n-            np.random.shuffle(paths)\n-            train_set.append(facenet.ImageClass(cls.name, paths[:nrof_train_images_per_class]))\n-            test_set.append(facenet.ImageClass(cls.name, paths[nrof_train_images_per_class:]))\n-    return train_set, test_set\n-\n-\n-def parse_arguments(argv):\n-    parser = argparse.ArgumentParser()\n-\n-    parser.add_argument(\'mode\', type=str, choices=[\'TRAIN\', \'CLASSIFY\'],\n-                        help=\'Indicates if a new classifier should be trained or a classification \' +\n-                             \'Models should be used for classification\', default=\'CLASSIFY\')\n-    parser.add_argument(\'data_dir\', type=str,\n-                        help=\'Path to the data directory containing aligned LFW face patches.\')\n-    parser.add_argument(\'Models\', type=str,\n-                        help=\'Could be either a directory containing the meta_file and ckpt_file or a Models protobuf (.pb) file\')\n-    parser.add_argument(\'classifier_filename\',\n-                        help=\'Classifier Models file name as a pickle (.pkl) file. \' +\n-                             \'For training this is the output and for classification this is an input.\')\n-    parser.add_argument(\'--use_split_dataset\',\n-                        help=\'Indicates that the dataset specified by data_dir should be split into a training and test set. \' +\n-                             \'Otherwise a separate test set can be specified using the test_data_dir option.\',\n-                        action=\'store_true\')\n-    parser.add_argument(\'--test_data_dir\', type=str,\n-                        help=\'Path to the test data directory containing aligned images used for testing.\')\n-    parser.add_argument(\'--batch_size\', type=int,\n-                        help=\'Number of images to process in a batch.\', default=90)\n-    parser.add_argument(\'--image_size\', type=int,\n-                        help=\'Image size (height, width) in pixels.\', default=160)\n-    parser.add_argument(\'--seed\', type=int,\n-                        help=\'Random seed.\', default=666)\n-    parser.add_argument(\'--min_nrof_images_per_class\', type=int,\n-                        help=\'Only include classes with at least this number of images in the dataset\', default=20)\n-    parser.add_argument(\'--nrof_train_images_per_class\', type=int,\n-                        help=\'Use this number of images from each class for training and the rest for testing\',\n-                        default=10)\n-\n-    return parser.parse_args(argv)\n-\n-\n-if __name__ == \'__main__\':\n-    main(parse_arguments(sys.argv[1:]))\ndiff --git a/BackEnd/Face_AI/src/cut_img.py b/BackEnd/Face_AI/src/cut_img.py\ndeleted file mode 100644\nindex 328a722..0000000\n--- a/BackEnd/Face_AI/src/cut_img.py\n+++ /dev/null\n@@ -1,48 +0,0 @@\n-import cv2\n-import os\n-\n-\n-def create_student_folder(parent_folder, student_id):\n-    folder_path = os.path.join(parent_folder, student_id)\n-    if not os.path.exists(folder_path):\n-        os.makedirs(folder_path)\n-    return folder_path\n-\n-\n-def capture_images(folder_path, num_images=100):\n-    count = 0\n-\n-    directions = [\'front\', \'left\', \'right\', \'up\', \'down\']\n-    direction_index = 0\n-\n-    while count < num_images:\n-        direction = directions[direction_index]\n-        print(f"Look {direction} and press any key to capture image for this direction.")\n-\n-        cap = cv2.VideoCapture(0)\n-        ret, frame = cap.read()\n-        cap.release()\n-\n-        if not ret:\n-            break\n-\n-        image_path = os.path.join(folder_path, f\'{count:03d}_{direction}.jpg\')\n-        cv2.imwrite(image_path, frame)\n-        count += 1\n-        print(f"Captured image {count}/{num_images} for direction {direction}.")\n-\n-        direction_index = (direction_index + 1) % len(directions)\n-\n-    cv2.destroyAllWindows()\n-\n-\n-def main():\n-    parent_folder = r\'D:\\AI_PROJECT\\Face_Pro\\Dataset\\FaceData\\raw\'\n-    student_id = input("Enter student ID: ")\n-\n-    folder_path = create_student_folder(parent_folder, student_id)\n-    capture_images(folder_path)\n-\n-\n-if __name__ == "__main__":\n-    main()\ndiff --git a/BackEnd/Face_AI/src/demo.py b/BackEnd/Face_AI/src/demo.py\ndeleted file mode 100644\nindex 0895804..0000000\n--- a/BackEnd/Face_AI/src/demo.py\n+++ /dev/null\n@@ -1,146 +0,0 @@\n-import cv2\n-import numpy as np\n-import tensorflow as tf\n-import facenet\n-import align.detect_face\n-import pickle\n-import pyodbc\n-import datetime\n-import pygame\n-import time\n-import base64\n-\n-class FaceRecognitionCamera:\n-    def __init__(self):\n-        # Load paths to classifier and FaceNet model\n-        self.CLASSIFIER_PATH = r\'D:\\AI_PROJECT\\Face_Pro\\Models\\facemodel.pkl\'  \n-        self.FACENET_MODEL_PATH = r\'D:\\AI_PROJECT\\Face_Pro\\Models\\20180402-114759.pb\'  \n-\n-        # Load classifier model\n-        with open(self.CLASSIFIER_PATH, \'rb\') as file:\n-            self.model, self.class_names = pickle.load(file)\n-\n-        # Load FaceNet model\n-        with tf.Graph().as_default():\n-            self.sess = tf.compat.v1.Session()\n-            facenet.load_model(self.FACENET_MODEL_PATH)\n-            self.images_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("input:0")\n-            self.embeddings = tf.compat.v1.get_default_graph().get_tensor_by_name("embeddings:0")\n-            self.phase_train_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("phase_train:0")\n-            self.mtcnn_pnet, self.mtcnn_rnet, self.mtcnn_onet = align.detect_face.create_mtcnn(self.sess, None)\n-\n-        # K\xe1\xba\xbft n\xe1\xbb\x91i \xc4\x91\xe1\xba\xbfn c\xc6\xa1 s\xe1\xbb\x9f d\xe1\xbb\xaf li\xe1\xbb\x87u SQL Server\n-        self.conn = pyodbc.connect(\'DRIVER={SQL Server};\'\n-                                   \'SERVER=.;\'\n-                                   \'DATABASE=DiemdanhAI;\'\n-                                   \'UID=sa;\'\n-                                   \'PWD=123456\')\n-        self.cursor = self.conn.cursor()\n-\n-        # Kh\xe1\xbb\x9fi t\xe1\xba\xa1o t\xe1\xba\xadp h\xe1\xbb\xa3p \xc4\x91\xe1\xbb\x83 theo d\xc3\xb5i nh\xe1\xbb\xafng khu\xc3\xb4n m\xe1\xba\xb7t \xc4\x91\xc3\xa3 \xc4\x91\xc6\xb0\xe1\xbb\xa3c nh\xe1\xba\xadn di\xe1\xbb\x87n\n-        self.detected_faces = set()\n-\n-        # Kh\xe1\xbb\x9fi t\xe1\xba\xa1o c\xe1\xbb\xada s\xe1\xbb\x95 Pygame v\xc3\xa0 \xc3\xa2m thanh\n-        pygame.init()\n-        self.success_sound = pygame.mixer.Sound(r\'D:\\AI_PROJECT\\Face_Pro\\news-ting-6832.mp3\')\n-\n-        # Kh\xe1\xbb\x9fi t\xe1\xba\xa1o bi\xe1\xba\xbfn l\xc6\xb0u th\xc3\xb4ng tin nh\xe1\xba\xadn di\xe1\xbb\x87n\n-        self.recognized_name = None\n-        self.recognized_time = None\n-        self.recognized_success = False\n-\n-    def detect_faces_camera(self):\n-        cap = cv2.VideoCapture(0)\n-\n-        while cap.isOpened():\n-            ret, frame = cap.read()\n-            if ret:\n-                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n-                self.detect_faces(frame)\n-\n-                if cv2.waitKey(1) & 0xFF == ord(\'q\'):\n-                    break\n-            else:\n-                break\n-\n-        cap.release()\n-        cv2.destroyAllWindows()\n-\n-    def detect_faces(self, image):\n-        bounding_boxes, _ = align.detect_face.detect_face(image, 20, self.mtcnn_pnet, self.mtcnn_rnet, self.mtcnn_onet,\n-                                                          [0.6, 0.7, 0.7], 0.709)\n-        faces_found = bounding_boxes.shape[0]\n-\n-        if faces_found > 0:\n-            largest_face_area = 0\n-            largest_face_index = 0\n-            for i, bbox in enumerate(bounding_boxes):\n-                det = np.squeeze(bbox[0:4])\n-                bb = np.zeros(4, dtype=np.int32)\n-                bb[0] = np.maximum(det[0], 0)\n-                bb[1] = np.maximum(det[1], 0)\n-                bb[2] = np.minimum(det[2], image.shape[1])\n-                bb[3] = np.minimum(det[3], image.shape[0])\n-\n-                face_area = (bb[2] - bb[0]) * (bb[3] - bb[1])\n-                if face_area > largest_face_area:\n-                    largest_face_area = face_area\n-                    largest_face_index = i\n-\n-            largest_bbox = bounding_boxes[largest_face_index]\n-            det = np.squeeze(largest_bbox[0:4])\n-            bb = np.zeros(4, dtype=np.int32)\n-            bb[0] = np.maximum(det[0], 0)\n-            bb[1] = np.maximum(det[1], 0)\n-            bb[2] = np.minimum(det[2], image.shape[1])\n-            bb[3] = np.minimum(det[3], image.shape[0])\n-\n-            cropped = image[bb[1]:bb[3], bb[0]:bb[2], :]\n-            scaled = cv2.resize(cropped, (160, 160), interpolation=cv2.INTER_CUBIC)\n-            scaled = facenet.prewhiten(scaled)\n-            scaled_reshape = scaled.reshape(-1, 160, 160, 3)\n-\n-            feed_dict = {self.images_placeholder: scaled_reshape, self.phase_train_placeholder: False}\n-            emb_array = self.sess.run(self.embeddings, feed_dict=feed_dict)\n-            predictions = self.model.predict_proba(emb_array)\n-            best_class_indices = np.argmax(predictions, axis=1)\n-            best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\n-\n-            if best_class_probabilities >= 0.8:\n-                best_name = self.class_names[best_class_indices[0]]\n-                # Ki\xe1\xbb\x83m tra xem khu\xc3\xb4n m\xe1\xba\xb7t \xc4\x91\xc3\xa3 \xc4\x91\xc6\xb0\xe1\xbb\xa3c nh\xe1\xba\xadn di\xe1\xbb\x87n ch\xc6\xb0a\n-                if best_name not in self.detected_faces:\n-                    # L\xc6\xb0u th\xc3\xb4ng tin v\xc3\xa0o bi\xe1\xba\xbfn\n-                    self.recognized_name = best_name\n-                    self.recognized_time = time.time()\n-                    self.recognized_success = True\n-                    # L\xc6\xb0u v\xc3\xa0o CSDL\n-                    self.save_recognition()\n-                    self.detected_faces.add(best_name)\n-                    self.success_sound.play()\n-                    print(f"{best_name} \xc4\x91\xc3\xa3 \xc4\x91\xc6\xb0\xe1\xbb\xa3c \xc4\x91i\xe1\xbb\x83m danh.")\n-            else:\n-                cv2.rectangle(image, (bb[0], bb[1]), (bb[2], bb[3]), (255, 0, 0), 2)\n-                cv2.putText(image, "Unknown", (bb[0], bb[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2,\n-                            cv2.LINE_AA)\n-\n-            cv2.imshow(\'Face Recognition\', cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n-        else:\n-            cv2.imshow(\'Face Recognition\', cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n-\n-    def save_recognition(self):\n-        # L\xc6\xb0u th\xc3\xb4ng tin v\xc3\xa0o CSDL\n-        self.cursor.execute("INSERT INTO data_sv (namesv, tt) VALUES (?, ?)", (self.recognized_name, 1))\n-        self.conn.commit()\n-\n-    def __del__(self):\n-        # \xc4\x90\xc3\xb3ng k\xe1\xba\xbft n\xe1\xbb\x91i CSDL khi h\xe1\xbb\xa7y \xc4\x91\xe1\xbb\x91i t\xc6\xb0\xe1\xbb\xa3ng\n-        self.conn.close()\n-        pygame.quit()\n-\n-def main():\n-    face_recognition = FaceRecognitionCamera()\n-    face_recognition.detect_faces_camera()\n-\n-if __name__ == "__main__":\n-    main()\ndiff --git a/BackEnd/Face_AI/src/facenet.py b/BackEnd/Face_AI/src/facenet.py\ndeleted file mode 100644\nindex 42354d1..0000000\n--- a/BackEnd/Face_AI/src/facenet.py\n+++ /dev/null\n@@ -1,572 +0,0 @@\n-"""Functions for building the face recognition network.\n-"""\n-# MIT License\n-# \n-# Copyright (c) 2016 David Sandberg\n-# \n-# Permission is hereby granted, free of charge, to any person obtaining a copy\n-# of this software and associated documentation files (the "Software"), to deal\n-# in the Software without restriction, including without limitation the rights\n-# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n-# copies of the Software, and to permit persons to whom the Software is\n-# furnished to do so, subject to the following conditions:\n-# \n-# The above copyright notice and this permission notice shall be included in all\n-# copies or substantial portions of the Software.p\n-# \n-# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n-# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n-# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n-# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n-# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n-# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n-# SOFTWARE.\n-\n-# pylint: disable=missing-docstring\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-import os\n-from subprocess import Popen, PIPE\n-import tensorflow as tf\n-import numpy as np\n-from scipy import misc\n-from sklearn.model_selection import KFold\n-from scipy import interpolate\n-from tensorflow.python.training import training\n-import random\n-import re\n-from tensorflow.python.platform import gfile\n-import math\n-from six import iteritems\n-\n-def triplet_loss(anchor, positive, negative, alpha):\n-    """Calculate the triplet loss according to the FaceNet paper\n-    \n-    Args:\n-      anchor: the embeddings for the anchor images.\n-      positive: the embeddings for the positive images.\n-      negative: the embeddings for the negative images.\n-  \n-    Returns:\n-      the triplet loss according to the FaceNet paper as a float tensor.\n-    """\n-    with tf.variable_scope(\'triplet_loss\'):\n-        pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, positive)), 1)\n-        neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor, negative)), 1)\n-        \n-        basic_loss = tf.add(tf.subtract(pos_dist,neg_dist), alpha)\n-        loss = tf.reduce_mean(tf.maximum(basic_loss, 0.0), 0)\n-      \n-    return loss\n-  \n-def center_loss(features, label, alfa, nrof_classes):\n-    """Center loss based on the paper "A Discriminative Feature Learning Approach for Deep Face Recognition"\n-       (http://ydwen.github.io/papers/WenECCV16.pdf)\n-    """\n-    nrof_features = features.get_shape()[1]\n-    centers = tf.get_variable(\'centers\', [nrof_classes, nrof_features], dtype=tf.float32,\n-        initializer=tf.constant_initializer(0), trainable=False)\n-    label = tf.reshape(label, [-1])\n-    centers_batch = tf.gather(centers, label)\n-    diff = (1 - alfa) * (centers_batch - features)\n-    centers = tf.scatter_sub(centers, label, diff)\n-    with tf.control_dependencies([centers]):\n-        loss = tf.reduce_mean(tf.square(features - centers_batch))\n-    return loss, centers\n-\n-def get_image_paths_and_labels(dataset):\n-    image_paths_flat = []\n-    labels_flat = []\n-    for i in range(len(dataset)):\n-        image_paths_flat += dataset[i].image_paths\n-        labels_flat += [i] * len(dataset[i].image_paths)\n-    return image_paths_flat, labels_flat\n-\n-def shuffle_examples(image_paths, labels):\n-    shuffle_list = list(zip(image_paths, labels))\n-    random.shuffle(shuffle_list)\n-    image_paths_shuff, labels_shuff = zip(*shuffle_list)\n-    return image_paths_shuff, labels_shuff\n-\n-def random_rotate_image(image):\n-    angle = np.random.uniform(low=-10.0, high=10.0)\n-    return misc.imrotate(image, angle, \'bicubic\')\n-  \n-# 1: Random rotate 2: Random crop  4: Random flip  8:  Fixed image standardization  16: Flip\n-RANDOM_ROTATE = 1\n-RANDOM_CROP = 2\n-RANDOM_FLIP = 4\n-FIXED_STANDARDIZATION = 8\n-FLIP = 16\n-def create_input_pipeline(input_queue, image_size, nrof_preprocess_threads, batch_size_placeholder):\n-    images_and_labels_list = []\n-    for _ in range(nrof_preprocess_threads):\n-        filenames, label, control = input_queue.dequeue()\n-        images = []\n-        for filename in tf.unstack(filenames):\n-            file_contents = tf.read_file(filename)\n-            image = tf.image.decode_image(file_contents, 3)\n-            image = tf.cond(get_control_flag(control[0], RANDOM_ROTATE),\n-                            lambda:tf.py_func(random_rotate_image, [image], tf.uint8), \n-                            lambda:tf.identity(image))\n-            image = tf.cond(get_control_flag(control[0], RANDOM_CROP), \n-                            lambda:tf.random_crop(image, image_size + (3,)), \n-                            lambda:tf.image.resize_image_with_crop_or_pad(image, image_size[0], image_size[1]))\n-            image = tf.cond(get_control_flag(control[0], RANDOM_FLIP),\n-                            lambda:tf.image.random_flip_left_right(image),\n-                            lambda:tf.identity(image))\n-            image = tf.cond(get_control_flag(control[0], FIXED_STANDARDIZATION),\n-                            lambda:(tf.cast(image, tf.float32) - 127.5)/128.0,\n-                            lambda:tf.image.per_image_standardization(image))\n-            image = tf.cond(get_control_flag(control[0], FLIP),\n-                            lambda:tf.image.flip_left_right(image),\n-                            lambda:tf.identity(image))\n-            #pylint: disable=no-member\n-            image.set_shape(image_size + (3,))\n-            images.append(image)\n-        images_and_labels_list.append([images, label])\n-\n-    image_batch, label_batch = tf.train.batch_join(\n-        images_and_labels_list, batch_size=batch_size_placeholder, \n-        shapes=[image_size + (3,), ()], enqueue_many=True,\n-        capacity=4 * nrof_preprocess_threads * 100,\n-        allow_smaller_final_batch=True)\n-    \n-    return image_batch, label_batch\n-\n-def get_control_flag(control, field):\n-    return tf.equal(tf.mod(tf.floor_div(control, field), 2), 1)\n-  \n-def _add_loss_summaries(total_loss):\n-    """Add summaries for losses.\n-  \n-    Generates moving average for all losses and associated summaries for\n-    visualizing the performance of the network.\n-  \n-    Args:\n-      total_loss: Total loss from loss().\n-    Returns:\n-      loss_averages_op: op for generating moving averages of losses.\n-    """\n-    # Compute the moving average of all individual losses and the total loss.\n-    loss_averages = tf.train.ExponentialMovingAverage(0.9, name=\'avg\')\n-    losses = tf.get_collection(\'losses\')\n-    loss_averages_op = loss_averages.apply(losses + [total_loss])\n-  \n-    # Attach a scalar summmary to all individual losses and the total loss; do the\n-    # same for the averaged version of the losses.\n-    for l in losses + [total_loss]:\n-        # Name each loss as \'(raw)\' and name the moving average version of the loss\n-        # as the original loss name.\n-        tf.summary.scalar(l.op.name +\' (raw)\', l)\n-        tf.summary.scalar(l.op.name, loss_averages.average(l))\n-  \n-    return loss_averages_op\n-\n-def train(total_loss, global_step, optimizer, learning_rate, moving_average_decay, update_gradient_vars, log_histograms=True):\n-    # Generate moving averages of all losses and associated summaries.\n-    loss_averages_op = _add_loss_summaries(total_loss)\n-\n-    # Compute gradients.\n-    with tf.control_dependencies([loss_averages_op]):\n-        if optimizer==\'ADAGRAD\':\n-            opt = tf.train.AdagradOptimizer(learning_rate)\n-        elif optimizer==\'ADADELTA\':\n-            opt = tf.train.AdadeltaOptimizer(learning_rate, rho=0.9, epsilon=1e-6)\n-        elif optimizer==\'ADAM\':\n-            opt = tf.train.AdamOptimizer(learning_rate, beta1=0.9, beta2=0.999, epsilon=0.1)\n-        elif optimizer==\'RMSPROP\':\n-            opt = tf.train.RMSPropOptimizer(learning_rate, decay=0.9, momentum=0.9, epsilon=1.0)\n-        elif optimizer==\'MOM\':\n-            opt = tf.train.MomentumOptimizer(learning_rate, 0.9, use_nesterov=True)\n-        else:\n-            raise ValueError(\'Invalid optimization algorithm\')\n-    \n-        grads = opt.compute_gradients(total_loss, update_gradient_vars)\n-        \n-    # Apply gradients.\n-    apply_gradient_op = opt.apply_gradients(grads, global_step=global_step)\n-  \n-    # Add histograms for trainable variables.\n-    if log_histograms:\n-        for var in tf.trainable_variables():\n-            tf.summary.histogram(var.op.name, var)\n-   \n-    # Add histograms for gradients.\n-    if log_histograms:\n-        for grad, var in grads:\n-            if grad is not None:\n-                tf.summary.histogram(var.op.name + \'/gradients\', grad)\n-  \n-    # Track the moving averages of all trainable variables.\n-    variable_averages = tf.train.ExponentialMovingAverage(\n-        moving_average_decay, global_step)\n-    variables_averages_op = variable_averages.apply(tf.trainable_variables())\n-  \n-    with tf.control_dependencies([apply_gradient_op, variables_averages_op]):\n-        train_op = tf.no_op(name=\'train\')\n-  \n-    return train_op\n-\n-def prewhiten(x):\n-    mean = np.mean(x)\n-    std = np.std(x)\n-    std_adj = np.maximum(std, 1.0/np.sqrt(x.size))\n-    y = np.multiply(np.subtract(x, mean), 1/std_adj)\n-    return y  \n-\n-def crop(image, random_crop, image_size):\n-    if image.shape[1]>image_size:\n-        sz1 = int(image.shape[1]//2)\n-        sz2 = int(image_size//2)\n-        if random_crop:\n-            diff = sz1-sz2\n-            (h, v) = (np.random.randint(-diff, diff+1), np.random.randint(-diff, diff+1))\n-        else:\n-            (h, v) = (0,0)\n-        image = image[(sz1-sz2+v):(sz1+sz2+v),(sz1-sz2+h):(sz1+sz2+h),:]\n-    return image\n-  \n-def flip(image, random_flip):\n-    if random_flip and np.random.choice([True, False]):\n-        image = np.fliplr(image)\n-    return image\n-\n-def to_rgb(img):\n-    w, h = img.shape\n-    ret = np.empty((w, h, 3), dtype=np.uint8)\n-    ret[:, :, 0] = ret[:, :, 1] = ret[:, :, 2] = img\n-    return ret\n-  \n-def load_data(image_paths, do_random_crop, do_random_flip, image_size, do_prewhiten=True):\n-    nrof_samples = len(image_paths)\n-    images = np.zeros((nrof_samples, image_size, image_size, 3))\n-    for i in range(nrof_samples):\n-        import imageio\n-        img = imageio.imread(image_paths[i])\n-        if img.ndim == 2:\n-            img = to_rgb(img)\n-        if do_prewhiten:\n-            img = prewhiten(img)\n-        img = crop(img, do_random_crop, image_size)\n-        img = flip(img, do_random_flip)\n-        images[i,:,:,:] = img\n-    return images\n-\n-def get_label_batch(label_data, batch_size, batch_index):\n-    nrof_examples = np.size(label_data, 0)\n-    j = batch_index*batch_size % nrof_examples\n-    if j+batch_size<=nrof_examples:\n-        batch = label_data[j:j+batch_size]\n-    else:\n-        x1 = label_data[j:nrof_examples]\n-        x2 = label_data[0:nrof_examples-j]\n-        batch = np.vstack([x1,x2])\n-    batch_int = batch.astype(np.int64)\n-    return batch_int\n-\n-def get_batch(image_data, batch_size, batch_index):\n-    nrof_examples = np.size(image_data, 0)\n-    j = batch_index*batch_size % nrof_examples\n-    if j+batch_size<=nrof_examples:\n-        batch = image_data[j:j+batch_size,:,:,:]\n-    else:\n-        x1 = image_data[j:nrof_examples,:,:,:]\n-        x2 = image_data[0:nrof_examples-j,:,:,:]\n-        batch = np.vstack([x1,x2])\n-    batch_float = batch.astype(np.float32)\n-    return batch_float\n-\n-def get_triplet_batch(triplets, batch_index, batch_size):\n-    ax, px, nx = triplets\n-    a = get_batch(ax, int(batch_size/3), batch_index)\n-    p = get_batch(px, int(batch_size/3), batch_index)\n-    n = get_batch(nx, int(batch_size/3), batch_index)\n-    batch = np.vstack([a, p, n])\n-    return batch\n-\n-def get_learning_rate_from_file(filename, epoch):\n-    with open(filename, \'r\') as f:\n-        for line in f.readlines():\n-            line = line.split(\'#\', 1)[0]\n-            if line:\n-                par = line.strip().split(\':\')\n-                e = int(par[0])\n-                if par[1]==\'-\':\n-                    lr = -1\n-                else:\n-                    lr = float(par[1])\n-                if e <= epoch:\n-                    learning_rate = lr\n-                else:\n-                    return learning_rate\n-\n-class ImageClass():\n-    "Stores the paths to images for a given class"\n-    def __init__(self, name, image_paths):\n-        self.name = name\n-        self.image_paths = image_paths\n-  \n-    def __str__(self):\n-        return self.name + \', \' + str(len(self.image_paths)) + \' images\'\n-  \n-    def __len__(self):\n-        return len(self.image_paths)\n-  \n-def get_dataset(path, has_class_directories=True):\n-    dataset = []\n-    path_exp = os.path.expanduser(path)\n-    classes = [path for path in os.listdir(path_exp) \\\n-                    if os.path.isdir(os.path.join(path_exp, path))]\n-    classes.sort()\n-    nrof_classes = len(classes)\n-    for i in range(nrof_classes):\n-        class_name = classes[i]\n-        facedir = os.path.join(path_exp, class_name)\n-        image_paths = get_image_paths(facedir)\n-        dataset.append(ImageClass(class_name, image_paths))\n-  \n-    return dataset\n-\n-def get_image_paths(facedir):\n-    image_paths = []\n-    if os.path.isdir(facedir):\n-        images = os.listdir(facedir)\n-        image_paths = [os.path.join(facedir,img) for img in images]\n-    return image_paths\n-  \n-def split_dataset(dataset, split_ratio, min_nrof_images_per_class, mode):\n-    if mode==\'SPLIT_CLASSES\':\n-        nrof_classes = len(dataset)\n-        class_indices = np.arange(nrof_classes)\n-        np.random.shuffle(class_indices)\n-        split = int(round(nrof_classes*(1-split_ratio)))\n-        train_set = [dataset[i] for i in class_indices[0:split]]\n-        test_set = [dataset[i] for i in class_indices[split:-1]]\n-    elif mode==\'SPLIT_IMAGES\':\n-        train_set = []\n-        test_set = []\n-        for cls in dataset:\n-            paths = cls.image_paths\n-            np.random.shuffle(paths)\n-            nrof_images_in_class = len(paths)\n-            split = int(math.floor(nrof_images_in_class*(1-split_ratio)))\n-            if split==nrof_images_in_class:\n-                split = nrof_images_in_class-1\n-            if split>=min_nrof_images_per_class and nrof_images_in_class-split>=1:\n-                train_set.append(ImageClass(cls.name, paths[:split]))\n-                test_set.append(ImageClass(cls.name, paths[split:]))\n-    else:\n-        raise ValueError(\'Invalid train/test split mode "%s"\' % mode)\n-    return train_set, test_set\n-\n-def load_model(model, input_map=None):\n-    # Check if the Models is a Models directory (containing a metagraph and a checkpoint file)\n-    #  or if it is a protobuf file with a frozen graph\n-    model_exp = os.path.expanduser(model)\n-    if (os.path.isfile(model_exp)):\n-        print(\'Model filename: %s\' % model_exp)\n-        with gfile.FastGFile(model_exp,\'rb\') as f:\n-            graph_def = tf.compat.v1.GraphDef()\n-            graph_def.ParseFromString(f.read())\n-            tf.import_graph_def(graph_def, input_map=input_map, name=\'\')\n-    else:\n-        print(\'Model directory: %s\' % model_exp)\n-        meta_file, ckpt_file = get_model_filenames(model_exp)\n-        \n-        print(\'Metagraph file: %s\' % meta_file)\n-        print(\'Checkpoint file: %s\' % ckpt_file)\n-      \n-        saver = tf.train.import_meta_graph(os.path.join(model_exp, meta_file), input_map=input_map)\n-        saver.restore(tf.get_default_session(), os.path.join(model_exp, ckpt_file))\n-    \n-def get_model_filenames(model_dir):\n-    files = os.listdir(model_dir)\n-    meta_files = [s for s in files if s.endswith(\'.meta\')]\n-    if len(meta_files)==0:\n-        raise ValueError(\'No meta file found in the Models directory (%s)\' % model_dir)\n-    elif len(meta_files)>1:\n-        raise ValueError(\'There should not be more than one meta file in the Models directory (%s)\' % model_dir)\n-    meta_file = meta_files[0]\n-    ckpt = tf.train.get_checkpoint_state(model_dir)\n-    if ckpt and ckpt.model_checkpoint_path:\n-        ckpt_file = os.path.basename(ckpt.model_checkpoint_path)\n-        return meta_file, ckpt_file\n-\n-    meta_files = [s for s in files if \'.ckpt\' in s]\n-    max_step = -1\n-    for f in files:\n-        step_str = re.match(r\'(^Models-[\\w\\- ]+.ckpt-(\\d+))\', f)\n-        if step_str is not None and len(step_str.groups())>=2:\n-            step = int(step_str.groups()[1])\n-            if step > max_step:\n-                max_step = step\n-                ckpt_file = step_str.groups()[0]\n-    return meta_file, ckpt_file\n-  \n-def distance(embeddings1, embeddings2, distance_metric=0):\n-    if distance_metric==0:\n-        # Euclidian distance\n-        diff = np.subtract(embeddings1, embeddings2)\n-        dist = np.sum(np.square(diff),1)\n-    elif distance_metric==1:\n-        # Distance based on cosine similarity\n-        dot = np.sum(np.multiply(embeddings1, embeddings2), axis=1)\n-        norm = np.linalg.norm(embeddings1, axis=1) * np.linalg.norm(embeddings2, axis=1)\n-        similarity = dot / norm\n-        dist = np.arccos(similarity) / math.pi\n-    else:\n-        raise \'Undefined distance metric %d\' % distance_metric \n-        \n-    return dist\n-\n-def calculate_roc(thresholds, embeddings1, embeddings2, actual_issame, nrof_folds=10, distance_metric=0, subtract_mean=False):\n-    assert(embeddings1.shape[0] == embeddings2.shape[0])\n-    assert(embeddings1.shape[1] == embeddings2.shape[1])\n-    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n-    nrof_thresholds = len(thresholds)\n-    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\n-    \n-    tprs = np.zeros((nrof_folds,nrof_thresholds))\n-    fprs = np.zeros((nrof_folds,nrof_thresholds))\n-    accuracy = np.zeros((nrof_folds))\n-    \n-    indices = np.arange(nrof_pairs)\n-    \n-    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n-        if subtract_mean:\n-            mean = np.mean(np.concatenate([embeddings1[train_set], embeddings2[train_set]]), axis=0)\n-        else:\n-          mean = 0.0\n-        dist = distance(embeddings1-mean, embeddings2-mean, distance_metric)\n-        \n-        # Find the best threshold for the fold\n-        acc_train = np.zeros((nrof_thresholds))\n-        for threshold_idx, threshold in enumerate(thresholds):\n-            _, _, acc_train[threshold_idx] = calculate_accuracy(threshold, dist[train_set], actual_issame[train_set])\n-        best_threshold_index = np.argmax(acc_train)\n-        for threshold_idx, threshold in enumerate(thresholds):\n-            tprs[fold_idx,threshold_idx], fprs[fold_idx,threshold_idx], _ = calculate_accuracy(threshold, dist[test_set], actual_issame[test_set])\n-        _, _, accuracy[fold_idx] = calculate_accuracy(thresholds[best_threshold_index], dist[test_set], actual_issame[test_set])\n-          \n-        tpr = np.mean(tprs,0)\n-        fpr = np.mean(fprs,0)\n-    return tpr, fpr, accuracy\n-\n-def calculate_accuracy(threshold, dist, actual_issame):\n-    predict_issame = np.less(dist, threshold)\n-    tp = np.sum(np.logical_and(predict_issame, actual_issame))\n-    fp = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\n-    tn = np.sum(np.logical_and(np.logical_not(predict_issame), np.logical_not(actual_issame)))\n-    fn = np.sum(np.logical_and(np.logical_not(predict_issame), actual_issame))\n-  \n-    tpr = 0 if (tp+fn==0) else float(tp) / float(tp+fn)\n-    fpr = 0 if (fp+tn==0) else float(fp) / float(fp+tn)\n-    acc = float(tp+tn)/dist.size\n-    return tpr, fpr, acc\n-\n-\n-  \n-def calculate_val(thresholds, embeddings1, embeddings2, actual_issame, far_target, nrof_folds=10, distance_metric=0, subtract_mean=False):\n-    assert(embeddings1.shape[0] == embeddings2.shape[0])\n-    assert(embeddings1.shape[1] == embeddings2.shape[1])\n-    nrof_pairs = min(len(actual_issame), embeddings1.shape[0])\n-    nrof_thresholds = len(thresholds)\n-    k_fold = KFold(n_splits=nrof_folds, shuffle=False)\n-    \n-    val = np.zeros(nrof_folds)\n-    far = np.zeros(nrof_folds)\n-    \n-    indices = np.arange(nrof_pairs)\n-    \n-    for fold_idx, (train_set, test_set) in enumerate(k_fold.split(indices)):\n-        if subtract_mean:\n-            mean = np.mean(np.concatenate([embeddings1[train_set], embeddings2[train_set]]), axis=0)\n-        else:\n-          mean = 0.0\n-        dist = distance(embeddings1-mean, embeddings2-mean, distance_metric)\n-      \n-        # Find the threshold that gives FAR = far_target\n-        far_train = np.zeros(nrof_thresholds)\n-        for threshold_idx, threshold in enumerate(thresholds):\n-            _, far_train[threshold_idx] = calculate_val_far(threshold, dist[train_set], actual_issame[train_set])\n-        if np.max(far_train)>=far_target:\n-            f = interpolate.interp1d(far_train, thresholds, kind=\'slinear\')\n-            threshold = f(far_target)\n-        else:\n-            threshold = 0.0\n-    \n-        val[fold_idx], far[fold_idx] = calculate_val_far(threshold, dist[test_set], actual_issame[test_set])\n-  \n-    val_mean = np.mean(val)\n-    far_mean = np.mean(far)\n-    val_std = np.std(val)\n-    return val_mean, val_std, far_mean\n-\n-\n-def calculate_val_far(threshold, dist, actual_issame):\n-    predict_issame = np.less(dist, threshold)\n-    true_accept = np.sum(np.logical_and(predict_issame, actual_issame))\n-    false_accept = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\n-    n_same = np.sum(actual_issame)\n-    n_diff = np.sum(np.logical_not(actual_issame))\n-    val = float(true_accept) / float(n_same)\n-    far = float(false_accept) / float(n_diff)\n-    return val, far\n-\n-def store_revision_info(src_path, output_dir, arg_string):\n-    try:\n-        # Get git hash\n-        cmd = [\'git\', \'rev-parse\', \'HEAD\']\n-        gitproc = Popen(cmd, stdout = PIPE, cwd=src_path)\n-        (stdout, _) = gitproc.communicate()\n-        git_hash = stdout.strip()\n-    except OSError as e:\n-        git_hash = \' \'.join(cmd) + \': \' +  e.strerror\n-  \n-    try:\n-        # Get local changes\n-        cmd = [\'git\', \'diff\', \'HEAD\']\n-        gitproc = Popen(cmd, stdout = PIPE, cwd=src_path)\n-        (stdout, _) = gitproc.communicate()\n-        git_diff = stdout.strip()\n-    except OSError as e:\n-        git_diff = \' \'.join(cmd) + \': \' +  e.strerror\n-    \n-    # Store a text file in the log directory\n-    rev_info_filename = os.path.join(output_dir, \'revision_info.txt\')\n-    with open(rev_info_filename, "w") as text_file:\n-        text_file.write(\'arguments: %s\\n--------------------\\n\' % arg_string)\n-        text_file.write(\'tensorflow version: %s\\n--------------------\\n\' % tf.__version__)  # @UndefinedVariable\n-        text_file.write(\'git hash: %s\\n--------------------\\n\' % git_hash)\n-        text_file.write(\'%s\' % git_diff)\n-\n-def list_variables(filename):\n-    reader = training.NewCheckpointReader(filename)\n-    variable_map = reader.get_variable_to_shape_map()\n-    names = sorted(variable_map.keys())\n-    return names\n-\n-def put_images_on_grid(images, shape=(16,8)):\n-    nrof_images = images.shape[0]\n-    img_size = images.shape[1]\n-    bw = 3\n-    img = np.zeros((shape[1]*(img_size+bw)+bw, shape[0]*(img_size+bw)+bw, 3), np.float32)\n-    for i in range(shape[1]):\n-        x_start = i*(img_size+bw)+bw\n-        for j in range(shape[0]):\n-            img_index = i*shape[0]+j\n-            if img_index>=nrof_images:\n-                break\n-            y_start = j*(img_size+bw)+bw\n-            img[x_start:x_start+img_size, y_start:y_start+img_size, :] = images[img_index, :, :, :]\n-        if img_index>=nrof_images:\n-            break\n-    return img\n-\n-def write_arguments_to_file(args, filename):\n-    with open(filename, \'w\') as f:\n-        for key, value in iteritems(vars(args)):\n-            f.write(\'%s: %s\\n\' % (key, str(value)))\ndiff --git a/BackEnd/Face_AI/src/main.py b/BackEnd/Face_AI/src/main.py\ndeleted file mode 100644\nindex 6282015..0000000\n--- a/BackEnd/Face_AI/src/main.py\n+++ /dev/null\n@@ -1,90 +0,0 @@\n-import cv2\n-import numpy as np\n-import tensorflow as tf\n-import facenet\n-import align.detect_face\n-import pickle\n-\n-class FaceRecognitionCamera:\n-    def __init__(self):\n-        # Load paths to classifier and FaceNet model\n-        self.CLASSIFIER_PATH = r\'D:\\AI_PROJECT\\ProJect_DiemDanh\\BackEnd\\Face_AI\\Models\\facemodel.pkl\'\n-        self.FACENET_MODEL_PATH = r\'D:\\AI_PROJECT\\ProJect_DiemDanh\\BackEnd\\Face_AI\\Models\\20180402-114759.pb\'\n-\n-        # Load classifier model\n-        with open(self.CLASSIFIER_PATH, \'rb\') as file:\n-            self.model, self.class_names = pickle.load(file)\n-\n-        # Load FaceNet model\n-        with tf.Graph().as_default():\n-            self.sess = tf.compat.v1.Session()\n-            facenet.load_model(self.FACENET_MODEL_PATH)\n-            self.images_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("input:0")\n-            self.embeddings = tf.compat.v1.get_default_graph().get_tensor_by_name("embeddings:0")\n-            self.phase_train_placeholder = tf.compat.v1.get_default_graph().get_tensor_by_name("phase_train:0")\n-            self.mtcnn_pnet, self.mtcnn_rnet, self.mtcnn_onet = align.detect_face.create_mtcnn(self.sess, None)\n-\n-    def detect_faces_camera(self):\n-        cap = cv2.VideoCapture(0)\n-\n-        while cap.isOpened():\n-            ret, frame = cap.read()\n-            if ret:\n-                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n-                self.detect_faces(frame)\n-                # Hi\xe1\xbb\x83n th\xe1\xbb\x8b video v\xe1\xbb\x9bi k\xe1\xba\xbft qu\xe1\xba\xa3 nh\xe1\xba\xadn di\xe1\xbb\x87n khu\xc3\xb4n m\xe1\xba\xb7t\n-                cv2.imshow(\'Face Recognition\', cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))\n-\n-                if cv2.waitKey(1) & 0xFF == ord(\'q\'):\n-                    break\n-            else:\n-                break\n-\n-        cap.release()\n-        cv2.destroyAllWindows()\n-\n-    def detect_faces(self, image):\n-        bounding_boxes, _ = align.detect_face.detect_face(image, 20, self.mtcnn_pnet, self.mtcnn_rnet, self.mtcnn_onet,\n-                                                          [0.6, 0.7, 0.7], 0.709)\n-        faces_found = bounding_boxes.shape[0]\n-\n-        if faces_found > 0:\n-            for bbox in bounding_boxes:\n-                det = np.squeeze(bbox[0:4])\n-                bb = np.zeros(4, dtype=np.int32)\n-                bb[0] = np.maximum(det[0], 0)\n-                bb[1] = np.maximum(det[1], 0)\n-                bb[2] = np.minimum(det[2], image.shape[1])\n-                bb[3] = np.minimum(det[3], image.shape[0])\n-\n-                cropped = image[bb[1]:bb[3], bb[0]:bb[2], :]\n-                scaled = cv2.resize(cropped, (160, 160), interpolation=cv2.INTER_CUBIC)\n-                scaled = facenet.prewhiten(scaled)\n-                scaled_reshape = scaled.reshape(-1, 160, 160, 3)\n-\n-                feed_dict = {self.images_placeholder: scaled_reshape, self.phase_train_placeholder: False}\n-                emb_array = self.sess.run(self.embeddings, feed_dict=feed_dict)\n-                predictions = self.model.predict_proba(emb_array)\n-                best_class_indices = np.argmax(predictions, axis=1)\n-                best_class_probabilities = predictions[np.arange(len(best_class_indices)), best_class_indices]\n-\n-                if best_class_probabilities >= 0.8:\n-                    best_name = self.class_names[best_class_indices[0]]\n-                    # Hi\xe1\xbb\x83n th\xe1\xbb\x8b k\xe1\xba\xbft qu\xe1\xba\xa3 nh\xe1\xba\xadn di\xe1\xbb\x87n tr\xc3\xaan video\n-                    self.show_detection_result(image, bb, best_name)\n-\n-        else:\n-            # Hi\xe1\xbb\x83n th\xe1\xbb\x8b "Kh\xc3\xb4ng c\xc3\xb3 khu\xc3\xb4n m\xe1\xba\xb7t \xc4\x91\xc6\xb0\xe1\xbb\xa3c ph\xc3\xa1t hi\xe1\xbb\x87n" n\xe1\xba\xbfu kh\xc3\xb4ng c\xc3\xb3 khu\xc3\xb4n m\xe1\xba\xb7t n\xc3\xa0o trong khung h\xc3\xacnh\n-            cv2.putText(image, "Khong co khuon mat duoc phat hien", (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n-\n-    def show_detection_result(self, image, bb, name):\n-        # Hi\xe1\xbb\x83n th\xe1\xbb\x8b khu\xc3\xb4n m\xe1\xba\xb7t v\xc3\xa0 t\xc3\xaan c\xe1\xbb\xa7a ng\xc6\xb0\xe1\xbb\x9di \xc4\x91\xc6\xb0\xe1\xbb\xa3c nh\xe1\xba\xadn di\xe1\xbb\x87n\n-        cv2.rectangle(image, (bb[0], bb[1]), (bb[2], bb[3]), (0, 255, 0), 2)\n-        cv2.putText(image, name, (bb[0], bb[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n-\n-def main():\n-    face_recognition = FaceRecognitionCamera()\n-    face_recognition.detect_faces_camera()\n-\n-if __name__ == "__main__":\n-    main()\ndiff --git a/BackEnd/app/FaceRecognitionCamera.py b/BackEnd/app/FaceRecognitionCamera.py\nindex 59b0d02..ebc805d 100644\n--- a/BackEnd/app/FaceRecognitionCamera.py\n+++ b/BackEnd/app/FaceRecognitionCamera.py\n@@ -8,8 +8,8 @@ import pickle\n class FaceRecognitionCamera:\n     def __init__(self):\n         # Load paths to classifier and FaceNet model\n-        self.CLASSIFIER_PATH = r\'D:\\AI_PROJECT\\ProJect_DiemDanh\\BackEnd\\Face_AI\\Models\\facemodel.pkl\' \n-        self.FACENET_MODEL_PATH = r\'D:\\AI_PROJECT\\ProJect_DiemDanh\\BackEnd\\Face_AI\\Models\\20180402-114759.pb\'\n+        self.CLASSIFIER_PATH = r\'D:\\AI_PROJECT\\ProJect_DiemDanh\\BackEnd\\app\\Models\\facemodel1.pkl\' \n+        self.FACENET_MODEL_PATH = r\'D:\\AI_PROJECT\\ProJect_DiemDanh\\BackEnd\\app\\Models\\20180402-114759.pb\'\n \n         # Load classifier model\n         with open(self.CLASSIFIER_PATH, \'rb\') as file:\ndiff --git a/BackEnd/app/__pycache__/FaceRecognitionCamera.cpython-39.pyc b/BackEnd/app/__pycache__/FaceRecognitionCamera.cpython-39.pyc\nindex 13aac0b..58d2901 100644\nBinary files a/BackEnd/app/__pycache__/FaceRecognitionCamera.cpython-39.pyc and b/BackEnd/app/__pycache__/FaceRecognitionCamera.cpython-39.pyc differ\ndiff --git a/BackEnd/app/app.py b/BackEnd/app/app.py\nindex 165049d..ef1c588 100644\n--- a/BackEnd/app/app.py\n+++ b/BackEnd/app/app.py\n@@ -10,6 +10,8 @@ from fastapi.middleware.cors import CORSMiddleware\n from fastapi import File, UploadFile\n from pydantic import BaseModel\n import cv2\n+import os\n+import subprocess\n from FaceRecognitionCamera import FaceRecognitionCamera\n import base64\n SECRET_KEY = "duycao12"\n@@ -106,7 +108,8 @@ async def get_user_info(username: str):\n             user_info["Date"] = row[6]\n             user_info["img"] = row[7]\n             user_info["ClassTeacher"] = row[8]\n-            user_info["StudentClass"] = row[9]\n+            user_info["StudentClass"] = row[9],\n+            user_info["Khoa"]=row[10]\n         elif user_type == "Giaovien":\n             user_info["ID"] = row[1]\n             user_info["UserName"] = row[2]\n@@ -116,9 +119,8 @@ async def get_user_info(username: str):\n             user_info["Date"] = row[6]\n             user_info["img"] = row[7]\n             user_info["ClassTeacher"] = row[8]\n-            user_info["StudentClass"] = row[9]\n-       \n-    \n+            user_info["StudentClass"] = row[9],\n+            user_info["Khoa"]=row[10]\n     return user_info\n \n     user = call_get_user_information_procedure(username)\n@@ -267,7 +269,64 @@ async def get_monhoc():\n     except Exception as e:\n         # N\xe1\xba\xbfu c\xc3\xb3 l\xe1\xbb\x97i, tr\xe1\xba\xa3 v\xe1\xbb\x81 l\xe1\xbb\x97i 500 v\xc3\xa0 th\xc3\xb4ng b\xc3\xa1o l\xe1\xbb\x97i\n         raise HTTPException(status_code=500, detail=str(e))\n-    \n+@app.get("/api/khoa")\n+async def get_khoa():\n+    try:\n+        # K\xe1\xba\xbft n\xe1\xbb\x91i t\xe1\xbb\x9bi c\xc6\xa1 s\xe1\xbb\x9f d\xe1\xbb\xaf li\xe1\xbb\x87u\n+        connection = connect_to_database()\n+        cursor = connection.cursor()\n+        \n+        # Th\xe1\xbb\xb1c hi\xe1\xbb\x87n stored procedure "HocKy"\n+        cursor.execute("exec Khoa")\n+        \n+        # L\xe1\xba\xa5y k\xe1\xba\xbft qu\xe1\xba\xa3 t\xe1\xbb\xab stored procedure\n+        rows = cursor.fetchall()\n+        listHK=[]\n+        for row in rows:\n+                listhk = {\n+                       "Khoa" : row[0],\n+                       "LopSv": row[1]\n+                }\n+                listHK.append(listhk)\n+        # \xc4\x90\xc3\xb3ng k\xe1\xba\xbft n\xe1\xbb\x91i\n+        connection.close()\n+\n+        # Tr\xe1\xba\xa3 v\xe1\xbb\x81 danh s\xc3\xa1ch k\xe1\xba\xbft qu\xe1\xba\xa3 d\xc6\xb0\xe1\xbb\x9bi d\xe1\xba\xa1ng JSON\n+        return listHK\n+    except Exception as e:\n+        # N\xe1\xba\xbfu c\xc3\xb3 l\xe1\xbb\x97i, tr\xe1\xba\xa3 v\xe1\xbb\x81 l\xe1\xbb\x97i 500 v\xc3\xa0 th\xc3\xb4ng b\xc3\xa1o l\xe1\xbb\x97i\n+        raise HTTPException(status_code=500, detail=str(e))\n+@app.get("/showStudent")\n+async def get_showStudent(LopSv:str):\n+    try:\n+\n+        connection = connect_to_database()\n+        cursor = connection.cursor()\n+        \n+        # Th\xe1\xbb\xb1c hi\xe1\xbb\x87n stored procedure "HocKy"\n+        cursor.execute("exec showStudent @LopSv = ?",LopSv)\n+        \n+        # L\xe1\xba\xa5y k\xe1\xba\xbft qu\xe1\xba\xa3 t\xe1\xbb\xab stored procedure\n+        rows = cursor.fetchall()\n+        listHK=[]\n+        for row in rows:\n+                listhk = {\n+                       "MaSV" : row[0],\n+                       "name": row[1],\n+                       "date":row[2],\n+                       "gioitinh":row[3],\n+                       "email":row[7],\n+                       "password":row[10]\n+                }\n+                listHK.append(listhk)\n+        # \xc4\x90\xc3\xb3ng k\xe1\xba\xbft n\xe1\xbb\x91i\n+        connection.close()\n+\n+        # Tr\xe1\xba\xa3 v\xe1\xbb\x81 danh s\xc3\xa1ch k\xe1\xba\xbft qu\xe1\xba\xa3 d\xc6\xb0\xe1\xbb\x9bi d\xe1\xba\xa1ng JSON\n+        return listHK\n+    except Exception as e:\n+        # N\xe1\xba\xbfu c\xc3\xb3 l\xe1\xbb\x97i, tr\xe1\xba\xa3 v\xe1\xbb\x81 l\xe1\xbb\x97i 500 v\xc3\xa0 th\xc3\xb4ng b\xc3\xa1o l\xe1\xbb\x97i\n+        raise HTTPException(status_code=500, detail=str(e))\n @app.get("/getList/")\n async def get_ListTkb(MaGV : str,HocKy: str,Nam: str ):\n     try:\n@@ -364,6 +423,85 @@ async def updateInfo(request:Request,MaSV:str,MaLop:str,Starttime : str,EndTime:\n     else:\n         return {"Message": "C\xc3\xb3 l\xe1\xbb\x97i x\xe1\xba\xa3y ra"}\n     \n+@app.post("/api/insertlogin")\n+async def insertLogin(request: Request,username:str,password:str,Chucvu:str):\n+    print(username,password,Chucvu)\n+    try:\n+        connection = connect_to_database()\n+        cursor = connection.cursor()\n+        cursor.execute("EXEC IntoLogin @username=?, @password=?, @Chucvu=?, @Action=?;", \n+                       (username, password, Chucvu, \'INSERT\'))\n+        connection.commit()\n+        return {"message": "Th\xc3\xaam t\xc3\xa0i kho\xe1\xba\xa3n th\xc3\xa0nh c\xc3\xb4ng"}\n+    except Exception as e:\n+        # N\xe1\xba\xbfu c\xc3\xb3 l\xe1\xbb\x97i, in ra l\xe1\xbb\x97i \xc4\x91\xe1\xbb\x83 ki\xe1\xbb\x83m tra v\xc3\xa0 tr\xe1\xba\xa3 v\xe1\xbb\x81 HTTPException\n+        print(f"L\xe1\xbb\x97i khi th\xe1\xbb\xb1c thi c\xc3\xa2u l\xe1\xbb\x87nh SQL: {str(e)}")\n+        raise HTTPException(status_code=500, detail=str(e))\n+    finally:\n+        connection.close()\n+   \n+@app.delete("/deleteLogin")\n+async def deleteLogin(username:str):\n+    connection = connect_to_database()\n+    cursor = connection.cursor()\n+    cursor.execute("EXEC IntoLogin @username=?, @password=?,@Chucvu = ?,  @Action = ?; ",username,None,None,\'DELETE\')\n+    connection.commit()\n+    return{"ban da xoa thanh cong"}\n+\n+@app.put("/updateLogin")\n+async def updateLogin(username:str,password:str,Chucvu:str):\n+    connection = connect_to_database()\n+    cursor = connection.cursor()\n+    cursor.execute("EXEC IntoLogin @username=?, @password=?,@Chucvu = ?,  @Action = ?; ",username,password,Chucvu,\'UPDATE\')\n+    connection.commit()\n+    return{"ban da sua thanh cong"}\n+class ImageCaptureRequest(BaseModel):\n+    student_id: str\n+    image_data: str\n+def save_image(image_data: str, student_id: str):\n+    student_folder = os.path.join( r\'D:\\AI_PROJECT\\ProJect_DiemDanh\\BackEnd\\app\\Dataset\\raw\', student_id)  # \xc4\x90\xc6\xb0\xe1\xbb\x9dng d\xe1\xba\xabn th\xc6\xb0 m\xe1\xbb\xa5c sinh vi\xc3\xaan\n+    if not os.path.exists(student_folder):\n+        os.makedirs(student_folder)\n+\n+    image_path = os.path.join(student_folder, datetime.now().strftime(\'%Y%m%d_%H%M%S%f\') + \'.jpg\')\n+    with open(image_path, "wb") as fh:\n+        fh.write(base64.b64decode(image_data.split(",")[1]))\n+\n+    return image_path\n+\n+\n+\n+@app.post("/api/capture-image/")\n+async def capture_image(request: ImageCaptureRequest):\n+    student_id = request.student_id\n+    image_data_base64 = request.image_data\n+\n+    # Decode base64 image data\n+    try:\n+        image_path = save_image(image_data_base64, student_id)\n+        message = f"Saved image successfully at {image_path}"\n+        return {"message": message}\n+    except Exception as e:\n+        raise HTTPException(status_code=500, detail=f"Failed to save image: {str(e)}")\n+def run_command(command):\n+    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n+    stdout, stderr = process.communicate()\n+    return stdout, stderr   \n+@app.post("/api/align-dataset")\n+async def align_dataset():\n+    try:\n+        align_command = "python BackEnd/app/align_dataset_mtcnn.py BackEnd/app/Dataset/raw BackEnd/app/Dataset/processed --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25"\n+        model_command = "python BackEnd/app/classifier.py TRAIN BackEnd/app/Dataset/processed BackEnd/app/Models/20180402-114759.pb BackEnd/app/Models/facemodel1.pkl --batch_size 1000"\n+\n+        align_output, align_error = run_command(align_command)\n+        model_output, model_error = run_command(model_command)\n+        if align_error:\n+            raise Exception(f"Error in align dataset: {align_error.decode(\'utf-8\')}")\n+\n+        return {"message": "Dataset aligned successfully"}\n+    except Exception as e:\n+        raise HTTPException(status_code=500, detail=f"Failed to align dataset: {str(e)}")\n+\n if __name__ == "__main__":\n     import uvicorn\n     uvicorn.run(app, host="127.0.0.1", port=8000)\n\\ No newline at end of file\ndiff --git a/demo/src/Page/Home/index.js b/demo/src/Page/Home/index.js\nindex 71bb613..87ffe1e 100644\n--- a/demo/src/Page/Home/index.js\n+++ b/demo/src/Page/Home/index.js\n@@ -4,7 +4,6 @@ import getUserSchedule from \'../../common/Api/ApiTkb\'; // Import h\xc3\xa0m API\n import \'./style.css\'\n import { format } from \'date-fns\';\n import { Link } from \'react-router-dom\';\n-\n const Home = () => {\n   const [userInfo, setUserInfo] = useState(null);\n   const Role = localStorage.getItem(\'chuc vu\');\n@@ -118,6 +117,7 @@ const Home = () => {\n           <div  className="user-info">\n           <p><label>H\xe1\xbb\x8d v\xc3\xa0 t\xc3\xaan: </label>{userInfo.UserName}</p>\n           <p><label>M\xc3\xa3 s\xe1\xbb\x91 sinh vi\xc3\xaan: </label>{userInfo.ID}</p>\n+          <p><label>Khoa: </label>{userInfo.Khoa}</p>\n           <p><label>Email: </label>{userInfo.Email}</p>\n           <p><label>Gi\xe1\xbb\x9bi t\xc3\xadnh: </label>{userInfo.Role}</p>\n           <p><label>L\xe1\xbb\x9bp sinh vi\xc3\xaan: </label>{userInfo.Class}</p>\n@@ -141,11 +141,7 @@ const Home = () => {\n          \n         </div>\n       )}\n-      {Role === \'admin\' && (\n-        <div className=\'HomePage\'>\n-          <h1>Th\xc3\xb4ng tin admin</h1>           \n-        </div>\n-      )}\n+    \n     </div>\n   );\n };\ndiff --git a/demo/src/Page/Tkb/index.js b/demo/src/Page/Tkb/index.js\nindex 4271b66..450c75c 100644\n--- a/demo/src/Page/Tkb/index.js\n+++ b/demo/src/Page/Tkb/index.js\n@@ -6,7 +6,7 @@ import interactionPlugin from \'@fullcalendar/interaction\';\n import viLocale from \'@fullcalendar/core/locales/vi\';\n import getUserInfo from \'../../common/Api/ApiTkb\';\n import { format } from \'date-fns\';\n-import { Modal,Button } from \'antd\';\n+import { Modal,Button,Spin } from \'antd\';\n import EventDetailForm from \'../../common/component/FormAntDesign\'\n import \'./style.css\';\n import { useNavigate} from \'react-router-dom\';\n@@ -115,7 +115,7 @@ const TKB = () => {\n   return (\n     <div>\n       {loading ? (\n-        <div>Loading...</div>\n+          <Spin />\n       ) : (\n         <FullCalendar\n           plugins={[dayGridPlugin, timeGridPlugin, interactionPlugin]}\ndiff --git a/demo/src/Router/AppRouter.js b/demo/src/Router/AppRouter.js\nindex 93adee7..0e5c17c 100644\n--- a/demo/src/Router/AppRouter.js\n+++ b/demo/src/Router/AppRouter.js\n@@ -11,6 +11,8 @@ import Class from "../Page/Class"\n import Test from "../Page/Test";\n import Diemdanh from "../Page/DiemDanh";\n import DefaultPage from "../Page/Default-page"\n+import CreateAcc from "../Page/CreateAcc"\n+import TrainFace from "../Page/TrainFace";\n const router = createBrowserRouter([\n   {\n     path: "/login",\n@@ -40,9 +42,16 @@ const router = createBrowserRouter([\n           path:"/default-page",\n           element:<DefaultPage></DefaultPage>\n       },\n+      {\n+          path:"/createAcc",\n+          element:<CreateAcc></CreateAcc>\n+      },\n       {\n         path : "/test",\n         element:<Test></Test>\n+      },{\n+        path:"/trainFace",\n+        element:<TrainFace/>\n       }\n     ]\n   },\ndiff --git a/demo/src/layout/Rootlayout.js b/demo/src/layout/Rootlayout.js\nindex f082620..1eb7650 100644\n--- a/demo/src/layout/Rootlayout.js\n+++ b/demo/src/layout/Rootlayout.js\n@@ -4,6 +4,7 @@ import { FaRegUserCircle } from "react-icons/fa";\n import { FaAddressBook } from "react-icons/fa";\n import {  Card, Button,Tooltip  } from \'antd\';\n import { IoMdLogOut } from "react-icons/io";\n+import { FaCentSign } from "react-icons/fa6";\n import {\n   DesktopOutlined,\n   UserOutlined,\n@@ -63,7 +64,8 @@ const RootLayout = () => {\n     case \'admin\':\n       items = [\n         getItem(\'Trang ch\xe1\xbb\xa7\', \'1\', <PieChartOutlined />, \'/\'),\n-        getItem(\'T\xe1\xba\xa1o t\xc3\xa0i kho\xe1\xba\xa3n\', \'2\', <UserAddOutlined />, \'/create-account\'),\n+        getItem(\'T\xe1\xba\xa1o t\xc3\xa0i kho\xe1\xba\xa3n\', \'2\', <UserAddOutlined />, \'/createAcc\'),\n+        getItem(\'Train m\xc3\xb4 h\xc3\xacnh\', \'3\', <FaCentSign />, \'/trainFace\'),\n       ];\n       break;\n     case \'Sinh vien\':'